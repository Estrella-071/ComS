const t={en:`
# Preface

Computers play a large part in our everyday lives and will continue to do so in the future. Computer science is a young discipline that is evolving and progressing. Computer networks have connected people from far-flung points of the globe. Virtual reality is creating three-dimensional images that amaze the eyes. Space exploration owes part of its success to computers. Computer-generated special effects have changed the movie industry. Computers have played important roles in genetics.

## Audience
This book is written for both academic and professional audience. The book can be used as a self-study guide for interested professionals. As a textbook, it can be used for a one-semester or one-quarter course. It is designed as the first course in computer science. This book is designed for a CS0 course based on the recommendations of the Association of Computing Machinery (ACM). It covers all areas of computer science in breadth. The book, totally or partially, can also be used in other disciplines where the students need to have a bird’s-eye view approach to the computer science.

## Changes in the fourth edition
I have made several categories of changes in this edition.

### Revised chapters and appendices
Minor changes have been made to almost all the chapters. Two new chapters have been added (Chapters 19 and 20). Some materials have been removed from Chapter 4, expanded and inserted as two new appendices (Appendices I and J).

### Organization
The book is made of 20 chapters and 10 appendices.

## Chapters
Chapters are intended to provide the basic materials. However, not all chapters are needed for every audience. The professor who teaches the course can decide which chapters to use. We give guidance below.

## Appendices
The appendices are intended to provide a quick reference or review of materials needed to understand the concepts discussed in the book. There are ten appendices that can be used by the students for reference and study.

## Acronyms
The book contains a list of acronyms for finding the corresponding terms quickly.

## Glossary
The book contains an extensive glossary giving full explanations of the terms used in the book.

## Pedagogy
Several pedagogical features of this text are designed to make it particularly easy for students to understand the materials.

### Visual approach
The book presents highly technical subject matter without complex formulas by using a balance of text and figures. More than 400 figures accompanying the text provide a visual and intuitive opportunity for understanding the material. Figures are particularly important in explaining the relationship between components of a whole. For many students, these concepts are more easily grasped visually than verbally.

### Highlighted points
I have repeated important concepts in boxes for quick reference and immediate attention.

### Examples and applications
Whenever appropriate, I have included examples that illustrate the concepts introduced in the text.

### Algorithms
The inclusion of algorithms in the text helps students with problem solving and programming.

## Unified Modeling Language (UML)
Throughout the book I have used UML diagrams to make students familiar with this tool, which is becoming the de facto standard in the industry.

## End-of-chapter materials
Each chapter ends with a set of materials that includes the following:

### Recommended reading
This section gives a brief list of references relative to the chapter. The references can be used to quickly find the corresponding literature.

### Key terms
The new terms used in each chapter are listed at the end of the chapter and their definitions are included in the glossary.

### Summary
Each chapter ends with a summary of the material covered by that chapter. The summary consolidates the important learning points in one place for ease of access by students.

### Practice set
Each chapter includes a practice set designed to reinforce salient concepts and encourage students to apply them. It consists of three parts: quizzes, questions, and problems.

*   **Quizzes**: Quizzes, which are posted on the book website, provide quick concept checking. Students can take these quizzes to check their understanding of the materials. The feedback to the students’ responses is given immediately.
*   **Questions**: This section contains simple questions about the concepts discussed in the book. Answers to the odd-numbered questions are posted on the book website to be checked by the student.
*   **Problems**: This section contains more difficult problems that need a deeper understanding of the materials discussed in the chapter. I strongly recommend that the student trys to solve all of these problems. Answers to the odd-numbered problems are also posted on the book website to be checked by the student.

## How to use the book
The chapters in the book are organized to provide a great deal of flexibility. I suggest the following:
*   Materials provided in Chapters 1 to 8 are essential to understand the rest of the book.
*   Materials provided in Chapters 9 to 14 can be taught if the time allows. They can be skipped in a quarter system.
*   Chapters 15 to 20 can be taught at the discretion of the professor and the majors of students.

## Acknowledgments
It is obvious that the development of a book of this scope needs the support of many people.

### Peer reviewers
I would like to acknowledge the contributions from peer reviewers to the development of the book. These reviewers are:

*   Sam Ssemugabi, UNISA
*   Ronald Chikati, Botswana Accountancy College
*   Alex Dandadzi, University of Limpopo
*   Tom Verhoeff, Eindhoven University of Technology
*   Stefan Gruner, University of Pretoria
*   Harin Sellahwea, University of Buckingham
*   John Newman, University of Wales
*   Steve Maybank, Birbeck College
*   Mario Kolberg, University of Stirling
*   Colin Price, University of Worcester
*   Boris Cogan, London Metropolitan University
*   Thomas Mandl, University of Hildesheim
*   Daphne Becker, University of South Africa
*   Lubna Fekry Abdulhai and Osama Abulnaja, King Abdulaziz University
*   Katie Atkinson, University of Liverpool

## Publisher staff
Special thanks go to the staff of the publisher.

*   Andrew Ashwin
*   Annabel Ainscow
*   Jennifer Grene
*   Phillipa Davidson-Blake

Behrouz A. Forouzan
Los Angeles, CA.
January 2018
`,zh:`
# 前言

電腦在我們的日常生活中扮演著重要的角色，並且在未來將繼續如此。電腦科學是一門年輕且不斷發展進步的學科。電腦網路連接了全球各地的人們。虛擬實境創造出令人驚嘆的三維影像。太空探索的成功部分歸功於電腦。電腦生成的特效改變了電影工業。電腦在遺傳學中也扮演了重要的角色。

## 目標讀者
本書專為學術及專業讀者撰寫。有興趣的專業人士可將本書作為自學指南。作為教科書，它可用於一學期或一季的課程，設計為電腦科學的第一門課。本書根據計算機協會（ACM）的建議設計為 CS0 課程，廣泛涵蓋電腦科學的所有領域。本書的全部或部分內容也可用於其他學科，讓學生對電腦科學有一個鳥瞰式的了解。

## 第四版的變更
我在這個版本中做了幾類變更。

### 修訂的章節與附錄
幾乎所有章節都做了微幅修改。新增了兩個新章節（第 19 章和第 20 章）。第 4 章的部分內容被移除、擴充並作為兩個新附錄（附錄 I 和 J）插入。

### 組織架構
本書由 20 個章節和 10 個附錄組成。

## 章節
章節旨在提供基礎材料。然而，並非所有章節都適用於每位讀者。授課教授可以決定使用哪些章節。我們在下方提供指引。

## 附錄
附錄旨在提供快速參考或複習理解書中概念所需的材料。書中有十個附錄可供學生參考和學習。

## 縮寫詞
本書包含一個縮寫詞列表，以便快速查找對應的術語。

## 詞彙表
本書包含一個詳盡的詞彙表，對書中使用的術語提供完整解釋。

## 教學法
本書的幾個教學特色旨在讓學生特別容易理解材料。

### 視覺化方法
本書透過平衡的文字和圖表來呈現高度技術性的主題，而無需複雜的公式。超過 400 幅圖伴隨文本，為理解材料提供了視覺化和直觀的機會。圖表在解釋整體各組成部分之間的關係時尤其重要。對許多學生來說，這些概念透過視覺比透過文字更容易掌握。

### 重點提示
我將重要的概念重複放在方框中，以便快速參考和立即注意。

### 範例與應用
在適當的時候，我加入了範例來說明文本中介紹的概念。

### 演算法
在文本中包含演算法有助於學生解決問題和編程。

## 統一塑模語言 (UML)
在整本書中，我使用 UML 圖表讓學生熟悉這個工具，它正成為業界的實質標準。

## 章末材料
每章結尾都有一套材料，包括以下內容：

### 推薦閱讀
本節提供與該章相關的簡短參考資料列表。這些參考資料可用於快速查找相關文獻。

### 關鍵詞
每章使用的新術語列於章末，其定義包含在詞彙表中。

### 摘要
每章結尾都有該章內容的摘要。摘要將重要的學習點彙整在一處，方便學生查閱。

### 練習題
每章都包含一組練習題，旨在鞏固重要概念並鼓勵學生應用。它由三部分組成：測驗、問題和習題。

*   **測驗**：發佈在書籍網站上的測驗，提供快速的概念檢查。學生可以參加這些測驗來檢查他們對材料的理解。學生的回答會立即得到反饋。
*   **問題**：本節包含關於書中討論概念的簡單問題。奇數題的答案發佈在書籍網站上，供學生核對。
*   **習題**：本節包含較難的問題，需要對章節中討論的材料有更深入的理解。我強烈建議學生嘗試解決所有這些問題。奇數題的答案也發佈在書籍網站上，供學生核對。

## 如何使用本書
本書的章節組織提供了很大的靈活性。我建議如下：
*   第 1 至 8 章提供的材料是理解本書其餘部分的基礎。
*   如果時間允許，可以教授第 9 至 14 章的材料。在季制（quarter system）中可以跳過。
*   第 15 至 20 章可由教授根據學生主修酌情教授。

## 致謝
顯然，開發一本如此規模的書需要許多人的支持。

### 同行評審
我想感謝同行評審對本書開發的貢獻。這些評審員是：

*   Sam Ssemugabi, UNISA
*   Ronald Chikati, Botswana Accountancy College
*   Alex Dandadzi, University of Limpopo
*   Tom Verhoeff, Eindhoven University of Technology
*   Stefan Gruner, University of Pretoria
*   Harin Sellahwea, University of Buckingham
*   John Newman, University of Wales
*   Steve Maybank, Birbeck College
*   Mario Kolberg, University of Stirling
*   Colin Price, University of Worcester
*   Boris Cogan, London Metropolitan University
*   Thomas Mandl, University of Hildesheim
*   Daphne Becker, University of South Africa
*   Lubna Fekry Abdulhai and Osama Abulnaja, King Abdulaziz University
*   Katie Atkinson, University of Liverpool

## 出版社工作人員
特別感謝出版社的工作人員。

*   Andrew Ashwin
*   Annabel Ainscow
*   Jennifer Grene
*   Phillipa Davidson-Blake

Behrouz A. Forouzan
Los Angeles, CA.
2018 年 1 月
`},a={en:`
# Chapter 1: Introduction

The phrase computer science has a very broad meaning today. However, in this book, we define the phrase as ‘issues related to the computer’. This introductory chapter first tries to find out what a computer is, then investigates other issues directly related to computers. We look first at the Turing model as a mathematical and philosophical definition of computation. We then show how today’s computers are based on the von Neumann model. The chapter ends with a brief history of this culture-changing device . . . the computer.

## Objectives
After studying this chapter, the student should be able to:
- Define the Turing model of a computer.
- Define the von Neumann model of a computer.
- Describe the three components of a computer: hardware, data, and software.
- List topics related to computer hardware.
- List topics related to data.
- List topics related to software.
- Give a short history of computers.

## 1.1 TURING MODEL
The idea of a universal computational device was first described by Alan Turing in 1936. He proposed that all computation could be performed by a special kind of a machine, now called a **Turing machine**. Although Turing presented a mathematical description of such a machine, he was more interested in the philosophical definition of computation than in building the actual machine. He based the model on the actions that people perform when involved in computation. He abstracted these actions into a model for a computational machine that has really changed the world.

### 1.1.1 Data processors
Before discussing the Turing model, let us define a computer as a **data processor**. Using this definition, a computer acts as a black box that accepts input data, processes the data, and creates output data (Figure 1.1). Although this model can define the functionality of a computer today, it is too general. In this model, a pocket calculator is also a computer (which it is, in a literal sense).

**Figure 1.1 A single-purpose computing machine**
Input data -> Computer -> Output data

Another problem with this model is that it does not specify the type of processing, or whether more than one type of processing is possible. In other words, it is not clear how many types or sets of operations a machine based on this model can perform. Is it a specific-purpose machine or a general-purpose machine?

This model could represent a specific-purpose computer (or processor) that is designed to do a single job, such as controlling the temperature of a building or controlling the fuel usage in a car. However, computers, as the term is used today, are *general-purpose* machines. They can do many different types of tasks. This implies that we need to change this model into the Turing model to be able to reflect the actual computers of today.

### 1.1.2 Programmable data processors
The Turing model is a better model for a general-purpose computer. This model adds an extra element to the specific computing machine: the *program*. A **program** is a set of instructions that tells the computer what to do with data. Figure 1.2 shows the Turing model.

**Figure 1.2 A computer based on the Turing model: programmable data processor**
Input data + Program -> Computer -> Output data

In the Turing model, the **output data** depends on the combination of two factors: the **input data** and the program. With the same input data, we can generate different output if we change the program. Similarly, with the same program, we can generate different outputs if we change the input data. Finally, if the input data and the program remain the same, the output should be the same. Let us look at three cases.

**Same program, different input data**
Figure 1.3 shows the same sorting program with different input data. Although the program is the same, the outputs are different, because different input data is processed.

*   **Case 1**: Input (3, 12, 8, 22) -> Program: Sort -> Output (3, 8, 12, 22)
*   **Case 2**: Input (14, 6, 8, 12) -> Program: Sort -> Output (6, 8, 12, 14)

**Same input data, different programs**
Figure 1.4 shows the same input data with different programs. Each program makes the computer perform different operations on the input data. The first program sorts the data, the second adds the data, and the third finds the smallest number.

*   **Case 1**: Input (3, 12, 8, 22) -> Program: Sort -> Output (3, 8, 12, 22)
*   **Case 2**: Input (3, 12, 8, 22) -> Program: Add -> Output (45)
*   **Case 3**: Input (3, 12, 8, 22) -> Program: Find smallest -> Output (3)

**Same input data, same program**
We expect the same result each time if both input data and the program are the same, of course. In other words, when the same program is run with the same input data, we expect the same output.

### 1.1.3 The universal Turing machine
A *universal Turing machine*, a machine that can do any computation if the appropriate program is provided, was the first description of a modern computer. It can be proved that a very powerful computer and a universal Turing machine can compute the same thing. We need only provide the data and the program—the description of how to do the computation—to either machine. In fact, a universal Turing machine is capable of computing anything that is computable.

## 1.2 VON NEUMANN MODEL
Computers built on the Turing universal machine store data in their memory. Around 1944–1945, John von Neumann proposed that, since program and data are logically the same, programs should also be stored in the memory of a computer.

### 1.2.1 Four subsystems
Computers built on the von Neumann model divide the computer hardware into four subsystems: memory, arithmetic logic unit, control unit, and input/output (Figure 1.5).

**Memory**
Memory is the storage area. This is where programs and data are stored during processing. We discuss the reasons for storing programs and data later in the chapter.

**Arithmetic logic unit**
The **arithmetic logic unit (ALU)** is where calculation and **logical operations** take place. For a computer to act as a data processor, it must be able to do arithmetic operations on data (such as adding a list of numbers). It should also be able to do logical operations on data, as we will see in Chapter 4.

**Control unit**
The **control unit** controls the operations of the **memory**, ALU, and the input/output subsystem.

**Input / output**
The **input subsystem** accepts input data and the program from outside the computer, while the **output subsystem** sends the result of processing to the outside world. The definition of the input/output subsystem is very broad: it also includes secondary storage devices such as disk or tape that stores data and programs for processing. When a disk stores data that results from processing, it is considered an output device: when it reads data from the disk, it is considered an input device.

### 1.2.2 The stored program concept
The von Neumann model states that the program must be stored in memory. This is totally different from the architecture of early computers in which only the data was stored in memory: the programs for their task were implemented by manipulating a set of switches or by changing the wiring system.

The memory of modern computers hosts both a program and its corresponding data. This implies that both the data and programs should have the same format, because they are stored in memory. In fact, they are stored as *binary* patterns in memory—a sequence of 0s and 1s.

### 1.2.3 Sequential execution of instructions
A program in the von Neumann model is made of a finite number of **instructions**. In this model, the control unit fetches one instruction from memory, decodes it, then executes it. In other words, the instructions are executed one after another. Of course, one instruction may request the control unit to jump to some previous or following instruction, but this does not mean that the instructions are not executed sequentially. Sequential execution of a program was the initial requirement of a computer based on the von Neumann model. Today’s computers execute programs in the order that is the most efficient.

## 1.3 COMPUTER COMPONENTS
We can think of a computer as being made up of three components: computer hardware, data, and computer software.

### 1.3.1 Computer hardware
Computer hardware today has four components under the von Neumann model, although we can have different types of memory, different types of input/output subsystems, and so on. We discuss computer hardware in more detail in Chapter 5.

### 1.3.2 Data
The von Neumann model clearly defines a computer as a data processing machine that accepts the input data, processes it, and outputs the result.

**Storing data**
The von Neumann model does not define how data must be stored in a computer. If a computer is an electronic device, the best way to store data is in the form of an electrical signal, specifically its presence or absence. This implies that a computer can store data in one of two states.

Obviously, the data we use in daily life is not just in one of two states. For example, our numbering system uses digits that can take one of ten states (0 to 9). We cannot (as yet) store this type of information in a computer: it needs to be changed to another system that uses only two states (0 and 1). We also need to be able to process other types of data (text, image, audio, video). These also cannot be stored in a computer directly, but need to be changed to the appropriate form (0s and 1s).

In Chapter 3, we will learn how to store different types of data as a binary pattern, a sequence of 0s and 1s. In Chapter 4, we show how data is manipulated, as a binary pattern, inside a computer.

**Organizing data**
Although data should be stored only in one form inside a computer, a binary pattern, data outside a computer can take many forms. In addition, computers (and the notion of data processing) have created a new field of study known as *data organization*, which asks the question: can we organize our data into different entities and formats before storing them inside a computer? Today, data is not treated as a flat sequence of information. Instead, data is organized into small units, small units are organized into larger units, and so on. We will look at data from this point of view in Chapters 11–14.

### 1.3.3 Computer software
The main feature of the Turing or von Neumann models is the concept of the *program*. Although early computers did not store the program in the computer’s memory, they did use the concept of programs. *Programming* those early computers meant changing the wiring systems or turning a set of switches on or off. Programming was therefore a task done by an operator or engineer before the actual data processing began.

**Programs must be stored**
In the von Neumann model programs are stored in the computer’s memory. Not only do we need memory to hold data, but we also need memory to hold the program.

**A sequence of instructions**
Another requirement of the model is that the program must consist of a sequence of instructions. Each instruction operates on one or more data items. Thus, an instruction can change the effect of a previous instruction. For example, Figure 1.7 shows a program that inputs two numbers, adds them, and prints the result. This program consists of four individual instructions.

We might ask why a program must be composed of instructions. The answer is reusability. Today, computers do millions of tasks. If the program for each task was an independent entity without anything in common with other programs, programming would be difficult. The Turing and von Neumann models make programming easier by defining the different instructions that can be used by computers. A programmer can then combine these instructions to make any number of programs. Each program can be a different combination of different instructions.

**Algorithms**
The requirement for a program to consist of a sequence of instructions made programming possible, but it brought another dimension to using a computer. A programmer must not only learn the task performed by each instruction, but also learn how to combine these instructions to do a particular task. Looking at this issue differently, a programmer must first solve the problem in a step-by-step manner, then try to find the appropriate instruction (or series of instructions) to implement those steps. This step-by-step solution is called an **algorithm**. Algorithms play a very important role in computer science and are discussed in Chapter 8.

**Languages**
At the beginning of the computer age there was only one computer language, *machine language*. Programmers wrote instructions (using binary patterns) to solve a problem. However, as programs became larger, writing long programs using these patterns became tedious. Computer scientists came up with the idea of using symbols to represent binary patterns, just as people use symbols (words) for commands in daily life. Of course, the symbols used in daily life are different from those used in computers. So the concept of **computer languages** was born. A natural language such as English is rich and has many rules to combine words correctly: a computer language, on the other hand, has a more limited number of symbols and also a limited number of words. We will study computer languages in Chapter 9.

**Software engineering**
Something that was not defined in the von Neumann model is **software engineering**, which is the design and writing of **structured programs**. Today it is not acceptable just to write a program that does a task: the program must follow strict rules and principles. We discuss these principles, collectively known as *software engineering*, in Chapter 10.

**Operating systems**
During the evolution of computers, scientists became aware that there was a series of instructions common to all programs. For example, instructions to tell a computer where to receive data and where to send data are needed by almost all programs. It is more efficient to write these instructions only once for the use of all programs. Thus the concept of the **operating system** emerged. An operating system originally worked as a manager to facilitate access to the computer’s components by a program, although today operating systems do much more. We will learn about them in Chapter 7.

## 1.4 HISTORY
In this section we briefly review the history of computing and computers. We divide this history into three periods.

### 1.4.1 Mechanical machines (before 1930)
During this period, several computing machines were invented that bear little resemblance to the modern concept of a computer.
*   In the seventeenth century, Blaise Pascal, a French mathematician and philosopher, invented Pascaline, a mechanical calculator for addition and subtraction operations. In the twentieth century, when Niklaus Wirth invented a structured programming language, he called it Pascal to honor the inventor of the first mechanical calculator.
*   In the late seventeenth century, German mathematician Gottfried Leibniz invented a more sophisticated mechanical calculator that could do multiplication and division as well as addition and subtraction. It was called the Leibniz Wheel.
*   The first machine that used the idea of storage and programming was the Jacquard loom, invented by Joseph-Marie Jacquard at the beginning of the nineteenth century. The loom used punched cards (like a stored program) to control the raising of the warp threads in the manufacture of textiles.
*   In 1823, Charles Babbage invented the Difference Engine, which could do more than simple arithmetic operations—it could solve polynomial equations, too. Later, he invented a machine called the Analytical Engine that, to some extent, parallels the idea of modern computers. It had four components: a mill (corresponding to a modern ALU), a store (memory), an operator (control unit), and output (input/output).
*   In 1890, Herman Hollerith, working at the US Census Bureau, designed and built a programmer machine that could automatically read, tally, and sort data stored on punched cards.

### 1.4.2 The birth of electronic computers (1930–1950)
Between 1930 and 1950, several computers were invented by scientists who could be considered the pioneers of the electronic computer industry.

**Early electronic computers**
The early computers of this period did not store the program in memory—all were programmed externally. Five computers were prominent during these years:
*   The first special-purpose computer that encoded information electrically was invented by John V. Atanasoff and his assistant Clifford Berry in 1939. It was called the ABC (Atanasoff Berry Computer) and was specifically designed to solve a system of linear equations.
*   At the same time, a German mathematician called Konrad Zuse designed a general-purpose machine called Z1.
*   In the 1930s, the US Navy and IBM sponsored a project at Harvard University under the direction of Howard Aiken to build a huge computer called Mark I. This computer used both electrical and mechanical components.
*   In England, Alan Turing invented a computer called Colossus that was designed to break the German Enigma code.
*   The first general-purpose, totally electronic computer was made by John Mauchly and J. Presper Eckert and was called ENIAC (Electronic Numerical Integrator and Calculator). It was completed in 1946. It used 18000 vacuum tubes, was 100 feet long by 10 feet high, and weighed 30 tons.

**Computers based on the von Neumann model**
The preceding five computers used memory only for storing data, and were programmed externally using wires or switches. John von Neumann proposed that the program and the data should be stored in memory. That way, every time we use a computer to do a new task, we need only change the program instead of rewiring the machine or turning hundreds of switches on and off.
The first computer based on von Neumann’s ideas was made in 1950 at the University of Pennsylvania and was called EDVAC. At the same time, a similar computer called EDSAC was built by Maurice Wilkes at Cambridge University in England.

### 1.4.3 Computer generations (1950–present)
Computers built after 1950 more or less follow the von Neumann model. They have become faster, smaller, and cheaper, but the principle is almost the same. Historians divide this period into generations, with each generation witnessing some major change in hardware or software (but not in the model).

**First generation**
The first generation (roughly 1950–1959) is characterized by the emergence of commercial computers. During this time, computers were used only by professionals. They were locked in rooms with access limited only to the operator or computer specialist. Computers were bulky and used vacuum tubes as electronic switches. At this time, computers were affordable only by big organizations.

**Second generation**
Second-generation computers (roughly 1959–1965) used transistors instead of vacuum tubes. This reduced the size of computers, as well as their cost, and made them affordable to small and medium-size corporations. Two high-level programming languages, FORTRAN and COBOL (see Chapter 9), were invented and made programming easier. These two languages separated the programming task from the computer operation task. A civil engineer, for example could write a FORTRAN program to solve a problem without being involved in the electronic details of computer architecture.

**Third generation**
The invention of the **integrated circuit** (transistors, wiring, and other components on a single chip) reduced the cost and size of computers even further. *Minicomputers* appeared on the market. Canned programs, popularly known as software packages, became available. A small corporation could buy a package, for example for accounting, instead of writing its own program. A new industry, the software industry, was born. This generation lasted roughly from 1965 to 1975.

**Fourth generation**
The fourth generation (approximately 1975–1985) saw the appearance of **microcomputers**. The first desktop calculator, the Altair 8800, became available in 1975. Advances in the electronics industry allowed whole computer subsystems to fit on a single circuit board. This generation also saw the emergence of computer networks (see Chapter 6).

**Fifth generation**
This open-ended generation started in 1985. It has witnessed the appearance of laptop and palmtop computers, improvements in secondary storage media (CD-ROM, DVD, and so on), the use of multimedia, and the phenomenon of virtual reality.

## 1.5 COMPUTER SCIENCE AS A DISCIPLINE
With the invention of computers, a new discipline has evolved: *computer science*. Like any other discipline, computer science has now divided into several areas. We can divide these areas into two broad categories: *systems areas* and *applications areas*. Systems areas cover those areas that directly related to the creation of hardware and software, such as *computer architecture*, *computer networking*, *security issues*, *operating systems*, *algorithms*, *programming languages*, and *software engineering*. Applications areas cover those that are related to the *use* of computers, such as *databases* and *artificial intelligence*. This book is a breadth-first approach to all of these areas. After reading the book, the reader should have enough information to select the desired area of specialty.

## 1.6 OUTLINE OF THE COURSE
After this introductory chapter, the book is divided into five parts.

### 1.6.1 Part I: Data representation and operation
This part includes Chapters 2, 3, and 4. Chapter 2 discusses number systems, how a quantity can be represented using symbols. Chapter 3 discusses how different data is stored inside the computer. Chapter 4 discusses some primitive operations on *bits*.

### 1.6.2 Part II: Computer hardware
This part includes Chapters 5 and 6. Chapter 5 gives a general idea of computer hardware, discussing different computer organizations. Chapter 6 shows how individual computers are connected to make computer networks, and *internetworks* (internets). In particular, this chapter explores some subjects related to the Internet and its applications.

### 1.6.3 Part III: Computer software
This part includes Chapters 7, 8, 9, and 10. Chapter 7 discusses operating systems, the system software that controls access to the hardware by users—either human or application programs. Chapter 8 shows how problem solving is reduced to writing an algorithm for the problem. Chapter 9 takes a journey through the list of contemporary programming languages. Finally, Chapter 10 is a review of software engineering, the engineering approach to the development of software.

### 1.6.4 Part IV: Data organization and abstraction
This part complements Part I. In computer science, *atomic* data is collected into records, files, and databases. Data *abstraction* allows the programmer to create abstract notions about data. Part IV includes Chapters 11, 12, 13, and 14. Chapter 11 discusses data structure, collecting data of the same or different type under one category. Chapter 12 discusses abstract data types. Chapter 13 shows how different file structures can be used for different purposes. Finally, Chapter 14 discusses databases.

### 1.6.5 Part V: Advanced topics
Part V gives an overview of advanced topics, topics that students of computer science will encounter later in their education. This part covers Chapters 15, 16, 17, and 18. Chapter 15 discusses data compression, which is prevalent in today’s data communications. Chapter 16 explores some issues to do with security, which is becoming more and more important when we communicate over insecure channels. Chapter 17 discusses the theory of computation: what can and cannot be computed. Finally Chapter 18 gives some idea of artificial intelligence, a topic wih day-to-day challenges in computer science.

### 1.6.6 Part VI: Social media and social Issues
Part VI briefly discusses social media and social issues, two topics that students of computer science may be interested to explore.

## 1.7 END-CHAPTER MATERIALS
### 1.7.1 Recommended reading
For more details about the subjects discussed in this chapter, the following books are recommended:
*   Schneider, G. M. and Gersting, J. L. *Invitation to Computer Science*, Boston, MA: Course Technology, 2004
*   Dale, N. and Lewis, J. *Computer Science Illuminated*, Sudbury, MA: Jones and Bartlett, 2004
*   Patt, Y. and Patel, S. *Introduction to Computing Systems*, New York: McGraw-Hill, 2004

### 1.7.2 Key terms
*   algorithm
*   arithmetic logic unit (ALU)
*   computer languages
*   control unit
*   data processor
*   input data
*   input/output subsystem
*   instruction
*   integrated circuit
*   logical operation
*   memory
*   microcomputer
*   operating system
*   output data
*   program
*   structured programs
*   software engineering
*   Turing machine
*   Turing model
*   von Neumann model

### 1.7.3 Summary
*   The idea of a universal computational device was first put forward by Alan Turing in 1936. He proposed that all computations can be performed by a special kind of a machine, now called a Turing machine.
*   The von Neumann model defines a computer as four subsystems: memory, arithmetic logic unit, control unit, and input/output. The von Neumann model states that the program must be stored in memory.
*   We can think of a computer as made up of three components: computer hardware, data, and computer software.
*   The history of computing and computers can be divided into three periods: the period of mechanical machines (before 1930), the period of electronic computers (1930–1950), and the period that includes the five modern computer generations.
*   With the invention of computers a new discipline has evolved, *computer science*, which is now divided into several areas.
`,zh:`
# 第一章：簡介

「電腦科學」這個詞彙現今的含義非常廣泛。然而，在本書中，我們將其定義為「與電腦相關的議題」。本介紹性章節首先試圖找出什麼是電腦，然後探討與電腦直接相關的其他問題。我們首先將圖靈模型視為計算的數學和哲學定義。然後，我們將展示今日的電腦如何基於馮·諾伊曼模型。本章最後簡要介紹了這個改變文化的設備——電腦的歷史。

## 學習目標
學完本章後，學生應能：
- 定義電腦的圖靈模型。
- 定義電腦的馮·諾伊曼模型。
- 描述電腦的三個組成部分：硬體、資料和軟體。
- 列出與電腦硬體相關的主題。
- 列出與資料相關的主題。
- 列出與軟體相關的主題。
- 簡述電腦的歷史。

## 1.1 圖靈模型
通用計算設備的概念最早由艾倫·圖靈於 1936 年提出。他提出所有的計算都可以由一種特殊的機器執行，現在稱為**圖靈機**。雖然圖靈對這種機器進行了數學描述，但他更感興趣的是計算的哲學定義，而非建造實際的機器。他將模型建立在人們進行計算時所執行的動作上。他將這些動作抽象化為一個計算機模型，這個模型確實改變了世界。

### 1.1.1 資料處理器
在討論圖靈模型之前，讓我們先將電腦定義為**資料處理器**。根據這個定義，電腦就像一個黑盒子，接受輸入資料，處理資料，並產生輸出資料（圖 1.1）。雖然這個模型可以定義今日電腦的功能，但它太過籠統。在這個模型中，袖珍計算機也是一台電腦（從字面上看，它確實是）。

**圖 1.1 單一用途的計算機器**
輸入資料 -> 電腦 -> 輸出資料

這個模型還有另一個問題，就是它沒有指定處理的類型，或者是否可以進行多種處理。換句話說，目前還不清楚基於這個模型的機器可以執行多少種類型或集合的操作。它是專用機器還是通用機器？

這個模型可以代表一台專用電腦（或處理器），其設計目的是執行單一工作，例如控制建築物的溫度或控制汽車的燃料使用。然而，就現今使用的術語而言，電腦是*通用*機器。它們可以執行許多不同類型的任務。這意味著我們需要將此模型更改為圖靈模型，以便能夠反映今日實際的電腦。

### 1.1.2 可程式化資料處理器
圖靈模型是通用電腦的一個更好模型。此模型為特定的計算機器增加了一個額外元素：*程式*。**程式**是一組指令，告訴電腦如何處理資料。圖 1.2 顯示了圖靈模型。

**圖 1.2 基於圖靈模型的電腦：可程式化資料處理器**
輸入資料 + 程式 -> 電腦 -> 輸出資料

在圖靈模型中，**輸出資料**取決於兩個因素的組合：**輸入資料**和程式。使用相同的輸入資料，如果我們改變程式，可以產生不同的輸出。同樣地，使用相同的程式，如果我們改變輸入資料，也可以產生不同的輸出。最後，如果輸入資料和程式保持不變，則輸出應該相同。讓我們來看三種情況。

**相同的程式，不同的輸入資料**
圖 1.3 顯示了相同的排序程式使用不同的輸入資料。雖然程式相同，但輸出不同，因為處理的是不同的輸入資料。

*   **情況 1**: 輸入 (3, 12, 8, 22) -> 程式: 排序 -> 輸出 (3, 8, 12, 22)
*   **情況 2**: 輸入 (14, 6, 8, 12) -> 程式: 排序 -> 輸出 (6, 8, 12, 14)

**相同的輸入資料，不同的程式**
圖 1.4 顯示了相同的輸入資料使用不同的程式。每個程式使電腦對輸入資料執行不同的操作。第一個程式對資料進行排序，第二個將資料相加，第三個找出最小的數字。

*   **情況 1**: 輸入 (3, 12, 8, 22) -> 程式: 排序 -> 輸出 (3, 8, 12, 22)
*   **情況 2**: 輸入 (3, 12, 8, 22) -> 程式: 相加 -> 輸出 (45)
*   **情況 3**: 輸入 (3, 12, 8, 22) -> 程式: 找最小值 -> 輸出 (3)

**相同的輸入資料，相同的程式**
當然，如果輸入資料和程式都相同，我們期望每次都能得到相同的結果。換句話說，當使用相同的輸入資料執行相同的程式時，我們期望得到相同的輸出。

### 1.1.3 通用圖靈機
*通用圖靈機*，一種只要提供適當程式就能進行任何計算的機器，是現代電腦的首次描述。可以證明，一台非常強大的電腦和一台通用圖靈機可以計算相同的東西。我們只需要向任一機器提供資料和程式——即如何進行計算的描述。事實上，通用圖靈機能夠計算任何可計算的事物。

## 1.2 馮·諾伊曼模型
基於圖靈通用機建造的電腦將資料儲存在其記憶體中。大約在 1944-1945 年，約翰·馮·諾伊曼提出，由於程式和資料在邏輯上是相同的，程式也應該儲存在電腦的記憶體中。

### 1.2.1 四個子系統
基於馮·諾伊曼模型建造的電腦將電腦硬體分為四個子系統：記憶體、算術邏輯單元、控制單元和輸入/輸出（圖 1.5）。

**記憶體**
記憶體是儲存區域。這是程式和資料在處理過程中儲存的地方。我們將在本章稍後討論儲存程式和資料的原因。

**算術邏輯單元**
**算術邏輯單元 (ALU)** 是進行計算和**邏輯運算**的地方。要使電腦充當資料處理器，它必須能夠對資料執行算術運算（例如將一列數字相加）。它還應該能夠對資料執行邏輯運算，我們將在第 4 章中看到。

**控制單元**
**控制單元**控制**記憶體**、ALU 和輸入/輸出子系統的操作。

**輸入/輸出**
**輸入子系統**從電腦外部接受輸入資料和程式，而**輸出子系統**將處理結果發送到外部世界。輸入/輸出子系統的定義非常廣泛：它還包括輔助儲存設備，如磁碟或磁帶，用於儲存處理用的資料和程式。當磁碟儲存處理產生的資料時，它被視為輸出設備：當它從磁碟讀取資料時，它被視為輸入設備。

### 1.2.2 儲存程式概念
馮·諾伊曼模型指出程式必須儲存在記憶體中。這與早期電腦的架構完全不同，早期電腦只有資料儲存在記憶體中：它們的任務程式是透過操作一組開關或改變佈線系統來實現的。

現代電腦的記憶體同時存放著程式及其對應的資料。這意味著資料和程式都應該有相同的格式，因為它們都儲存在記憶體中。事實上，它們在記憶體中以*二進位*模式儲存——即 0 和 1 的序列。

### 1.2.3 指令的循序執行
在馮·諾伊曼模型中，程式由有限數量的**指令**組成。在這個模型中，控制單元從記憶體中取出一個指令，解碼，然後執行它。換句話說，指令是逐一執行的。當然，一個指令可能會請求控制單元跳轉到某個先前或之後的指令，但這並不意味著指令不是按順序執行的。程式的循序執行是基於馮·諾伊曼模型的電腦的初始要求。今日的電腦以最有效率的順序執行程式。

## 1.3 電腦組件
我們可以將電腦視為由三個組件組成：電腦硬體、資料和電腦軟體。

### 1.3.1 電腦硬體
今日的電腦硬體在馮·諾伊曼模型下有四個組件，儘管我們可以有不同類型的記憶體、不同類型的輸入/輸出子系統等等。我們將在第 5 章更詳細地討論電腦硬體。

### 1.3.2 資料
馮·諾伊曼模型清楚地將電腦定義為一台資料處理機器，它接受輸入資料，處理它，並輸出結果。

**儲存資料**
馮·諾伊曼模型並沒有定義資料必須如何在電腦中儲存。如果電腦是一個電子設備，最好的資料儲存方式是以電信號的形式，具體來說是它的存在或不存在。這意味著電腦可以用兩種狀態之一來儲存資料。

顯然，我們在日常生活中使用的資料不僅僅是兩種狀態。例如，我們的數字系統使用可以採用十種狀態之一（0 到 9）的數字。我們（目前）無法將這類資訊直接儲存在電腦中：它需要轉換為另一個只使用兩種狀態（0 和 1）的系統。我們還需要能夠處理其他類型的資料（文字、圖像、音訊、視訊）。這些也不能直接儲存在電腦中，而需要轉換為適當的形式（0 和 1）。

在第 3 章，我們將學習如何將不同類型的資料儲存為二進位模式，即 0 和 1 的序列。在第 4 章，我們將展示如何在電腦內部操作二進位模式的資料。

**組織資料**
雖然資料在電腦內部應該只以一種形式儲存，即二進位模式，但在電腦外部資料可以有多種形式。此外，電腦（以及資料處理的概念）創造了一個新的研究領域，稱為*資料組織*，它提出的問題是：我們能否在將資料儲存到電腦內部之前，將其組織成不同的實體和格式？如今，資料不再被視為扁平的資訊序列。相反，資料被組織成小單元，小單元被組織成更大的單元，依此類推。我們將在第 11-14 章從這個角度來看資料。

### 1.3.3 電腦軟體
圖靈或馮·諾伊曼模型的主要特點是*程式*的概念。雖然早期電腦沒有將程式儲存在電腦的記憶體中，但它們確實使用了程式的概念。對那些早期電腦進行*編程*意味著改變佈線系統或打開/關閉一組開關。因此，編程是在實際資料處理開始之前由操作員或工程師完成的任務。

**程式必須被儲存**
在馮·諾伊曼模型中，程式儲存在電腦的記憶體中。我們不僅需要記憶體來保存資料，還需要記憶體來保存程式。

**指令序列**
該模型的另一個要求是程式必須由一系列指令組成。每個指令對一個或多個資料項目進行操作。因此，一個指令可以改變前一個指令的效果。例如，圖 1.7 顯示了一個輸入兩個數字、將它們相加並印出結果的程式。這個程式由四個單獨的指令組成。

我們可能會問為什麼程式必須由指令組成。答案是可重用性。如今，電腦執行數百萬項任務。如果每個任務的程式都是一個獨立的實體，與其他程式沒有任何共同之處，那麼編程將會很困難。圖靈和馮·諾伊曼模型透過定義電腦可以使用的不同指令，使編程變得更容易。程式設計師隨後可以組合這些指令來製作任意數量的程式。每個程式都可以是不同指令的不同組合。

**演算法**
程式必須由一系列指令組成的要求使編程成為可能，但它為使用電腦帶來了另一個維度。程式設計師不僅必須學習每個指令執行的任務，還必須學習如何組合這些指令來完成特定任務。換個角度看，程式設計師必須首先以逐步的方式解決問題，然後嘗試找到適當的指令（或指令系列）來實現這些步驟。這種逐步的解決方案稱為**演算法**。演算法在電腦科學中扮演著非常重要的角色，將在第 8 章中討論。

**語言**
在電腦時代的初期，只有一種電腦語言，即*機器語言*。程式設計師編寫指令（使用二進位模式）來解決問題。然而，隨著程式變得越來越大，使用這些模式編寫長程式變得乏味。電腦科學家想出了使用符號來表示二進位模式的想法，就像人們在日常生活中使用符號（單詞）來表示命令一樣。當然，日常生活中使用的符號與電腦中使用的符號不同。於是**電腦語言**的概念誕生了。像英語這樣的自然語言很豐富，有許多規則來正確組合單詞：另一方面，電腦語言的符號數量較有限，單詞數量也有限。我們將在第 9 章學習電腦語言。

**軟體工程**
馮·諾伊曼模型中沒有定義的是**軟體工程**，即**結構化程式**的設計與撰寫。如今，僅僅編寫一個執行任務的程式是不可接受的：程式必須遵循嚴格的規則和原則。我們將在第 10 章討論這些統稱為*軟體工程*的原則。

**作業系統**
在電腦演進的過程中，科學家們意識到有一系列指令是所有程式通用的。例如，幾乎所有程式都需要告訴電腦從哪裡接收資料以及將資料發送到哪裡的指令。只編寫這些指令一次供所有程式使用會更有效率。於是**作業系統**的概念應運而生。作業系統最初是作為一個管理者，以方便程式存取電腦的組件，儘管今日的作業系統做的更多。我們將在第 7 章學習它們。

## 1.4 歷史
在本節中，我們簡要回顧計算和電腦的歷史。我們將這段歷史分為三個時期。

### 1.4.1 機械機器（1930 年以前）
在此期間，發明了幾種計算機器，它們與現代電腦的概念幾乎沒有相似之處。
*   在十七世紀，法國數學家和哲學家布萊茲·帕斯卡發明了 Pascaline（帕斯卡計算器），一種用於加減法運算的機械計算器。在二十世紀，當 Niklaus Wirth 發明一種結構化程式語言時，他將其命名為 Pascal，以紀念第一台機械計算器的發明者。
*   在十七世紀晚期，德國數學家戈特弗里德·萊布尼茲發明了一種更複雜的機械計算器，可以進行乘法和除法以及加法和減法。它被稱為萊布尼茲輪 (Leibniz Wheel)。
*   第一台使用儲存和編程思想的機器是緹花織布機 (Jacquard loom)，由約瑟夫·瑪麗·雅卡爾在十九世紀初發明。織布機使用打孔卡（就像儲存的程式）來控制紡織品製造中經線的升降。
*   1823 年，查爾斯·巴貝奇發明了差分機 (Difference Engine)，它可以做的不僅僅是簡單的算術運算——它還可以解多項式方程式。後來，他發明了一台名為分析機 (Analytical Engine) 的機器，在某種程度上與現代電腦的思想相似。它有四個組件：一個磨坊 (相當於現代 ALU)、一個倉庫 (記憶體)、一個操作員 (控制單元) 和輸出 (輸入/輸出)。
*   1890 年，在美國人口普查局工作的赫爾曼·何樂禮設計並建造了一台程式設計機器，可以自動讀取、計數和排序儲存在打孔卡上的資料。

### 1.4.2 電子電腦的誕生（1930–1950）
在 1930 年至 1950 年間，科學家們發明了幾台電腦，這些科學家可以被視為電子電腦產業的先驅。

**早期電子電腦**
這一時期的早期電腦沒有將程式儲存在記憶體中——全部都是外部編程的。這幾年有五台電腦表現突出：
*   第一台以電力編碼資訊的專用電腦是由約翰·V·阿塔納索夫和他的助手克利福德·貝里於 1939 年發明的。它被稱為 ABC (阿塔納索夫-貝瑞電腦)，專門設計用於解線性方程組。
*   與此同時，德國數學家 Konrad Zuse 設計了一台名為 Z1 的通用機器。
*   在 1930 年代，美國海軍和 IBM 資助了哈佛大學的一個專案，由霍華德·艾肯指導，建造了一台名為 Mark I 的巨型電腦。這台電腦同時使用了電子和機械組件。
*   在英國，艾倫·圖靈發明了一台名為 Colossus (巨像) 的電腦，旨在破解德國的恩尼格瑪密碼。
*   第一台通用、完全電子的電腦是由約翰·莫奇利和 J. 普雷斯珀·埃克特製造的，名為 ENIAC (電子數值積分計算機)。它於 1946 年完成。它使用了 18000 個真空管，長 100 英尺，高 10 英尺，重 30 噸。

**基於馮·諾伊曼模型的電腦**
上述五台電腦僅使用記憶體來儲存資料，並使用電線或開關進行外部編程。約翰·馮·諾伊曼提出程式和資料應該儲存在記憶體中。這樣，每次我們使用電腦執行新任務時，我們只需要更改程式，而不是重新佈線機器或打開和關閉數百個開關。
第一台基於馮·諾伊曼思想的電腦於 1950 年在賓夕法尼亞大學製造，名為 EDVAC。與此同時，劍橋大學的 Maurice Wilkes 在英國建造了一台類似的電腦，名為 EDSAC。

### 1.4.3 電腦世代（1950–至今）
1950 年以後建造的電腦或多或少都遵循馮·諾伊曼模型。它們變得更快、更小、更便宜，但原理幾乎相同。歷史學家將這一時期分為幾個世代，每個世代都見證了硬體或軟體的一些重大變化（但模型沒有變）。

**第一代**
第一代（大約 1950–1959）的特徵是商用電腦的出現。在此期間，電腦僅由專業人員使用。它們被鎖在房間裡，只有操作員或電腦專家才能進入。電腦體積龐大，使用真空管作為電子開關。當時，只有大型組織才負擔得起電腦。

**第二代**
第二代電腦（大約 1959–1965）使用電晶體取代真空管。這減小了電腦的尺寸以及成本，使中小型企業也能負擔得起。發明了兩種高階程式語言，FORTRAN 和 COBOL（參見第 9 章），使編程變得更容易。這兩種語言將編程任務與電腦操作任務分開。例如，土木工程師可以編寫 FORTRAN 程式來解決問題，而無需涉及電腦架構的電子細節。

**第三代**
**積體電路**（單一晶片上的電晶體、佈線和其他組件）的發明進一步降低了電腦的成本和尺寸。*迷你電腦*出現在市場上。罐頭程式，通稱為軟體套件，變得可用。一家小公司可以購買一個套件，例如用於會計，而不是編寫自己的程式。一個新的產業，軟體產業，誕生了。這一代大約持續從 1965 年到 1975 年。

**第四代**
第四代（大約 1975–1985）見證了**微電腦**的出現。第一台桌上型計算機 Altair 8800 於 1975 年問世。電子工業的進步使得整個電腦子系統可以安裝在單一電路板上。這一代也見證了電腦網路的出現（參見第 6 章）。

**第五代**
這個開放式的世代始於 1985 年。它見證了筆記型電腦和掌上型電腦的出現、輔助儲存媒體（CD-ROM、DVD 等）的改進、多媒體的使用以及虛擬實境現象。

## 1.5 作為一門學科的電腦科學
隨著電腦的發明，一門新的學科應運而生：*電腦科學*。像任何其他學科一樣，電腦科學現在已分為幾個領域。我們可以將這些領域分為兩大類：*系統領域*和*應用領域*。系統領域涵蓋那些與硬體和軟體創造直接相關的領域，例如*電腦架構*、*電腦網路*、*安全性議題*、*作業系統*、*演算法*、*程式語言*和*軟體工程*。應用領域涵蓋那些與電腦*使用*相關的領域，例如*資料庫*和*人工智慧*。本書是對所有這些領域的廣度優先探討。讀完本書後，讀者應該有足夠的資訊來選擇所需的專業領域。

## 1.6 課程大綱
在介紹性章節之後，本書分為五個部分。

### 1.6.1 第一部分：資料表示與運算
這部分包括第 2、3 和 4 章。第 2 章討論數字系統，即如何使用符號表示數量。第 3 章討論如何在電腦內部儲存不同的資料。第 4 章討論對*位元*的一些基本運算。

### 1.6.2 第二部分：電腦硬體
這部分包括第 5 和 6 章。第 5 章給出了電腦硬體的一般概念，討論了不同的電腦組織。第 6 章展示了各個電腦如何連接成電腦網路和*互連網* (internets)。特別是，本章探討了一些與網際網路及其應用相關的主題。

### 1.6.3 第三部分：電腦軟體
這部分包括第 7、8、9 和 10 章。第 7 章討論作業系統，即控制使用者（人類或應用程式）存取硬體的系統軟體。第 8 章展示了如何將解決問題簡化為為問題編寫演算法。第 9 章帶領讀者遊歷當代程式語言列表。最後，第 10 章回顧了軟體工程，即軟體開發的工程方法。

### 1.6.4 第四部分：資料組織與抽象
這部分補充了第一部分。在電腦科學中，*原子*資料被收集成記錄、檔案和資料庫。資料*抽象*允許程式設計師創建關於資料的抽象概念。第四部分包括第 11、12、13 和 14 章。第 11 章討論資料結構，將相同或不同類型的資料收集在一個類別下。第 12 章討論抽象資料型別。第 13 章展示了如何將不同的檔案結構用於不同的目的。最後，第 14 章討論資料庫。

### 1.6.5 第五部分：進階主題
第五部分概述了進階主題，即電腦科學學生在以後的教育中會遇到的主題。這部分涵蓋第 15、16、17 和 18 章。第 15 章討論資料壓縮，這在當今的資料通訊中很普遍。第 16 章探討了一些與安全性相關的問題，當我們透過不安全的通道進行通訊時，安全性變得越來越重要。第 17 章討論計算理論：什麼可以計算，什麼不能計算。最後第 18 章給出了一些關於人工智慧的概念，這是電腦科學中日益受到挑戰的主題。

### 1.6.6 第六部分：社群媒體與社會議題
第六部分簡要討論社群媒體和社會議題，這兩個主題是電腦科學學生可能有興趣探索的。

## 1.7 章末材料
### 1.7.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
*   Schneider, G. M. and Gersting, J. L. *Invitation to Computer Science*, Boston, MA: Course Technology, 2004
*   Dale, N. and Lewis, J. *Computer Science Illuminated*, Sudbury, MA: Jones and Bartlett, 2004
*   Patt, Y. and Patel, S. *Introduction to Computing Systems*, New York: McGraw-Hill, 2004

### 1.7.2 關鍵詞
*   演算法 (algorithm)
*   算術邏輯單元 (ALU)
*   電腦語言 (computer languages)
*   控制單元 (control unit)
*   資料處理器 (data processor)
*   輸入資料 (input data)
*   輸入/輸出子系統 (input/output subsystem)
*   指令 (instruction)
*   積體電路 (integrated circuit)
*   邏輯運算 (logical operation)
*   記憶體 (memory)
*   微電腦 (microcomputer)
*   作業系統 (operating system)
*   輸出資料 (output data)
*   程式 (program)
*   結構化程式 (structured programs)
*   軟體工程 (software engineering)
*   圖靈機 (Turing machine)
*   圖靈模型 (Turing model)
*   馮·諾伊曼模型 (von Neumann model)

### 1.7.3 摘要
*   通用計算設備的想法最早由艾倫·圖靈於 1936 年提出。他提出所有的計算都可以由一種特殊的機器執行，現在稱為圖靈機。
*   馮·諾伊曼模型將電腦定義為四個子系統：記憶體、算術邏輯單元、控制單元和輸入/輸出。馮·諾伊曼模型指出程式必須儲存在記憶體中。
*   我們可以將電腦視為由三個組件組成：電腦硬體、資料和電腦軟體。
*   計算和電腦的歷史可以分為三個時期：機械機器時期（1930 年以前）、電子電腦時期（1930–1950），以及包括五個現代電腦世代的時期。
*   隨著電腦的發明，一門新的學科應運而生，即*電腦科學*，它現在分為幾個領域。
`},o={en:`
# Chapter 2: Number Systems

This chapter is a prelude to Chapters 3 and 4. In Chapter 3 we will show how data is stored inside the computer. In Chapter 4 we will show how logic and arithmetic operations are performed on data. This chapter is a preparation for understanding the contents of Chapters 3 and 4. Readers who know about number systems can skip this chapter and move on to Chapter 3 without loss of continuity. Note that the number systems discussed in this chapter are ‘paper and pencil representations’: we show how these numbers are stored in a computer in Chapter 3.

## Objectives
After studying this chapter, the student should be able to:
- Understand the concept of number systems.
- Distinguish between nonpositional and positional number systems.
- Describe the decimal system (base 10).
- Describe the binary system (base 2).
- Describe the hexadecimal system (base 16).
- Describe the octal system (base 8).
- Convert a number in binary, octal, or hexadecimal to a number in the decimal system.
- Convert a number in the decimal system to a number in binary, octal, or hexadecimal.
- Convert a number in binary to octal and vice versa.
- Convert a number in binary to hexadecimal and vice versa.
- Find the number of digits needed in each system to represent a particular value.

## 2.1 INTRODUCTION
A **number system** (or numeral system) defines how a number can be represented using distinct symbols. A number can be represented differently in different systems. For example, the two numbers (2A)₁₆ and (52)₈ both refer to the same quantity, (42)₁₀, but their representations are different. This is the same as using the words *cheval* (French) and *equus* (Latin) to refer to the same entity, a horse.

As we use symbols (characters) to create words in a language, we use symbols (digits) to represent numbers. However, we know that the number of symbols (characters) in any language is limited. We need to repeat characters and combine them to create words. It is the same for numbers: we have a limited number of symbols (digits) to represent numbers, which means that the digits need to be repeated.

Several number systems have been used in the past and can be categorized into two groups: positional and nonpositional systems. Our main goal is to discuss the positional number systems, but we also give examples of nonpositional systems.

## 2.2 POSITIONAL NUMBER SYSTEMS
In a **positional number system**, the position a symbol occupies in the number determines the value it represents. In this system, a number represented as:

± (Sₖ₋₁ ... S₂ S₁ S₀ . S₋₁ S₋₂ ... S₋ₗ)b

has the value of:

n = ± Sₖ₋₁ × bᵏ⁻¹ + ... + S₁ × b¹ + S₀ × b⁰ + S₋₁ × b⁻¹ + S₋₂ × b⁻² + ... + S₋ₗ × b⁻ˡ

in which S is the set of symbols, b is the **base** (or **radix**), which is equal to the total number of the symbols in the set S, and Sₖ and S₋ₗ are symbols in the whole and fraction parts of the number. Note that we have used an expression that can be extended from the right or from the left. In other words, the power of b can be 0 to K - 1 in one direction and -1 to -L in the other direction. The terms with non-negative powers of b are related to the integral part of the number, while the terms with negative power of b are related to the fractional part of the number. The ± sign shows that the number can be either positive or negative. We will study several positional number systems in this chapter.

### 2.2.1 The decimal system (base 10)
The first positional number system we discuss in this chapter is the **decimal system**. The word *decimal* is derived from the Latin root *decem* (ten). In this system the base b = 10 and we use ten symbols to represent a number. The set of symbols is S = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}. As we know, the symbols in this system are often referred to as **decimal digits** or just digits. In this chapter, we use ± to show that a number can be positive or negative, but remember that these signs are not stored in computers—computers handle the sign differently, as we discuss in Chapter 3.

In the decimal system, a number is written as:

± (Sₖ₋₁ ... S₂ S₁ S₀ . S₋₁ S₋₂ ... S₋ₗ)₁₀

but for simplicity, we often drop the parentheses, the base, and the plus sign (if the number is positive). For example, we write the number +(552.23)₁₀ as 552.23—the base and plus signs are implicit.

**Integers**
An **integer** (an integral number with no fractional part) in the decimal system is familiar to all of us—we use integers in our daily life. In fact, we have used them so much that they are intuitive. We represent an integer as ± Sₖ₋₁ ... S₁ S₀. The value is calculated as:

N = ± Sₖ₋₁ × 10ᵏ⁻¹ + Sₖ₋₂ × 10ᵏ⁻² + ... + S₂ × 10² + S₁ × 10¹ + S₀ × 10⁰

in which Sᵢ is a digit, b = 10 is the base, and K is the number of digits.
Another way to show an integer in a number system is to use **place values**, which are powers of 10 (10⁰, 10¹, ..., 10ᵏ⁻¹) for decimal numbers.

**Example 2.1**
The following shows the place values for the integer +224 in the decimal system:
*   Place values: 10² 10¹ 10⁰
*   Number: 2 2 4
*   Values: N = + 2 × 10² + 2 × 10¹ + 4 × 10⁰

Note that the digit in position 1 has the value 20, but the same digit in position 2 has the value 200. Also note that we normally drop the plus sign, but it is implicit.

**Example 2.2**
The following shows the place values for the decimal number –7508. We have used 1, 10, 100, and 1000 instead of powers of 10:
*   Place values: 1000 100 10 1
*   Number: 7 5 0 8
*   Values: N = – (7 × 1000 + 5 × 100 + 0 × 10 + 8 × 1)

**Maximum value**
Sometimes we need to know the maximum value of a decimal integer that can be represented by K digits. The answer is N_max = 10ᴷ – 1. For example, if K = 5, then the maximum value is N_max = 10⁵ – 1 = 99999.

**Reals**
A **real** (a number with a fractional part) in the decimal system is also familiar. For example, we use this system to show dollars and cents ($23.40). We can represent a real as ± Sₖ₋₁ ... S₁ S₀ . S₋₁ ... S₋ₗ. The value is calculated as:

R = ± Sₖ₋₁ × 10ᵏ⁻¹ + ... + S₁ × 10¹ + S₀ × 10⁰ + S₋₁ × 10⁻¹ + ... + S₋ₗ × 10⁻ˡ

in which Sᵢ is a digit, b = 10 is the base, K is the number of digits in the integral part, and L is the number of digits in the fractional part. The decimal point we use in our representation separates the fractional part from the integral part.

**Example 2.3**
The following shows the place values for the real number +24.13:
*   Place values: 10¹ 10⁰ . 10⁻¹ 10⁻²
*   Number: 2 4 . 1 3
*   Values: R = + 2 × 10 + 4 × 1 + 1 × 0.1 + 3 × 0.01

### 2.2.2 The binary system (base 2)
The second positional number system we discuss in this chapter is the **binary system**. The word *binary* is derived from the Latin root *bini* (or two by two). In this system the base b = 2 and we use only two symbols, S = {0, 1}. The symbols in this system are often referred to as **binary digits** or **bits** (binary digit). As we will see in Chapter 3, data and programs are stored in the computer using binary patterns, a string of bits. This is because the computer is made of electronic switches that can have only two states, on and off. The bit 1 represents one of these two states and the bit 0 the other.

**Integers**
We can represent an integer as ± (Sₖ₋₁ ... S₁ S₀)₂. The value is calculated as:

N = ± Sₖ₋₁ × 2ᵏ⁻¹ + Sₖ₋₂ × 2ᵏ⁻² + ... + S₂ × 2² + S₁ × 2¹ + S₀ × 2⁰

in which Sᵢ is a digit, b = 2 is the base, and K is the number of bits. Another way to show a binary number is to use place values (2⁰, 2¹, ... 2ᵏ⁻¹).

**Example 2.4**
The following shows that the number (11001)₂ in binary is the same as 25 in decimal. The subscript 2 shows that the base is 2:
*   Place values: 2⁴ 2³ 2² 2¹ 2⁰
*   Number: 1 1 0 0 1
*   Decimal: N = 1 × 2⁴ + 1 × 2³ + 0 × 2² + 0 × 2¹ + 1 × 2⁰
Note that the equivalent decimal number is N = 16 + 8 + 0 + 0 + 1 = 25.

**Maximum value**
The maximum value of a binary integer with K digits is N_max = 2ᴷ – 1. For example, if K = 5, then the maximum value is N_max = 2⁵ – 1 = 31.

**Reals**
A real—a number with an optional fractional part—in the binary system can be made of K bits on the left and L bits on the right, ± (Sₖ₋₁ ... S₁ S₀ . S₋₁ ... S₋ₗ)₂. The value can be calculated as:

R = ± Sₖ₋₁ × 2ᵏ⁻¹ x ... x S₁ × 2¹ x S₀ × 2⁰ + S₋₁ × 2⁻¹ + ... + S₋ₗ × 2⁻ˡ

in which Sᵢ is a bit, b = 2 is the base, K is the number of bits to the left, and L is the number of bits to the right of the decimal point. Note that K starts from 0, but L starts from -1. The highest power is K – 1 and the lowest power is -L.

**Example 2.5**
The following shows that the number (101.11)₂ in binary is equal to the number 5.75 in decimal:
*   Place values: 2² 2¹ 2⁰ . 2⁻¹ 2⁻²
*   Number: 1 0 1 . 1 1
*   Values: R = 1 × 2² + 0 × 2¹ + 1 × 2⁰ + 1 × 2⁻¹ + 1 × 2⁻²
Note that the value in the decimal system is R = 4 + 0 + 1 + 0.5 + 0.25 = 5.75.

### 2.2.3 The hexadecimal system (base 16)
Although the binary system is used to store data in computers, it is not convenient for representation of numbers outside the computer, as a number in binary notation is much longer than the corresponding number in decimal notation. However, the decimal system does not show what is stored in the computer as binary directly—there is no obvious relationship between the number of bits in binary and the number of decimal digits. Conversion from one to the other is not fast, as we will see shortly.

To overcome this problem, two positional systems were devised: hexadecimal and octal. We first discuss the hexadecimal system, which is more common. The word **hexadecimal** is derived from the Greek root *hex* (six) and the Latin root *decem* (ten). To be consistent with decimal and binary, it should really have been called *sexadecimal*, from the Latin roots *sex* and *decem*. In this system the base b = 16 and we use 16 symbols to represent a number. The set of symbols is S = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F}. Note that the symbols A, B, C, D, E, F (uppercase or lowercase) are equivalent to 10, 11, 12, 13, 14, and 15 respectively. The symbols in this system are often referred to as **hexadecimal digits**.

**Integers**
We can represent an integer as ± Sₖ₋₁ ... S₁ S₀. The value is calculated as:

N = ± Sₖ₋₁ × 16ᵏ⁻¹ + Sₖ₋₂ × 16ᵏ⁻² + ... + S₂ × 16² + S₁ × 16¹ + S₀ × 16⁰

in which Sᵢ is a digit, b = 16 is the base, and K is the number of digits.
Another way to show a hexadecimal number is to use place values (16⁰, 16¹, ..., 16ᵏ⁻¹).

**Example 2.6**
The following shows that the number (2AE)₁₆ in hexadecimal is equivalent to 686 in decimal:
*   Place values: 16² 16¹ 16⁰
*   Number: 2 A E
*   Values: N = 2 × 16² + 10 × 16¹ + 14 × 16⁰
Note that the value in the decimal system is N = 512 + 160 + 14 = 686.

**Maximum value**
The maximum value of a hexadecimal integer with K digits is N_max = 16ᴷ – 1. For example, if K = 5, then the maximum value is N_max = 16⁵ – 1 = 1048575.

**Reals**
Although a real number can be also represented in the hexadecimal system, it is not very common.

### 2.2.4 The octal system (base 8)
The second system that was devised to show the equivalent of the binary system outside the computer is the **octal system**. The word *octal* is derived from the Latin root *octo* (eight). In this system the base b = 8 and we use eight symbols to represent a number. The set of symbols is S = {0, 1, 2, 3, 4, 5, 6, 7}. The symbols in this system are often referred to as **octal digits**.

**Integers**
We can represent an integer as ± Sₖ₋₁ ... S₁ S₀. The value is calculated as:

N = ± Sₖ₋₁ × 8ᵏ⁻¹ + Sₖ₋₂ × 8ᵏ⁻² + ... + S₂ × 8² + S₁ × 8¹ + S₀ × 8⁰

in which Sᵢ is a digit, b = 8 is the base, and K is the number of digits.
Another way to show an octal number is to use place values (8⁰, 8¹, ..., 8ᵏ⁻¹).

**Example 2.7**
The following shows that the number (1256)₈ in octal is the same as 686 in decimal:
*   Place values: 8³ 8² 8¹ 8⁰
*   Number: 1 2 5 6
*   Values: N = 1 × 8³ + 2 × 8² + 5 × 8¹ + 6 × 8⁰
Note that the decimal number is N = 512 + 128 + 40 + 6 = 686.

**Maximum Value**
The maximum value of an octal integer with K digits is N_max = 8ᴷ – 1. For example, if K = 5, then the maximum value is N_max = 8⁵ – 1 = 32767.

**Reals**
Although a real number can be also represented in the octal system, it is not very common.

### 2.2.5 Summary of the four positional systems
Table 2.1 shows a summary of the four positional number systems discussed in this chapter.

**Table 2.1 Summary of the four positional number systems**
| System | Base | Symbols | Examples |
| :--- | :--- | :--- | :--- |
| Decimal | 10 | 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 | 2345.56 |
| Binary | 2 | 0, 1 | (1001.11)₂ |
| Octal | 8 | 0, 1, 2, 3, 4, 5, 6, 7 | (156.23)₈ |
| Hexadecimal | 16 | 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F | (A2C.A1)₁₆ |

Table 2.2 shows how the number 15 is represented with two digits in decimal, four digits in binary, two digits in octal, and only one digit in hexadecimal. The hexadecimal representation is definitely the shortest.

**Table 2.2 Comparison of numbers in the four systems**
| Decimal | Binary | Octal | Hexadecimal |
| :--- | :--- | :--- | :--- |
| 0 | 0 | 0 | 0 |
| 1 | 1 | 1 | 1 |
| 2 | 10 | 2 | 2 |
| 3 | 11 | 3 | 3 |
| 4 | 100 | 4 | 4 |
| 5 | 101 | 5 | 5 |
| 6 | 110 | 6 | 6 |
| 7 | 111 | 7 | 7 |
| 8 | 1000 | 10 | 8 |
| 9 | 1001 | 11 | 9 |
| 10 | 1010 | 12 | A |
| 11 | 1011 | 13 | B |
| 12 | 1100 | 14 | C |
| 13 | 1101 | 15 | D |
| 14 | 1110 | 16 | E |
| 15 | 1111 | 17 | F |

### 2.2.6 Conversion
We need to know how to convert a number in one system to the equivalent number in another system. Since the decimal system is more familiar than the other systems, we first show how to covert from any base to decimal. Then we show how to convert from decimal to any base. Finally, we show how we can easily convert from binary to hexadecimal or octal and vice versa.

**Any base to decimal conversion**
This type of conversion is easy and fast. We multiply each digit with its place value in the source system and add the results to get the number in the decimal system.

**Example 2.8**
The following shows how to convert the binary number (110.11)₂ to decimal: (110.11)₂ = 6.75:
*   Binary: 1 1 0 . 1 1
*   Place values: 2² 2¹ 2⁰ . 2⁻¹ 2⁻²
*   Partial results: 4 + 2 + 0 + 0.5 + 0.25
*   Decimal: 6.75

**Example 2.9**
The following shows how to convert the hexadecimal number (1A.23)₁₆ to decimal:
*   Hexadecimal: 1 A . 2 3
*   Place values: 16¹ 16⁰ . 16⁻¹ 16⁻²
*   Partial result: 16 + 10 + 0.125 + 0.012
*   Decimal: 26.137
Note that the result in the decimal notation is not exact, because 3 × 16⁻² = 0.01171875. We have rounded this value to three digits (0.012). In other words, (1A.23)₁₆ ≈ 26.137. When we convert a number in decimal to hexadecimal, we need to specify how many digits we allow to the right of the decimal point.

**Example 2.10**
The following shows how to convert (23.17)₈ to decimal:
*   Octal: 2 3 . 1 7
*   Place values: 8¹ 8⁰ . 8⁻¹ 8⁻²
*   Partial result: 16 + 3 + 0.125 + 0.109
*   Decimal: 19.234
This means that (23.17)₈ ≈ 19.234 in decimal. Again, we have rounded up 7 × 8⁻² = 0.109375.

**Decimal to any base**
We can convert a decimal number to its equivalent in any base. We need two procedures, one for the integral part and one for the fractional part.

**Converting the integral part**
The integral part can be converted using repetitive division. We call the integral part of the decimal number the source and the integral part of the converted number the destination. We first create an empty destination. We then repetitively divide the source to get the quotient and the remainder. The remainder is inserted to the left of the destination. The quotient becomes a new source.

**Example 2.11**
The following shows how to convert 35 in decimal to binary. We start with the number in decimal, we move to the left while continuously finding the quotients and the remainder of division by 2. The result is 35 = (100011)₂:
*   Decimal: 35
*   Divide by 2: 35/2 -> Q=17, R=1
*   Divide by 2: 17/2 -> Q=8, R=1
*   Divide by 2: 8/2 -> Q=4, R=0
*   Divide by 2: 4/2 -> Q=2, R=0
*   Divide by 2: 2/2 -> Q=1, R=0
*   Divide by 2: 1/2 -> Q=0, R=1
*   Binary: 100011

**Example 2.12**
The following shows how to convert 126 in decimal to its equivalent in the octal system. We move to the right while continuously finding the quotients and the remainder of division by 8. The result is 126 = (176)₈:
*   Decimal: 126
*   Divide by 8: 126/8 -> Q=15, R=6
*   Divide by 8: 15/8 -> Q=1, R=7
*   Divide by 8: 1/8 -> Q=0, R=1
*   Octal: 176

**Example 2.13**
The following shows how we convert 126 in decimal to its equivalent in the hexadecimal system. We move to the right while continuously finding the quotients and the remainder of division by 16. The result is 126 = (7E)₁₆:
*   Decimal: 126
*   Divide by 16: 126/16 -> Q=7, R=14 (E)
*   Divide by 16: 7/16 -> Q=0, R=7
*   Hexadecimal: 7E

**Converting the fractional part**
The fractional part can be converted using repetitive multiplication. We call the fractional part of the decimal number the source and the fractional part of the converted number the destination. We first create an empty destination. We then repetitively multiply the source to get the result. The integral part of the result is inserted to the right of the destination, while the fractional part becomes the new source.

**Example 2.14**
Convert the decimal number 0.625 to binary.
Solution: Since the number 0.625 has no integral part, the example shows how the fractional part is calculated. The base here is 2. Write the decimal number at the left corner. Multiply the number continuously by 2 and record the integral and fractional part of the result. The fractional part moves to the right, and the integral part is recorded under each operation. Stop when the fractional part is 0 or there are enough bits. The result is (0.101)₂:
*   0.625 * 2 = 1.25 -> I=1, F=0.25
*   0.25 * 2 = 0.50 -> I=0, F=0.50
*   0.50 * 2 = 1.00 -> I=1, F=0.00
*   Binary: .101

**Example 2.15**
The following shows how to convert 0.634 to octal using a maximum of four digits. The result is 0.634 = (0.5044)₈. Note that we multiply by 8 (base octal):
*   0.634 * 8 = 5.072 -> I=5
*   0.072 * 8 = 0.576 -> I=0
*   0.576 * 8 = 4.608 -> I=4
*   0.608 * 8 = 4.864 -> I=4
*   Octal: .5044

**Example 2.16**
The following shows how to convert 178.6 in decimal to hexadecimal using only one digit to the right of the decimal point. The result is 178.6 = (B2.9)₁₆ Note that we divide or multiply by 16 (base hexadecimal):
*   Integral part 178: 178/16 -> Q=11 (B), R=2 -> B2
*   Fractional part 0.6: 0.6 * 16 = 9.6 -> I=9
*   Hexadecimal: B2.9

**Example 2.17**
An alternative method for converting a small decimal integer (usually less than 256) to binary is to break the number as the sum of numbers that are equivalent to the binary place values. Using this table, we can convert 165 to binary (10100101)₂ as shown below:
165 = 128 + 0 + 32 + 0 + 0 + 4 + 0 + 1 -> 10100101

**Example 2.18**
A similar method can be used to convert a decimal fraction to binary when the denominator is a power of two. Using this table, we convert 27/64 to binary (0.011011)₂ as shown below:
27/64 = 0 + 1/4 + 1/8 + 0 + 1/32 + 1/64 -> 0.011011

**Number of digits**
We often need to know the number of digits before converting a number from decimal to other bases. In a positional number system with base b, we can always find the number of digits of an integer using the relation K = ⌈log_b N⌉, in which ⌈x⌉ means the smallest integer greater than or equal to x (it is also called the ceiling of x), and N is the decimal value of the integer.

**Binary–hexadecimal conversion**
We can easily change a number from binary to hexadecimal and vice versa. The reason is that there is a relationship between the two bases: four bits in binary is one digit in hexadecimal.

**Example 2.19**
Show the hexadecimal equivalent of the binary number (10011100010)₂.
Solution: We first arrange the binary number in 4-bit patterns: 100 1110 0010. Note that the leftmost pattern can have one to four bits. We then use the equivalent of each pattern shown in Table 2.2 in section 2.2.5 to change the number to hexadecimal: (4E2)₁₆.

**Example 2.20**
What is the binary equivalent of (24C)₁₆?
Solution: Each hexadecimal digit is converted to 4-bit patterns: 2 → 0010, 4 → 0100, and C → 1100. The result is (001001001100)₂.

**Binary–octal conversion**
We can easily convert a number from binary to octal and vice versa. The reason is that there is an interesting relationship between the two bases: three bits is one octal digit.

**Example 2.21**
Show the octal equivalent of the binary number (101110010)₂.
Solution: Each group of three bits is translated into one octal digit. The equivalent of each 3‑bit group is shown in Table 2.2 in section 2.2.5. The result is (562)₈.

**Example 2.22**
What is the binary equivalent of for (24)₈?
Solution: Write each octal digit as its equivalent bit pattern to get (010100)₂.

**Octal–hexadecimal conversion**
It is not difficult to convert a number in octal to hexadecimal or vice versa. We can use the binary system as the intermediate system.
*   To convert from octal to hexadecimal, we first convert the number in the octal system to binary. We then rearrange the bits in groups of four bits to find the hexadecimal equivalent.
*   To convert from hexadecimal to octal, we first convert the number in the hexadecimal system to binary. We then rearrange the bits in groups of three to find the octal equivalent.

**Number of digits**
In conversion from one base to another, we often need to know the minimum number of digits we need in the destination system if we know the maximum number of digits in the source system. In general, assume that we are using K digits in base b₁ system. The maximum number we can represent in the source system is b₁ᴷ – 1. The maximum number we can have in the destination system is b₂ˣ – 1. Therefore, b₂ˣ – 1 ≥ b₁ᴷ – 1. This means x ≥ K × (log b₁ / log b₂).

**Example 2.23**
Find the minimum number of binary digits required to store decimal integers with a maximum of six digits.
Solution: K = 6, b₁ = 10, and b₂ = 2. Then x = ⌈6 × (log 10 / log 2)⌉ = ⌈6 × 3.322⌉ = ⌈19.93⌉ = 20.

## 2.3 NONPOSITIONAL NUMBER SYSTEMS
Although nonpositional number systems are not used in computers, we give a short review here for comparison with positional number systems. A **nonpositional number system** still uses a limited number of symbols in which each symbol has a value. However, the position a symbol occupies in the number normally bears no relation to its value—the value of each symbol is fixed. To find the value of a number, we add the value of all symbols present in the representation.

**Example 2.24**
The **Roman number system** is a good example of a nonpositional number system. This system was invented by the Romans and was used until the sixteenth century in Europe. Roman numerals are still used in sports events, clock dials, and other applications. This number system has a set of symbols S = {I, V, X, L, C, D, M}. The values of each symbol are shown in Table 2.3.

**Table 2.3 Values of symbols in the Roman number system**
| Symbol | I | V | X | L | C | D | M |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Value | 1 | 5 | 10 | 50 | 100 | 500 | 1000 |

To find the value of a number, we need to add the value of symbols subject to specific rules:
1.  When a symbol with a smaller value is placed after a symbol having an equal or larger value, the values are added.
2.  When a symbol with a smaller value is placed before a symbol having a larger value, the smaller value is subtracted from the larger one.
3.  A symbol S₁ cannot come before another symbol S₂ if S₁ ≤ 10 × S₂. For example, I or V cannot come before C.
4.  For large numbers a bar is placed above any of the six symbols (all symbols except I) to express multiplication by 1000. For example, V̅ = 5000 and M̅ = 1000000.
5.  Although Romans used the word *nulla* (nothing) to convey the concept of zero, the Roman numerals lack a zero digit in their system.

The following shows some Roman numbers and their values:
*   III → 1 + 1 + 1 = 3
*   IV → 5 – 1 = 4
*   VIII → 5 + 1 + 1 + 1 = 8
*   XVIII → 10 + 5 + 1 + 1 + 1 = 18
*   XIX → 10 + (10 – 1) = 19
*   LXXII → 50 + 10 + 10 + 1 + 1 = 72
*   CI → 100 + 1 = 101
*   MMVII → 1000 + 1000 + 5 + 1 + 1 = 2007
*   MDC → 1000 + 500 + 100 = 1600

## 2.4 END-CHAPTER MATERIALS
### 2.4.1 Recommended reading
For more details about the subjects discussed in this chapter, the following books are recommended:
*   Stalling, W. *Computer Organization and Architecture*, Upper Saddle River, NJ: Prentice-Hall, 2000
*   Mano, M. *Computer System Architecture*, Upper Saddle River, NJ: Prentice-Hall, 1993
*   Null, L. and Lobur, J. *Computer Organization and Architecture*, Sudbury, MA: Jones and Bartlett, 2003
*   Brown, S. and Vranesic, Z. *Fundamentals of Digital Logic with Verilog Design*, New York: McGraw-Hill, 2003

### 2.4.2 Key terms
*   base
*   binary digit
*   binary system
*   bit
*   decimal digit
*   decimal system
*   hexadecimal digit
*   hexadecimal system
*   integer
*   nonpositional number system
*   number system
*   octal digit
*   octal system
*   place value
*   positional number system
*   radix
*   real
*   Roman number system

### 2.4.3 Summary
*   A number system (or numeral system) is a system that uses distinct symbols to represent a number. In a positional number system, the position a symbol occupies in the number determines the value it represents. Each position has a place value associated with it. A nonpositional number system uses a limited number of symbols in which each symbol has a value. However, the position a symbol occupies in the number normally bears no relation to its value: the value of each symbol is normally fixed.
*   In the decimal system, the base b = 10 and we use ten symbols to represent numbers. The symbols in this system are often referred to as decimal digits or just digits. In the binary system, the base b = 2 and we use only two symbols to represent numbers. The symbols in this system are often referred to as binary digits or bits. In a hexadecimal system, the base = 16 and we use 16 symbols to represent numbers. The symbols in this system are often referred to as hexadecimal digits. In an octal system, the base b = 8 and we use eight symbols to represent numbers. The symbols in this system are often referred to as octal digits.
*   We can convert a number in any system to decimal. We multiply each digit with its place value in the source system and add the result to get the number in the decimal system. We can convert a decimal number to its equivalent in any base using two different procedures, one for the integral part and one for the fractional part. The integral part needs repeated division and the fraction part needs repeated multiplication.
*   Conversion from the binary system to the hexadecimal system and from the hexadecimal system to the binary system is very easy, because four bits in the binary system are represented as one digit in the hexadecimal system.
*   Conversion from the binary system to the octal system and from the octal system to the binary system is very easy, because three bits in the binary system are represented as one digit in the octal system.
`,zh:`
# 第二章：數字系統

本章是第三章和第四章的前奏。在第三章中，我們將展示資料如何儲存在電腦內部。在第四章中，我們將展示如何在資料上執行邏輯和算術運算。本章是為了理解第三章和第四章內容所做的準備。已經了解數字系統的讀者可以跳過本章，直接進入第三章，不會影響連貫性。請注意，本章討論的數字系統是「紙筆表示法」：我們將在第三章展示這些數字如何儲存在電腦中。

## 學習目標
學完本章後，學生應能：
- 理解數字系統的概念。
- 區分非進位制和進位制數字系統。
- 描述十進位系統（基底為 10）。
- 描述二進位系統（基底為 2）。
- 描述十六進位系統（基底為 16）。
- 描述八進位系統（基底為 8）。
- 將二進位、八進位或十六進位的數字轉換為十進位數字。
- 將十進位數字轉換為二進位、八進位或十六進位的數字。
- 將二進位數字轉換為八進位，反之亦然。
- 將二進位數字轉換為十六進位，反之亦然。
- 計算在各系統中表示特定值所需的位數。

## 2.1 簡介
**數字系統**（或計數系統）定義了如何使用不同的符號來表示一個數字。一個數字在不同的系統中可以有不同的表示方式。例如，兩個數字 (2A)₁₆ 和 (52)₈ 都指代相同的數量 (42)₁₀，但它們的表示方式不同。這就像使用 *cheval*（法語）和 *equus*（拉丁語）來指代同一個實體——馬。

就像我們使用符號（字元）在語言中創造單詞一樣，我們使用符號（數字）來表示數字。然而，我們知道任何語言中的符號（字元）數量是有限的。我們需要重複字元並將它們組合起來創造單詞。數字也是如此：我們用來表示數字的符號（數字）數量有限，這意味著數字需要被重複使用。

過去曾使用過多種數字系統，可分為兩類：進位制和非進位制系統。我們的主要目標是討論進位制數字系統，但我們也會給出非進位制系統的例子。

## 2.2 進位制數字系統
在**進位制數字系統**中，符號在數字中所佔的位置決定了它所代表的值。在這個系統中，一個表示為：

± (Sₖ₋₁ ... S₂ S₁ S₀ . S₋₁ S₋₂ ... S₋ₗ)b

的數字，其值為：

n = ± Sₖ₋₁ × bᵏ⁻¹ + ... + S₁ × b¹ + S₀ × b⁰ + S₋₁ × b⁻¹ + S₋₂ × b⁻² + ... + S₋ₗ × b⁻ˡ

其中 S 是符號集合，b 是**基底**（或**底數**），它等於集合 S 中符號的總數，Sₖ 和 S₋ₗ 是數字的整數和小數部分的符號。請注意，我們使用了一個可以向右或向左擴展的表達式。換句話說，b 的冪次在一個方向上可以是 0 到 K - 1，在另一個方向上可以是 -1 到 -L。b 的非負冪次項與數字的整數部分有關，而 b 的負冪次項與數字的小數部分有關。± 符號表示數字可以是正數或負數。我們將在本章學習幾種進位制數字系統。

### 2.2.1 十進位系統（基底為 10）
我們在本章討論的第一個進位制數字系統是**十進位系統**。「decimal」一詞源於拉丁詞根 *decem*（十）。在這個系統中，基底 b = 10，我們使用十個符號來表示數字。符號集合為 S = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}。如我們所知，這個系統中的符號通常被稱為**十進位數字**或簡稱數字。在本章中，我們使用 ± 來表示數字可以是正數或負數，但請記住，這些符號並不儲存在電腦中——電腦以不同的方式處理符號，我們將在第 3 章討論。

在十進位系統中，一個數字寫作：

± (Sₖ₋₁ ... S₂ S₁ S₀ . S₋₁ S₋₂ ... S₋ₗ)₁₀

但為了簡單起見，我們通常省略括號、基底和加號（如果數字是正數）。例如，我們將數字 +(552.23)₁₀ 寫作 552.23——基底和加號是隱含的。

**整數**
十進位系統中的**整數**（沒有小數部分的整數）對我們所有人來說都很熟悉——我們在日常生活中使用整數。事實上，我們使用它們太多了，以至於它們變得很直觀。我們將整數表示為 ± Sₖ₋₁ ... S₁ S₀。其值計算如下：

N = ± Sₖ₋₁ × 10ᵏ⁻¹ + Sₖ₋₂ × 10ᵏ⁻² + ... + S₂ × 10² + S₁ × 10¹ + S₀ × 10⁰

其中 Sᵢ 是一個數字，b = 10 是基底，K 是位數。
在數字系統中顯示整數的另一種方法是使用**位值**，對於十進位數字來說，就是 10 的冪次（10⁰, 10¹, ..., 10ᵏ⁻¹）。

**範例 2.1**
以下顯示了十進位整數 +224 的位值：
*   位值：10² 10¹ 10⁰
*   數字：2 2 4
*   值：N = + 2 × 10² + 2 × 10¹ + 4 × 10⁰

請注意，位置 1 的數字值為 20，但位置 2 的相同數字值為 200。另請注意，我們通常省略加號，但它是隱含的。

**範例 2.2**
以下顯示了十進位數字 –7508 的位值。我們使用了 1, 10, 100, 1000 代替 10 的冪次：
*   位值：1000 100 10 1
*   數字：7 5 0 8
*   值：N = – (7 × 1000 + 5 × 100 + 0 × 10 + 8 × 1)

**最大值**
有時我們需要知道由 K 位數表示的十進位整數的最大值。答案是 N_max = 10ᴷ – 1。例如，如果 K = 5，則最大值為 N_max = 10⁵ – 1 = 99999。

**實數**
十進位系統中的**實數**（帶有小數部分的數字）也很常見。例如，我們使用這個系統來顯示美元和美分 ($23.40)。我們可以將實數表示為 ± Sₖ₋₁ ... S₁ S₀ . S₋₁ ... S₋ₗ。其值計算如下：

R = ± Sₖ₋₁ × 10ᵏ⁻¹ + ... + S₁ × 10¹ + S₀ × 10⁰ + S₋₁ × 10⁻¹ + ... + S₋ₗ × 10⁻ˡ

其中 Sᵢ 是一個數字，b = 10 是基底，K 是整數部分的位數，L 是小數部分的位數。我們在表示中使用的小數點將小數部分與整數部分分開。

**範例 2.3**
以下顯示了實數 +24.13 的位值：
*   位值：10¹ 10⁰ . 10⁻¹ 10⁻²
*   數字：2 4 . 1 3
*   值：R = + 2 × 10 + 4 × 1 + 1 × 0.1 + 3 × 0.01

### 2.2.2 二進位系統（基底為 2）
我們在本章討論的第二個進位制數字系統是**二進位系統**。「binary」一詞源於拉丁詞根 *bini*（或二乘二）。在這個系統中，基底 b = 2，我們只使用兩個符號 S = {0, 1}。這個系統中的符號通常被稱為**二進位數字**或**位元** (bit)。正如我們將在第 3 章中看到的，資料和程式使用二進位模式（一串位元）儲存在電腦中。這是因為電腦由只能有兩種狀態（開和關）的電子開關組成。位元 1 代表這兩種狀態之一，位元 0 代表另一種。

**整數**
我們可以將整數表示為 ± (Sₖ₋₁ ... S₁ S₀)₂。其值計算如下：

N = ± Sₖ₋₁ × 2ᵏ⁻¹ + Sₖ₋₂ × 2ᵏ⁻² + ... + S₂ × 2² + S₁ × 2¹ + S₀ × 2⁰

其中 Sᵢ 是一個數字，b = 2 是基底，K 是位元數。顯示二進位數字的另一種方法是使用位值（2⁰, 2¹, ... 2ᵏ⁻¹）。

**範例 2.4**
以下顯示二進位數字 (11001)₂ 與十進位數字 25 相同。下標 2 表示基底為 2：
*   位值：2⁴ 2³ 2² 2¹ 2⁰
*   數字：1 1 0 0 1
*   十進位：N = 1 × 2⁴ + 1 × 2³ + 0 × 2² + 0 × 2¹ + 1 × 2⁰
請注意，等價的十進位數字是 N = 16 + 8 + 0 + 0 + 1 = 25。

**最大值**
具有 K 位數的二進位整數的最大值是 N_max = 2ᴷ – 1。例如，如果 K = 5，則最大值為 N_max = 2⁵ – 1 = 31。

**實數**
二進位系統中的實數——帶有可選小數部分的數字——可以由左邊的 K 個位元和右邊的 L 個位元組成，即 ± (Sₖ₋₁ ... S₁ S₀ . S₋₁ ... S₋ₗ)₂。其值計算如下：

R = ± Sₖ₋₁ × 2ᵏ⁻¹ x ... x S₁ × 2¹ x S₀ × 2⁰ + S₋₁ × 2⁻¹ + ... + S₋ₗ × 2⁻ˡ

其中 Sᵢ 是一個位元，b = 2 是基底，K 是小數點左邊的位元數，L 是小數點右邊的位元數。請注意，K 從 0 開始，但 L 從 -1 開始。最高冪次是 K – 1，最低冪次是 -L。

**範例 2.5**
以下顯示二進位數字 (101.11)₂ 等於十進位數字 5.75：
*   位值：2² 2¹ 2⁰ . 2⁻¹ 2⁻²
*   數字：1 0 1 . 1 1
*   值：R = 1 × 2² + 0 × 2¹ + 1 × 2⁰ + 1 × 2⁻¹ + 1 × 2⁻²
請注意，十進位系統中的值是 R = 4 + 0 + 1 + 0.5 + 0.25 = 5.75。

### 2.2.3 十六進位系統（基底為 16）
雖然二進位系統用於在電腦中儲存資料，但它不便於在電腦外部表示數字，因為二進位表示法的數字比相應的十進位表示法長得多。然而，十進位系統並不能直接顯示電腦中儲存的二進位內容——二進位位數和十進位位數之間沒有明顯的關係。從一種轉換到另一種並不快，我們稍後會看到。

為了克服這個問題，設計了兩種進位制系統：十六進位和八進位。我們首先討論較常見的十六進位系統。**十六進位**（Hexadecimal）一詞源於希臘詞根 *hex*（六）和拉丁詞根 *decem*（十）。為了與十進位和二進位保持一致，它實際上應該被稱為 *sexadecimal*，源自拉丁詞根 *sex* 和 *decem*。在這個系統中，基底 b = 16，我們使用 16 個符號來表示數字。符號集合為 S = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F}。請注意，符號 A, B, C, D, E, F（大寫或小寫）分別相當於 10, 11, 12, 13, 14 和 15。這個系統中的符號通常被稱為**十六進位數字**。

**整數**
我們可以將整數表示為 ± Sₖ₋₁ ... S₁ S₀。其值計算如下：

N = ± Sₖ₋₁ × 16ᵏ⁻¹ + Sₖ₋₂ × 16ᵏ⁻² + ... + S₂ × 16² + S₁ × 16¹ + S₀ × 16⁰

其中 Sᵢ 是一個數字，b = 16 是基底，K 是位數。
顯示十六進位數字的另一種方法是使用位值（16⁰, 16¹, ..., 16ᵏ⁻¹）。

**範例 2.6**
以下顯示十六進位數字 (2AE)₁₆ 等於十進位數字 686：
*   位值：16² 16¹ 16⁰
*   數字：2 A E
*   值：N = 2 × 16² + 10 × 16¹ + 14 × 16⁰
請注意，十進位系統中的值是 N = 512 + 160 + 14 = 686。

**最大值**
具有 K 位數的十六進位整數的最大值是 N_max = 16ᴷ – 1。例如，如果 K = 5，則最大值為 N_max = 16⁵ – 1 = 1048575。

**實數**
雖然實數也可以在十六進位系統中表示，但這不是很常見。

### 2.2.4 八進位系統（基底為 8）
第二個為在電腦外部顯示二進位系統等價值而設計的系統是**八進位系統**。*Octal* 一詞源於拉丁詞根 *octo*（八）。在這個系統中，基底 b = 8，我們使用八個符號來表示數字。符號集合為 S = {0, 1, 2, 3, 4, 5, 6, 7}。這個系統中的符號通常被稱為**八進位數字**。

**整數**
我們可以將整數表示為 ± Sₖ₋₁ ... S₁ S₀。其值計算如下：

N = ± Sₖ₋₁ × 8ᵏ⁻¹ + Sₖ₋₂ × 8ᵏ⁻² + ... + S₂ × 8² + S₁ × 8¹ + S₀ × 8⁰

其中 Sᵢ 是一個數字，b = 8 是基底，K 是位數。
顯示八進位數字的另一種方法是使用位值（8⁰, 8¹, ..., 8ᵏ⁻¹）。

**範例 2.7**
以下顯示八進位數字 (1256)₈ 與十進位數字 686 相同：
*   位值：8³ 8² 8¹ 8⁰
*   數字：1 2 5 6
*   值：N = 1 × 8³ + 2 × 8² + 5 × 8¹ + 6 × 8⁰
請注意，十進位數字是 N = 512 + 128 + 40 + 6 = 686。

**最大值**
具有 K 位數的八進位整數的最大值是 N_max = 8ᴷ – 1。例如，如果 K = 5，則最大值為 N_max = 8⁵ – 1 = 32767。

**實數**
雖然實數也可以在八進位系統中表示，但這不是很常見。

### 2.2.5 四種進位制系統摘要
表 2.1 顯示了本章討論的四種進位制數字系統的摘要。

**表 2.1 四種進位制數字系統摘要**
| 系統 | 基底 | 符號 | 範例 |
| :--- | :--- | :--- | :--- |
| 十進位 | 10 | 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 | 2345.56 |
| 二進位 | 2 | 0, 1 | (1001.11)₂ |
| 八進位 | 8 | 0, 1, 2, 3, 4, 5, 6, 7 | (156.23)₈ |
| 十六進位 | 16 | 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F | (A2C.A1)₁₆ |

表 2.2 顯示了數字 15 如何在十進位中用兩位數表示，在二進位中用四位數，在八進位中用兩位數，而在十六進位中僅用一位數表示。十六進位表示法無疑是最短的。

**表 2.2 四種系統中的數字比較**
| 十進位 | 二進位 | 八進位 | 十六進位 |
| :--- | :--- | :--- | :--- |
| 0 | 0 | 0 | 0 |
| 1 | 1 | 1 | 1 |
| 2 | 10 | 2 | 2 |
| 3 | 11 | 3 | 3 |
| 4 | 100 | 4 | 4 |
| 5 | 101 | 5 | 5 |
| 6 | 110 | 6 | 6 |
| 7 | 111 | 7 | 7 |
| 8 | 1000 | 10 | 8 |
| 9 | 1001 | 11 | 9 |
| 10 | 1010 | 12 | A |
| 11 | 1011 | 13 | B |
| 12 | 1100 | 14 | C |
| 13 | 1101 | 15 | D |
| 14 | 1110 | 16 | E |
| 15 | 1111 | 17 | F |

### 2.2.6 轉換
我們需要知道如何將一個系統中的數字轉換為另一個系統中的等價數字。由於十進位系統比其他系統更熟悉，我們首先展示如何從任意基底轉換為十進位。然後我們展示如何從十進位轉換為任意基底。最後，我們展示如何輕鬆地將二進位轉換為十六進位或八進位，反之亦然。

**任意基底轉十進位**
這種類型的轉換既簡單又快速。我們將每個數字與其在來源系統中的位值相乘，並將結果相加，得到十進位系統中的數字。

**範例 2.8**
以下顯示如何將二進位數字 (110.11)₂ 轉換為十進位：(110.11)₂ = 6.75：
*   二進位：1 1 0 . 1 1
*   位值：2² 2¹ 2⁰ . 2⁻¹ 2⁻²
*   部分結果：4 + 2 + 0 + 0.5 + 0.25
*   十進位：6.75

**範例 2.9**
以下顯示如何將十六進位數字 (1A.23)₁₆ 轉換為十進位：
*   十六進位：1 A . 2 3
*   位值：16¹ 16⁰ . 16⁻¹ 16⁻²
*   部分結果：16 + 10 + 0.125 + 0.012
*   十進位：26.137
請注意，十進位表示法中的結果並不精確，因為 3 × 16⁻² = 0.01171875。我們將此值四捨五入到小數點後三位 (0.012)。換句話說，(1A.23)₁₆ ≈ 26.137。當我們將十進位數字轉換為十六進位時，我們需要指定允許小數點右邊有多少位數。

**範例 2.10**
以下顯示如何將 (23.17)₈ 轉換為十進位：
*   八進位：2 3 . 1 7
*   位值：8¹ 8⁰ . 8⁻¹ 8⁻²
*   部分結果：16 + 3 + 0.125 + 0.109
*   十進位：19.234
這意味著 (23.17)₈ ≈ 19.234 (十進位)。同樣，我們將 7 × 8⁻² = 0.109375 向上取整。

**十進位轉任意基底**
我們可以將十進位數字轉換為其在任意基底中的等價值。我們需要兩個程序，一個用於整數部分，一個用於小數部分。

**轉換整數部分**
整數部分可以使用重複除法轉換。我們將十進位數字的整數部分稱為來源，轉換後數字的整數部分稱為目的地。我們先建立一個空的目的地。然後我們重複地除以來源以獲得商和餘數。餘數被插入到目的地的左邊。商成為新的來源。

**範例 2.11**
以下顯示如何將十進位 35 轉換為二進位。我們從十進位數字開始，向左移動，同時不斷找出除以 2 的商和餘數。結果是 35 = (100011)₂：
*   十進位：35
*   除以 2：35/2 -> 商=17, 餘=1
*   除以 2：17/2 -> 商=8, 餘=1
*   除以 2：8/2 -> 商=4, 餘=0
*   除以 2：4/2 -> 商=2, 餘=0
*   除以 2：2/2 -> 商=1, 餘=0
*   除以 2：1/2 -> 商=0, 餘=1
*   二進位：100011

**範例 2.12**
以下顯示如何將十進位 126 轉換為其在八進位系統中的等價值。我們向右移動，同時不斷找出除以 8 的商和餘數。結果是 126 = (176)₈：
*   十進位：126
*   除以 8：126/8 -> 商=15, 餘=6
*   除以 8：15/8 -> 商=1, 餘=7
*   除以 8：1/8 -> 商=0, 餘=1
*   八進位：176

**範例 2.13**
以下顯示我們如何將十進位 126 轉換為其在十六進位系統中的等價值。我們向右移動，同時不斷找出除以 16 的商和餘數。結果是 126 = (7E)₁₆：
*   十進位：126
*   除以 16：126/16 -> 商=7, 餘=14 (E)
*   除以 16：7/16 -> 商=0, 餘=7
*   十六進位：7E

**轉換小數部分**
小數部分可以使用重複乘法轉換。我們將十進位數字的小數部分稱為來源，轉換後數字的小數部分稱為目的地。我們先建立一個空的目的地。然後我們重複地乘以來源以獲得結果。結果的整數部分被插入到目的地的右邊，而小數部分成為新的來源。

**範例 2.14**
將十進位數字 0.625 轉換為二進位。
解答：由於數字 0.625 沒有整數部分，該範例顯示了如何計算小數部分。這裡的基底是 2。在左上角寫下十進位數字。將該數字不斷乘以 2，並記錄結果的整數和小數部分。小數部分向右移動，整數部分記錄在每個操作下方。當小數部分為 0 或有足夠的位數時停止。結果是 (0.101)₂：
*   0.625 * 2 = 1.25 -> I=1, F=0.25
*   0.25 * 2 = 0.50 -> I=0, F=0.50
*   0.50 * 2 = 1.00 -> I=1, F=0.00
*   二進位：.101

**範例 2.15**
以下顯示如何使用最多四位數將 0.634 轉換為八進位。結果是 0.634 = (0.5044)₈。請注意，我們乘以 8（八進位基底）：
*   0.634 * 8 = 5.072 -> I=5
*   0.072 * 8 = 0.576 -> I=0
*   0.576 * 8 = 4.608 -> I=4
*   0.608 * 8 = 4.864 -> I=4
*   八進位：.5044

**範例 2.16**
以下顯示如何將十進位 178.6 轉換為十六進位，且小數點右邊僅保留一位數。結果是 178.6 = (B2.9)₁₆ 請注意，我們除以或乘以 16（十六進位基底）：
*   整數部分 178：178/16 -> 商=11 (B), 餘=2 -> B2
*   小數部分 0.6：0.6 * 16 = 9.6 -> I=9
*   十六進位：B2.9

**範例 2.17**
將小十進位整數（通常小於 256）轉換為二進位的另一種方法是將數字分解為等於二進位位值的數字之和。使用此表，我們可以將 165 轉換為二進位 (10100101)₂，如下所示：
165 = 128 + 0 + 32 + 0 + 0 + 4 + 0 + 1 -> 10100101

**範例 2.18**
當分母是 2 的冪時，可以使用類似的方法將十進位分數轉換為二進位。使用此表，我們將 27/64 轉換為二進位 (0.011011)₂，如下所示：
27/64 = 0 + 1/4 + 1/8 + 0 + 1/32 + 1/64 -> 0.011011

**位數**
在將數字從十進位轉換為其他基底之前，我們經常需要知道位數。在基底為 b 的進位制數字系統中，我們總是可以使用關係式 K = ⌈log_b N⌉ 來找到整數的位數，其中 ⌈x⌉ 表示大於或等於 x 的最小整數（也稱為 x 的上限），N 是整數的十進位值。

**二進位–十六進位轉換**
我們可以輕鬆地將數字從二進位轉換為十六進位，反之亦然。原因是這兩個基底之間存在關係：二進位中的四個位元是十六進位中的一個數字。

**範例 2.19**
顯示二進位數字 (10011100010)₂ 的十六進位等價值。
解答：我們先將二進位數字排列成 4 位元的模式：100 1110 0010。請注意，最左邊的模式可以有一到四個位元。然後我們使用 2.2.5 節表 2.2 中顯示的每個模式的等價值將數字更改為十六進位：(4E2)₁₆。

**範例 2.20**
(24C)₁₆ 的二進位等價值是多少？
解答：每個十六進位數字轉換為 4 位元模式：2 → 0010, 4 → 0100, 和 C → 1100。結果是 (001001001100)₂。

**二進位–八進位轉換**
我們可以輕鬆地將數字從二進位轉換為八進位，反之亦然。原因是這兩個基底之間存在有趣的關係：三個位元是一個八進位數字。

**範例 2.21**
顯示二進位數字 (101110010)₂ 的八進位等價值。
解答：每組三個位元被翻譯成一個八進位數字。每個 3 位元組的等價值顯示在 2.2.5 節的表 2.2 中。結果是 (562)₈。

**範例 2.22**
(24)₈ 的二進位等價值是多少？
解答：將每個八進位數字寫成其等價的位元模式，得到 (010100)₂。

**八進位–十六進位轉換**
將八進位數字轉換為十六進位或反之亦然並不困難。我們可以使用二進位系統作為中間系統。
*   要從八進位轉換為十六進位，我們先將八進位系統中的數字轉換為二進位。然後我們將位元重新排列成四位一組，以找到十六進位等價值。
*   要從十六進位轉換為八進位，我們先將十六進位系統中的數字轉換為二進位。然後我們將位元重新排列成三位一組，以找到八進位等價值。

**位數**
在從一個基底轉換到另一個基底時，如果我們知道來源系統中的最大位數，我們經常需要知道目的地系統中所需的最小位數。一般來說，假設我們在基底 b₁ 系統中使用 K 位數。我們可以在來源系統中表示的最大數字是 b₁ᴷ – 1。我們可以在目的地系統中擁有的最大數字是 b₂ˣ – 1。因此，b₂ˣ – 1 ≥ b₁ᴷ – 1。這意味著 x ≥ K × (log b₁ / log b₂)。

**範例 2.23**
找出儲存最多六位數十進位整數所需的最小二進位位數。
解答：K = 6, b₁ = 10, 且 b₂ = 2。那麼 x = ⌈6 × (log 10 / log 2)⌉ = ⌈6 × 3.322⌉ = ⌈19.93⌉ = 20。

## 2.3 非進位制數字系統
雖然非進位制數字系統不用於電腦，但我們在此簡要回顧以與進位制數字系統進行比較。**非進位制數字系統**仍然使用有限數量的符號，其中每個符號都有一個值。然而，符號在數字中所佔的位置通常與其值無關——每個符號的值是固定的。要找到一個數字的值，我們將表示中所有符號的值相加。

**範例 2.24**
**羅馬數字系統**是非進位制數字系統的一個很好的例子。這個系統由羅馬人發明，並在歐洲使用到十六世紀。羅馬數字仍用於體育賽事、鐘面和其他應用。這個數字系統有一組符號 S = {I, V, X, L, C, D, M}。每個符號的值顯示在表 2.3 中。

**表 2.3 羅馬數字系統中符號的值**
| 符號 | I | V | X | L | C | D | M |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 值 | 1 | 5 | 10 | 50 | 100 | 500 | 1000 |

要找到一個數字的值，我們需要將符號的值相加，但要遵守特定規則：
1.  當一個值較小的符號放在一個值相等或較大的符號後面時，這些值相加。
2.  當一個值較小的符號放在一個值較大的符號前面時，較小的值從較大的值中減去。
3.  如果 S₁ ≤ 10 × S₂，則符號 S₁ 不能在另一個符號 S₂ 之前。例如，I 或 V 不能在 C 之前。
4.  對於大數字，在六個符號中的任何一個（除 I 以外的所有符號）上方放置一條橫線表示乘以 1000。例如，V̅ = 5000 和 M̅ = 1000000。
5.  雖然羅馬人使用單詞 *nulla*（無）來傳達零的概念，但羅馬數字系統中缺乏零數字。

以下顯示了一些羅馬數字及其值：
*   III → 1 + 1 + 1 = 3
*   IV → 5 – 1 = 4
*   VIII → 5 + 1 + 1 + 1 = 8
*   XVIII → 10 + 5 + 1 + 1 + 1 = 18
*   XIX → 10 + (10 – 1) = 19
*   LXXII → 50 + 10 + 10 + 1 + 1 = 72
*   CI → 100 + 1 = 101
*   MMVII → 1000 + 1000 + 5 + 1 + 1 = 2007
*   MDC → 1000 + 500 + 100 = 1600

## 2.4 章末材料
### 2.4.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
*   Stalling, W. *Computer Organization and Architecture*, Upper Saddle River, NJ: Prentice-Hall, 2000
*   Mano, M. *Computer System Architecture*, Upper Saddle River, NJ: Prentice-Hall, 1993
*   Null, L. and Lobur, J. *Computer Organization and Architecture*, Sudbury, MA: Jones and Bartlett, 2003
*   Brown, S. and Vranesic, Z. *Fundamentals of Digital Logic with Verilog Design*, New York: McGraw-Hill, 2003

### 2.4.2 關鍵詞
*   基底 (base)
*   二進位數字 (binary digit)
*   二進位系統 (binary system)
*   位元 (bit)
*   十進位數字 (decimal digit)
*   十進位系統 (decimal system)
*   十六進位數字 (hexadecimal digit)
*   十六進位系統 (hexadecimal system)
*   整數 (integer)
*   非進位制數字系統 (nonpositional number system)
*   數字系統 (number system)
*   八進位數字 (octal digit)
*   八進位系統 (octal system)
*   位值 (place value)
*   進位制數字系統 (positional number system)
*   基數 (radix)
*   實數 (real)
*   羅馬數字系統 (Roman number system)

### 2.4.3 摘要
*   數字系統（或計數系統）是一個使用不同符號來表示數字的系統。在進位制數字系統中，符號在數字中所佔的位置決定了它所代表的值。每個位置都有一個與之相關聯的位值。非進位制數字系統使用有限數量的符號，其中每個符號都有一個值。然而，符號在數字中所佔的位置通常與其值無關：每個符號的值通常是固定的。
*   在十進位系統中，基底 b = 10，我們使用十個符號來表示數字。這個系統中的符號通常被稱為十進位數字或簡稱數字。在二進位系統中，基底 b = 2，我們只使用兩個符號來表示數字。這個系統中的符號通常被稱為二進位數字或位元。在十六進位系統中，基底 = 16，我們使用 16 個符號來表示數字。這個系統中的符號通常被稱為十六進位數字。在八進位系統中，基底 b = 8，我們使用八個符號來表示數字。這個系統中的符號通常被稱為八進位數字。
*   我們可以將任何系統中的數字轉換為十進位。我們將每個數字與其在來源系統中的位值相乘，並將結果相加，得到十進位系統中的數字。我們可以使用兩個不同的程序將十進位數字轉換為其在任何基底中的等價值，一個用於整數部分，一個用於小數部分。整數部分需要重複除法，小數部分需要重複乘法。
*   從二進位系統轉換到十六進位系統以及從十六進位系統轉換到二進位系統非常容易，因為二進位系統中的四個位元在十六進位系統中表示為一個數字。
*   從二進位系統轉換到八進位系統以及從八進位系統轉換到二進位系統非常容易，因為二進位系統中的三個位元在八進位系統中表示為一個數字。
`},i={en:`
# Chapter 3: Data Storage

As discussed in Chapter 1, a computer is a programmable data processing machine. Before we can talk about processing data, we need to understand the nature of data. In this chapter we discuss different data types and how they are stored inside a computer. In Chapter 4, we show how data is manipulated inside a computer.

## Objectives
After studying this chapter, the student should be able to:
- List five different data types used in a computer.
- Describe how different data is stored inside the computer as bit patterns.
- Describe how integers are stored in a computer using unsigned format.
- Describe how integers are stored in a computer using sign-and-magnitude format.
- Describe how integers are stored in two’s complement format.
- Describe how reals are stored in a computer using floating-point format.
- Describe how text is stored in a computer using one of the various encoding systems.
- Describe how audio is stored in a computer using sampling, quantization, and encoding.
- Describe how images are stored in a computer using raster and vector graphics schemes.
- Describe how video is stored in a computer as a representation of images changing in time.

## 3.1 DATA TYPES
Data today come in different forms including numbers, text, audio, images, and video (Figure 3.1).
People need to be able to process many different types of data:
- An engineering program uses a computer mainly to process numbers: to do arithmetic, to solve algebraic or trigonometric equations, to find the roots of a differential equation, and so on.
- A word processing program, on the other hand, uses a computer mainly to process text: justify, move, delete, and so on.
- A computer also handles audio data. We can play music on a computer and can record sound as data.
- An image processing program uses a computer to manipulate images: create, shrink, expand, rotate, and so on.
- Finally, a computer can be used not only to show movies, but also to create the special effects seen in movies.

The computer industry uses the term **'multimedia'** to define information that contains numbers, text, audio, images, and video.

### 3.1.1 Data inside the computer
All data types are transformed into a uniform representation when they are stored in a computer and transformed back to their original form when retrieved. This universal representation is called a **bit pattern**, as discussed shortly.

#### Bits
A **bit** (binary digit) is the smallest unit of data that can be stored in a computer and has a value of 0 or 1. A bit represents the state of a device that can take one of two states. For example, a switch can be on or off. A convention can be established to represent the ‘on’ state as 1 and the ‘off’ state as 0, or vice versa. In this way, a switch can store one bit of information. Today, computers use various two-state devices to store data.

#### Bit patterns
To represent different types of data, we use a **bit pattern**, a sequence, or as it is sometimes called, a string of bits. Figure 3.2 shows a bit pattern made up of sixteen bits. It is a combination of sixteen 0s and 1s. This means that if we need to store a bit pattern made of sixteen bits, we need sixteen electronic switches. If we need to store 1000 bit patterns, each sixteen bits long, we need 16 000 switches, and so on. By tradition a bit pattern with eight bits is called a **byte**. Sometimes the term **word** is used to refer to a longer bit pattern.

As Figure 3.3 shows, a piece of data belonging to different data types can be stored as the same pattern in the memory.

If we are using a **text editor** (a word processor), the character A typed on the keyboard can be stored as the 8-bit pattern 01000001. The same 8-bit pattern can represent the number 65 if we are using a mathematical routine. Moreover, the same pattern can represent part of an image, part of a song, or part of a scene in a film. The computer’s memory stores all of them without recognizing what type of data they represent.

### 3.1.2 Data compression
To occupy less memory space, data is normally compressed before being stored in the computer. Data compression is a very broad and involved subject, so we have dedicated the whole of Chapter 15 to this subject.

### 3.1.3 Error detection and correction
Another issue related to data is the detection and correction of errors during transmission or storage. We discuss this issue briefly in Appendix H.

## 3.2 STORING NUMBERS
A number is changed to the binary system before being stored in the computer memory, as described in Chapter 2. However, there are still two issues that need to be handled:
1.  How to store the sign of the number.
2.  How to show the decimal point.

There are several ways to handle the sign issue, discussed later in this chapter. For the decimal point, computers use two different representations: **fixed-point** and **floating-point**. The first is used to store a number as an integer—without a fractional part, the second is used to store a number as a real—with a fractional part.

### 3.2.1 Storing integers
Integers are whole numbers (numbers without a fractional part). For example, 134 and -125 are integers, whereas 134.23 and -0.235 are not. An integer can be thought of as a number in which the position of the decimal point is fixed: the decimal point is to the right of the least significant (rightmost) bit. For this reason, **fixed-point representation** is used to store an integer, as shown in Figure 3.4. In this representation the decimal point is assumed but not stored.

However, a user (or a program) may store an integer as a real with the fractional part set to zero. This may happen, for example, if an integer is too large to be stored in the size defined for an integer. To use computer memory more efficiently, unsigned and signed integers are stored inside the computer differently.

**An integer is normally stored in memory using fixed-point representation.**

#### Unsigned representation
An **unsigned integer** is an integer that can never be negative and can take only 0 or positive values. Its range is between 0 and positive infinity. However, since no computer can possibly represent all the integers in this range, most computers define a constant called the **maximum unsigned integer**, which has the value of $(2^n - 1)$ where $n$ is the number of bits allocated to represent an unsigned integer.

**Storing unsigned integers**
An input device stores an unsigned integer using the following steps:
1.  The integer is changed to binary.
2.  If the number of bits is less than $n$, 0s are added to the left of the binary integer so that there is a total of $n$ bits. If the number of bits is greater than $n$, the integer cannot be stored. A condition referred to as **overflow** will occur, which we discuss later.

> **Example 3.1**
> Store 7 in an 8-bit memory location using unsigned representation.
>
> **Solution**
> First change the integer to binary, $(111)_2$. Add five 0s to make a total of eight bits, $(00000111)_2$. The integer is stored in the memory location. Note that the subscript 2 is used to emphasize that the integer is binary, but the subscript is not stored in the computer:
> Change 7 to binary → 1 1 1
> Add five bits at the left → 0 0 0 0 0 1 1 1

> **Example 3.2**
> Store 258 in a 16-bit memory location.
>
> **Solution**
> First change the integer to binary $(100000010)_2$. Add seven 0s to make a total of sixteen bits $(0000000100000010)_2$. The integer is stored in the memory location:
> Change 258 to binary → 1 0 0 0 0 0 0 1 0
> Add seven bits at the left → 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0

**Retrieving unsigned integers**
An output device retrieves a bit string from memory as a bit pattern and converts it to an unsigned decimal integer.

> **Example 3.3**
> What is returned from an output device when it retrieves the bit string 00101011 stored in the memory as an unsigned integer?
>
> **Solution**
> Using the procedure shown in Chapter 2, the binary integer is converted to the unsigned integer 43.

**Overflow**
Due to size limitations—the allocated number of bits—the range of integers that can be represented is limited. In an $n$-bit memory location we can only store an unsigned integer between 0 and $2^n - 1$. Figure 3.5 shows what happens if we try to store an integer that is larger than $2^4 - 1 = 15$ in a memory location that can only hold four bits. This situation, called **overflow**, happens when, for example, we have stored the integer 11 in a memory location and then try to add 9 to the integer. The minimum number of bits we need to represent the decimal 20 is five bits. In other words, $20 = (10100)_2$, so the computer drops the leftmost bit and keeps the rightmost four bits $(0100)_2$. People are surprised when they see that the new integer is printed as 4 instead of 20. Figure 3.5 shows why this happens.

**Applications of unsigned integers**
Unsigned integer representation can improve the efficiency of storage because we do not need to store the sign of the integer. This means that the entire bit allocation can be used for storing the number. Unsigned integer representation can be used whenever we do not need negative integers. The following lists some cases:
- **Counting.** When we count, we do not need negative numbers. We start counting from 1 (sometimes 0) and go up.
- **Addressing.** Some computer programs store the address of a memory location inside another memory location. Addresses are positive integers starting from 0 (the first memory location) and going up to an integer representing the total memory capacity. Here again, we do not need negative integers—unsigned integers can easily do the job.
- **Storing other data types.** Other data types (text, images, audio, and video), as we will discuss shortly, are stored as bit patterns, which can be interpreted as unsigned integers.

#### Sign-and-magnitude representation
Although the **sign-and-magnitude representation** format is not commonly used to store integers, this format is used to store part of a real number in a computer, as described in the next section. For this reason we briefly discuss this format here. In this method, the available range for unsigned integers ($0$ to $2^n - 1$) is divided into two equal subranges. The first half represents positive integers, the second half, negative integers. For example, if $n$ is 4, the range is 0000 to 1111. This range is divided into two halves: 0000 to 0111 and 1000 to 1111 (Figure 3.6). The bit patterns are then assigned to negative and positive integers. Note that the negative numbers appear to the right of the positive numbers, which is contrary to conventional thinking about positive and negative numbers. Also note that we have two 0s: positive zero (0000) and negative zero (1000).

Storing an integer in sign-and-magnitude format requires 1 bit to represent the sign (0 for positive, 1 for negative). This means that in an 8-bit allocation, we can only use seven bits to represent the absolute value of the number (number without the sign). Therefore, the maximum positive value is one half the unsigned value. The range of numbers that can be stored in an $n$-bit location is $-(2^{n-1} -1)$ to $+ (2^{n-1} -1)$. In an $n$-bit allocation, the leftmost bit is dedicated to store the sign (0 for positive, 1 for negative).

**In sign-and-magnitude representation, the leftmost bit defines the sign of the integer. If it is 0, the integer is positive. If it is 1, the integer is negative.**

> **Example 3.4**
> Store +28 in an 8-bit memory location using sign-and-magnitude representation.
>
> **Solution**
> The integer is changed to 7-bit binary. The leftmost bit is set to 0. The 8-bit number is stored:
> Change 28 to 7-bit binary: 0 0 1 1 1 0 0
> Add the sign and store: 0 0 0 1 1 1 0 0

> **Example 3.5**
> Store -28 in an 8-bit memory location using sign-and-magnitude representation.
>
> **Solution**
> The integer is changed to 7-bit binary. The leftmost bit is set to 1. The 8-bit number is stored:
> Change 28 to 7-bit binary: 0 0 1 1 1 0 0
> Add the sign and store: 1 0 0 1 1 1 0 0

> **Example 3.6**
> Retrieve the integer that is stored as 01001101 in sign-and-magnitude representation.
>
> **Solution**
> Since the leftmost bit is 0, the sign is positive. The rest of the bits (1001101) are changed to decimal as 77. After adding the sign, the integer is +77.

> **Example 3.7**
> Retrieve the integer that is stored as 10100001 in sign-and-magnitude representation.
>
> **Solution**
> Since the leftmost bit is 1, the sign is negative. The rest of the bits (0100001) are changed to decimal as 33. After adding the sign, the integer is -33.

**Overflow in sign-and-magnitude representation**
Like unsigned integers, signed integers are also subjected to overflow. However, in this case, we may have both positive and negative overflow. Figure 3.7 shows both positive and negative overflow when storing an integer in sign-and-magnitude representation using a 4-bit memory location. Positive overflow occurs when we try to store a positive integer larger than 7. For example, assume that we have stored integer 5 in a memory location and we then try to add 6 to the integer. We expect the result to be 11, but the computer’s response is –3. The reason is that if we start from 5 on a circular representation and go six units in the clockwise direction, we end up at –3. A positive overflow wraps the integer back to the range.
A negative overflow can happen when we try to store a integer that is less than –7, for example if we have stored the integer –5 in a memory and try to subtract 7 from it. We expect the result to be –12, but the computer’s response is +6. The reason is that if we start from –5 on a circular representation and go seven units in the counterclockwise direction, we end up at +6.

**There are two 0s in sign-and-magnitude representation: +0 and −0.**

**Applications of sign-and-magnitude representation**
Sign-and-magnitude representation is not used to store integers. However, it is used to store part of real numbers, as we will see shortly. In addition, sign-and-magnitude representation is often used when we quantize an analog signal, such as audio.

#### Two’s complement representation
Almost all computers use **two’s complement representation** to store a signed integer in an $n$-bit memory location. In this method, the available range for an unsigned integer of ($0$ to $2^n - 1$) is divided into two equal subranges. The first subrange is used to represent nonnegative integers, the second half to represent negative integers. For example, if $n$ is 4, the range is 0000 to 1111. This range is divided into two halves: 0000 to 0111 and 1000 to 1111. The two halves are swapped to be in agreement with the common convention of showing negative integers to the left of positive integers. The bit patterns are then assigned to negative and nonnegative (zero and positive) integers as shown in Figure 3.8.

Although the sign of the integer affects every bit in the binary integer stored, the first (leftmost) bit determines the sign. If the leftmost bit is 0, the integer is nonnegative: if the leftmost bit is 1, the integer is negative.

**In two’s complement representation, the leftmost bit defines the sign of the integer. If it is 0, the integer is positive. If it is 1, the integer is negative.**

**Two operations**
Before we discuss this representation further, we need to introduce two operations. The first is called *one’s completing* or *taking the one’s complement of an integer*. The operation can be applied to any integer, positive or negative. This operation simply reverses (flips) each bit. A 0-bit is changed to a 1-bit, a 1-bit is changed to a 0-bit.

> **Example 3.8**
> The following shows how we take the **one’s complement** of the integer 00110110:
> Original pattern: 0 0 1 1 0 1 1 0
> After applying one’s complement operation: 1 1 0 0 1 0 0 1

> **Example 3.9**
> The following shows that we get the original integer if we apply the one’s complement operations twice:
> Original pattern: 0 0 1 1 0 1 1 0
> One’s complementing once: 1 1 0 0 1 0 0 1
> One’s complementing twice: 0 0 1 1 0 1 1 0

The second operation is called *two’s completing* or *taking the two’s complement of an integer* in binary. This operation is done in two steps. First, we copy bits from the right until a 1 is copied, Then, we flip the rest of the bits.

> **Example 3.10**
> The following shows how we take the **two’s complement** of the integer 00110100:
> Original integer: 0 0 1 1 0 1 0 0
> Two’s complementing once: 1 1 0 0 1 1 0 0

> **Example 3.11**
> The following shows that we always get the original integer if we apply the two’s complement operation twice:
> Original integer: 0 0 1 1 0 1 0 0
> Two’s complementing once: 1 1 0 0 1 1 0 0
> Two’s complementing twice: 0 0 1 1 0 1 0 0

An alternative way to take the two’s complement of an integer is to first take the one’s complement and then add 1 to the result (see Chapter 4 for binary addition).

**Storing an integer in two’s complement format**
To store an integer in two’s complement representation, the computer follows the steps below:
- The absolute value of the integer is changed to an $n$-bit binary.
- If the integer is positive or zero, it is stored as it is: if it is negative, the computer takes the two’s complement of the integer and then stores it.

**Retrieving an integer in two’s complement format**
To retrieve an integer in two’s complement representation, the computer follows the steps below:
- If the leftmost bit is 1, the computer applies the two’s complement operation to the integer. If the leftmost bit is 0, no operation is applied.
- The computer changes the integer to decimal.

> **Example 3.12**
> Store the integer 28 in an 8-bit memory location using two’s complement representation.
>
> **Solution**
> The integer is positive (no sign means positive), so after decimal to binary transformation no more action is needed. Note that three extra 0s are added to the left of the integer to make it eight bits:
> Change 28 to 8-bit binary: 0 0 0 1 1 1 0 0

> **Example 3.13**
> Store -28 in an 8-bit memory location using two’s complement representation.
>
> **Solution**
> The integer is negative, so after changing to binary, the computer applies the two’s complement operation on the integer:
> Change 28 to 8-bit binary: 0 0 0 1 1 1 0 0
> Apply two’s complement operation: 1 1 1 0 0 1 0 0

> **Example 3.14**
> Retrieve the integer that is stored as 00001101 in memory in two’s complement format.
>
> **Solution**
> The leftmost bit is 0, so the sign is positive. The integer is changed to decimal and the sign is added:
> Leftmost bit is 0. The sign is positive. 0 0 0 0 1 1 0 1
> Integer changed to decimal: 13
> Sign is added: +13

> **Example 3.15**
> Retrieve the integer that is stored as 11100110 in memory using two’s complement format.
>
> **Solution**
> The leftmost bit is 1, so the integer is negative. The integer needs to be two’s complemented before changing to decimal:
> Leftmost bit is 1. The sign is negative. 1 1 1 0 0 1 1 0
> Apply two’s complement operation. 0 0 0 1 1 0 1 0
> Integer changed to decimal. 26
> Sign is added. -26

A very interesting point about two’s complement is that there is only one zero in this representation. In sign-and-magnitude representation, there are two zeros (+0 and -0).

**There is only one zero in two’s complement notation.**

**Overflow in two’s complement notation**
Like other representations, integers stored in two’s complement format are also subject to overflow. Figure 3.9 shows both positive and negative overflow when storing a signed integer in a 4-bit memory location. Positive overflow occurs when we try to store a positive integer larger than 7. For example, assume that we have stored an integer value 5 in a memory location and we then try to add 6 to the integer. We expect the result to be 11, but the computer’s response is –5. The reason is if we start from 5 on the circular representation and move six units in the clockwise direction, we end up at –5. The positive overflow wraps the integer back to the range.
A negative overflow can happen when we try to store an integer that is less than –8, for example if we have stored –3 and try to subtract 7 from it. We expect the result to be –10, but the computer’s response is +6. The reason is that if we start from –3 on a circular representation and go seven units in the counterclockwise direction, we end up at +6.

**Applications of two’s complement notation**
Two’s complement representation is the standard representation for storing integers in computers today. In the next chapter we will see why this is the case when we see the simplicity of operations using two’s complement.

### 3.2.2 Comparison of the three systems
Table 3.1 shows a comparison between unsigned, two’s complement, and sign-and-magnitude integers. A 4-bit memory location can store an unsigned integer between 0 and 15, and the same location can store two’s complement signed integers between -8 and +7. It is very important that we store and retrieve an integer in the same format. For example, if the integer 13 is stored in signed format, it needs to be retrieved in signed format: the same integer is retrieved as -3 in two’s complement format.

**Table 3.1 Summary of integer representations**

| Contents of memory | Unsigned | Sign-and-magnitude | Two’s complement |
| :--- | :--- | :--- | :--- |
| 0000 | 0 | 0 | +0 |
| 0001 | 1 | 1 | +1 |
| 0010 | 2 | 2 | +2 |
| 0011 | 3 | 3 | +3 |
| 0100 | 4 | 4 | +4 |
| 0101 | 5 | 5 | +5 |
| 0110 | 6 | 6 | +6 |
| 0111 | 7 | 7 | +7 |
| 1000 | 8 | -0 | -8 |
| 1001 | 9 | -1 | -7 |
| 1010 | 10 | -2 | -6 |
| 1011 | 11 | -3 | -5 |
| 1100 | 12 | -4 | -4 |
| 1101 | 13 | -5 | -3 |
| 1110 | 14 | -6 | -2 |
| 1111 | 15 | -7 | -1 |

### 3.2.3 Storing reals
A **real** is a number with an integral part and a fractional part. For example, 23.7 is a real number—the integral part is 23 and the fractional part is 7/10. Although a fixed-point representation can be used to represent a real number, the result may not be accurate or it may not have the required precision. The next two examples explain why.

> **Example 3.16**
> In the decimal system, assume that we use a fixed-point representation with two digits at the right of the decimal point and fourteen digits at the left of the decimal point, for a total of sixteen digits. The precision of a real number in this system is lost if we try to represent a decimal number such as 1.00234: the system stores the number as 1.00.

> **Example 3.17**
> In the decimal system, assume that we use a fixed-point representation with six digits to the right of the decimal point and ten digits for the left of the decimal point, for a total of sixteen digits. The accuracy of a real number in this system is lost if we try to represent a decimal number such as 236154302345.00. The system stores the number as 6154302345.00: the integral part is much smaller than it should be.

**Real numbers with very large integral parts or very small fractional parts should not be stored in fixed-point representation.**

#### Floating-point representation
The solution for maintaining accuracy or precision is to use **floating-point representation**. This representation allows the decimal point to float: we can have different numbers of digits to the left or right of the decimal point. The range of real numbers that can be stored using this method increases tremendously: numbers with large integral parts or small fractional parts can be stored in memory. In floating-point representation, either decimal or binary, a number is made up of three sections, as shown in Figure 3.10.

The first section is the sign, either positive or negative. The second section shows how many places the decimal point should be shifted to the right or left to form the actual number. The third section is a fixed-point representation in which the position of the decimal is fixed.

**A floating-point representation of a number is made up of three parts: a sign, a shifter, and a fixed-point number.**

Floating-point representation is used in science to represent very small or very large decimal numbers. In this representation, which is called **scientific notation**, the fixed-point section has only one digit to the left of the decimal point and the shifter is the power of 10.

> **Example 3.18**
> The following shows the decimal number 7425000000000000000000.00 in scientific notation (floating-point representation):
>
> **Solution**
> Actual number → + 7425000000000000000000.00
> Scientific notation → + 7.425 × 10²¹

The three sections are the sign (+), the shifter (21), and the fixed-point part (7.425). Note that the shifter is the exponent. We can easily see the advantage of this. Even if we just want to write the number on a piece of paper, the scientific notation is shorter and takes less space. The notation uses the concept of floating-point because the position of the decimal point, which is near the right-hand end in the example, has moved 21 digits to the left to make the fixed-point part of the number. Some programming languages and calculators show the number as +7.425E21 because the base 10 is understood and does not need to be mentioned.

> **Example 3.19**
> Show the number -0.0000000000000232 in scientific notation.
>
> **Solution**
> We use the same approach as in the previous example—we move the decimal point after the digit 2, as shown below:
> Actual number → - 0.0000000000000232
> Scientific notation → - 2.32 × 10⁻¹⁴
> Note that the exponent is negative here because the decimal point in 2.32 needs to move to the left (fourteen positions) to form the original number. Again, we can say that the number in this notation is made of three parts: sign (-), the real number (2.32), and the negative integer (-14). Some programming languages and calculators show this as -2.32E-14.

Similar approaches have been used to represent very large or very small numbers (both integers and reals) in binary, to be stored in computers.

> **Example 3.20**
> Show the number $(101001000000000000000000000000000.00)_2$ in floating-point format.
>
> **Solution**
> We use the same idea, keeping only one digit to the left of the decimal point:
> Actual number → + $(101001000000000000000000000000000.00)_2$
> Scientific notation → + $1.01001 × 2^{32}$

Note that we don’t have to worry about all those 0s at the right of the rightmost 1, because they are not significant when we use the real $(1.01001)_2$. The exponent is shown as 32, but it is actually stored in the computer in binary, as we will see shortly. We have also shown the sign as positive, but it would be stored as one bit.

> **Example 3.21**
> Show the number $-(0.00000000000000000000000101)_2$ in floating-point format.
>
> **Solution**
> We use the same idea, keeping only one non zero digit on the left-hand side of the decimal point:
> Actual number → - $(0.00000000000000000000000101)_2$
> Scientific notation → - $1.01 × 2^{-24}$
> Note that exponent is stored as a negative binary in the computer.

**Normalization**
To make the fixed part of the representation uniform, both the scientific method (for the decimal system) and the floating-point method (for the binary system) use only one non-zero digit on the left of the decimal point. This is called **normalization**. In the decimal system this digit can be 1 to 9, while in the binary system it can only be 0 or 1. In the following, d is a non zero digit, x is a digit, and y is either 0 or 1:
Decimal ± d.xxxxxxxxxxxxxx (Note: d is 1 to 9 and each x is 0 to 9)
Binary ± 1.yyyyyyyyyyyyyy (Note: each y is 0 or 1)

**Sign, exponent, and mantissa**
After a binary number is normalized, only three pieces of information about the number are stored: sign, exponent, and mantissa (the bits to the right of the decimal point). For example, +1000111.0101 becomes:
Sign: + (1)
Exponent: $2^6$ (6)
Mantissa: $1.0001110101$ ($0001110101$)

**Note that the point and the bit 1 to the left of the fixed-point section are not stored—they are implicit.**

**Sign**
The sign of the number can be stored using 1 bit (0 or 1).

**Exponent**
The exponent (power of 2) defines the shifting of the decimal point. Note that the power can be negative or positive. The **Excess representation** (discussed later) is the method used to store the exponent.

**Mantissa**
The **mantissa** is the binary integer to the right of the decimal point. It defines the precision of the number. The mantissa is stored in fixed-point notation. If we think of the mantissa and the sign together, we can say this combination is stored as an integer in sign-and-magnitude format. However, we need to remember that it is not an integer—it is a fractional part that is stored like an integer. We emphasize this point because in a mantissa, if we insert extra 0s to the right of the number, the value will not change, whereas in a real integer if we insert extra 0s to the left of the number, the value will not change.

**The mantissa is a fractional part that, together with the sign, is treated like an integer stored in sign-and-magnitude representation.**

**The Excess system**
The mantissa can be stored as an unsigned integer. The exponent, the power that shows how many bits the decimal point should be moved to the left or right, is a signed number. Although this could have been stored using two’s complement representation, a new representation, called the Excess system, is used instead. In the Excess system, both positive and negative integers are stored as unsigned integers. To represent a positive or negative integer, a positive integer (called a bias) is added to each number to shift them uniformly to the nonnegative side. The value of this bias is $2^{m-1} - 1$, where $m$ is the size of the memory location to store the exponent.

> **Example 3.22**
> We can express sixteen integers in a number system with 4-bit allocation. Using one location for 0 and splitting the other fifteen (not quite equally) we can express integers in the range of -7 to 8, as shown in Figure 3.11. By adding seven units to each integer in this range, we can uniformly translate all integers to the right and make all of them positive without changing the relative position of the integers with respect to each other, as shown in the figure. The new system is referred to as Excess-7, or biased representation with biasing value of 7.

The advantage of this new representation compared to that before the translation is that all integers in the Excess system are positive, so we don’t need to be concerned about the sign when we are comparing or doing operations on the integers. For 4-bit allocation, the bias is $2^{4-1} -1 = 7$, as we expected.

**IEEE standards**
The Institute of Electrical and Electronics Engineers (IEEE) has defined several standards for storing floating-point numbers. We discuss the two most common ones here, single precision and double precision. These formats are shown in Figure 3.12. The numbers above the boxes are the number of bits for each field.

**Single-precision** format uses a total of 32 bits to store a real number in floating-point representation. The sign occupies one bit (0 for positive and 1 for negative), the exponent occupies eight bits (using a bias of 127), the mantissa uses 23 bits (unsigned number). This standard is sometimes referred to as **Excess_127** because the bias is 127.

**Double-precision** format uses a total of 64 bits to store a real number in floating-point representation. The sign occupies one bit, the exponent occupies eleven bits (using a bias of 1023), and the mantissa uses 52 bits. The standard is sometimes referred to as **Excess_1023** because the bias is 1023. Table 3.2 summarizes the specification of the two standards.

**Table 3.2 Specifications of the two IEEE floating-point standards**

| Parameter | Single Precision | Double Precision |
| :--- | :--- | :--- |
| Memory location size (number of bits) | 32 | 64 |
| Sign size (number of bits) | 1 | 1 |
| Exponent size (number of bits) | 8 | 11 |
| Mantissa size (number of bits) | 23 | 52 |
| Bias (integer) | 127 | 1023 |

**Storage of IEEE standard floating-point numbers**
A real number can be stored in one of the IEEE standard floating-point formats using the following procedure, with reference to Figure 3.12:
- Store the sign in S (0 or 1).
- Change the number to binary.
- Normalize.
- Find the values of E and M.
- Concatenate S, E, and M.

> **Example 3.23**
> Show the Excess_127 (single precision) representation of the decimal number 5.75.
>
> **Solution**
> a. The sign is positive, so S = 0.
> b. Decimal to binary transformation: 5.75 = $(101.11)_2$.
> c. Normalization: $(101.11)_2 = (1.0111)_2 	imes 2^2$.
> d. E = 2 + 127 = 129 = $(10000001)_2$, M = 0111. We need to add 19 zeros at the right of M to make it 23 bits.
> e. The presentation is shown below:
> S: 0
> E: 10000001
> M: 01110000000000000000000
> The number is stored in the computer as 01000000101110000000000000000000.

> **Example 3.24**
> Show the Excess_127 (single precision) representation of the decimal number –161.875.
>
> **Solution**
> a. The sign is negative, so S = 1.
> b. Decimal to binary transformation: 161.875 = $(10100001.111)_2$.
> c. Normalization: $(10100001.111)_2 = (1.0100001111)_2 	imes 2^7$.
> d. E = 7 + 127 = 134 = $(10000110)_2$ and M = $(0100001111)_2$.
> e. Representation:
> S: 1
> E: 10000110
> M: 01000011110000000000000
> The number is stored in the computer as 11000011010000111100000000000000.

> **Example 3.25**
> Show the Excess_127 (single precision) representation of the decimal number –0.0234375.
>
> **Solution**
> a. S = 1 (the number is negative).
> b. Decimal to binary transformation: 0.0234375 = $(0.0000011)_2$.
> c. Normalization: $(0.0000011)_2 = (1.1)_2 	imes 2^{-6}$.
> d. E = –6 + 127 = 121 = $(01111001)_2$ and M = $(1)_2$.
> e. Representation:
> S: 1
> E: 01111001
> M: 10000000000000000000000
> The number is stored in the computer as 10111100110000000000000000000000.

**Retrieving numbers stored in IEEE standard floating-point format**
A number stored in one of the IEEE floating-point formats can be retrieved using the following method:
- Find the value of S, E, and M.
- If S = 0, set the sign to positive, otherwise, set the sign to negative.
- Find the shifter (E -127).
- Denormalize the mantissa.
- Change the denormalized number to binary to find the absolute value.
- Add the sign.

> **Example 3.26**
> The bit pattern $(11001010000000000111000100001111)_2$ is stored in memory in Excess_127 format. Show what is the value of the number in decimal notation.
>
> **Solution**
> a. The first bit represents S, the next eight bits, E and the remaining 23 bits, M:
> S: 1
> E: 10010100
> M: 00000000111000100001111
> b. The sign is negative.
> c. The shifter = E - 127 = 148 - 127 = 21.
> d. Denormalization gives us $(1.00000000111000100001111)_2 	imes 2^{21}$.
> e. The binary number is $(1000000001110001000011.11)_2$.
> f. The absolute value is 2104378.75.
> g. The number is -2104378.75.

> **Example 3.27**
> The bit pattern 01000011111000000000000000000000 is stored in memory in Excess_127 format. Show the value of the number in decimal notation.
>
> **Solution**
> a. The first bit represents S, the next eight bits E, and the remaining 23 bits, M:
> S: 0
> E: 10000111
> M: 11000000000000000000000
> b. The sign is positive.
> c. The shifter = E - 127 = 135 - 127 = 8.
> d. Denormalization gives us $(1.11000000000000000000000)_2 	imes 2^8$.
> e. The binary number is $(111000000.00)_2$.
> f. The absolute value is 448.
> g. The number is +448.

**Overflow and underflow**
In the case of floating-point numbers, we can have both an **overflow** and **underflow**. Figure 3.13 shows the ranges of floating-point representations using 32-bit memory locations (Excess_127). This representation cannot store numbers with very small or very large absolute values. An attempt to store numbers with very small absolute values results in an underflow condition, while an attempt to store numbers with very large absolute values results to an overflow condition. We leave the calculation of boundary values (+largest, -largest, +smallest, and -smallest) as problems.

**Storing zero**
You may have noticed that a real number with an integral part and the fractional part set to zero, that is, 0.0, cannot be stored using the steps discussed above. To handle this special case, it is agreed that in this case the sign, exponent, and the mantissa are set to 0s.

**Truncation errors**
When a real number is stored using floating-point representation, the value of the numbered stored may not be exactly as we expect it to be. For example, assume we need to store the number:
$(1111111111111111.11111111111)_2$
in memory using Excess_127 representation. After normalization, we have:
$(1.11111111111111111111111111)_2$
This means that the mantissa has 26 1s. This mantissa needs to be truncated to 23 1s. In other words, what is stored in the computer is:
$(1.11111111111111111111111)_2$
which means the original number is changed to:
$(1111111111111111.11111111)_2$
with the three 1s at the right of the fractional part truncated. The difference between the original number and what is retrieved is called the **truncation error**. This type of error is very important in areas in which very small or very large numbers are being used, such as calculations in the space industry. In such cases we need to use larger memory locations and other presentations. The IEEE defines other standards with larger mantissas for these purposes.

## 3.3 STORING TEXT
A section of **text** in any language is a sequence of symbols used to represent an idea in that language. For example, the English language uses 26 symbols (A, B, C,…, Z) to represent uppercase letters, 26 symbols (a, b, c, …, z) to represent lowercase letters, ten symbols (0, 1, 2, …, 9) to represent numeric characters (not actual numbers—numbers are treated separately, as we explained in the previous section), and symbols (., ?, :, ; , …, !) to represent punctuation. Other symbols such as blank, newline, and tab are used for text alignment and readability.
We can represent each symbol with a bit pattern. In other words, text such as ‘CATS’, which is made up from four symbols, can be represented as four n-bit patterns, each pattern defining a single symbol (Figure 3.14).

Now the question is: how many bits are needed in a bit pattern to represent a symbol in a language? It depends on how many symbols are in the set used for the language. For example, if we create an imaginary language that uses only English uppercase letters, we need only 26 symbols. A bit pattern in this language needs to represent at least 26 symbols.
For another language, such as Chinese, we may need many more symbols. The length of the bit pattern that represents a symbol in a language depends on the number of symbols used in that language. More symbols mean a longer bit pattern.
Although the length of the bit pattern depends on the number of symbols, the relationship is not linear: it is logarithmic. If we need two symbols, the length is one bit ($log_2 2$ is 1). If we need four symbols, the length is two bits ($log_2 4$ is 2). Table 3.3 shows the relationship. A bit pattern of two bits can take four different forms: 00, 01, 10, and 11. Each of these forms can represent a symbol. In the same way, a bit pattern of three bits can take eight different forms: 000, 001, 010, 011, 100, 101, 110, and 111.

**Table 3.3 Number of symbols and bit pattern length**

| Number of symbols | Bit pattern length | Number of symbols | Bit pattern length |
| :--- | :--- | :--- | :--- |
| 2 | 1 | 128 | 7 |
| 4 | 2 | 256 | 8 |
| 8 | 3 | 65536 | 16 |
| 16 | 4 | 4294967296 | 32 |

### 3.3.1 Codes
Different sets of bit patterns have been designed to represent text symbols. Each set is called a **code**, and the process of representing symbols is called **coding**. In this section, we explain the common codes.

**ASCII**
The **American National Standards Institute (ANSI)** developed a code called **American Standard Code for Information Interchange (ASCII)**. This code uses seven bits for each symbol. This means that $2^7 = 128$ different symbols can be defined in this code. The full bit patterns for ASCII code are included in Appendix A. Today ASCII is part of Unicode, which is discussed next.

**Unicode**
A coalition of hardware and software manufacturers have designed a code called **Unicode** that uses 32 bits and can therefore represent up to $2^{32} = 4294967296$ symbols. Different sections of the code are allocated to symbols from different languages in the world. Some parts of the code are used for graphical and special symbols. A brief set of Unicode symbols is listed in Appendix A. ASCII is part of Unicode today.

## 3.4 STORING AUDIO
**Audio** is a representation of sound or music. Audio, by nature, is different from the numbers or text we have discussed so far. Text is composed of countable entities (characters): we can count the number of characters in text. Text is an example of **digital** data. In contrast, audio is not countable. Audio is an entity that changes with time—we can only measure the intensity of the sound at each moment. When we discuss storing audio in computer memory, we mean storing the intensity of an audio signal, such as the signal from a microphone, over a period of time: one second, one hour.
Audio is an example of **analog** data. Even if we are able to measure all its values in a period of time, we cannot store these in the computer’s memory, as we would need an infinite number of memory locations. Figure 3.15 shows the nature of an analog signal, such as audio, that varies with time.

### 3.4.1 Sampling
If we cannot record all the values of an audio signal over an interval, we can record some of them. **Sampling** means that we select only a finite number of points on the analog signal, measure their values, and record them. Figure 3.16 shows a selection of ten samples from the signal: we can then record these values to represent the analog signal.

**Sampling rate**
The next logical question is, how many samples do we need in each second to be able to retrieve a replica of the original signal? The number of samples depends on the maximum number of changes in the analog signal. If the signal is smooth, we need fewer samples: if the signal is changing rapidly, we need more samples. It has been shown that a **sampling rate** of 40000 samples per second is good enough to reproduce an audio signal.

### 3.4.2 Quantization
The value measured for each sample is a real number. This means that we can store 40000 real values for each one second sample. However, it is simpler to use an unsigned number (a bit pattern) for each sample. **Quantization** refers to a process that rounds the value of a sample to the closest integer value. For example, if the real value is 17.2, it can be rounded down to 17: if the value is 17.7, it can be rounded up to 18.

### 3.4.3 Encoding
The next task is encoding. The quantized sample values need to be encoded as bit patterns. Some systems assign positive and negative values to samples, some just shift the curve to the positive part and assign only positive values. In other words, some systems use an unsigned integer to represent a sample, while others use signed integers to do so. However, the signed integers don’t have to be in two’s complement, they can be sign-and-magnitude values. The leftmost bit is used to represent the sign (0 for positive values and 1 for negative values), and the rest of the bits are used to represent the absolute values.

**Bit per sample**
The system needs to decide how many bits should be allocated for each sample. Although in the past only 8 bits were assigned to sound samples, today 16, 24, or even 32 bits per sample is normal. The number of bits per sample is sometimes referred to as the **bit depth**.

**Bit rate**
If we call the bit depth or number of bits per sample B, the number of samples per second, S, we need to store S × B bits for each second of audio. This product is sometimes referred to as **bit rate**, R. For example, if we use 40000 samples per second and 16 bits per sample, the bit rate is R = 40000 × 16 = 640000 bits per second = 640 kilobits per second.

### 3.4.4 Standards for sound encoding
Today the dominant standard for storing audio is **MP3** (short for MPEG Layer 3). This standard is a modification of the **MPEG** (Motion Picture Experts Group) compression method used for video. It uses 44100 samples per second and 16 bits per sample. The result is a signal with a bit rate of 705600 bits per second, which is compressed using a compression method that discards information that cannot be detected by the human ear. This is called lossy compression, as opposed to lossless compression: see Chapter 15.

## 3.5 STORING IMAGES
Images are stored in computers using two different techniques: raster graphics and vector graphics.

### 3.5.1 Raster graphics
**Raster graphics** (or **bitmap graphics**) is used when we need to store an analog image such as a photograph. A photograph consists of analog data, similar to audio information: the difference is that the intensity (color) of data varies in space instead of in time. This means that data must be sampled. However, sampling in this case is normally called **scanning**. The samples are called **pixels** (which stands for **picture elements**). In other words, the whole image is divided into small pixels where each pixel is assumed to have a single intensity value.

**Resolution**
Just like audio sampling, in image scanning we need to decide how many pixels we need to record for each square or linear inch. The scanning rate in image processing is called **resolution**. If the resolution is sufficiently high, the human eye cannot recognize the discontinuity in reproduced images.

**Color depth**
The number of bits used to represent a pixel, its **color depth**, depends on how a pixel’s color is handled by different encoding techniques. The perception of color is how our eyes respond to a beam of light. Our eyes have different types of *photoreceptor* cells: some respond to the three primary colors red, green, and blue (often called **RGB**), while others merely respond to the intensity of light.

**True-Color**
One of the techniques used to encode a pixel is called **True-Color**, which uses 24 bits to encode a pixel. In this technique, each of the three primary colors (RGB) are represented by eight bits. Since an 8-bit pattern can represent a number between 0 to 255 in this technique, each color is represented by three decimal numbers between 0 to 255. Table 3.4 shows the three values for some of the colors in this technique.

**Table 3.4 Some colors defined in True-Color**

| Color | Red | Green | Blue | Color | Red | Green | Blue |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Black | 0 | 0 | 0 | Yellow | 255 | 255 | 0 |
| Red | 255 | 0 | 0 | Cyan | 0 | 255 | 255 |
| Green | 0 | 255 | 0 | Magenta | 255 | 0 | 255 |
| Blue | 0 | 0 | 255 | White | 255 | 255 | 255 |

Note that the True-Color scheme can encode $2^{24}$ or 16776216 colors. In other words, the color intensity of each pixel is one of these values.

**Indexed color**
The True-Color scheme uses more than 16 million colors. Many applications do not need such a large range of colors. The **indexed color**—or **palette color**—scheme uses only a portion of these colors. In this scheme each application selects a few (normally 256) colors from the large set of colors and indexes them, assigning a number between 0 and 255 to each selected color. This is similar to the way in which an artist might have a great many colors in their studio, but at each moment use only a few on their palette. Figure 3.17 illustrates the idea of indexed color.

The use of indexing reduces the number of bits required to store a pixel. For example, in the True-Color scheme 24 bits are needed to store a single pixel. The index color scheme normally uses 256 indexes, which needs only eight bits to store the same pixel. For example, a high-quality digital camera uses almost three million pixels for a 3 × 5 inch photo.
The following shows the number of bits that need to be stored using each scheme:
True-Color: 3000000 × 24 = 72000000
Indexed-Color: 3000000 × 8 = 24000000

**Standards for image encoding**
Several de facto standards for image encoding are in use. **JPEG (Joint Photographic Experts Group)** uses the True-Color scheme, but compresses the image to reduce the number of bits (see Chapter 15). **GIF (Graphic Interchange Format)**, on the other hand, uses the indexed color scheme.

### 3.5.2 Vector graphics
Raster graphics has two disadvantages: the file size is big and rescaling is troublesome. To enlarge a raster graphics image means enlarging the pixels, so the image looks ragged when it is enlarged. The **vector graphic** image encoding method, however, does not store the bit patterns for each pixel. An image is decomposed into a combination of geometrical shapes such as lines, squares, or circles. Each geometrical shape is represented by a mathematical formula. For example, a line may be described by the coordinates of its endpoints, and a circle may be described by the coordinates of its center and the length of its radius. A vector graphic image is made up from a series of commands that defines how these shapes should be drawn.
When the image is to be displayed or printed, the size of the image is given to the system as an input. The system rescales the image to the new size and uses the same formulae to draw the image. In this case, each time an image is drawn, the formulae are reevaluated. For this reason, vector graphics are also called *geometric modeling* or *object-oriented graphics*.

For example, consider a circle of radius r. The main pieces of information a program needs to draw this circle are:
1. The radius r and equation of a circle.
2. The location of the center point of the circle.
3. The stroke line style and color.
4. The fill style and color.

When the size of the circle is changed, the program changes the value of the radius and recalculates the information to draw the circle again. Rescaling does not change the quality of the drawing.

Vector graphics is not suitable for storing the subtleties of photographic images. JPEG or GIF raster graphics provide much better and more vivid pictures. Vector graphics is suitable for applications that use mainly geometric primitives to create images. It is used in applications such as FLASH, and to create TrueType (Microsoft, Apple) and PostScript (Adobe) fonts. Computer-aided design (CAD) also uses vector graphics for engineering drawings.

## 3.6 STORING VIDEO
**Video** is a representation of images (called **frames**) over time. A movie consists of a series of frames shown one after another to create the illusion of motion. In other words, video is the representation of information that changes in space (single image) and in time (a series of images). So, if we know how to store an image inside a computer, we also know how to store video: each image or frame is transformed into a set of bit patterns and stored. The combination of the images then represents the video. Today video is normally compressed. In Chapter 15 we discuss MPEG, a common video compression technique.

## 3.7 END-CHAPTER MATERIALS
### 3.7.1 Recommended reading
For more details about the subjects discussed in this chapter, the following books are recommended:
- Halsall, F. *Multimedia Communication*, Boston, MA: Addison-Wesley, 2001
- Koren, I. *Computer Arithmetic Algorithms*, Natick, MA: A K Peters, 2001
- Long, B. *Complete Digital Photography*, Hignham, MA: Charles River Media, 2003
- Mano, M. *Computer System Architecture*, Upper Saddle River, NJ: Prentice-Hall, 1993
- Miano, J. *Compressed Image File Formats*, Boston, MA: Addison-Wesley, 1999

### 3.7.2 Key terms
- American National Standards Institute (ANSI)
- American Standard Code for Information Interchange (ASCII)
- analog
- audio
- binary digit
- bit
- bit depth
- bitmap graphic
- bit pattern
- bit rate
- byte
- code
- color depth
- digital
- Excess_1023
- Excess_127
- Excess representation
- floating-point representation
- frames
- Graphic Interchange Format (GIF)
- indexed color
- Joint Photographer Experts Group (JPEG)
- mantissa
- MP3
- MPEG
- normalization
- one’s complement
- overflow
- palette color
- picture element
- pixel
- quantization
- raster graphic
- real
- resolution
- RGB
- sampling
- sampling rate
- scanning
- scientific notation
- sign-and-magnitude representation
- text
- text editor
- True-Color
- truncation error
- two’s complement
- two’s complement representation
- underflow
- Unicode
- unsigned integer
- vector graphic
- video

### 3.7.3 Summary
- Data comes in different forms, including numbers, text, audio, image, and video. All data types are transformed into a uniform representation called a bit pattern.
- A number is changed to the binary system before being stored in computer memory. There are several ways to handle the sign. There are two ways to handle the decimal point: fixed-point and floating-point. An integer can be thought of as a number in which the position of the decimal point is fixed: the decimal point is at the right of the least significant bit. An unsigned integer is an integer that can never be negative. One of the methods used to store a signed integer is the sign-and-magnitude format. In this format, the leftmost bit is used to show the sign and the rest of the bits define the magnitude. Sign and magnitude are separated from each other. Almost all computers use the two’s complement representation to store a signed integer in an n-bit memory location. In this method, the available range for unsigned integers is divided into two equal subranges. The first half is used to represent non negative integers, the second half is used to represent negative integers. In two’s complement representation, the leftmost bit defines the sign of the integer, but sign and magnitude are not separated from each other. A real is a number with an integral part and a fractional part. Real numbers are stored in the computer using floating-point representation. In floating-point representation a number is made up of three sections: a sign, a shifter, and a fixed-point number.
- A piece of text in any language is a sequence of symbols. We can represent each symbol with a bit pattern. Different sets of bit patterns (codes) have been designed to represent text symbols. A coalition of hardware and software manufacturers have designed a code called Unicode that uses 32 bits to represent a symbol.
- Audio is a representation of sound or music. Audio is analog data. We cannot record an infinite number of values in an interval, we can only record some samples. The number of samples depends on the maximum number of changes in the analog signal. The values measured for each sample is a real number. Quantization refers to a process that rounds up the sample values to integers.
- Storage of images is done using two different techniques: raster graphics and vector graphics. Raster graphics are used when we need to store an analog image such as a photograph. The image is scanned (sampled) and pixels are stored. In the vector graphic method, an image is decomposed into a combination of geometrical shapes such as lines, squares, or circles. Each geometrical shape is represented by a mathematical formula.
- Video is a representation of images (called frames) in time. A movie is a series of frames shown one after another to create the illusion of continuous motion. In other words, video is the representation of information that changes in space (single image) and in time (a series of images).

## 3.8 PRACTICE SET
### 3.8.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 3.8.2 Review questions
1. Name five types of data that a computer can process.
2. How is bit pattern length related to the number of symbols the bit pattern can represent?
3. How does the bitmap graphic method represent an image as a bit pattern?
4. What is the advantage of the vector graphic method over the bitmap graphic method? What is the disadvantage?
5. What steps are needed to convert audio data to bit patterns?
6. Compare and contrast the representation of positive integers in unsigned, sign-and-magnitude format, and two’s complement format.
7. Compare and contrast the representation of negative integers in sign-and-magnitude and two’s complement format.
8. Compare and contrast the representation of zero in sign-and-magnitude, two’s complement, and Excess formats.
9. Discuss the role of the leftmost bit in sign-and-magnitude, and two’s complement formats.
10. Answer the following questions about floating-point representations of real numbers:
    a. Why is normalization necessary?
    b. What is the mantissa?
    c. After a number is normalized, what kind of information does a computer store in memory?

### 3.8.3 Problems
1. How many distinct 5-bit patterns can we have?
2. In some countries vehicle license plates have two decimal digits (0 to 9). How many distinct plates can we have? If the digit 0 is not allowed on the license plate, how many distinct plates can we have?
3. Redo Problem P3-2 for a license plate that has two digits followed by three uppercase letters (A to Z).
4. A machine has eight different cycles. How many bits are needed to represent each cycle?
5. A student’s grade in a course can be A, B, C, D, F, W (withdraw), or I (incomplete). How many bits are needed to represent the grade?
6. A company has decided to assign a unique bit pattern to each employee. If the company has 900 employees, what is the minimum number of bits needed to create this system of representation? How many patterns are unassigned? If the company hires another 300 employees, should it increase the number of bits? Explain your answer.
7. If we use a 4-bit pattern to represent the digits 0 to 9, how many bit patterns are wasted?
8. An audio signal is sampled 8000 times per second. Each sample is represented by 256 different levels. How many bits per second are needed to represent this signal?
9. Change the following decimal numbers to 8-bit unsigned integers.
    a. 23
    b. 121
    c. 34
    d. 342
10. Change the following decimal numbers to 16-bit unsigned integers.
    a. 41
    b. 411
    c. 1234
    d. 342
11. Change the following decimal numbers to 8-bit two’s complement integers.
    a. −12
    b. −145
    c. 56
    d. 142
12. Change the following decimal numbers to 16-bit two’s complement integers.
    a. 102
    b. −179
    c. 534
    d. 62,056
13. Change the following 8-bit unsigned numbers to decimal.
    a. 01101011
    b. 10010100
    c. 00000110
    d. 01010000
14. Change the following 8-bit two’s complement numbers to decimal.
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
15. The following are two’s complement binary numbers. Show how to change the sign of the number.
    a. 01110111
    b. 11111100
    c. 01110111
    d. 11001110
16. If we apply the two’s complement operation to a number twice, we should get the original number. Apply the two’s complement operation to each of the following numbers and see if we can get the original number.
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
17. Normalize the following binary floating-point numbers. Explicitly show the value of the exponent after normalization.
    a. 1.10001
    b. $2^3 \\times 111.1111$
    c. $2^{-2} \\times 101.110011$
    d. $2^{-5} \\times 101101.00000110011000$
18. Convert the following numbers in 32-bit IEEE format.
    a. $-2^0 \\times 1.10001$
    b. $+2^3 \\times 1.111111$
    c. $+2^{-4} \\times 1.01110011$
    d. $-2^{-5} \\times 1.01101000$
19. Convert the following numbers in 64-bit IEEE format.
    a. $-2^0 \\times 1.10001$
    b. $+2^3 \\times 1.111111$
    c. $+2^{-4} \\times 1.01110011$
    d. $-2^{-5} \\times 1.01101000$
20. Convert the following numbers in 32-bit IEEE format.
    a. 7.1875
    b. −12.640625
    c. 11.40625
    d. −0.375
21. The following are sign-and-magnitude binary numbers in a 8-bit allocation. Convert them to decimal.
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
22. Convert the following decimal integers to sign-and-magnitude with 8-bit allocation.
    a. 53
    b. −107
    c. −5
    d. 154
23. One method of representing signed numbers in a computer is one’s complement representation. In this representation, to represent a positive number, we store the binary number. To represent a negative number, we apply the one’s complement operation on the number. Store the following decimal integers to one’s complement with 8-bit allocation.
    a. 53
    b. −107
    c. −5
    d. 154
24. The following are one’s complement binary numbers in a 8-bit allocation. Convert them to decimal.
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
25. If we apply the one’s complement operation to a number twice, we should get the original number. Apply the one’s complement operation twice to each of the following numbers and see if you can get the original number.
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
26. An alternative method to find the two’s complement of a number is to first take the one’s complement of the number and then add 1 to the result. (Adding binary integers is explained in Chapter 4). Try both methods using the following numbers. Compare and contrast the results.
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
27. The equivalent of one’s complement in the binary system is nine’s complement in the decimal system ($1 = 2 - 1$ and $9 = 10 - 1$). With $n$-digit allocation, we can represent nine’s complement numbers in the range of: $- [(10^n/2) - 1]$ to $+ [(10^n/2 - 1)]$. The nine’s complement of a number with $n$ digit allocation is obtained as follows. If the number is positive, the nine’s complement of the number is itself. If the number is negative, we subtract each digit from 9. Answer the following questions for three-digit allocation:
    a. What is the range of the numbers we can represent using nine’s complement?
    b. In this system, how can we determine the sign of a number?
    c. Do we have two zeros in this system?
    d. If the answer to c. is yes, what is the representation for +0 and -0?
28. Assuming three-digit allocation, find the nine’s complement of the following decimal numbers.
    a. +234
    b. +560
    c. -125
    d. -111
29. The equivalent of two’s complement in the binary system is ten’s complement in the decimal system (in the binary system, 2 is the base, in the decimal system, 10 is the base). Using $n$-digit allocation, we can represent numbers in the range of: $-(10^n/2)$ to $+(10^n/2 - 1)$ in ten’s complement format. The ten’s complement of a number with $n$-digit allocation is obtained by first finding the nine’s complement of the number and then adding 1 to the result. Answer the following questions for three-digit allocation.
    a. What is the range of the numbers we can represent using ten’s complement?
    b. In this system, how can we determine the sign of a number?
    c. Do we have two zeros in this system?
    d. If the answer to c. is yes, what is the representation for +0 and −0?
30. Assuming three-digit allocation, find the ten’s complement of the following decimal numbers.
    a. +234
    b. +560
    c. -125
    d. -111
31. The equivalent of one’s complement in the binary system is fifteen’s complement in the hexadecimal system ($1 = 2 - 1$ and $15 = 16 - 1$).
    a. What range of numbers can we represent with three-digit allocation in fifteen’s complement?
    b. Explain how the fifteen’s complement of a number is obtained in the hexadecimal system.
    c. Do we have two zeros in this system?
    d. If the answer to c. is yes, what is the representation for +0 and −0?
32. Assuming three-digit allocation, find the fifteen’s complement of the following hexadecimal numbers.
    a. +B14
    b. +FE1
    c. -1A
    d. -1E2
33. The equivalent of two’s complement in the binary system is sixteen’s complement in the hexadecimal system.
    a. What range of numbers can we represent with three-digit allocation in sixteen’s complement?
    b. Explain how a sixteen’s complement of a number is obtained in the hexadecimal system.
    c. Do we have two zeros in this system?
    d. If the answer to c. is yes, what is the representation for +0 and −0?
34. Assuming three-digit allocation, find the sixteen’s complement of the following hexadecimal numbers.
    a. +B14
    b. +FE1
    c. −1A
    d. −1E2
`,zh:`
# 第三章：資料儲存

如第一章所述，電腦是一種可程式化的資料處理機器。在我們討論處理資料之前，我們需要了解資料的本質。本章我們將討論不同的資料類型以及它們如何儲存在電腦內部。在第四章，我們將展示資料如何在電腦內部被操作。

## 學習目標
學完本章後，學生應能：
- 列舉電腦中使用的五種不同資料類型。
- 描述不同的資料如何以位元模式儲存在電腦內部。
- 描述整數如何使用無符號格式儲存在電腦中。
- 描述整數如何使用符號與數值格式儲存在電腦中。
- 描述整數如何以二的補數格式儲存。
- 描述實數如何使用浮點數格式儲存在電腦中。
- 描述文字如何使用各種編碼系統之一儲存在電腦中。
- 描述音訊如何透過取樣、量化和編碼儲存在電腦中。
- 描述圖像如何使用點陣圖和向量圖形方案儲存在電腦中。
- 描述影像如何以隨時間變化的圖像表示形式儲存在電腦中。

## 3.1 資料類型
今日的資料以不同形式存在，包括數字、文字、音訊、圖像和影像 (圖 3.1)。
人們需要能夠處理許多不同類型的資料：
- 工程程式主要使用電腦來處理數字：進行算術運算、解代數或三角方程式、求微分方程式的根等等。
- 另一方面，文字處理程式主要使用電腦來處理文字：對齊、移動、刪除等等。
- 電腦也處理音訊資料。我們可以在電腦上播放音樂，並可以將聲音錄製為資料。
- 圖像處理程式使用電腦來操作圖像：創建、縮小、擴大、旋轉等等。
- 最後，電腦不僅可以用來放映電影，還可以用來創造電影中看到的特效。

電腦產業使用「多媒體」一詞來定義包含數字、文字、音訊、圖像和影像的資訊。

### 3.1.1 電腦內部的資料
所有資料類型在儲存於電腦時都會被轉換為統一的表示形式，並在檢索時轉換回其原始形式。這種通用表示形式稱為位元模式，稍後將進行討論。

**位元 (Bits)**
**位元**（二進位數字）是電腦中可儲存的最小資料單位，值為 0 或 1。位元代表可以採取兩種狀態之一的設備的狀態。例如，開關可以是開或關。可以建立一個慣例，將「開」狀態表示為 1，「關」狀態表示為 0，反之亦然。這樣，一個開關就可以儲存一位元的資訊。今日，電腦使用各種雙態設備來儲存資料。

**位元模式 (Bit patterns)**
為了表示不同類型的資料，我們使用**位元模式**，即一個序列，或者有時稱為一串位元。圖 3.2 顯示了一個由十六個位元組成的位元模式。它是十六個 0 和 1 的組合。這意味著如果我們需要儲存一個由十六個位元組成的位元模式，我們需要十六個電子開關。如果我們需要儲存 1000 個位元模式，每個十六位元長，我們需要 16000 個開關，依此類推。按照傳統，一個八位元的位元模式稱為一個**位元組 (byte)**。有時術語*字 (word)* 用於指代更長的位元模式。

如圖 3.3 所示，屬於不同資料類型的資料片段可以作為相同的模式儲存在記憶體中。

如果我們正在使用**文字編輯器**（文字處理器），在鍵盤上輸入的字元 A 可以儲存為 8 位元模式 01000001。如果我們正在使用數學例程，相同的 8 位元模式可以表示數字 65。此外，相同的模式可以表示圖像的一部分、歌曲的一部分或電影場景的一部分。電腦的記憶體儲存所有這些，而不識別它們代表什麼類型的資料。

### 3.1.2 資料壓縮
為了佔用更少的記憶體空間，資料通常在儲存到電腦之前進行壓縮。資料壓縮是一個非常廣泛且複雜的主題，因此我們將第 15 章整章專門討論此主題。

### 3.1.3 錯誤偵測與更正
與資料相關的另一個問題是在傳輸或儲存期間錯誤的偵測與更正。我們在附錄 H 中簡要討論此問題。

## 3.2 儲存數字
數字在儲存到電腦記憶體之前會被轉換為二進位系統，如第 2 章所述。但是，仍有兩個問題需要處理：
1.  如何儲存數字的正負號。
2.  如何顯示小數點。

有幾種方法可以處理正負號問題，稍後將在本章討論。對於小數點，電腦使用兩種不同的表示法：定點數和浮點數。第一種用於將數字儲存為整數——沒有小數部分，第二種用於將數字儲存為實數——有小數部分。

### 3.2.1 儲存整數
整數是整數（沒有小數部分的數字）。例如，134 和 -125 是整數，而 134.23 和 -0.235 不是。整數可以被認為是小數點位置固定的數字：小數點位於最低有效（最右邊）位元的右邊。因此，使用**定點數表示法**來儲存整數，如圖 3.4 所示。在這種表示法中，小數點是假設的，但不儲存。

然而，使用者（或程式）可能會將整數儲存為小數部分設為零的實數。例如，如果整數太大而無法儲存在為整數定義的大小中，就可能發生這種情況。為了更有效地利用電腦記憶體，無符號和有符號整數在電腦內部的儲存方式不同。

**整數通常使用定點數表示法儲存在記憶體中。**

#### 無符號表示法
**無符號整數**是永遠不會為負的整數，只能取 0 或正值。其範圍在 0 到正無窮大之間。然而，由於沒有電腦可能表示此範圍內的所有整數，大多數電腦定義了一個稱為*最大無符號整數*的常數，其值為 $(2^n - 1)$，其中 $n$ 是分配用於表示無符號整數的位元數。

**儲存無符號整數**
輸入設備使用以下步驟儲存無符號整數：
1.  整數被轉換為二進位。
2.  如果位元數少於 $n$，則在二進位整數的左邊添加 0，使總共有 $n$ 個位元。如果位元數大於 $n$，則無法儲存該整數。將發生稱為*溢位 (overflow)* 的情況，我們將在稍後討論。

> **範例 3.1**
> 使用無符號表示法將 7 儲存在 8 位元記憶體位置中。
>
> **解答**
> 首先將整數轉換為二進位 $(111)_2$。添加五個 0 以構成總共八個位元 $(00000111)_2$。整數儲存在記憶體位置中。請注意，下標 2 用於強調整數是二進位的，但下標不儲存在電腦中：
> 將 7 轉換為二進位 → 1 1 1
> 在左邊添加五個位元 → 0 0 0 0 0 1 1 1

> **範例 3.2**
> 將 258 儲存在 16 位元記憶體位置中。
>
> **解答**
> 首先將整數轉換為二進位 $(100000010)_2$。添加七個 0 以構成總共十六個位元 $(0000000100000010)_2$。整數儲存在記憶體位置中：
> 將 258 轉換為二進位 → 1 0 0 0 0 0 0 1 0
> 在左邊添加七個位元 → 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0

**檢索無符號整數**
輸出設備從記憶體中檢索位元字串作為位元模式，並將其轉換為無符號十進位整數。

> **範例 3.3**
> 當輸出設備檢索儲存在記憶體中作為無符號整數的位元字串 00101011 時，會回傳什麼？
>
> **解答**
> 使用第 2 章中顯示的程序，二進位整數被轉換為無符號整數 43。

**溢位**
由於大小限制——分配的位元數——可以表示的整數範圍是有限的。在一個 $n$ 位元記憶體位置中，我們只能儲存 0 到 $2^n - 1$ 之間的無符號整數。圖 3.5 顯示了如果我們試圖將大於 $2^4 - 1 = 15$ 的整數儲存在只能容納四個位元的記憶體位置中會發生什麼。這種情況稱為**溢位**，例如，當我們在記憶體位置中儲存了整數 11，然後試圖將 9 加到該整數時，就會發生這種情況。表示十進位 20 所需的最小位元數是五個位元。換句話說，$20 = (10100)_2$，因此電腦丟棄最左邊的位元並保留最右邊的四個位元 $(0100)_2$。當人們看到新整數被印成 4 而不是 20 時，會感到驚訝。圖 3.5 顯示了為什麼會發生這種情況。

**無符號整數的應用**
無符號整數表示法可以提高儲存效率，因為我們不需要儲存整數的符號。這意味著整個位元分配都可以用於儲存數字。只要我們不需要負整數，就可以使用無符號整數表示法。以下列出了一些情況：
- **計數 (Counting)**。當我們計數時，我們不需要負數。我們從 1（有時是 0）開始向上數。
- **定址 (Addressing)**。一些電腦程式將記憶體位置的位址儲存在另一個記憶體位置內。位址是從 0（第一個記憶體位置）開始並上升到代表總記憶體容量的整數的正整數。在這裡，我們也不需要負整數——無符號整數可以輕鬆完成工作。
- **儲存其他資料類型**。其他資料類型（文字、圖像、音訊和視訊），如我們稍後將討論的，儲存為位元模式，可以解釋為無符號整數。

#### 符號與數值表示法
雖然**符號與數值表示法**格式通常不用於儲存整數，但此格式用於儲存電腦中實數的一部分，如下一節所述。因此，我們在此簡要討論這種格式。在這種方法中，無符號整數的可用範圍（$0$ 到 $2^n - 1$）被分為兩個相等的子範圍。前半部分代表正整數，後半部分代表負整數。例如，如果 $n$ 是 4，範圍是 0000 到 1111。此範圍分為兩半：0000 到 0111 和 1000 到 1111（圖 3.6）。然後將位元模式分配給負整數和正整數。請注意，負數出現在正數的右邊，這與關於正數和負數的傳統思維相反。另請注意，我們有兩個 0：正零 (0000) 和負零 (1000)。

以符號與數值格式儲存整數需要 1 個位元來表示符號（0 為正，1 為負）。這意味著在 8 位元分配中，我們只能使用七個位元來表示數字的絕對值（沒有符號的數字）。因此，最大正值是無符號值的一半。可以在 $n$ 位元位置儲存的數字範圍是 $-(2^{n-1} -1)$ 到 $+ (2^{n-1} -1)$。在 $n$ 位元分配中，最左邊的位元專用於儲存符號（0 為正，1 為負）。

**在符號與數值表示法中，最左邊的位元定義整數的符號。如果是 0，整數為正。如果是 1，整數為負。**

> **範例 3.4**
> 使用符號與數值表示法將 +28 儲存在 8 位元記憶體位置中。
>
> **解答**
> 整數被轉換為 7 位元二進位。最左邊的位元設為 0。儲存 8 位元數字：
> 將 28 轉換為 7 位元二進位：0 0 1 1 1 0 0
> 添加符號並儲存：0 0 0 1 1 1 0 0

> **範例 3.5**
> 使用符號與數值表示法將 -28 儲存在 8 位元記憶體位置中。
>
> **解答**
> 整數被轉換為 7 位元二進位。最左邊的位元設為 1。儲存 8 位元數字：
> 將 28 轉換為 7 位元二進位：0 0 1 1 1 0 0
> 添加符號並儲存：1 0 0 1 1 1 0 0

> **範例 3.6**
> 檢索以符號與數值表示法儲存為 01001101 的整數。
>
> **解答**
> 由於最左邊的位元是 0，符號為正。其餘位元 (1001101) 轉換為十進位 77。添加符號後，整數為 +77。

> **範例 3.7**
> 檢索以符號與數值表示法儲存為 10100001 的整數。
>
> **解答**
> 由於最左邊的位元是 1，符號為負。其餘位元 (0100001) 轉換為十進位 33。添加符號後，整數為 -33。

**符號與數值表示法中的溢位**
像無符號整數一樣，有符號整數也會發生溢位。然而，在這種情況下，我們可能會有正溢位和負溢位。圖 3.7 顯示了使用 4 位元記憶體位置以符號與數值表示法儲存整數時的正溢位和負溢位。當我們試圖儲存大於 7 的正整數時，會發生正溢位。例如，假設我們在記憶體位置中儲存了整數 5，然後試圖將 6 加到該整數。我們期望結果是 11，但電腦的回應是 –3。原因是如果我們從循環表示法上的 5 開始，沿順時針方向走六個單位，我們最終會到達 –3。正溢位將整數包裹回範圍內。
當我們試圖儲存小於 –7 的整數時，可能會發生負溢位，例如，如果我們在記憶體中儲存了整數 –5，並試圖從中減去 7。我們期望結果是 –12，但電腦的回應是 +6。原因是如果我們從循環表示法上的 –5 開始，沿逆時針方向走七個單位，我們最終會到達 +6。

**符號與數值表示法中有兩個 0：+0 和 −0。**

**符號與數值表示法的應用**
符號與數值表示法不用於儲存整數。然而，它用於儲存實數的一部分，我們稍後將看到。此外，當我們量化類比信號（如音訊）時，通常使用符號與數值表示法。

#### 二的補數表示法
幾乎所有電腦都使用**二的補數表示法**將有符號整數儲存在 $n$ 位元記憶體位置中。在這種方法中，無符號整數的可用範圍 ($0$ 到 $2^n - 1$) 分為兩個相等的子範圍。第一個子範圍用於表示非負整數，後半部分用於表示負整數。例如，如果 $n$ 是 4，範圍是 0000 到 1111。此範圍分為兩半：0000 到 0111 和 1000 到 1111。兩半被交換以符合負整數在正整數左邊的常見慣例。然後將位元模式分配給負整數和非負（零和正）整數，如圖 3.8 所示。

雖然整數的符號影響儲存的二進位整數中的每個位元，但第一個（最左邊）位元決定了符號。如果最左邊的位元是 0，整數是非負的：如果最左邊的位元是 1，整數是負的。

**在二的補數表示法中，最左邊的位元定義整數的符號。如果是 0，整數為正。如果是 1，整數為負。**

**兩個運算**
在進一步討論此表示法之前，我們需要介紹兩個運算。第一個稱為*一的補數運算*或*取整數的一的補數*。該運算可以應用於任何整數，正數或負數。此運算只是反轉（翻轉）每個位元。0 位元變為 1 位元，1 位元變為 0 位元。

> **範例 3.8**
> 以下顯示我們如何取整數 00110110 的**一的補數**：
> 原始模式：0 0 1 1 0 1 1 0
> 應用一的補數運算後：1 1 0 0 1 0 0 1

> **範例 3.9**
> 以下顯示如果我們應用兩次一的補數運算，我們會得到原始整數：
> 原始模式：0 0 1 1 0 1 1 0
> 一次一的補數：1 1 0 0 1 0 0 1
> 兩次一的補數：0 0 1 1 0 1 1 0

第二個運算稱為*二的補數運算*或*取二進位整數的二的補數*。此運算分兩步完成。首先，我們從右邊複製位元，直到複製了一個 1，然後，我們翻轉其餘的位元。

> **範例 3.10**
> 以下顯示我們如何取整數 00110100 的**二的補數**：
> 原始整數：0 0 1 1 0 1 0 0
> 一次二的補數：1 1 0 0 1 1 0 0

> **範例 3.11**
> 以下顯示如果我們應用兩次二的補數運算，我們總是會得到原始整數：
> 原始整數：0 0 1 1 0 1 0 0
> 一次二的補數：1 1 0 0 1 1 0 0
> 兩次二的補數：0 0 1 1 0 1 0 0

取整數二的補數的另一種方法是先取一的補數，然後將結果加 1（見第 4 章的二進位加法）。

**以二的補數格式儲存整數**
要以二的補數表示法儲存整數，電腦遵循以下步驟：
- 整數的絕對值轉換為 $n$ 位元二進位。
- 如果整數是正數或零，則照原樣儲存：如果是負數，電腦取整數的二的補數然後儲存。

**以二的補數格式檢索整數**
要以二的補數表示法檢索整數，電腦遵循以下步驟：
- 如果最左邊的位元是 1，電腦對整數應用二的補數運算。如果最左邊的位元是 0，則不應用任何運算。
- 電腦將整數轉換為十進位。

> **範例 3.12**
> 使用二的補數表示法將整數 28 儲存在 8 位元記憶體位置中。
>
> **解答**
> 整數是正數（無符號表示正數），因此在十進位轉二進位轉換後不需要更多操作。請注意，在整數左邊添加了三個額外的 0 以使其成為八個位元：
> 將 28 轉換為 8 位元二進位：0 0 0 1 1 1 0 0

> **範例 3.13**
> 使用二的補數表示法將 -28 儲存在 8 位元記憶體位置中。
>
> **解答**
> 整數是負數，因此在轉換為二進位後，電腦對整數應用二的補數運算：
> 將 28 轉換為 8 位元二進位：0 0 0 1 1 1 0 0
> 應用二的補數運算：1 1 1 0 0 1 0 0

> **範例 3.14**
> 檢索以二的補數格式儲存在記憶體中的整數 00001101。
>
> **解答**
> 最左邊的位元是 0，因此符號為正。將整數轉換為十進位並添加符號：
> 最左邊位元是 0。符號為正。0 0 0 0 1 1 0 1
> 整數轉換為十進位：13
> 添加符號：+13

> **範例 3.15**
> 檢索以二的補數格式儲存在記憶體中的整數 11100110。
>
> **解答**
> 最左邊的位元是 1，因此整數是負數。在轉換為十進位之前，需要對整數進行二的補數運算：
> 最左邊位元是 1。符號為負。1 1 1 0 0 1 1 0
> 應用二的補數運算。0 0 0 1 1 0 1 0
> 整數轉換為十進位。26
> 添加符號。-26

關於二的補數的一個非常有趣的點是，在這種表示法中只有一個零。在符號與數值表示法中，有兩個零（+0 和 -0）。

**二的補數表示法中只有一個零。**

**二的補數表示法中的溢位**
像其他表示法一樣，以二的補數格式儲存的整數也會發生溢位。圖 3.9 顯示了在 4 位元記憶體位置中儲存有符號整數時的正溢位和負溢位。當我們試圖儲存大於 7 的正整數時，會發生正溢位。例如，假設我們在記憶體位置中儲存了整數值 5，然後試圖將 6 加到該整數。我們期望結果是 11，但電腦的回應是 –5。原因是如果我們從循環表示法上的 5 開始，沿順時針方向移動六個單位，我們最終會到達 –5。正溢位將整數包裹回範圍內。
當我們試圖儲存小於 –8 的整數時，可能會發生負溢位，例如，如果我們儲存了 –3 並試圖從中減去 7。我們期望結果是 –10，但電腦的回應是 +6。原因是如果我們從 –3 開始，沿逆時針方向走七個單位，我們最終會到達 +6。

**二的補數表示法的應用**
二的補數表示法是當今電腦中儲存整數的標準表示法。在下一章中，當我們看到使用二的補數進行運算的簡單性時，我們就會明白為什麼會這樣。

### 3.2.2 三種系統的比較
表 3.1 顯示了無符號、二的補數和符號與數值整數之間的比較。4 位元記憶體位置可以儲存 0 到 15 之間的無符號整數，同一位置可以儲存 -8 到 +7 之間的二的補數有符號整數。非常重要的一點是，我們以相同的格式儲存和檢索整數。例如，如果整數 13 以有符號格式儲存，則需要以有符號格式檢索：同一整數在二的補數格式中被檢索為 -3。

**表 3.1 整數表示法摘要**

| 記憶體內容 | 無符號 | 符號與數值 | 二的補數 |
| :--- | :--- | :--- | :--- |
| 0000 | 0 | 0 | +0 |
| 0001 | 1 | 1 | +1 |
| 0010 | 2 | 2 | +2 |
| 0011 | 3 | 3 | +3 |
| 0100 | 4 | 4 | +4 |
| 0101 | 5 | 5 | +5 |
| 0110 | 6 | 6 | +6 |
| 0111 | 7 | 7 | +7 |
| 1000 | 8 | -0 | -8 |
| 1001 | 9 | -1 | -7 |
| 1010 | 10 | -2 | -6 |
| 1011 | 11 | -3 | -5 |
| 1100 | 12 | -4 | -4 |
| 1101 | 13 | -5 | -3 |
| 1110 | 14 | -6 | -2 |
| 1111 | 15 | -7 | -1 |

### 3.2.3 儲存實數
**實數**是帶有整數部分和小數部分的數字。例如，23.7 是一個實數——整數部分是 23，小數部分是 7/10。雖然定點數表示法可以用來表示實數，但結果可能不準確，或者可能沒有所需的精度。接下來的兩個範例解釋了原因。

> **範例 3.16**
> 在十進位系統中，假設我們使用定點數表示法，小數點右邊有兩位數，小數點左邊有十四位數，總共十六位數。如果我們試圖表示像 1.00234 這樣的十進位數字，此系統中實數的精度就會喪失：系統將數字儲存為 1.00。

> **範例 3.17**
> 在十進位系統中，假設我們使用定點數表示法，小數點右邊有六位數，小數點左邊有十位數，總共十六位數。如果我們試圖表示像 236154302345.00 這樣的十進位數字，此系統中實數的準確度就會喪失。系統將數字儲存為 6154302345.00：整數部分比它應該有的要小得多。

**具有非常大整數部分或非常小將數部分的實數不應以定點數表示法儲存。**

#### 浮點數表示法
保持準確度或精度的解決方案是使用**浮點數表示法**。這種表示法允許小數點浮動：我們可以在小數點左邊或右邊有不同數量的位數。使用這種方法可以儲存的實數範圍大大增加：具有大整數部分或小將數部分的數字可以儲存在記憶體中。在浮點數表示法中，無論是十進位還是二進位，一個數字由三個部分組成，如圖 3.10 所示。

第一部分是符號，正或負。第二部分顯示小數點應該向右或向左移動多少位以形成實際數字。第三部分是定點數表示法，其中小數點的位置是固定的。

**數字的浮點數表示法由三個部分組成：一個符號、一個移位器和一個定點數。**

浮點數表示法在科學中用於表示非常小或非常大的十進位數字。在這種稱為**科學記數法**的表示法中，定點部分在小數點左邊只有一位數字，移位器是 10 的冪。

> **範例 3.18**
> 以下以科學記數法（浮點數表示法）顯示十進位數字 7425000000000000000000.00：
>
> **解答**
> 實際數字 → + 7425000000000000000000.00
> 科學記數法 → + 7.425 × 10²¹

這三個部分是符號 (+)，移位器 (21) 和定點部分 (7.425)。請注意，移位器是指數。我們可以很容易地看到這點的優勢。即使我們只想將數字寫在紙上，科學記數法也更短，佔用的空間更少。該表示法使用浮點數的概念，因為小數點的位置（在範例中靠近右端）向左移動了 21 位數以構成數字的定點部分。一些程式語言和計算機將數字顯示為 +7.425E21，因為底數 10 是被理解的，不需要提及。

> **範例 3.19**
> 以科學記數法顯示數字 -0.0000000000000232。
>
> **解答**
> 我們使用與前一個範例相同的方法——我們將小數點移動到數字 2 之後，如下所示：
> 實際數字 → - 0.0000000000000232
> 科學記數法 → - 2.32 × 10⁻¹⁴
> 請注意，這裡的指數是負的，因為 2.32 中的小數點需要向左移動（十四個位置）以形成原始數字。同樣，我們可以說這種表示法中的數字由三個部分組成：符號 (-)，實數 (2.32) 和負整數 (-14)。一些程式語言和計算機將此顯示為 -2.32E-14。

類似的方法已用於以二進位表示非常大或非常小的數字（整數和實數），以便儲存在電腦中。

> **範例 3.20**
> 以浮點格式顯示數字 $(101001000000000000000000000000000.00)_2$。
>
> **解答**
> 我們使用相同的想法，只在小數點左邊保留一位數字：
> 實際數字 → + $(101001000000000000000000000000000.00)_2$
> 科學記數法 → + $1.01001 × 2^{32}$

請注意，我們不必擔心最右邊 1 右邊的所有 0，因為當我們使用實數 $(1.01001)_2$ 時，它們並不重要。指數顯示為 32，但它實際上是以二進位儲存在電腦中的，我們稍後會看到。我們還將符號顯示為正，但它將被儲存為一個位元。

> **範例 3.21**
> 以浮點格式顯示數字 $-(0.00000000000000000000000101)_2$。
>
> **解答**
> 我們使用相同的想法，只在小數點左側保留一個非零數字：
> 實際數字 → - $(0.00000000000000000000000101)_2$
> 科學記數法 → - $1.01 × 2^{-24}$
> 請注意，指數在電腦中儲存為負二進位。

**正規化**
為了使表示的定點部分統一，科學方法（對於十進位系統）和浮點方法（對於二進位系統）都在小數點左邊只使用一個非零數字。這稱為**正規化**。在十進位系統中，此數字可以是 1 到 9，而在二進位系統中，它只能是 0 或 1。在下文中，d 是非零數字，x 是數字，y 是 0 或 1：
十進位 ± d.xxxxxxxxxxxxxx（註：d 是 1 到 9，每個 x 是 0 到 9）
二進位 ± 1.yyyyyyyyyyyyyy（註：每個 y 是 0 或 1）

**符號、指數和尾數**
在二進位數字被正規化後，只儲存關於數字的三條資訊：符號、指數和尾數（小數點右邊的位元）。例如，+1000111.0101 變為：
符號：+ (1)
指數：$2^6$ (6)
尾數：$1.0001110101$ ($0001110101$)

**請注意，小數點和定點部分左邊的位元 1 不儲存——它們是隱含的。**

**符號**
數字的符號可以使用 1 個位元（0 或 1）儲存。

**指數**
指數（2 的冪）定義小數點的移位。請注意，冪可以是負數或正數。**超額表示法**（稍後討論）是用於儲存指數的方法。

**尾數**
**尾數**是小數點右邊的二進位整數。它定義了數字的精度。尾數以定點表示法儲存。如果我們將尾數和符號放在一起考慮，我們可以說這種組合是以符號與數值格式儲存的整數。然而，我們需要記住它不是整數——它是一個像整數一樣儲存的小數部分。我們強調這一點是因為在尾數中，如果我們在數字右邊插入額外的 0，值不會改變，而在實整數中，如果我們在數字左邊插入額外的 0，值不會改變。

**尾數是一個小數部分，與符號一起，被視為以符號與數值表示法儲存的整數。**

**超額系統**
尾數可以儲存為無符號整數。指數，即顯示小數點應向左或向右移動多少位元的冪，是有符號數。雖然這可以使用二的補數表示法儲存，但使用了另一種稱為超額系統的表示法。在超額系統中，正整數和負整數都儲存為無符號整數。為了表示正整數或負整數，將一個正整數（稱為偏置）加到每個數字上，將它們均勻地移向非負側。此偏置的值為 $2^{m-1} - 1$，其中 $m$ 是儲存指數的記憶體位置大小。

> **範例 3.22**
> 我們可以在 4 位元分配的數字系統中表示十六個整數。使用一個位置表示 0 並分割其他十五個（不完全均等），我們可以表示 -7 到 8 範圍內的整數，如圖 3.11 所示。透過將七個單位加到此範圍內的每個整數，我們可以將所有整數均勻地向右平移，使它們全部為正，而不改變整數相對於彼此的相對位置，如圖所示。新系統稱為 Excess-7，或偏置值為 7 的偏置表示法。

與平移之前相比，這種新表示法的優點是超額系統中的所有整數都是正的，因此當我們比較或對整數進行運算時，不需要關心符號。對於 4 位元分配，偏置為 $2^{4-1} -1 = 7$，正如我們預期的那樣。

**IEEE 標準**
電機電子工程師學會 (IEEE) 定義了幾種儲存浮點數的標準。我們在此討論最常見的兩種，單精度和雙精度。這些格式如圖 3.12 所示。方框上方的數字是每個欄位的位元數。

**單精度**格式使用總共 32 個位元以浮點數表示法儲存實數。符號佔用一個位元（0 為正，1 為負），指數佔用八個位元（使用 127 的偏置），尾數使用 23 個位元（無符號數）。此標準有時稱為 **Excess_127**，因為偏置為 127。

**雙精度**格式使用總共 64 個位元以浮點數表示法儲存實數。符號佔用一個位元，指數佔用十一個位元（使用 1023 的偏置），尾數使用 52 個位元。此標準有時稱為 **Excess_1023**，因為偏置為 1023。表 3.2 總結了這兩個標準的規格。

**表 3.2 兩個 IEEE 浮點數標準的規格**

| 參數 | 單精度 | 雙精度 |
| :--- | :--- | :--- |
| 記憶體位置大小（位元數） | 32 | 64 |
| 符號大小（位元數） | 1 | 1 |
| 指數大小（位元數） | 8 | 11 |
| 尾數大小（位元數） | 23 | 52 |
| 偏置（整數） | 127 | 1023 |

**IEEE 標準浮點數的儲存**
參考圖 3.12，可以使用以下程序將實數儲存在 IEEE 標準浮點數格式之一中：
- 將符號儲存在 S 中（0 或 1）。
- 將數字轉換為二進位。
- 正規化。
- 找出 E 和 M 的值。
- 連接 S、E 和 M。

> **範例 3.23**
> 顯示十進位數字 5.75 的 Excess_127（單精度）表示法。
>
> **解答**
> a. 符號為正，所以 S = 0。
> b. 十進位轉二進位轉換：5.75 = $(101.11)_2$。
> c. 正規化：$(101.11)_2 = (1.0111)_2 	imes 2^2$。
> d. E = 2 + 127 = 129 = $(10000001)_2$，M = 0111。我們需要在 M 的右邊添加 19 個零使其成為 23 位元。
> e. 表示法如下所示：
> S: 0
> E: 10000001
> M: 01110000000000000000000
> 數字在電腦中儲存為 01000000101110000000000000000000。

> **範例 3.24**
> 顯示十進位數字 –161.875 的 Excess_127（單精度）表示法。
>
> **解答**
> a. 符號為負，所以 S = 1。
> b. 十進位轉二進位轉換：161.875 = $(10100001.111)_2$。
> c. 正規化：$(10100001.111)_2 = (1.0100001111)_2 	imes 2^7$。
> d. E = 7 + 127 = 134 = $(10000110)_2$ 且 M = $(0100001111)_2$。
> e. 表示法：
> S: 1
> E: 10000110
> M: 01000011110000000000000
> 數字在電腦中儲存為 11000011010000111100000000000000。

> **範例 3.25**
> 顯示十進位數字 –0.0234375 的 Excess_127（單精度）表示法。
>
> **解答**
> a. S = 1（數字為負）。
> b. 十進位轉二進位轉換：0.0234375 = $(0.0000011)_2$。
> c. 正規化：$(0.0000011)_2 = (1.1)_2 	imes 2^{-6}$。
> d. E = –6 + 127 = 121 = $(01111001)_2$ 且 M = $(1)_2$。
> e. 表示法：
> S: 1
> E: 01111001
> M: 10000000000000000000000
> 數字在電腦中儲存為 10111100110000000000000000000000。

**檢索以 IEEE 標準浮點格式儲存的數字**
可以使用以下方法檢索儲存在 IEEE 浮點格式之一中的數字：
- 找出 S、E 和 M 的值。
- 如果 S = 0，將符號設為正，否則，將符號設為負。
- 找出移位器 (E - 127)。
- 對尾數進行反正規化。
- 將反正規化的數字轉換為二進位以找出絕對值。
- 添加符號。

> **範例 3.26**
> 位元模式 $(11001010000000000111000100001111)_2$ 以 Excess_127 格式儲存在記憶體中。顯示數字的十進位值是多少。
>
> **解答**
> a. 第一個位元代表 S，接下來的八個位元代表 E，其餘的 23 個位元代表 M：
> S: 1
> E: 10010100
> M: 00000000111000100001111
> b. 符號為負。
> c. 移位器 = E - 127 = 148 - 127 = 21。
> d. 反正規化給出 $(1.00000000111000100001111)_2 	imes 2^{21}$。
> e. 二進位數字為 $(1000000001110001000011.11)_2$。
> f. 絕對值為 2104378.75。
> g. 數字為 -2104378.75。

> **範例 3.27**
> 位元模式 01000011111000000000000000000000 以 Excess_127 格式儲存在記憶體中。顯示數字的十進位值。
>
> **解答**
> a. 第一個位元代表 S，接下來的八個位元代表 E，其餘的 23 個位元代表 M：
> S: 0
> E: 10000111
> M: 11000000000000000000000
> b. 符號為正。
> c. 移位器 = E - 127 = 135 - 127 = 8。
> d. 反正規化給出 $(1.11000000000000000000000)_2 	imes 2^8$。
> e. 二進位數字為 $(111000000.00)_2$。
> f. 絕對值為 448。
> g. 數字為 +448。

**溢位與下溢**
在浮點數的情況下，我們可能會有**溢位**和**下溢**。圖 3.13 顯示了使用 32 位元記憶體位置 (Excess_127) 的浮點數表示法範圍。此表示法無法儲存絕對值非常小或非常大的數字。試圖儲存絕對值非常小的數字會導致下溢情況，而試圖儲存絕對值非常大的數字會導致溢位情況。我們將邊界值（+最大、-最大、+最小和-最小）的計算留作習題。

**儲存零**
您可能已經注意到，整數部分和將數部分都設為零的實數，即 0.0，無法使用上述步驟儲存。為了處理這種特殊情況，約定在此情況下，符號、指數和尾數都設為 0。

**截斷誤差**
當使用浮點數表示法儲存實數時，儲存的數字值可能不完全是我們期望的那樣。例如，假設我們需要儲存數字：
$(1111111111111111.11111111111)_2$
在記憶體中使用 Excess_127 表示法。正規化後，我們有：
$(1.11111111111111111111111111)_2$
這意味著尾數有 26 個 1。此尾數需要被截斷為 23 個 1。換句話說，儲存在電腦中的是：
$(1.11111111111111111111111)_2$
這意味著原始數字變為：
$(1111111111111111.11111111)_2$
小數部分右邊的三個 1 被截斷。原始數字與檢索到的數字之間的差異稱為**截斷誤差**。這種類型的誤差在使用非常小或非常大數字的領域（如航太工業的計算）中非常重要。在這種情況下，我們需要使用更大的記憶體位置和其他表示法。IEEE 定義了其他具有更大尾數的標準用於這些目的。

## 3.3 儲存文字
任何語言中的一段**文字**都是用來代表該語言中思想的符號序列。例如，英語使用 26 個符號 (A, B, C,…, Z) 代表大寫字母，26 個符號 (a, b, c, …, z) 代表小寫字母，十個符號 (0, 1, 2, …, 9) 代表數字字元（不是實際數字——數字是分開處理的，如前一節所述），以及符號 (., ?, :, ; , …, !) 代表標點符號。其他符號如空白、換行和定位用於文字對齊和可讀性。
我們可以用一個位元模式來表示每個符號。換句話說，像「CATS」這樣的文字，由四個符號組成，可以表示為四個 n 位元模式，每個模式定義一個符號（圖 3.14）。

現在的問題是：表示語言中的一個符號需要多少位元的位元模式？這取決於該語言使用的集合中有多少符號。例如，如果我們創建一個只使用英語大寫字母的想像語言，我們只需要 26 個符號。這種語言中的位元模式至少需要表示 26 個符號。
對於另一種語言，如中文，我們可能需要更多的符號。表示語言中符號的位元模式長度取決於該語言中使用的符號數量。更多符號意味著更長的位元模式。
雖然位元模式的長度取決於符號數量，但這種關係不是線性的：它是對數的。如果我們需要兩個符號，長度是一個位元 ($log_2 2$ 是 1)。如果我們需要四個符號，長度是兩個位元 ($log_2 4$ 是 2)。表 3.3 顯示了這種關係。兩個位元的位元模式可以採取四種不同形式：00, 01, 10 和 11。這些形式中的每一種都可以代表一個符號。同樣地，三個位元的位元模式可以採取八種不同形式：000, 001, 010, 011, 100, 101, 110 和 111。

**表 3.3 符號數量與位元模式長度**

| 符號數量 | 位元模式長度 | 符號數量 | 位元模式長度 |
| :--- | :--- | :--- | :--- |
| 2 | 1 | 128 | 7 |
| 4 | 2 | 256 | 8 |
| 8 | 3 | 65536 | 16 |
| 16 | 4 | 4294967296 | 32 |

### 3.3.1 代碼
已經設計了不同的位元模式集來表示文字符號。每個集合稱為一個**代碼**，表示符號的過程稱為**編碼**。在本節中，我們解釋常見的代碼。

**ASCII**
**美國國家標準協會 (ANSI)** 開發了一種稱為**美國資訊交換標準碼 (ASCII)** 的代碼。此代碼為每個符號使用七個位元。這意味著可以在此代碼中定義 $2^7 = 128$ 個不同的符號。ASCII 碼的完整位元模式包含在附錄 A 中。今天 ASCII 是 Unicode 的一部分，接下來將討論 Unicode。

**Unicode**
硬體和軟體製造商聯盟設計了一種稱為 **Unicode** 的代碼，它使用 32 位元，因此可以表示多達 $2^{32} = 4294967296$ 個符號。代碼的不同部分分配給世界不同語言的符號。代碼的某些部分用於圖形和特殊符號。附錄 A 列出了一組簡短的 Unicode 符號。ASCII 是今天 Unicode 的一部分。

## 3.4 儲存音訊
**音訊**是聲音或音樂的表示。從本質上講，音訊與我們目前討論的數字或文字不同。文字由可數的實體（字元）組成：我們可以計算文字中的字元數。文字是**數位**資料的一個例子。相比之下，音訊是不可數的。音訊是隨時間變化的實體——我們只能測量每一時刻的聲音強度。當我們討論在電腦記憶體中儲存音訊時，我們指的是儲存一段時間內（一秒、一小時）音訊信號（例如來自麥克風的信號）的強度。
音訊是**類比**資料的一個例子。即使我們能夠測量一段時間內的所有值，我們也無法將這些儲存在電腦記憶體中，因為我們需要無限數量的記憶體位置。圖 3.15 顯示了隨時間變化的類比信號（如音訊）的性質。

### 3.4.1 取樣
如果我們不能記錄一段間隔內音訊信號的所有值，我們可以記錄其中的一部分。**取樣**意味著我們只選擇類比信號上有限數量的點，測量它們的值並記錄下來。圖 3.16 顯示了從信號中選擇十個樣本：然後我們可以記錄這些值來表示類比信號。

**取樣率**
下一個合乎邏輯的問題是，我們每秒需要多少個樣本才能檢索原始信號的複製品？樣本數取決於類比信號中的最大變化數。如果信號平滑，我們需要較少的樣本：如果信號變化迅速，我們需要更多的樣本。已經證明，每秒 40000 個樣本的**取樣率**足以重現音訊信號。

### 3.4.2 量化
每個樣本測量的值是一個實數。這意味著我們可以為每一秒樣本儲存 40000 個實數值。然而，為每個樣本使用一個無符號數字（位元模式）更簡單。**量化**是指將樣本值四捨五入到最接近整數值的過程。例如，如果實數值是 17.2，它可以向下捨入為 17：如果值是 17.7，它可以向上捨入為 18。

### 3.4.3 編碼
下一個任務是編碼。量化後的樣本值需要被編碼為位元模式。一些系統為樣本分配正值和負值，一些只是將曲線移到正部分並只分配正值。換句話說，一些系統使用無符號整數來表示樣本，而其他系統使用有符號整數。然而，有符號整數不必是二的補數，它們可以是符號與數值。最左邊的位元用於表示符號（0 為正值，1 為負值），其餘位元用於表示絕對值。

**每個樣本的位元數**
系統需要決定應為每個樣本分配多少位元。雖然過去只分配 8 位元給聲音樣本，但今天每個樣本 16、24 甚至 32 位元是正常的。每個樣本的位元數有時稱為**位元深度**。

**位元率**
如果我們稱位元深度或每個樣本的位元數為 B，每秒樣本數為 S，我們需要為每秒音訊儲存 S × B 位元。這個乘積有時稱為**位元率** R。例如，如果我們使用每秒 40000 個樣本和每個樣本 16 位元，位元率是 R = 40000 × 16 = 640000 位元每秒 = 640 kbps。

### 3.4.4 聲音編碼標準
今天儲存音訊的主流標準是 **MP3**（MPEG Layer 3 的縮寫）。此標準是用於視訊的 **MPEG**（動態影像專家小組）壓縮方法的修改版。它使用每秒 44100 個樣本和每個樣本 16 位元。結果是一個位元率為 705600 bps 的信號，該信號使用一種丟棄人耳無法檢測到的資訊的壓縮方法進行壓縮。這稱為失真壓縮，與無損壓縮相對：見第 15 章。

## 3.5 儲存圖像
圖像在電腦中使用兩種不同的技術儲存：點陣圖形和向量圖形。

### 3.5.1 點陣圖形
當我們需要儲存像照片這樣的類比圖像時，使用**點陣圖形**（或**位圖**）。照片由類比資料組成，類似於音訊資訊：不同之處在於資料的強度（顏色）隨空間而不是隨時間變化。這意味著資料必須被取樣。然而，這種情況下的取樣通常稱為**掃描**。樣本稱為**像素**（代表**圖片元素**）。換句話說，整個圖像被劃分為小像素，其中每個像素被假定具有單一強度值。

**解析度**
就像音訊取樣一樣，在圖像掃描中，我們需要決定每平方或線性英吋需要記錄多少像素。圖像處理中的掃描率稱為**解析度**。如果解析度足夠高，人眼無法識別再現圖像中的不連續性。

**色彩深度**
用於表示像素的位元數，即其**色彩深度**，取決於不同編碼技術如何處理像素的顏色。顏色的感知是我們的眼睛對光束的反應。我們的眼睛有不同類型的*感光*細胞：一些對三種原色紅、綠和藍（通常稱為 **RGB**）有反應，而其他僅對光的強度有反應。

**全彩 (True-Color)**
用於編碼像素的技術之一稱為**全彩**，它使用 24 位元來編碼一個像素。在這種技術中，三種原色（RGB）中的每一種都由八個位元表示。由於 8 位元模式可以表示 0 到 255 之間的數字，因此在這種技術中，每種顏色都由三個 0 到 255 之間的十進位數字表示。表 3.4 顯示了這種技術中某些顏色的三個值。

**表 3.4 全彩中定義的一些顏色**

| 顏色 | 紅 | 綠 | 藍 | 顏色 | 紅 | 綠 | 藍 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 黑色 | 0 | 0 | 0 | 黃色 | 255 | 255 | 0 |
| 紅色 | 255 | 0 | 0 | 青色 | 0 | 255 | 255 |
| 綠色 | 0 | 255 | 0 | 洋紅色 | 255 | 0 | 255 |
| 藍色 | 0 | 0 | 255 | 白色 | 255 | 255 | 255 |

請注意，全彩方案可以編碼 $2^{24}$ 或 16776216 種顏色。換句話說，每個像素的顏色強度是這些值之一。

**索引色**
全彩方案使用超過 1600 萬種顏色。許多應用程式不需要如此大範圍的顏色。**索引色**——或**調色盤色**——方案只使用這些顏色的一部分。在這種方案中，每個應用程式從大量顏色集合中選擇少數（通常是 256 種）顏色並對它們進行索引，為每個選定的顏色分配一個 0 到 255 之間的數字。這類似於藝術家可能在工作室中有許多顏色，但在任何時候只在調色盤上使用少數幾種顏色。圖 3.17 說明了索引色的概念。

使用索引減少了儲存像素所需的位元數。例如，在全彩方案中，需要 24 位元來儲存單個像素。索引色方案通常使用 256 個索引，這只需要八個位元來儲存同一個像素。例如，高品質數位相機使用近三百萬像素拍攝 3 × 5 英吋的照片。
以下顯示了使用每種方案需要儲存的位元數：
全彩：3000000 × 24 = 72000000
索引色：3000000 × 8 = 24000000

**圖像編碼標準**
目前使用幾種事實上的圖像編碼標準。**JPEG (聯合圖像專家小組)** 使用全彩方案，但壓縮圖像以減少位元數（見第 15 章）。另一方面，**GIF (圖形交換格式)** 使用索引色方案。

### 3.5.2 向量圖形
點陣圖形有兩個缺點：檔案大小大且重新縮放很麻煩。放大點陣圖形圖像意味著放大像素，因此放大時圖像看起來呈鋸齒狀。然而，**向量圖形**圖像編碼方法不儲存每個像素的位元模式。圖像被分解為幾何形狀的組合，如線條、正方形或圓形。每個幾何形狀由數學公式表示。例如，一條線可以由其端點的坐標描述，圓可以由其中心點的坐標及其半徑長度描述。向量圖形圖像由一系列定義應如何繪製這些形狀的命令組成。
當要顯示或列印圖像時，圖像的大小作為輸入提供給系統。系統將圖像重新縮放到新大小，並使用相同的公式繪製圖像。在這種情況下，每次繪製圖像時，公式都會重新計算。因此，向量圖形也稱為*幾何建模*或*物件導向圖形*。

例如，考慮一個半徑為 r 的圓。程式繪製此圓所需的主要資訊是：
1. 半徑 r 和圓的方程式。
2. 圓中心點的位置。
3. 筆劃線條樣式和顏色。
4. 填充樣式和顏色。

當圓的大小改變時，程式改變半徑的值並重新計算資訊以再次繪製圓。重新縮放不會改變繪圖的品質。

向量圖形不適合儲存攝影圖像的細微差別。JPEG 或 GIF 點陣圖形提供更好、更生動的圖片。向量圖形適用於主要使用幾何圖元創建圖像的應用程式。它用於 FLASH 等應用程式，以及創建 TrueType (Microsoft, Apple) 和 PostScript (Adobe) 字體。電腦輔助設計 (CAD) 也使用向量圖形進行工程繪圖。

## 3.6 儲存影像
**影像**是一段時間內圖像（稱為**影格**）的表示。電影由一系列相繼顯示的影格組成，以產生運動的錯覺。換句話說，影像是隨空間（單一圖像）和時間（一系列圖像）變化的資訊的表示。因此，如果我們知道如何在電腦內儲存圖像，我們也就知道如何儲存影像：每個圖像或影格都被轉換為一組位元模式並儲存起來。圖像的組合隨後代表影像。今天影像通常被壓縮。在第 15 章中，我們討論 MPEG，一種常見的影像壓縮技術。

## 3.7 章末材料
### 3.7.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Halsall, F. *Multimedia Communication*, Boston, MA: Addison-Wesley, 2001
- Koren, I. *Computer Arithmetic Algorithms*, Natick, MA: A K Peters, 2001
- Long, B. *Complete Digital Photography*, Hignham, MA: Charles River Media, 2003
- Mano, M. *Computer System Architecture*, Upper Saddle River, NJ: Prentice-Hall, 1993
- Miano, J. *Compressed Image File Formats*, Boston, MA: Addison-Wesley, 1999

### 3.7.2 關鍵詞
- 美國國家標準協會 (ANSI)
- 美國資訊交換標準碼 (ASCII)
- 類比 (analog)
- 音訊 (audio)
- 二進位數字 (binary digit)
- 位元 (bit)
- 位元深度 (bit depth)
- 點陣圖形 (bitmap graphic)
- 位元模式 (bit pattern)
- 位元率 (bit rate)
- 位元組 (byte)
- 代碼 (code)
- 色彩深度 (color depth)
- 數位 (digital)
- Excess_1023
- Excess_127
- 超額表示法 (Excess representation)
- 浮點數表示法 (floating-point representation)
- 影格 (frames)
- 圖形交換格式 (GIF)
- 索引色 (indexed color)
- 聯合圖像專家小組 (JPEG)
- 尾數 (mantissa)
- MP3
- MPEG
- 正規化 (normalization)
- 一的補數 (one’s complement)
- 溢位 (overflow)
- 調色盤色 (palette color)
- 圖片元素 (picture element)
- 像素 (pixel)
- 量化 (quantization)
- 點陣圖形 (raster graphic)
- 實數 (real)
- 解析度 (resolution)
- RGB
- 取樣 (sampling)
- 取樣率 (sampling rate)
- 掃描 (scanning)
- 科學記數法 (scientific notation)
- 符號與數值表示法 (sign-and-magnitude representation)
- 文字 (text)
- 文字編輯器 (text editor)
- 全彩 (True-Color)
- 截斷誤差 (truncation error)
- 二的補數 (two’s complement)
- 二的補數表示法 (two’s complement representation)
- 下溢 (underflow)
- Unicode
- 無符號整數 (unsigned integer)
- 向量圖形 (vector graphic)
- 影像 (video)

### 3.7.3 摘要
- 資料以不同形式存在，包括數字、文字、音訊、圖像和影像。所有資料類型都被轉換為稱為位元模式的統一表示形式。
- 數字在儲存到電腦記憶體之前被轉換為二進位系統。有幾種方法可以處理符號。有兩種方法可以處理小數點：定點數和浮點數。整數可以被認為是小數點位置固定的數字：小數點位於最低有效位元的右邊。無符號整數是永遠不會為負的整數。用於儲存有符號整數的方法之一是符號與數值格式。在這種格式中，最左邊的位元用於顯示符號，其餘位元定義數值。符號和數值彼此分開。幾乎所有電腦都使用二的補數表示法在 $n$ 位元記憶體位置中儲存有符號整數。在這種方法中，無符號整數的可用範圍分為兩個相等的子範圍。前半部分用於表示非負整數，後半部分用於表示負整數。在二的補數表示法中，最左邊的位元定義整數的符號，但符號和數值沒有彼此分開。實數是具有整數部分和小數部分的數字。實數使用浮點數表示法儲存在電腦中。在浮點數表示法中，數字由三個部分組成：符號、移位器和定點數。
- 任何語言中的一段文字都是符號序列。我們可以用位元模式表示每個符號。已經設計了不同的位元模式集（代碼）來表示文字符號。硬體和軟體製造商聯盟設計了一種稱為 Unicode 的代碼，它使用 32 位元來表示一個符號。
- 音訊是聲音或音樂的表示。音訊是類比資料。我們不能記錄一段間隔內的無限數量的值，我們只能記錄一些樣本。樣本數取決於類比信號中的最大變化數。為每個樣本測量的值是一個實數。量化是指將樣本值四捨五入為整數的過程。
- 圖像的儲存使用兩種不同的技術完成：點陣圖形和向量圖形。當我們需要儲存像照片這樣的類比圖像時，使用點陣圖形。圖像被掃描（取樣）並儲存像素。在向量圖形方法中，圖像被分解為幾何形狀的組合，如線條、正方形或圓形。每個幾何形狀由數學公式表示。
- 影像是時間內的圖像（稱為影格）的表示。電影是一系列相繼顯示的影格，以產生連續運動的錯覺。換句話說，影像是隨空間（單一圖像）和時間（一系列圖像）變化的資訊的表示。

## 3.8 練習題
### 3.8.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 3.8.2 複習問題
1. 列舉電腦可以處理的五種資料類型。
2. 位元模式長度與位元模式可以表示的符號數量有何關係？
3. 點陣圖形方法如何將圖像表示為位元模式？
4. 向量圖形方法相對於點陣圖形方法有什麼優點？缺點是什麼？
5. 將音訊資料轉換為位元模式需要哪些步驟？
6. 比較和對比無符號、符號與數值格式以及二的補數格式中正整數的表示法。
7. 比較和對比符號與數值和二的補數格式中負整數的表示法。
8. 比較和對比符號與數值、二的補數和超額格式中零的表示法。
9. 討論最左邊位元在符號與數值和二的補數格式中的作用。
10. 回答有關實數浮點表示法的以下問題：
    a. 為什麼需要正規化？
    b. 什麼是尾數？
    c. 數字正規化後，電腦在記憶體中儲存什麼樣的資訊？

### 3.8.3 問題
1. 我們可以有多少個不同的 5 位元模式？
2. 在某些國家，車輛牌照有兩個十進位數字（0 到 9）。我們可以有多少個不同的牌照？如果牌照上不允許使用數字 0，我們可以有多少個不同的牌照？
3. 為一個有兩位數字後面跟著三個大寫字母（A 到 Z）的牌照重做問題 P3-2。
4. 一台機器有八個不同的週期。需要多少位元來表示每個週期？
5. 學生在課程中的成績可以是 A、B、C、D、F、W（退選）或 I（未完成）。需要多少位元來表示成績？
6. 一家公司決定為每位員工分配一個唯一的位元模式。如果公司有 900 名員工，創建此表示系統所需的最小位元數是多少？有多少模式未分配？如果公司再僱用 300 名員工，是否應該增加位元數？解釋您的答案。
7. 如果我們使用 4 位元模式來表示數字 0 到 9，有多少位元模式被浪費了？
8. 音訊信號每秒取樣 8000 次。每個樣本由 256 個不同級別表示。表示此信號每秒需要多少位元？
9. 將以下十進位數字更改為 8 位元無符號整數。
    a. 23
    b. 121
    c. 34
    d. 342
10. 將以下十進位數字更改為 16 位元無符號整數。
    a. 41
    b. 411
    c. 1234
    d. 342
11. 將以下十進位數字更改為 8 位元二的補數整數。
    a. −12
    b. −145
    c. 56
    d. 142
12. 將以下十進位數字更改為 16 位元二的補數整數。
    a. 102
    b. −179
    c. 534
    d. 62,056
13. 將以下 8 位元無符號數字更改為十進位。
    a. 01101011
    b. 10010100
    c. 00000110
    d. 01010000
14. 將以下 8 位元二的補數數字更改為十進位。
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
15. 以下是二的補數二進位數字。顯示如何更改數字的符號。
    a. 01110111
    b. 11111100
    c. 01110111
    d. 11001110
16. 如果我們對一個數字應用兩次二的補數運算，我們應該得到原始數字。對以下每個數字應用二的補數運算，看看是否能得到原始數字。
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
17. 正規化以下二進位浮點數。明確顯示正規化後指數的值。
    a. 1.10001
    b. $2^3 \\times 111.1111$
    c. $2^{-2} \\times 101.110011$
    d. $2^{-5} \\times 101101.00000110011000$
18. 將以下數字轉換為 32 位元 IEEE 格式。
    a. $-2^0 \\times 1.10001$
    b. $+2^3 \\times 1.111111$
    c. $+2^{-4} \\times 1.01110011$
    d. $-2^{-5} \\times 1.01101000$
19. 將以下數字轉換為 64 位元 IEEE 格式。
    a. $-2^0 \\times 1.10001$
    b. $+2^3 \\times 1.111111$
    c. $+2^{-4} \\times 1.01110011$
    d. $-2^{-5} \\times 1.01101000$
20. 將以下數字轉換為 32 位元 IEEE 格式。
    a. 7.1875
    b. −12.640625
    c. 11.40625
    d. −0.375
21. 以下是 8 位元分配的符號與數值二進位數字。將它們轉換為十進位。
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
22. 將以下十進位整數轉換為具有 8 位元分配的符號與數值。
    a. 53
    b. −107
    c. −5
    d. 154
23. 電腦中表示有符號數字的一種方法是一的補數表示法。在這種表示法中，為了表示正數，我們儲存二進位數字。為了表示負數，我們對數字應用一的補數運算。將以下十進位整數儲存為具有 8 位元分配的一的補數。
    a. 53
    b. −107
    c. −5
    d. 154
24. 以下是 8 位元分配的一的補數二進位數字。將它們轉換為十進位。
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
25. 如果我們對一個數字應用兩次一的補數運算，我們應該得到原始數字。對以下每個數字應用兩次一的補數運算，看看是否能得到原始數字。
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
26. 找出數字二的補數的另一種方法是先取數字的一的補數，然後將結果加 1。（二進位整數的加法在第 4 章解釋）。對以下數字嘗試這兩種方法。比較和對比結果。
    a. 01110111
    b. 11111100
    c. 01110100
    d. 11001110
27. 二進位系統中一的補數等同於十進位系統中的九的補數（$1 = 2 - 1$ 和 $9 = 10 - 1$）。使用 $n$ 位數分配，我們可以表示範圍在 $- [(10^n/2) - 1]$ 到 $+ [(10^n/2 - 1)]$ 的九的補數數字。具有 $n$ 位數分配的數字的九的補數獲得如下。如果數字為正，數字的九的補數就是它本身。如果數字為負，我們從 9 中減去每個數字。回答有關三位數分配的以下問題：
    a. 我們可以使用九的補數表示的數字範圍是多少？
    b. 在這個系統中，我們如何確定數字的符號？
    c. 我們在這個系統中有兩個零嗎？
    d. 如果 c 的答案是肯定的，+0 和 -0 的表示是什麼？
28. 假設三位數分配，找出以下十進位數字的九的補數。
    a. +234
    b. +560
    c. -125
    d. -111
29. 二進位系統中二的補數等同於十進位系統中的十的補數（在二進位系統中，2 是基底，在十進位系統中，10 是基底）。使用 $n$ 位數分配，我們可以用十的補數格式表示範圍在 $-(10^n/2)$ 到 $+(10^n/2 - 1)$ 的數字。具有 $n$ 位數分配的數字的十的補數是通過首先找到數字的九的補數然後將結果加 1 獲得的。回答有關三位數分配的以下問題。
    a. 我們可以使用十的補數表示的數字範圍是多少？
    b. 在這個系統中，我們如何確定數字的符號？
    c. 我們在這個系統中有兩個零嗎？
    d. 如果 c 的答案是肯定的，+0 和 -0 的表示是什麼？
30. 假設三位數分配，找出以下十進位數字的十的補數。
    a. +234
    b. +560
    c. -125
    d. -111
31. 二進位系統中一的補數等同於十六進位系統中的十五的補數（$1 = 2 - 1$ 和 $15 = 16 - 1$）。
    a. 我們可以用十五的補數和三位數分配表示什麼範圍的數字？
    b. 解釋如何在十六進位系統中獲得數字的十五的補數。
    c. 我們在這個系統中有兩個零嗎？
    d. 如果 c 的答案是肯定的，+0 和 -0 的表示是什麼？
32. 假設三位數分配，找出以下十六進位數字的十五的補數。
    a. +B14
    b. +FE1
    c. -1A
    d. -1E2
33. 二進位系統中二的補數等同於十六進位系統中的十六的補數。
    a. 我們可以用十六的補數和三位數分配表示什麼範圍的數字？
    b. 解釋如何在十六進位系統中獲得數字的十六的補數。
    c. 我們在這個系統中有兩個零嗎？
    d. 如果 c 的答案是肯定的，+0 和 -0 的表示是什麼？
34. 假設三位數分配，找出以下十六進位數字的十六的補數。
    a. +B14
    b. +FE1
    c. −1A
    d. −1E2
`},n={en:`
# Chapter 4: Operations on Data

In Chapter 3 we showed how to store different types of data in a computer. In this chapter, we show how to operate on data stored in a computer. Operations on data can be divided into three broad categories: logic operations, shift operations, and arithmetic operations.

## Objectives
After studying this chapter, the student should be able to:
- List the three categories of operations performed on data.
- Perform unary and binary logic operations on bit patterns.
- Distinguish between logic shift operations and arithmetic shift operations.
- Perform logic shift operations on bit patterns.
- Perform arithmetic shift operations on integers stored in two’s complement format.
- Perform addition and subtraction on integers when they are stored in two’s complement format.
- Perform addition and subtraction on integers when they are stored in sign-and-magnitude format.
- Perform addition and subtraction operations on reals when they are stored in floating-point format.
- Understand some applications of logical and shift operations such as setting, unsetting, and flipping specific bits.

## 4.1 LOGIC OPERATIONS
In Chapter 3 we discussed the fact that data inside a computer is stored as patterns of bits. Logic operations refer to those operations that apply the same basic operation on individual bits of a pattern, or on two corresponding bits in two patterns. This means that we can define logic operations at the bit level and at the pattern level. A logic operation at the pattern level is $n$ logic operations, of the same type, at the bit level where $n$ is the number of bits in the pattern.

### 4.1.1 Logic operations at bit level
A bit can take one of the two values: 0 or 1. If we interpret 0 as the value *false* and 1 as the value *true*, we can apply the operations defined in **Boolean algebra** to manipulate bits. Boolean algebra, named in honor of George Boole, belongs to a special field of mathematics called *logic*. Boolean algebra and its application to building logic circuits in computers are briefly discussed in Appendix E. In this section, we show briefly four bit-level operations that are used to manipulate bits: NOT, AND, OR, and XOR.

Figure 4.1 shows the symbols for these four bit-level operators and their truth tables. A **truth table** defines the values of output for each possible input or inputs. Note that the output of each operator is always one bit, but the input can be one or two bits.

**NOT**
The **NOT operator** is a unary operator: it takes only one input. The output bit is the complement of the input. If the input is 0, the output is 1, if the input is 1, the output is 0. In other words, the NOT operator flips its input. The truth table of the NOT operator has only two rows because the single input can be either 0 or 1: two possibilities.

| x | NOT x |
| :--- | :--- |
| 0 | 1 |
| 1 | 0 |

**AND**
The **AND operator** is a binary operator: it takes two inputs. The output bit is 1 if both inputs are 1s and the output is 0 in the other three cases. The truth table of the AND operator has four rows because, with two inputs, there are four possible input combinations.

| x | y | x AND y |
| :--- | :--- | :--- |
| 0 | 0 | 0 |
| 0 | 1 | 0 |
| 1 | 0 | 0 |
| 1 | 1 | 1 |

**A property**
One interesting point about the AND operator is that if a bit in one input is 0, we do not have to check the corresponding bit in the other input: we can quickly conclude that the result is 0. We use this property when we discuss the application of this operator in relation to a bit pattern:
For x = 0 or 1: x AND 0 → 0 and 0 AND x → 0

**OR**
The **OR operator** is a also a binary operator: it takes two inputs. The output bit is 0 if both inputs are 0s and the output is 1 in the other three cases. The truth table of the OR operator has also four rows. The OR operator is sometimes called the *inclusive-or operator* because the output is 1 not only when one of the inputs is 1, but also when both inputs are 1s. This is in contrast to the operator we introduce next.

| x | y | x OR y |
| :--- | :--- | :--- |
| 0 | 0 | 0 |
| 0 | 1 | 1 |
| 1 | 0 | 1 |
| 1 | 1 | 1 |

**A property**
One interesting point about the OR operator is that if a bit in one input is 1, we do not have to check the corresponding bit in the other input: we can quickly conclude that the result is 1. We use this property when we discuss the application of this operator in relation to a bit pattern:
For x = 0 or 1: x OR 1 → 1 and 1 OR x → 1

**XOR**
The **XOR operator** (pronounced ‘exclusive-or’) is also a binary operator like the OR operator, with only one difference: the output is 0 if both inputs are 1s. We can look at this operator in another way: the output is 0 when both inputs are the same, and the output is 1 when the inputs are different.

| x | y | x XOR y |
| :--- | :--- | :--- |
| 0 | 0 | 0 |
| 0 | 1 | 1 |
| 1 | 0 | 1 |
| 1 | 1 | 0 |

> **Example 4.1**
> In English we use the conjunction ‘or’ sometimes to mean an inclusive-or, and sometimes to mean an exclusive-or.
> a. The sentence ‘I wish to have a car *or* a house’ uses ‘or’ in the inclusive sense—I wish a car, a house, or both.
> b. The sentence ‘Today is either Monday *or* Tuesday’ uses ‘or’ in the exclusive sense—today is either Monday or Tuesday, but it cannot be both.

> **Example 4.2**
> The XOR operator is not actually a new operator. We can always simulate it using the other three operators. The following two expressions are equivalent:
> x XOR y ↔ [x AND (NOT y)] OR [(NOT x) AND y]
> The equivalence can be proved if we make the truth table for both.

**A property**
A property of XOR is that if a bit in one input is 1, the result is the complement of the corresponding bit in the other input. We use this property when we discuss the application of this operator in relation to a bit pattern:
For x = 0 or 1: 1 XOR x → NOT x and x XOR 1 → NOT x

### 4.1.2 Logic operations at pattern level
The same four operators (NOT, AND, OR, and XOR) can be applied to an $n$-bit pattern. The effect is the same as applying each operator to each individual bit for NOT and to each corresponding pair of bits for other three operators. Figure 4.2 shows these four operators with input and output patterns.

> **Example 4.3**
> Use the NOT operator on the bit pattern 10011000.
>
> **Solution**
> The solution is shown below. Note that the NOT operator changes every 0 to 1 and every 1 to 0:
> Input: 1 0 0 1 1 0 0 0
> NOT: 0 1 1 0 0 1 1 1

> **Example 4.4**
> Use the AND operator on the bit patterns 10011000 and 00101010.
>
> **Solution**
> The solution is shown below. Note that only one bit in the output is 1, where both corresponding inputs are 1s:
> Input 1: 1 0 0 1 1 0 0 0
> Input 2: 0 0 1 0 1 0 1 0
> AND: 0 0 0 0 1 0 0 0

> **Example 4.5**
> Use the OR operator on the bit patterns 10011001 and 00101110.
>
> **Solution**
> The solution is shown below. Note that only one bit in the output is 0, where both corresponding inputs are 0s:
> Input 1: 1 0 0 1 1 0 0 1
> Input 2: 0 0 1 0 1 1 1 0
> OR: 1 0 1 1 1 1 1 1

> **Example 4.6**
> Use the XOR operator on the bit patterns 10011001 and 00101110.
>
> **Solution**
> The solution is shown below. Compare the output in this example with the one in Example 4.5. The only difference is that when the two inputs are 1s, the result is 0 (the effect of exclusion):
> Input 1: 1 0 0 1 1 0 0 1
> Input 2: 0 0 1 0 1 1 1 0
> XOR: 1 0 1 1 0 1 1 1

**Applications**
Four logic operations can be used to modify a bit pattern.

**Complementing**
The only application of the NOT operator is to complement the whole pattern. Applying this operator to a pattern changes every 0 to 1 and every 1 to 0. This is sometimes referred to as a one’s complement operation. Example 4.3 shows the effect of complementing.

**Unsetting specific bits**
One of the applications of the AND operator is to unset (force to 0) specific bits in a bit pattern. The second input in this case is called a **mask**. The 0-bits in the mask unset the corresponding bits in the first input: the 1-bits in the mask leave the corresponding bits in the first input unchanged. This is due to the property we mentioned for the AND operator: if one of the inputs is 0, the output is 0 no matter what the other input is. Unsetting the bits in a pattern can have many applications. For example, if an image is using only one bit per pixel (a black and white image), then we can make a specific pixel black using a mask and the AND operator.

> **Example 4.7**
> Use a mask to unset (clear) the five leftmost bits of a pattern. Test the mask with the pattern 10100110.
>
> **Solution**
> The mask is 00000111. The result of applying the mask is:
> Input: 1 0 1 0 0 1 1 0
> Mask: 0 0 0 0 0 1 1 1
> AND: 0 0 0 0 0 1 1 0
> Note that the three rightmost bits remain unchanged, while the five leftmost bits are unset (changed to 0) no matter what their previous values.

**Setting specific bits**
One of the applications of the OR operator is to set (force to 1) specific bits in a bit pattern. Again we can use a mask, but a different one. The 1-bits in the mask set the corresponding bits in the first input, and the 0-bits in the mask leave the corresponding bits in the first input unchanged. This is due to the property we mentioned for the OR operator: if one of the inputs is 1, the output is 1 no matter what the other input is. Setting the bits in a pattern has many applications. For example, if an image is using only one bit per pixel (a black and white image), then we can make a specific pixel white using a mask and the OR operator.

> **Example 4.8**
> Use a mask to set the five leftmost bits of a pattern. Test the mask with the pattern 10100110.
>
> **Solution**
> The mask is 11111000. The result of applying the mask is:
> Input: 1 0 1 0 0 1 1 0
> Mask: 1 1 1 1 1 0 0 0
> OR: 1 1 1 1 1 1 1 0

**Flipping specific bits**
One of the applications of the XOR operator is to flip (complement) specific bits in a bit pattern. Again we can use a mask, but a different one. The 1-bits in the mask flip the corresponding bits in the first input, and the 0-bits in the mask leave the corresponding bits in the first input unchanged. This is due to the property we mentioned for the XOR operator: if one of the inputs is 1, the output is the complement of the corresponding bit. Note the difference between the NOT operator and the XOR operator. The NOT operator complements all the bits in the input, while the XOR operator complements only the specific bits in the first input as defined by the mask.

> **Example 4.9**
> Use a mask to flip the five leftmost bits of a pattern. Test the mask with the pattern 10100110.
>
> **Solution**
> The mask is 11111000. The result of applying the mask is:
> Input: 1 0 1 0 0 1 1 0
> Mask: 1 1 1 1 1 0 0 0
> XOR: 0 1 0 1 1 1 1 0

## 4.2 SHIFT OPERATIONS
Shift operations move the bits in a pattern, changing the positions of the bits. They can move bits to the left or to the right. We can divide shift operations into two categories: logical shift operations and arithmetic shift operations.

### 4.2.1 Logical shift operations
A **logical shift operation** is applied to a pattern that does not represent a signed number. The reason is that these shift operation may change the sign of the number that is defined by the leftmost bit in the pattern. We distinguish two types of logical shift operations, as described below.

**Simple shift**
A **simple right shift** operation shifts each bit one position to the right. In an $n$-bit pattern, the rightmost bit is lost and a 0 fills the leftmost bit. A **simple left shift** operation shifts each bit one position to the left. In an $n$-bit pattern, the leftmost bit is lost and a 0 fills the rightmost bit. Figure 4.3 shows the simple right shift and simple left shift operations for an 8-bit pattern.

> **Example 4.10**
> Use a simple left shift operation on the bit pattern 10011000.
>
> **Solution**
> The solution is shown below. The leftmost bit is lost and a 0 is inserted as the rightmost bit:
> Original: 1 0 0 1 1 0 0 0
> After shift: 0 0 1 1 0 0 0 0

**Circular shift**
A **circular shift operation** (or **rotate operation**) shifts bits, but no bit is lost or added. A **circular right shift** (or **right rotate**) shifts each bit one position to the right. The rightmost bit is circulated and becomes the leftmost bit. A **circular left shift** (or **left rotate**) shifts each bit one position to the left. The leftmost bit circulates and become the rightmost bit. Figure 4.4 shows the circular shift left and circular shift right operation.

> **Example 4.11**
> Use a circular left shift operation on the bit pattern 10011000.
>
> **Solution**
> The solution is shown below. The leftmost bit is circulated and becomes the rightmost bit:
> Original: 1 0 0 1 1 0 0 0
> After shift: 0 0 1 1 0 0 0 1

> **Example 4.12**
> Combining logic operations and logical shift operations gives us some tools for manipulating bit patterns. Assume that we have a pattern and we need to use the third bit (from the right) of this pattern in a decision-making process. We want to know if this particular bit is 0 or 1. The following shows how we can find out:
> Original: h g f e d c b a
> One right shift: 0 h g f e d c b
> Two right shifts: 0 0 h g f e d c
> Mask: 0 0 0 0 0 0 0 1
> AND result: 0 0 0 0 0 0 0 c
> We shift the pattern two bits to the right so that the target bit moves to the rightmost position. The result is then ANDed with a mask which has one 1 at the rightmost position. The result is a pattern with seven 0s and the target bit at the rightmost position. We can then test the result: if it is an unsigned integer 1, the target bit was 1, whereas if the result is an unsigned integer 0, the target bit was 0.

**Arithmetic shift operations**
**Arithmetic shift operations** assume that the bit pattern is a signed integer in two’s complement format. **Arithmetic right shift** is used to divide an integer by two, while **arithmetic left shift** is used to multiply an integer by two. These operations should not change the sign (leftmost) bit. An arithmetic right shift retains the sign bit, but also copies it into the next right bit, so that the sign is preserved. An arithmetic left shift discards the sign bit and accepts the bit to the left of the sign bit as the sign. If the new sign bit is the same as the previous one, the operation is successful, otherwise an overflow or underflow has occurred and the result is not valid. Figure 4.5 shows these two operations.

> **Example 4.13**
> Use an arithmetic right shift operation on the bit pattern 10011001. The pattern is an integer in two’s complement format.
>
> **Solution**
> The solution is shown below. The leftmost bit is retained and also copied to its right neighbor bit. The rightmost bit is lost:
> Original: 1 0 0 1 1 0 0 1
> After shift: 1 1 0 0 1 1 0 0
> The original number was –103 and the new number is –52, which is the result of dividing –103 by 2 truncated to the smaller integer.

> **Example 4.14**
> Use an arithmetic left shift operation on the bit pattern 11011001. The pattern is an integer in two’s complement format.
>
> **Solution**
> The solution is shown below. The leftmost bit is lost and a 0 is inserted as the rightmost bit:
> Original: 1 1 0 1 1 0 0 1
> After shift: 1 0 1 1 0 0 1 0
> The original number was –39 and the new number is –78. The original number is multiplied by two. The operation is valid because no underflow occurred.

> **Example 4.15**
> Use an arithmetic left shift operation on the bit pattern 01111111. The pattern is an integer in two’s complement format.
>
> **Solution**
> The solution is shown below. The leftmost bit is lost and a 0 is inserted as the rightmost bit:
> Original: 0 1 1 1 1 1 1 1
> After shift: 1 1 1 1 1 1 1 0
> The original number was 127 and the new number is –2. Here the result is not valid because an overflow has occurred. The expected answer 127 × 2 = 254 cannot be represented by an 8-bit pattern.

## 4.3 ARITHMETIC OPERATIONS
**Arithmetic operations** involve adding, subtracting, multiplying, and dividing. We can apply these operations to integers and floating-point numbers.

### 4.3.1 Arithmetic operations on integers
All arithmetic operations such as addition, subtraction, multiplication, and division can be applied to integers. Although multiplication (division) of integers can be implemented using repeated addition (subtraction), the procedure is not efficient. There are more efficient procedures for multiplication and division, such as Booth procedures, but these are beyond the scope of this book. For this reason, we only discuss addition and subtraction of integers here.

**Addition and subtraction for two’s complement integers**
We first discuss addition and subtraction for integers in two’s complement representation, because it is more common. As we discussed in Chapter 3, integers are normally stored in two’s complement format. One of the advantages of two’s complement representation is that there is no difference between addition and subtraction. When the subtraction operation is encountered, the computer simply changes it to an addition operation, but makes two’s complement of the second number. In other words:
$A - B leftrightarrow A + (\bar{B} + 1)$ where $(\bar{B} + 1)$ means the two’s complement of B.

This means that we only need to discuss addition. Adding numbers in two’s complement is like adding the numbers in decimal: we add column by column, and if there is a carry, it is added to the next column. However, the carry produced from the last column is discarded.
We should remember that we add integers column by column. In each column, we have either two bits to add if there is no carry from the previous column, or three bits to add if there is a carry from the previous column.
The procedure is as follows:
1. If the operation is subtraction, we take the two’s complement of the second integer. Otherwise, we move to the next step.
2. We add the two integers.

> **Example 4.16**
> Two integers A and B are stored in two’s complement format. Show how B is added to A:
> A = $(00010001)_2$ B = $(00010110)_2$
>
> **Solution**
> The operation is adding. A is added to B and the result is stored in R:
> A: 0 0 0 1 0 0 0 1
> B: 0 0 0 1 0 1 1 0
> R: 0 0 1 0 0 1 1 1
> We check the result in decimal: (+17) + (+22) = (+39).

> **Example 4.17**
> Two integers A and B are stored in two’s complement format. Show how B is added to A:
> A = $(00011000)_2$ B = $(11101111)_2$
>
> **Solution**
> The operation is adding. A is added to B and the result is stored in R. Note that the last carry is discarded because the size of the memory is only 8 bits:
> A: 0 0 0 1 1 0 0 0
> B: 1 1 1 0 1 1 1 1
> R: 0 0 0 0 0 1 1 1
> Checking the result in decimal, (+24) + (–17) = (+7).

> **Example 4.18**
> Two integers A and B are stored in two’s complement format. Show how B is subtracted from A:
> A = $(00011000)_2$ B = $(11101111)_2$
>
> **Solution**
> The operation is subtracting. A is added to $(\bar{B} + 1)$ and the result is stored in R:
> $(\bar{B} + 1) = 00010001$
> A: 0 0 0 1 1 0 0 0
> $(\bar{B} + 1)$: 0 0 0 1 0 0 0 1
> R: 0 0 1 0 1 0 0 1
> Checking the result in decimal, (+24) – (–17) = (+41).

> **Example 4.19**
> Two integers A and B are stored in two’s complement format. Show how B is subtracted from A:
> A = $(11011101)_2$ B = $(00010100)_2$
>
> **Solution**
> The operation is subtracting. A is added to $(\bar{B} + 1)$ and the result is stored in R:
> $(\bar{B} + 1) = 11101100$
> A: 1 1 0 1 1 1 0 1
> $(\bar{B} + 1)$: 1 1 1 0 1 1 0 0
> R: 1 1 0 0 1 0 0 1
> Checking the result in decimal, (–35) – (+20) = (–55). Note that the last carry is discarded.

> **Example 4.20**
> Two integers A and B are stored in two’s complement format. Show how B is added to A:
> A = $(01111111)_2$ B = $(00000011)_2$
>
> **Solution**
> The operation is adding. A is added to B and the result is stored in R:
> A: 0 1 1 1 1 1 1 1
> B: 0 0 0 0 0 0 1 1
> R: 1 0 0 0 0 0 1 0
> We expect the result to be 127 + 3 = 130, but the answer is −126. The error is due to overflow, because the expected answer (+130) is not in the range −128 to +127.
> When we do arithmetic operations on numbers in a computer, we should remember that each number and the result should be in the range defined by the bit allocation.

**Addition or subtraction for sign-and-magnitude integers**
Addition or subtraction for integers in sign-and-magnitude representation looks very complex. We have four different combinations of signs (two signs, each of two values) for addition, and four different conditions for subtraction. This means that we need to consider eight different situations. For those interested readers, we describe these in more detail in Appendix I.

### 4.3.2 Arithmetic operations on reals
All arithmetic operations such as addition, subtraction, multiplication, and division can be applied to reals stored in floating-point format. Multiplication of two reals involves multiplication of two integers in sign-and-magnitude representation. Division of two reals involves division of two integers in sign-and-magnitude representations. Since we did not discuss the multiplication or division of integers in sign-and-magnitude representation, we will not discuss the multiplication and division of reals, and only show addition and subtractions for reals in Appendix J.

## 4.4 END-CHAPTER MATERIALS
### 4.4.1 Recommended Reading
For more details about the subjects discussed in this chapter, the following books are recommended:
- Mano, M. *Computer System Architecture*, Upper Saddle River, NJ: Prentice-Hall, 1993
- Null, L. and Lobur, J. *Computer Organization and Architecture*, Sudbury, MA: Jones and Bartlett, 2003
- Stalling, W. *Computer Organization and Architecture*, Upper Saddle River, NJ: Prentice-Hall, 2000

### 4.4.2 Key terms
- AND operation
- arithmetic operation
- arithmetic shift operation
- Boolean algebra
- circular shift operation
- logical shift operation
- mask
- NOT operation
- OR operation
- truth table
- XOR operation

### 4.4.3 Summary
- Operations on data can be divided into three broad categories: logic operations, shift operations, and arithmetic operations. Logic operations refer to those operations that apply the same basic operation to individual bits of a pattern or to two corresponding bits in two patterns. Shift operations move the bits in the pattern. Arithmetic operations involve adding, subtracting, multiplying, and dividing.
- The four logic operators discussed in this chapter (NOT, AND, OR, and XOR) can be used at the bit level or the pattern level. The NOT operator is a unary operator, while the AND, OR, and XOR operators are binary operators.
- The only application of the NOT operator is to complement the whole pattern. One of the applications of the AND operator is to unset (force to 0) specific bits in a bit pattern. One of the applications of the OR operator is to set (force to 1) specific bits in a bit pattern. One of the applications of the XOR operator is to flip (complement) specific bits in a bit pattern.
- Shift operations move the bits in the pattern: they change the positions of the bits. We can divide shift operations into two categories: logical shift operations and arithmetic shift operations. A logical shift operation is applied to a pattern that does not represent a signed number. Arithmetic shift operations assume that the bit pattern is a signed integer in two’s complement format.
- All arithmetic operations such as addition, subtraction, multiplication, and division can be applied to integers. Integers are normally stored in two’s complement format. One of the advantages of two’s complement representation is that there is no difference between addition and subtraction. When the subtraction operation is encountered, the computer simply changes it to an addition operation, but forms the two’s complement of the second number. Addition and subtraction for integers in sign-and-magnitude representation looks very complex. We have eight situations to consider.
- All arithmetic operations such as addition, subtraction, multiplication, and division can be applied to reals stored in floating-point format. Addition and subtraction of real numbers stored in floating-point numbers is reduced to addition and subtraction of two integers stored in sign-and-magnitude after the alignment of decimal points.

## 4.5 PRACTICE SET
### 4.5.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 4.5.2 Review questions
1. What is the difference between an arithmetic operation and a logical operation?
2. What happens to the carry from the leftmost column in the addition of integers in two’s complement format?
3. Can n, the bit allocation, equal 1? Why, or why not?
4. Define the term overflow.
5. In the addition of floating-point numbers, how do we adjust the representation of numbers with different exponents?
6. What is the difference between a unary operation and a binary operation?
7. Name the logical binary operations.
8. What is a truth table?
9. What does the NOT operator do?
10. When is the result of an AND operator true?
11. When is the result of an OR operator true?
12. When is the result of an XOR operator true?
13. Mention an important property of the AND operator discussed in this chapter.
14. Mention an important property of the OR operator discussed in this chapter.
15. Mention an important property of the XOR operator discussed in this chapter.
16. What binary operation can be used to set bits? What bit pattern should the mask have?
17. What binary operation can be used to unset bits? What bit pattern should the mask have?
18. What binary operation can be used to flip bits? What bit pattern should the mask have?
19. What is the difference between simple and arithmetic shifts?

### 4.5.3 Problems
1. Show the result of the following operations:
    a. NOT (99)16
    b. NOT (FF)16
    c. NOT (00)16
    d. NOT (01)16
2. Show the result of the following operations:
    a. (99)16 AND (99)16
    b. (99)16 AND (00)16
    c. (99)16 AND (FF)16
    d. (FF)16 AND (FF)16
3. Show the result of the following operations:
    a. (99)16 OR (99)16
    b. (99)16 OR (00)16
    c. (99)16 OR (FF)16
    d. (FF)16 OR (FF)16
4. Show the result of the following operations:
    a. NOT [(99)16 OR (99)16)]
    b. (99)16 OR [NOT (00)16]
    c. [(99)16 AND (33)16)] OR [(00)16 AND (FF)16]
    d. (99)16 OR (33)16 AND [(00)16 OR (FF)16]
5. We need to unset (force to 0) the four leftmost bits of a pattern. Show the mask and the operation.
6. We need to set (force to 1) the four rightmost bits of a pattern. Show the mask and the operation.
7. We need to flip the three rightmost and the two leftmost bits of a pattern. Show the mask and the operation.
8. We need to unset the three leftmost bits and set the two rightmost bits of a pattern. Show the masks and operations.
9. Use the shift operation to divide an integer by 4.
10. Use the shift operation to multiply an integer by 8.
11. Use a combination of logical and shift operations to extract the fourth and fifth bits from the left of an unsigned integer.
12. Using an 8-bit allocation, first convert each of the following integers to two’s complement, do the operation, and then convert the result to decimal.
    a. 19 + 23
    b. 19 − 23
    c. −19 + 23
    d. −19 − 23
13. Using a 16-bit allocation, first convert each of the following numbers to two’s complement, do the operation, and then convert the result to decimal.
    a. 161 + 1023
    b. 161 − 1023
    c. −161 + 1023
    d. −161 − 1023
14. Which of the following operations creates an overflow if the numbers and the result are represented in 8-bit two’s complement representation?
    a. 11000010 + 00111111
    b. 00000010 + 00111111
    c. 11000010 + 11111111
    d. 00000010 + 11111111
15. Without actually doing the calculation, can we tell which of the following creates an overflow if the numbers and the result are in 8-bit two’s complement representation?
    a. 32 + 105
    b. 32 − 105
    c. −32 + 105
    d. −32 − 105
16. Show the result of the following operations assuming that the numbers are stored in 16-bit two’s complement representation. Show the result in hexadecimal notation.
    a. (012A)16 + (0E27)16
    b. (712A)16 + (9E00)16
    c. (8011)16 + (0001)16
    d. (E12A)16 + (9E27)16
17. Using an 8-bit allocation, first convert each of the following numbers to sign-and-magnitude representation, do the operation, and then convert the result to decimal.
    a. 19 + 23
    b. 19 − 23
    c. −19 + 23
    d. −19 − 23
18. Show the result of the following floating-point operations using IEEE_127—see Chapter 3.
    a. 34.75 + 23.125
    b. −12.625 + 451.00
    c. 33.1875 − 0.4375
    d. −344.3125 − 123.5625
19. In which of the following situations does an overflow never occur? Justify the answer.
    a. Adding two positive integers.
    b. Adding one positive integer to a negative integer.
    c. Subtracting one positive integer from a negative integer.
    d. Subtracting two negative integers.
20. What is the result of adding an integer to its one’s complement?
21. What is the result of adding an integer to its two’s complement?
`,zh:`
# 第四章：資料運算

在第三章中，我們展示了如何在電腦中儲存不同類型的資料。在本章中，我們將展示如何對儲存在電腦中的資料進行運算。資料的運算可以分為三大類：邏輯運算、移位運算和算術運算。

## 學習目標
學完本章後，學生應能：
- 列出對資料執行的三類運算。
- 對位元模式執行一元和二元邏輯運算。
- 區分邏輯移位運算和算術移位運算。
- 對位元模式執行邏輯移位運算。
- 對以二的補數格式儲存的整數執行算術移位運算。
- 對以二的補數格式儲存的整數執行加法和減法。
- 對以符號與數值格式儲存的整數執行加法和減法。
- 對以浮點數格式儲存的實數執行加法和減法運算。
- 理解邏輯和移位運算的一些應用，例如設定、取消設定和翻轉特定位元。

## 4.1 邏輯運算
在第三章中，我們討論了電腦內部的資料是以位元模式儲存的事實。邏輯運算指的是那些對模式中的單個位元，或對兩個模式中對應的位元應用相同的基本運算的操作。這意味著我們可以在位元層級和模式層級定義邏輯運算。模式層級的邏輯運算是在位元層級上進行 $n$ 次相同類型的邏輯運算，其中 $n$ 是模式中的位元數。

### 4.1.1 位元層級的邏輯運算
一個位元可以取兩個值之一：0 或 1。如果我們將 0 解釋為值*假 (false)*，將 1 解釋為值*真 (true)*，我們可以應用**布林代數**中定義的運算來操作位元。布林代數以喬治·布爾 (George Boole) 的名字命名，屬於數學的一個特殊領域，稱為*邏輯*。布林代數及其在構建電腦邏輯電路中的應用在附錄 E 中簡要討論。在本節中，我們簡要展示用於操作位元的四種位元層級運算：NOT、AND、OR 和 XOR。

圖 4.1 顯示了這四個位元層級運算子的符號及其真值表。**真值表**定義了每個可能輸入或輸入組合的輸出值。請注意，每個運算子的輸出總是一個位元，但輸入可以是一個或兩個位元。

**NOT**
**NOT 運算子**是一個一元運算子：它只接受一個輸入。輸出位元是輸入的補數。如果輸入是 0，輸出是 1，如果輸入是 1，輸出是 0。換句話說，NOT 運算子翻轉其輸入。NOT 運算子的真值表只有兩行，因為單個輸入只能是 0 或 1：兩種可能性。

| x | NOT x |
| :--- | :--- |
| 0 | 1 |
| 1 | 0 |

**AND**
**AND 運算子**是一個二元運算子：它接受兩個輸入。如果兩個輸入都是 1，則輸出位元為 1，在其他三種情況下輸出為 0。AND 運算子的真值表有四行，因為對於兩個輸入，有四種可能的輸入組合。

| x | y | x AND y |
| :--- | :--- | :--- |
| 0 | 0 | 0 |
| 0 | 1 | 0 |
| 1 | 0 | 0 |
| 1 | 1 | 1 |

**一個屬性**
關於 AND 運算子的一個有趣點是，如果一個輸入中的位元是 0，我們不必檢查另一個輸入中的對應位元：我們可以快速得出結果是 0。當我們討論此運算子在位元模式中的應用時，我們會使用此屬性：
對於 x = 0 或 1：x AND 0 → 0 和 0 AND x → 0

**OR**
**OR 運算子**也是一個二元運算子：它接受兩個輸入。如果兩個輸入都是 0，則輸出位元為 0，在其他三種情況下輸出為 1。OR 運算子的真值表也有四行。OR 運算子有時稱為*包含或 (inclusive-or) 運算子*，因為不僅當其中一個輸入為 1 時輸出為 1，而且當兩個輸入都為 1 時輸出也為 1。這與我們接下來介紹的運算子形成對比。

| x | y | x OR y |
| :--- | :--- | :--- |
| 0 | 0 | 0 |
| 0 | 1 | 1 |
| 1 | 0 | 1 |
| 1 | 1 | 1 |

**一個屬性**
關於 OR 運算子的一個有趣點是，如果一個輸入中的位元是 1，我們不必檢查另一個輸入中的對應位元：我們可以快速得出結果是 1。當我們討論此運算子在位元模式中的應用時，我們會使用此屬性：
對於 x = 0 或 1：x OR 1 → 1 和 1 OR x → 1

**XOR**
**XOR 運算子**（發音為「互斥或」）也是一個像 OR 運算子一樣的二元運算子，只有一個區別：如果兩個輸入都是 1，則輸出為 0。我們可以用另一種方式來看待這個運算子：當兩個輸入相同時輸出為 0，當輸入不同時輸出為 1。

| x | y | x XOR y |
| :--- | :--- | :--- |
| 0 | 0 | 0 |
| 0 | 1 | 1 |
| 1 | 0 | 1 |
| 1 | 1 | 0 |

> **範例 4.1**
> 在英語中，我們有時使用連接詞「或 (or)」來表示包含或，有時表示互斥或。
> a. 句子「我希望有一輛車*或*一棟房子」在包含意義上使用「或」——我希望有一輛車、一棟房子，或兩者兼有。
> b. 句子「今天是星期一*或*星期二」在互斥意義上使用「或」——今天是星期一或星期二，但不可能兩者都是。

> **範例 4.2**
> XOR 運算子實際上並不是一個新運算子。我們總是可以模擬它使用其他三個運算子。以下兩個表達式是等價的：
> x XOR y ↔ [x AND (NOT y)] OR [(NOT x) AND y]
> 如果我們為兩者製作真值表，就可以證明等價性。

**一個屬性**
XOR 的一個屬性是，如果一個輸入中的位元是 1，則結果是另一個輸入中對應位元的補數。當我們討論此運算子在位元模式中的應用時，我們會使用此屬性：
對於 x = 0 或 1：1 XOR x → NOT x 和 x XOR 1 → NOT x

### 4.1.2 模式層級的邏輯運算
同樣的四個運算子（NOT、AND、OR 和 XOR）可以應用於一個 $n$ 位元的模式。其效果與對每個單獨位元應用 NOT 運算子以及對其他三個運算子應用於每對應位元對是一樣的。圖 4.2 顯示了這四個具有輸入和輸出模式的運算子。

> **範例 4.3**
> 對位元模式 10011000 使用 NOT 運算子。
>
> **解答**
> 解答如下所示。請注意，NOT 運算子將每個 0 變為 1，每個 1 變為 0：
> 輸入：1 0 0 1 1 0 0 0
> NOT：0 1 1 0 0 1 1 1

> **範例 4.4**
> 對位元模式 10011000 和 00101010 使用 AND 運算子。
>
> **解答**
> 解答如下所示。請注意，輸出中只有一個位元是 1，其中兩個對應的輸入都是 1：
> 輸入 1：1 0 0 1 1 0 0 0
> 輸入 2：0 0 1 0 1 0 1 0
> AND：0 0 0 0 1 0 0 0

> **範例 4.5**
> 對位元模式 10011001 和 00101110 使用 OR 運算子。
>
> **解答**
> 解答如下所示。請注意，輸出中只有一個位元是 0，其中兩個對應的輸入都是 0：
> 輸入 1：1 0 0 1 1 0 0 1
> 輸入 2：0 0 1 0 1 1 1 0
> OR：1 0 1 1 1 1 1 1

> **範例 4.6**
> 對位元模式 10011001 和 00101110 使用 XOR 運算子。
>
> **解答**
> 解答如下所示。將此範例中的輸出與範例 4.5 中的輸出進行比較。唯一的區別是當兩個輸入都是 1 時，結果是 0（互斥的效果）：
> 輸入 1：1 0 0 1 1 0 0 1
> 輸入 2：0 0 1 0 1 1 1 0
> XOR：1 0 1 1 0 1 1 1

**應用**
四種邏輯運算可用於修改位元模式。

**補數運算**
NOT 運算子的唯一應用是對整個模式進行補數運算。對模式應用此運算子會將每個 0 變為 1，每個 1 變為 0。這有時被稱為一的補數運算。範例 4.3 顯示了補數運算的效果。

**取消設定特定位元**
AND 運算子的應用之一是取消設定（強制為 0）位元模式中的特定位元。在這種情況下，第二個輸入稱為**遮罩**。遮罩中的 0 位元取消設定第一個輸入中的對應位元：遮罩中的 1 位元保持第一個輸入中的對應位元不變。這是由於我們提到的 AND 運算子的屬性：如果其中一個輸入是 0，無論另一個輸入是什麼，輸出都是 0。取消設定模式中的位元可能有許多應用。例如，如果圖像每個像素僅使用一個位元（黑白圖像），那麼我們可以使用遮罩和 AND 運算子將特定像素變為黑色。

> **範例 4.7**
> 使用遮罩取消設定（清除）模式中最左邊的五個位元。使用模式 10100110 測試遮罩。
>
> **解答**
> 遮罩是 00000111。應用遮罩的結果是：
> 輸入：1 0 1 0 0 1 1 0
> 遮罩：0 0 0 0 0 1 1 1
> AND：0 0 0 0 0 1 1 0
> 請注意，最右邊的三個位元保持不變，而最左邊的五個位元被取消設定（變為 0），無論它們之前的值為何。

**設定特定位元**
OR 運算子的應用之一是設定（強制為 1）位元模式中的特定位元。我們再次可以使用遮罩，但使用不同的遮罩。遮罩中的 1 位元設定第一個輸入中的對應位元，遮罩中的 0 位元保持第一個輸入中的對應位元不變。這是由於我們提到的 OR 運算子的屬性：如果其中一個輸入是 1，無論另一個輸入是什麼，輸出都是 1。設定模式中的位元有許多應用。例如，如果圖像每個像素僅使用一個位元（黑白圖像），那麼我們可以使用遮罩和 OR 運算子將特定像素變為白色。

> **範例 4.8**
> 使用遮罩設定模式中最左邊的五個位元。使用模式 10100110 測試遮罩。
>
> **解答**
> 遮罩是 11111000。應用遮罩的結果是：
> 輸入：1 0 1 0 0 1 1 0
> 遮罩：1 1 1 1 1 0 0 0
> OR：1 1 1 1 1 1 1 0

**翻轉特定位元**
XOR 運算子的應用之一是翻轉（補數）位元模式中的特定位元。我們再次可以使用遮罩，但使用不同的遮罩。遮罩中的 1 位元翻轉第一個輸入中的對應位元，遮罩中的 0 位元保持第一個輸入中的對應位元不變。這是由於我們提到的 XOR 運算子的屬性：如果其中一個輸入是 1，輸出是對應位元的補數。請注意 NOT 運算子和 XOR 運算子之間的區別。NOT 運算子對輸入中的所有位元進行補數運算，而 XOR 運算子僅對遮罩定義的第一個輸入中的特定位元進行補數運算。

> **範例 4.9**
> 使用遮罩翻轉模式中最左邊的五個位元。使用模式 10100110 測試遮罩。
>
> **解答**
> 遮罩是 11111000。應用遮罩的結果是：
> 輸入：1 0 1 0 0 1 1 0
> 遮罩：1 1 1 1 1 0 0 0
> XOR：0 1 0 1 1 1 1 0

## 4.2 移位運算
移位運算移動模式中的位元，改變位元的位置。它們可以向左或向右移動位元。我們可以將移位運算分為兩大類：邏輯移位運算和算術移位運算。

### 4.2.1 邏輯移位運算
**邏輯移位運算**應用於不表示有符號數字的模式。原因是這些移位運算可能會改變由模式中最左邊位元定義的數字的符號。我們區分兩種類型的邏輯移位運算，如下所述。

**簡單移位**
**簡單右移**運算將每個位元向右移動一個位置。在 $n$ 位元模式中，最右邊的位元遺失，最左邊的位元填入 0。**簡單左移**運算將每個位元向左移動一個位置。在 $n$ 位元模式中，最左邊的位元遺失，最右邊的位元填入 0。圖 4.3 顯示了 8 位元模式的簡單右移和簡單左移運算。

> **範例 4.10**
> 對位元模式 10011000 使用簡單左移運算。
>
> **解答**
> 解答如下所示。最左邊的位元遺失，最右邊插入一個 0：
> 原始：1 0 0 1 1 0 0 0
> 移位後：0 0 1 1 0 0 0 0

**循環移位**
**循環移位運算**（或**旋轉運算**）移動位元，但沒有位元遺失或增加。**循環右移**（或**右旋**）將每個位元向右移動一個位置。最右邊的位元循環並成為最左邊的位元。**循環左移**（或**左旋**）將每個位元向左移動一個位置。最左邊的位元循環並成為最右邊的位元。圖 4.4 顯示了循環左移和循環右移運算。

> **範例 4.11**
> 對位元模式 10011000 使用循環左移運算。
>
> **解答**
> 解答如下所示。最左邊的位元循環並成為最右邊的位元：
> 原始：1 0 0 1 1 0 0 0
> 移位後：0 0 1 1 0 0 0 1

> **範例 4.12**
> 結合邏輯運算和邏輯移位運算為我們提供了一些操作位元模式的工具。假設我們有一個模式，我們需要在決策過程中使用該模式的第三個位元（從右邊數）。我們想知道這個特定位元是 0 還是 1。以下顯示了我們如何找出：
> 原始：h g f e d c b a
> 一次右移：0 h g f e d c b
> 兩次右移：0 0 h g f e d c
> 遮罩：0 0 0 0 0 0 0 1
> AND 結果：0 0 0 0 0 0 0 c
> 我們將模式向右移動兩個位元，使目標位元移動到最右邊的位置。然後將結果與最右邊位置為 1 的遮罩進行 AND 運算。結果是一個包含七個 0 和最右邊位置為目標位元的模式。然後我們可以測試結果：如果它是無符號整數 1，則目標位元為 1，而如果結果是無符號整數 0，則目標位元為 0。

**算術移位運算**
**算術移位運算**假設位元模式是以二的補數格式表示的有符號整數。**算術右移**用於將整數除以二，而**算術左移**用於將整數乘以二。這些運算不應改變符號（最左邊）位元。算術右移保留符號位元，但也將其複製到下一個右邊的位元，以便保留符號。算術左移丟棄符號位元並接受符號位元左邊的位元作為符號。如果新符號位元與前一個相同，則運算成功，否則發生溢位或下溢，結果無效。圖 4.5 顯示了這兩個運算。

> **範例 4.13**
> 對位元模式 10011001 使用算術右移運算。該模式是二的補數格式的整數。
>
> **解答**
> 解答如下所示。最左邊的位元被保留並複製到其右邊的相鄰位元。最右邊的位元遺失：
> 原始：1 0 0 1 1 0 0 1
> 移位後：1 1 0 0 1 1 0 0
> 原始數字是 –103，新數字是 –52，這是將 –103 除以 2 並截斷為較小整數的結果。

> **範例 4.14**
> 對位元模式 11011001 使用算術左移運算。該模式是二的補數格式的整數。
>
> **解答**
> 解答如下所示。最左邊的位元遺失，最右邊插入一個 0：
> 原始：1 1 0 1 1 0 0 1
> 移位後：1 0 1 1 0 0 1 0
> 原始數字是 –39，新數字是 –78。原始數字乘以二。運算有效，因為未發生下溢。

> **範例 4.15**
> 對位元模式 01111111 使用算術左移運算。該模式是二的補數格式的整數。
>
> **解答**
> 解答如下所示。最左邊的位元遺失，最右邊插入一個 0：
> 原始：0 1 1 1 1 1 1 1
> 移位後：1 1 1 1 1 1 1 0
> 原始數字是 127，新數字是 –2。這裡的結果無效，因為發生了溢位。預期答案 127 × 2 = 254 無法用 8 位元模式表示。

## 4.3 算術運算
**算術運算**包括加、減、乘和除。我們可以將這些運算應用於整數和浮點數。

### 4.3.1 整數的算術運算
所有算術運算（如加、減、乘和除）都可以應用於整數。雖然整數的乘法（除法）可以使用重複加法（減法）來實現，但該過程效率不高。有更有效的乘法和除法程序，如布斯程序，但這些超出了本書的範圍。因此，我們在此僅討論整數的加法和減法。

**二的補數整數的加法和減法**
我們首先討論二的補數表示法中整數的加法和減法，因為它更常見。正如我們在第三章中所討論的，整數通常以二的補數格式儲存。二的補數表示法的優點之一是加法和減法之間沒有區別。當遇到減法運算時，電腦只需將其更改為加法運算，但對第二個數字取二的補數。換句話說：
$A - B leftrightarrow A + (\bar{B} + 1)$ 其中 $(\bar{B} + 1)$ 表示 B 的二的補數。

這意味著我們只需要討論加法。在二的補數中加數字就像在十進位中加數字一樣：我們逐欄相加，如果有進位，則將其加到下一欄。然而，從最後一欄產生的進位被丟棄。
我們應該記住，我們是逐欄添加整數的。在每一欄中，如果沒有前一欄的進位，我們有兩個位元要相加，如果有前一欄的進位，則有三個位元要相加。
程序如下：
1. 如果運算是減法，我們取第二個整數的二的補數。否則，我們進入下一步。
2. 我們將兩個整數相加。

> **範例 4.16**
> 兩個整數 A 和 B 以二的補數格式儲存。顯示如何將 B 加到 A：
> A = $(00010001)_2$ B = $(00010110)_2$
>
> **解答**
> 運算是加法。將 A 加到 B，結果儲存在 R 中：
> A：0 0 0 1 0 0 0 1
> B：0 0 0 1 0 1 1 0
> R：0 0 1 0 0 1 1 1
> 我們以十進位檢查結果：(+17) + (+22) = (+39)。

> **範例 4.17**
> 兩個整數 A 和 B 以二的補數格式儲存。顯示如何將 B 加到 A：
> A = $(00011000)_2$ B = $(11101111)_2$
>
> **解答**
> 運算是加法。將 A 加到 B，結果儲存在 R 中。請注意，最後的進位被丟棄，因為記憶體的大小只有 8 位元：
> A：0 0 0 1 1 0 0 0
> B：1 1 1 0 1 1 1 1
> R：0 0 0 0 0 1 1 1
> 以十進位檢查結果，(+24) + (–17) = (+7)。

> **範例 4.18**
> 兩個整數 A 和 B 以二的補數格式儲存。顯示如何從 A 中減去 B：
> A = $(00011000)_2$ B = $(11101111)_2$
>
> **解答**
> 運算是減法。將 A 加到 $(\bar{B} + 1)$，結果儲存在 R 中：
> $(\bar{B} + 1) = 00010001$
> A：0 0 0 1 1 0 0 0
> $(\bar{B} + 1)$：0 0 0 1 0 0 0 1
> R：0 0 1 0 1 0 0 1
> 以十進位檢查結果，(+24) – (–17) = (+41)。

> **範例 4.19**
> 兩個整數 A 和 B 以二的補數格式儲存。顯示如何從 A 中減去 B：
> A = $(11011101)_2$ B = $(00010100)_2$
>
> **解答**
> 運算是減法。將 A 加到 $(\bar{B} + 1)$，結果儲存在 R 中：
> $(\bar{B} + 1) = 11101100$
> A：1 1 0 1 1 1 0 1
> $(\bar{B} + 1)$：1 1 1 0 1 1 0 0
> R：1 1 0 0 1 0 0 1
> 以十進位檢查結果，(–35) – (+20) = (–55)。請注意，最後的進位被丟棄。

> **範例 4.20**
> 兩個整數 A 和 B 以二的補數格式儲存。顯示如何將 B 加到 A：
> A = $(01111111)_2$ B = $(00000011)_2$
>
> **解答**
> 運算是加法。將 A 加到 B，結果儲存在 R 中：
> A：0 1 1 1 1 1 1 1
> B：0 0 0 0 0 0 1 1
> R：1 0 0 0 0 0 1 0
> 我們期望結果是 127 + 3 = 130，但答案是 −126。錯誤是由於溢位，因為預期答案 (+130) 不在範圍 −128 到 +127 內。
> 當我們在電腦中對數字進行算術運算時，我們應該記住每個數字和結果都應該在位元分配定義的範圍內。

**符號與數值整數的加法或減法**
符號與數值表示法中整數的加法或減法看起來非常複雜。我們有四種不同的符號組合（兩個符號，每個有兩個值）用於加法，還有四種不同的條件用於減法。這意味著我們需要考慮八種不同的情況。對於那些感興趣的讀者，我們在附錄 I 中更詳細地描述了這些。

### 4.3.2 實數的算術運算
所有算術運算（如加、減、乘和除）都可以應用於以浮點格式儲存的實數。兩個實數的乘法涉及符號與數值表示法中兩個整數的乘法。兩個實數的除法涉及符號與數值表示法中兩個整數的除法。由於我們沒有討論符號與數值表示法中整數的乘法或除法，我們將不討論實數的乘法和除法，而只在附錄 J 中顯示實數的加法和減法。

## 4.4 章末材料
### 4.4.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Mano, M. *Computer System Architecture*, Upper Saddle River, NJ: Prentice-Hall, 1993
- Null, L. and Lobur, J. *Computer Organization and Architecture*, Sudbury, MA: Jones and Bartlett, 2003
- Stalling, W. *Computer Organization and Architecture*, Upper Saddle River, NJ: Prentice-Hall, 2000

### 4.4.2 關鍵詞
- AND 運算
- 算術運算
- 算術移位運算
- 布林代數
- 循環移位運算
- 邏輯移位運算
- 遮罩
- NOT 運算
- OR 運算
- 真值表
- XOR 運算

### 4.4.3 摘要
- 資料的運算可以分為三大類：邏輯運算、移位運算和算術運算。邏輯運算指的是那些對模式中的單個位元或兩個模式中的對應位元應用相同基本運算的操作。移位運算移動模式中的位元。算術運算涉及加、減、乘和除。
- 本章討論的四個邏輯運算子（NOT、AND、OR 和 XOR）可以在位元層級或模式層級使用。NOT 運算子是一元運算子，而 AND、OR 和 XOR 運算子是二元運算子。
- NOT 運算子的唯一應用是對整個模式進行補數運算。AND 運算子的應用之一是取消設定（強制為 0）位元模式中的特定位元。OR 運算子的應用之一是設定（強制為 1）位元模式中的特定位元。XOR 運算子的應用之一是翻轉（補數）位元模式中的特定位元。
- 移位運算移動模式中的位元：它們改變位元的位置。我們可以將移位運算分為兩大類：邏輯移位運算和算術移位運算。邏輯移位運算應用於不表示有符號數字的模式。算術移位運算假設位元模式是以二的補數格式表示的有符號整數。
- 所有算術運算（如加、減、乘和除）都可以應用於整數。整數通常以二的補數格式儲存。二的補數表示法的優點之一是加法和減法之間沒有區別。當遇到減法運算時，電腦只需將其更改為加法運算，但形成第二個數字的二的補數。符號與數值表示法中整數的加法和減法看起來非常複雜。我們有八種情況需要考慮。
- 所有算術運算（如加、減、乘和除）都可以應用於以浮點格式儲存的實數。以浮點數儲存的實數的加法和減法在對齊小數點後簡化為以符號與數值儲存的兩個整數的加法和減法。

## 4.5 練習題
### 4.5.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 4.5.2 複習問題
1. 算術運算和邏輯運算有什麼區別？
2. 在二的補數格式的整數加法中，最左邊一欄的進位會發生什麼？
3. 位元分配 n 可以等於 1 嗎？為什麼或為什麼不？
4. 定義術語溢位。
5. 在浮點數加法中，我們如何調整具有不同指數的數字的表示？
6. 一元運算和二元運算有什麼區別？
7. 命名邏輯二元運算。
8. 什麼是真值表？
9. NOT 運算子做什麼？
10. AND 運算子的結果何時為真？
11. OR 運算子的結果何時為真？
12. XOR 運算子的結果何時為真？
13. 提到本章討論的 AND 運算子的一個重要屬性。
14. 提到本章討論的 OR 運算子的一個重要屬性。
15. 提到本章討論的 XOR 運算子的一個重要屬性。
16. 什麼二進位運算可用於設定位元？遮罩應該有什麼位元模式？
17. 什麼二進位運算可用於取消設定位元？遮罩應該有什麼位元模式？
18. 什麼二進位運算可用於翻轉位元？遮罩應該有什麼位元模式？
19. 簡單移位和算術移位有什麼區別？

### 4.5.3 問題
1. 顯示以下運算的結果：
    a. NOT (99)16
    b. NOT (FF)16
    c. NOT (00)16
    d. NOT (01)16
2. 顯示以下運算的結果：
    a. (99)16 AND (99)16
    b. (99)16 AND (00)16
    c. (99)16 AND (FF)16
    d. (FF)16 AND (FF)16
3. 顯示以下運算的結果：
    a. (99)16 OR (99)16
    b. (99)16 OR (00)16
    c. (99)16 OR (FF)16
    d. (FF)16 OR (FF)16
4. 顯示以下運算的結果：
    a. NOT [(99)16 OR (99)16)]
    b. (99)16 OR [NOT (00)16]
    c. [(99)16 AND (33)16)] OR [(00)16 AND (FF)16]
    d. (99)16 OR (33)16 AND [(00)16 OR (FF)16]
5. 我們需要取消設定（強制為 0）模式中最左邊的四個位元。顯示遮罩和運算。
6. 我們需要設定（強制為 1）模式中最右邊的四個位元。顯示遮罩和運算。
7. 我們需要翻轉模式中最右邊的三個和最左邊的兩個位元。顯示遮罩和運算。
8. 我們需要取消設定最左邊的三個位元並設定模式中最右邊的兩個位元。顯示遮罩和運算。
9. 使用移位運算將整數除以 4。
10. 使用移位運算將整數乘以 8。
11. 使用邏輯和移位運算的組合從無符號整數左邊提取第四和第五個位元。
12. 使用 8 位元分配，首先將以下每個整數轉換為二的補數，執行運算，然後將結果轉換為十進位。
    a. 19 + 23
    b. 19 − 23
    c. −19 + 23
    d. −19 − 23
13. 使用 16 位元分配，首先將以下每個數字轉換為二的補數，執行運算，然後將結果轉換為十進位。
    a. 161 + 1023
    b. 161 − 1023
    c. −161 + 1023
    d. −161 − 1023
14. 如果數字和結果以 8 位元二的補數表示法表示，以下哪種運算會產生溢位？
    a. 11000010 + 00111111
    b. 00000010 + 00111111
    c. 11000010 + 11111111
    d. 00000010 + 11111111
15. 在不實際進行計算的情況下，我們能分辨出以下哪種運算會產生溢位嗎？假設數字和結果以 8 位元二的補數表示法表示。
    a. 32 + 105
    b. 32 − 105
    c. −32 + 105
    d. −32 − 105
16. 假設數字以 16 位元二的補數表示法儲存，顯示以下運算的結果。以十六進位表示法顯示結果。
    a. (012A)16 + (0E27)16
    b. (712A)16 + (9E00)16
    c. (8011)16 + (0001)16
    d. (E12A)16 + (9E27)16
17. 使用 8 位元分配，首先將以下每個數字轉換為符號與數值表示法，執行運算，然後將結果轉換為十進位。
    a. 19 + 23
    b. 19 − 23
    c. −19 + 23
    d. −19 − 23
18. 使用 IEEE_127 顯示以下浮點運算的結果——見第 3 章。
    a. 34.75 + 23.125
    b. −12.625 + 451.00
    c. 33.1875 − 0.4375
    d. −344.3125 − 123.5625
19. 在以下哪種情況下永遠不會發生溢位？證明答案的合理性。
    a. 兩個正整數相加。
    b. 一個正整數加一個負整數。
    c. 從一個負整數中減去一個正整數。
    d. 兩個負整數相減。
20. 將一個整數加到其一的補數上的結果是什麼？
21. 將一個整數加到其二的補數上的結果是什麼？
`},s={en:`
# Chapter 5: Computer Organization

In this chapter we discuss the organization of a stand-alone computer. We explain how every computer is made up of three subsystems. We also show how a simple, hypothetical computer can run a simple program to perform primitive arithmetic or logic operations.

## Objectives
After studying this chapter, the student should be able to:
- List the three subsystems of a computer.
- Describe the role of the central processing unit (CPU) in a computer.
- Describe the fetch–decode–execute phases of a cycle in a typical computer.
- Describe the main memory and its addressing space.
- Distinguish between main memory and cache memory.
- Define the input/output subsystem.
- Understand the interconnection of subsystems and list different bus systems.
- Describe different methods of input/output addressing.
- Distinguish the two major trends in the design of computer architecture.
- Understand how computer throughput can be improved using pipelining.
- Understand how parallel processing can improve the throughput of computers.

## 5.1 INTRODUCTION
We can divide the parts that make up a computer into three broad categories or subsystems: the **central processing unit (CPU)**, the **main memory**, and the **input/output subsystem**. The next three sections discuss these subsystems and how they are connected to make a standalone computer. Figure 5.1 shows the three subsystems of a standalone computer.

## 5.2 CENTRAL PROCESSING UNIT
The **central processing unit (CPU)** performs operations on data. In most architectures it has three parts: an **arithmetic logic unit (ALU)**, a **control unit**, and a set of **registers** (Figure 5.2).

### 5.2.1 The arithmetic logic unit (ALU)
The **arithmetic logic unit (ALU)** performs logic, shift, and arithmetic operations on data.

**Logic operations**
We discussed several logic operations, such as NOT, AND, OR, and XOR, in Chapter 4. These operations treat the input data as bit patterns and the result of the operation is also a bit pattern.

**Shift operations**
We discussed two groups of shift operations on data in Chapter 4: logical shift operations and arithmetic shift operations. Logical shift operations are used to shift bit patterns to the left or right, while arithmetic operations are applied to integers. Their main purpose is to divide or multiply integers by two.

**Arithmetic operation**
We discussed some arithmetic operations on integers and reals on Chapter 4. We mentioned that some operations can be implemented more efficiently in hardware.

### 5.2.2 Registers
**Registers** are fast stand-alone storage locations that hold data temporarily. Multiple registers are needed to facilitate the operation of the CPU. Some of these registers are shown in Figure 5.2.

**Data registers**
In the past computers had only a few data registers to hold the input data and the result of the operations. Today, computers use dozens of registers inside the CPU to speed up their operations, because complex operations are done using hardware instead of software. These require several registers to hold the intermediate results. Data registers are named $R_0$ to $R_n$ in Figure 5.2.

**Instruction registers**
Today computers store not only data, but also programs, in their memory. The CPU is responsible for fetching instructions one by one from memory, storing them in the **instruction register (IR)** (in Figure 5.2), decoding them, and executing them. We will discuss this issue later in the chapter.

**Program counter**
Another common register in the CPU is the **program counter (PC)** (in Figure 5.2). The program counter keeps track of the instruction currently being executed. After execution of the instruction, the counter is incremented to point to the address of the next instruction in memory.

### 5.2.3 The control unit
The third part of any CPU is the control unit. The **control unit** controls the operation of each subsystem. Controlling is achieved through signals sent from the control unit to other subsystems.

## 5.3 MAIN MEMORY
**Main memory** is the second major subsystem in a computer (Figure 5.3). It consists of a collection of storage locations, each with a unique identifier, called an **address**. Data is transferred to and from memory in groups of bits called **words**. A word can be a group of 8 bits, 16 bits, 32 bits, or 64 bits (and growing). If the word is 8 bits, it is referred to as a **byte**. The term ‘byte’ is so common in computer science that sometimes a 16-bit word is referred to as a 2-byte word, or a 32-bit word is referred to as a 4-byte word.

### 5.3.1 Address space
To access a word in memory requires an identifier. Although programmers use a name to identify a word (or a collection of words), at the hardware level each word is identified by an address. The total number of uniquely identifiable locations in memory is called the **address space**. For example, a memory with 64 kilobytes and a word size of 1 byte has an address space that ranges from 0 to 65535.

Table 5.1 shows the units used to refer to memory. Note that the terminology is misleading: it approximates the number of bytes in powers of 10, but the actual number of bytes is in powers of 2. Units in powers of 2 facilitates addressing.

**Table 5.1 Memory units**

| Unit | Exact Number of Bytes | Approximation |
| :--- | :--- | :--- |
| kilobyte | $2^{10}$ (1024) bytes | $10^3$ bytes |
| megabyte | $2^{20}$ (1048576) bytes | $10^6$ bytes |
| gigabyte | $2^{30}$ (1073741824) bytes | $10^9$ bytes |
| terabyte | $2^{40}$ bytes | $10^{12}$ bytes |

**Addresses as bit patterns**
Because computers operate by storing numbers as bit patterns, a memory address is also represented as a bit pattern. So if a computer has 64 kilobytes ($2^{16}$) of memory with a word size of 1 byte, we need a bit pattern of 16 bits to define an address. Recall from Chapter 3 that addresses can be represented as unsigned integers (we do not have negative addresses). In other words, the first location is referred to as address 0000000000000000 (address 0), and the last location is referred to as address 1111111111111111 (address 65535). In general, if a computer has $N$ words of memory, we need an unsigned integer of size $\\log_2 N$ bits to refer to each memory location.

**Memory addresses are defined using unsigned binary integers.**

> **Example 5.1**
> A computer has 32 MB (megabytes) of memory. How many bits are needed to address any single byte in memory?
>
> **Solution**
> The memory address space is 32 MB, or $2^{25}$ ($2^5 \\times 2^{20}$). This means that we need $\\log_2 2^{25}$, or 25 bits, to address each byte.

> **Example 5.2**
> A computer has 128 MB of memory. Each word in this computer is eight bytes. How many bits are needed to address any single word in memory?
>
> **Solution**
> The memory address space is 128 MB, which means $2^{27}$. However, each word is eight ($2^3$) bytes, which means that we have $2^{24}$ words. This means that we need $\\log_2 2^{24}$, or 24 bits, to address each word.

### 5.3.2 Memory types
Two main types of memory exist: RAM and ROM.

**RAM**
**Random access memory (RAM)** makes up most of the main memory in a computer. In a random access device, a data item can be accessed randomly—using the address of the memory location—without the need to access all data items located before it. However, the term is confusing, because ROM can also be accessed randomly. What distinguishes RAM from ROM is that RAM can be read from and written to. The CPU can write something to RAM and later overwrite it. Another characteristic of RAM is that it is **volatile**: the information (program or data) is lost if the computer is powered down. In other words, all information in RAM is erased if you turn off the computer or if there is a power outage. RAM technology is divided into two broad categories: SRAM and DRAM.

**SRAM**
**Static RAM (SRAM)** technology uses traditional flip-flop gates (see Appendix E) to hold data. The gates hold their state (0 or 1), which means that data is stored as long as the power is on and there is no need to refresh memory locations. SRAM is fast but expensive.

**DRAM**
**Dynamic RAM (DRAM)** technology uses capacitors, electrical devices that can store energy, for data storage. If a capacitor is charged, the state is 1; if it is discharged, the state is 0. Because a capacitor loses some of its charge with time, DRAM memory cells need to be refreshed periodically. DRAMs are slow but inexpensive.

**ROM**
The contents of **read-only memory (ROM)** are written by the manufacturer, and the CPU can read from, but not write to, ROM. Its advantage is that it is **nonvolatile**—its contents are not lost if you turn off the computer. Normally, it is used for programs or data that must not be erased or changed even if you turn off the computer. For example, some computers come with ROM that holds the boot program that runs when we switch on the computer.

**PROM**
One variation of ROM is **programmable read-only memory (PROM)**. This type of memory is blank when the computer is shipped. The user of the computer, with some special equipment, can store programs on it. When programs are stored, it behaves like ROM and cannot be overwritten. This allows a computer user to store specific programs in PROM.

**EPROM**
A variation of PROM is **erasable programmable read-only memory (EPROM)**. It can be programmed by the user, but can also be erased with a special device that applies ultraviolet light. To erase EPROM memory requires physical removal and reinstallation of the EPROM.

**EEPROM**
A variation of EPROM is **electrically erasable programmable read-only memory (EEPROM)**. EEPROM can be programmed and erased using electronic impulses without being removed from the computer.

### 5.3.3 Memory hierarchy
Computer users need a lot of memory, especially memory that is very fast and inexpensive. This demand is not always possible to satisfy—very fast memory is usually not cheap. A compromise needs to be made. The solution is hierarchical levels of memory (Figure 5.4). The hierarchy is based on the following:
- Use a very small amount of costly high-speed memory where speed is crucial. The registers inside the CPU are of this type.
- Use a moderate amount of medium-speed memory to store data that is accessed often. Cache memory, discussed next, is of this type.
- Use a large amount of low-speed memory for data that is accessed less often. Main memory is of this type.

### 5.3.4 Cache memory
**Cache memory** is faster than main memory but slower than the CPU and its registers. Cache memory, which is normally small in size, is placed between the CPU and main memory (Figure 5.5).

Cache memory at any time contains a copy of a portion of main memory. When the CPU needs to access a word in main memory, it follows this procedure:
1.  The CPU checks the cache.
2.  If the word is there, it copies the word: if not, the CPU accesses main memory and copies a block of memory starting with the desired word. This block replaces the previous contents of cache memory.
3.  The CPU accesses the cache and copies the word.

This procedure can expedite operations; if the word is in the cache, it is accessed immediately. If the word is not in the cache, the word and a whole block are copied to the cache. Since it is probable that the CPU, in its next cycle, will need to access the words following the first word, the existence of the cache speeds processing.

We might wonder why cache memory is so efficient despite its small size. The answer lies in the ‘80–20 rule’. It has been observed that most computers typically spend 80 per cent of their time accessing only 20 per cent of the data. In other words, the same data is accessed over and over again. Cache memory, with its high speed, can hold this 20 per cent to make access faster at least 80 per cent of the time.

## 5.4 INPUT/OUTPUT SUBSYSTEM
The third major subsystem in a computer is the collection of devices referred to as the **input/output (I/O) subsystem**. This subsystem allows a computer to communicate with the outside world, and to store programs and data even when the power is off. Input/output devices can be divided into two broad categories: nonstorage and storage devices.

### 5.4.1 Nonstorage devices
**Nonstorage devices** allow the CPU/memory to communicate with the outside world, but they cannot store information.

**Keyboard and monitor**
Two of the more common nonstorage input/output devices are the **keyboard** and the **monitor**. The keyboard provides input, the monitor displays output and at the same time echoes input typed on the keyboard. Programs, commands, and data are input or output using strings of characters. The characters are encoded using a code such as ASCII (see Appendix A). Other devices that fall in this category are mice, joysticks, and so on.

**Printer**
A **printer** is an **output device** that creates a permanent record. A printer is a nonstorage device because the printed material cannot be directly entered into a computer again unless someone retypes or scans it.

### 5.4.2 Storage devices
**Storage devices**, although classified as I/O devices, can store large amounts of information to be retrieved at a later time. They are cheaper than main memory, and their contents are nonvolatile—that is, not erased when the power is turned off. They are sometimes referred to as **auxiliary storage devices**. We can categorize them as either magnetic or optical.

**Magnetic storage devices**
Magnetic storage devices use magnetization to store bits of data. If a location is magnetized, it represents 1, if not magnetized, it represents 0.

**Magnetic disks**
A **magnetic disk** consists of one or more disks stacked on top of each other. The disks are coated with a thin magnetic film. Information is stored on and retrieved from the surface of the disk using a **read/write head** for each magnetized surface of the disk. Figure 5.6 shows the physical layout of a magnetic disk drive and the organization of a disk.
- **Surface organization.** To organize data stored on the disk, each surface is divided into **tracks**, and each track is divided into **sectors** (Figure 5.6). The tracks are separated by an **intertrack gap**, and the sectors are separated by an **intersector gap**.
- **Data access.** A magnetic disk is considered a random access device. In a random access device, a data item can be accessed randomly without the need to access all other data items located before it. However, the smallest storage area that can be accessed at one time is a sector. A block of data can be stored in one or more sectors and retrieved without the need to retrieve the rest of the information on the disk.
- **Performance.** The performance of a disk depends on several factors, the most important being the rotational speed, the seek time, and the transfer time. The **rotational speed** defines how fast the disk is spinning. The **seek time** defines the time to move the read/write head to the desired track where the data is stored. The **transfer time** defines the time to move data from the disk to the CPU/memory.

**Magnetic tape**
**Magnetic tape** comes in various sizes. One common type is half-inch plastic tape coated with a thick magnetic film. The tape is mounted on two reels and uses a read/write head that reads or writes information when the tape is passed through it. Figure 5.7 shows the mechanical configuration of a magnetic tape drive.
- **Surface organization.** The width of the tape is divided into nine tracks, each location on a track storing 1 bit of information. Nine vertical locations can store 8 bits of information related to a byte plus a bit for error detection (Figure 5.7).
- **Data access.** A magnetic tape is considered a sequential access device. Although the surface may be divided into blocks, there is no addressing mechanism to access each block. To retrieve a specific block on the tape, we need to pass through all the previous blocks.
- **Performance.** Although magnetic tape is slower than a magnetic disk, it is cheaper. Today, people use magnetic tape to back up large amounts of data.

**Optical storage devices**
**Optical storage devices**, a relatively recent technology, use laser light to store and retrieve data. The use of optical storage technology followed the invention of the **compact disk (CD)** used to store audio information. Today, the same technology—slightly improved—is used to store information in a computer. Devices that use this technology include CD-ROMs, CD-Rs, CD-RWs, and DVDs.

**CD-ROMs**
**Compact disk read-only memory (CD-ROM)** disks use the same technology as the audio CD, originally developed by Phillips and Sony for recording music. The only difference between these two technologies is enhancement: a CD-ROM drive is more robust and checks for errors. Figure 5.8 shows the steps involved in creating and using a CD-ROM.
- **Creation.** CD-ROM technology uses three steps to create a large number of discs:
  a. A **master disk** is created using a high-power infrared laser that creates bit patterns on coated plastic. The laser translates the bit patterns into a sequence of **pits** (holes) and **lands** (no holes). The pits usually represent 0s and the lands usually represent 1s. However, this is only a convention, and it can be reversed. Other schemes use a transition (pit to land or land to pit) to represent 1, and a lack of transition to represent 0.
  b. From the master disk, a mold is made. In the mold, the pits (holes) are replaced by bumps.
  c. Molten **polycarbonate resin** is injected into the mold to produce the same pits as the master disk. A very thin layer of aluminum is added to the polycarbonate to provide a reflective surface. On top of this, a protective layer of lacquer is applied and a label is added. Only this last step needs to be repeated for each disk.
- **Reading.** The CD-ROM is read using a low-power laser beam. The beam is reflected by the aluminum surface when passing through a land. It is reflected twice when it encounters a pit, once by the pit boundary and once by the aluminum boundary. The two reflections have a destructive effect, because the depth of the pit is chosen to be exactly one-fourth of the beam wavelength. In other words, the sensor installed in the drive detects more light when the location is a land and less light when the location is a pit, so can read what was recorded on the original master disk and copied to the CD-ROM.
- **Format.** CD-ROM technology uses a different format than magnetic disk (Figure 5.9). The format of data on a CD-ROM is based on:
  a. A block of 8-bit data transformed into a 14-bit symbol using an error-correction method called Hamming code.
  b. A frame made up from 42 symbols (14 bits/symbol).
  c. A sector made up from 98 frames (2352 bytes).
- **Speed.** CD-ROM drives come in different speeds. Single speed is referred to as 1x, double speed 2x, and so on. If the drive is single speed, it can read up to 153 600 bytes per second. Table 5.2 shows the speeds and their corresponding data rates.

**Table 5.2 CD-ROM speeds**
| Speed | Data rate | Approximation |
|---|---|---|
| 1x | 153600 bytes per second | 150 KB/s |
| 2x | 307200 bytes per second | 300 KB/s |
| 4x | 614400 bytes per second | 600 KB/s |
| 6x | 921600 bytes per second | 900 KB/s |
| 8x | 1228800 bytes per second | 1.2 MB/s |
| 12x | 1843200 bytes per second | 1.8 MB/s |
| 16x | 2457600 bytes per second | 2.4 MB/s |
| 24x | 3688400 bytes per second | 3.6 MB/s |
| 32x | 4915200 bytes per second | 4.8 MB/s |
| 40x | 6144000 bytes per second | 6 MB/s |

- **Application.** The expense involved in creating a master disk, mold, and the actual disk can be justified if there are a large number of potential customers. In other words, this technology is economical if the discs are mass produced.

**CD-R**
Clearly, CD-ROM technology is justifiable only if the manufacturer can create a large number of disks. On the other hand, the **compact disk recordable (CD-R)** format allows users to create one or more disks without going through the expense involved in creating CD-ROMs. It is particularly useful for making backups. You can write once to CD-R disks, but they can be read many times. This is why the format is sometimes called **write once, read many (WORM)**.
- **Creation.** CD-R technology uses the same principles as CD-ROM to create a disk (Figure 5.10). The following lists the differences:
  a. There is no master disk or mold.
  b. The reflective layer is made of gold instead of aluminum.
  c. There are no physical pits (holes) in the polycarbonate: the pits and lands are only simulated. To simulate pits and lands, an extra layer of dye, similar to the material used in photography, is added between the reflective layer and the polycarbonate.
  d. A high-power laser beam, created by the CD burner of the drive, makes a dark spot in the dye, changing its chemical composition, which simulates a pit. The areas not struck by the beam become lands.
- **Reading.** CD-Rs can be read by a CD-ROM or a CD-R drive. This means that any differences should be transparent to the drive. The same low-power laser beam passes in front of the simulated pits and lands. For a land, the beam reaches the reflective layer and is reflected. For a simulated pit, the spot is opaque, so the beam cannot be reflected back.
- **Format and speed.** The format, capacity, and speed of CD-Rs are the same as CD-ROMs.
- **Application.** This technology is very attractive for the creation and distribution of a small number of disks. It is also very useful for making archive files and backups.

**CD-RW**
Although CD-Rs have become very popular, they can be written to only once. To overwrite previous materials, a new technology allows a new type of disk called **compact disk rewritable (CD-RW)**. It is sometimes called an *erasable optical disk*.
- **Creation.** CD-RW technology uses the same principles as CD-R to create the disk (Figure 5.11). The following lists the differences:
  a. Instead of dye, the technology uses an alloy of silver, indium, antimony, and tellurium. This alloy has two stable states: crystalline (transparent) and amorphous (nontransparent).
  b. The drive uses high-power lasers to create simulated pits in the alloy (changing it from crystalline to amorphous).
- **Reading.** The drive uses the same type of low-power laser beam as CD-ROM and CD-R to detect pits and lands.
- **Erasing.** The drive uses a medium-power laser beam to change pits to lands. The beam changes a location from the amorphous state to the crystalline state.
- **Format and speed.** The format, capacity, and speed of CD-RWs are the same as CD-ROMs.
- **Application.** The technology is definitely more attractive than CD-R technology. However, CD-Rs are more popular for two reasons. First, blank CD-R discs are less expensive than blank CD-RW discs. Second, CD-Rs are preferable in cases where the created disk must not be changed, either accidentally or intentionally.

**DVD**
The industry has felt the need for digital storage media with even higher capacity. The capacity of a CD-ROM (650 MB) is insufficient to store video information. The latest optical memory storage device on the market is called a **digital versatile disk (DVD)**. It uses a technology similar to CD-ROM, but with the following differences:
a. The pits are smaller: 0.4 microns in diameter instead of the 0.8 microns used in CDs.
b. The tracks are closer to each other.
c. The beam is a red laser instead of infrared.
d. DVDs use one to two recording layers, and can be single-sided or double-sided.
- **Capacity.** These improvements result in higher capacities (Table 5.3).

**Table 5.3 DVD capacities**
| Feature | Capacity |
|---|---|
| Single-sided, single-layer | 4.7 GB |
| Single-sided, dual-layer | 8.5 GB |
| Double-sided, single-layer | 9.4 GB |
| Double-sided, dual-layer | 17 GB |

- **Compression.** DVD technology uses MPEG (see Chapter 15) for compression. This means that a single-sided, single-layer DVD can hold 133 minutes of video at high resolution. This also includes both audio and subtitles.
- **Application.** Today, the high capacity of DVDs attracts many applications that need to store a high volume of data.

## 5.5 SUBSYSTEM INTERCONNECTION
The previous sections outlined the characteristics of the three subsystems (CPU, main memory, and I/O) in a stand-alone computer. In this section, we explore how these three subsystems are interconnected. The interconnection plays an important role because information needs to be exchanged between the three subsystems.

### 5.5.1 Connecting CPU and memory
The CPU and memory are normally connected by three groups of connections, each called a **bus**: data bus, address bus, and control bus (Figure 5.12).

**Data bus**
The **data bus** is made of several connections, each carrying 1 bit at a time. The number of connections depends on the size of the word used by the computer. If the word is 32 bits (4 bytes), we need a data bus with 32 connections so that all 32 bits of a word can be transmitted at the same time.

**Address bus**
The **address bus** allows access to a particular word in memory. The number of connections in the address bus depends on the address space of the memory. If the memory has $2^n$ words, the address bus needs to carry $n$ bits at a time. Therefore, it must have $n$ connections.

**Control bus**
The **control bus** carries communication between the CPU and memory. For example, there must be a code, sent from the CPU to memory, to specify a read or write operation. The number of connections used in the control bus depends on the total number of control commands a computer needs. If a computer has $2^m$ control actions, we need $m$ connections for the control bus, because $m$ bits can define $2^m$ different operations.

### 5.5.2 Connecting I/O devices
I/O devices cannot be connected directly to the buses that connect the CPU and memory because the nature of I/O devices is different from the nature of CPU and memory. I/O devices are electromechanical, magnetic, or optical devices, whereas the CPU and memory are electronic devices. I/O devices also operate at a much slower speed than the CPU/memory. There is a need for some sort of intermediary to handle this difference. Input/output devices are therefore attached to the buses through **input/output controllers** or **interfaces**. There is one specific **controller** for each input/output device (Figure 5.13).

**Controllers**
Controllers or interfaces bridge the gap between the nature of the I/O device and the CPU and memory. A controller can be a serial or parallel device. A serial controller has only one data wire, while a parallel controller has several data connections so that several bits can be transferred at a time.
Several kinds of controllers are in use. The most common ones today are SCSI, FireWire, USB, and HDMI.

**SCSI**
The **small computer system interface (SCSI)** was first developed for Macintosh computers in 1984. Today it is used in many systems. It has a parallel interface with 8, 16, or 32 connections. The SCSI interface provides a daisy-chained connection, as shown in Figure 5.14. Both ends of the chain must be connected to a special device called a *terminator*, and each device must have a unique address (target ID).

**FireWire**
IEEE standard 1394 defines a serial interface commonly called **FireWire**. It is a high-speed serial interface that transfers data in packets, achieving a transfer rate of up to 50 MB/sec, or double that in the most recent version. It can be used to connect up to 63 devices in a daisy chain or a tree connection (using only one connection). Figure 5.15 shows the connection of input/output devices to a FireWire controller. There is no need for termination as there is for SCSI.

**USB**
**Universal Serial Bus (USB)** is a competitor for FireWire. Although the nomenclature uses the term *bus*, USB is a serial controller that connects both low- and high-speed devices to the computer bus. Figure 5.16 shows the connection of the USB controller to the bus and the connection of devices to the controller.

Multiple devices can be connected to a USB controller, which is also referred to as a *root hub*. USB-2 (USB Version 2.0) allows up to 127 devices to be connected to a USB controller using a tree-like **topology** with the controller as the root of the tree, **hubs** as the intermediate nodes, and the devices as the end nodes. The difference between the controller (root hub) and the other hubs is that the controller is aware of the presence of other hubs in the tree, but other hubs are passive devices that simply pass the data.
Devices can easily be removed or attached to the tree without powering down the computer. This is referred to as *hot-swappable*. When a hub is removed from the system, all devices and other hubs connected to it are also removed.
USB uses a cable with four wires. Two wires (+5 volts and ground) are used to provide power for low-power devices such as keyboards or mice. A high-power device needs to be connected to a power source. A hub gets its power from the bus and can provide power for low-power devices. The other two wires (twisted together to reduce noise) are used to carry data, addresses, and control signals. USB uses two different connectors: A and B. The A connector (downstream connector) is rectangular and is used to connect to the USB controller or the hub. The B connector (upstream connector) is close to square and is used to connect to the device. Recently two new connectors, mini A and mini B, have been introduced that are used for connecting to small devices and laptop computers.
USB-2 provides three data transfer rates: 1.5 Mbps (megabits per second), 12 Mbps, and 480 Mbps. The low data rate can be used with slow devices such as keyboards and mice, the medium data rate with printers, and the high data rate with mass storage devices.

Data is transferred over USB in packets (see Chapter 6). Each packet contains an address part (device identifier), a control part, and part of the data to be transmitted to that device. All devices will receive the same packet, but only those devices with the address defined in the packet will accept it.
USB 3.0 is another revision of the Universal Serial Bus (USB) standard for computer connectivity. USB 3.0 adds a new transfer mode called *SuperSpeed* capable of transferring data at up to 4.8 Gbit/s. It is promised to update USB 3.0 to 10 Gbit/s.

**HDMI**
**HDMI (High-Definition Multimedia Interface)** is a digital replacement for existing analog video standards. It can be used for transferring video data digital audio data from a source to a compatible computer monitor, video projector, digital television, or digital audio device. There are a number of HDMI-standard cables available including standard, enhanced, high definition, and 3D video signals; up to eight channels of compressed or uncompressed digital audio; a CEC (Consumer Electronics Control) connection; and an Ethernet data connection.

### 5.5.3 Addressing input/output devices
The CPU usually uses the same bus to read data from or write data to main memory and I/O device. The only difference is the instruction. If the instruction refers to a word in main memory, data transfer is between main memory and the CPU. If the instruction identifies an I/O device, data transfer is between the I/O device and the CPU. There are two methods for handling the addressing of I/O devices: isolated I/O and memory-mapped I/O.

**Isolated I/O**
In the **isolated I/O** method, the instructions used to read/write memory are totally different than the instructions used to read/write I/O devices. There are instructions to test, control, read from, and write to I/O devices. Each I/O device has its own address. The I/O addresses can overlap with memory addresses without any ambiguity because the instruction itself is different. For example, the CPU can use a command ‘Read 101’ to read from memory word 101, and it can use a command ‘Input 101’ to read from I/O device 101. There is no confusion, because the read command is for reading from memory and the input command is for reading from an I/O device (Figure 5.17).

**Memory-mapped I/O**
In the **memory-mapped I/O** method, the CPU treats each register in the I/O controller as a word in memory. In other words, the CPU does not have separate instructions for transferring data from memory and I/O devices. For example, there is only one ‘Read’ instruction. If the address defines a word from memory, the data is read from that word. If the address defines a register from an I/O device, the data is read from that register. The advantage of the memory-mapped configuration is a smaller number of instructions: all the memory instructions can be used by I/O devices. The disadvantage is that part of the memory address space is allocated to registers in I/O controllers. For example, if we have five I/O controllers and each has four registers, 20 addresses are used for this purpose. The size of the memory is reduced by 20 words. Figure 5.18 shows the memory-mapped I/O concept.

## 5.6 PROGRAM EXECUTION
Today, general-purpose computers use a set of instructions called a *program* to process data. A computer executes the program to create output data from input data. Both the program and the data are stored in memory.

**At the end of this chapter we give some examples of how a hypothetical simple computer executes a program.**

### 5.6.1 Machine cycle
The CPU uses repeating **machine cycles** to execute instructions in the program, one by one, from beginning to end. A simplified cycle can consist of three phases: **fetch**, **decode**, and **execute** (Figure 5.19).

**Fetch**
In the **fetch** phase, the control unit orders the system to copy the next instruction into the instruction register in the CPU. The address of the instruction to be copied is held in the program counter register. After copying, the program counter is incremented to refer to the next instruction in memory.

**Decode**
The second phase in the cycle is the **decode** phase. When the instruction is in the instruction register, it is decoded by the control unit. The result of this decode step is the binary code for some operation that the system will perform.

**Execute**
After the instruction is decoded, the control unit sends the task order to a component in the CPU. For example, the control unit can tell the system to load (read) a data item from memory, or the CPU can tell the ALU to add the contents of two input registers and put the result in an output register. This is the **execute** phase.

### 5.6.2 Input/output operation
Commands are required to transfer data from I/O devices to the CPU and memory. Because I/O devices operate at much slower speeds than the CPU, the operation of the CPU must be somehow synchronized with the I/O devices. Three methods have been devised for this synchronization: programmed I/O, interrupt-driven I/O, and direct memory access (DMA).

**Programmed I/O**
In the **programmed I/O** method, synchronization is very primitive: the CPU waits for the I/O device (Figure 5.20).

The transfer of data between the I/O device and the CPU is done by an instruction in the program. When the CPU encounters an I/O instruction, it does nothing else until the data transfer is complete. The CPU constantly checks the status of the I/O device: if the device is ready to transfer, data is transferred to the CPU. If the device is not ready, the CPU continues checking the device status until the I/O device is ready. The big issue here is that CPU time is wasted by checking the status of the I/O device for each unit of data to be transferred. Note that data is transferred to memory after the input operation, while data is transferred from memory before the output operation.

**Interrupt-driven I/O**
In the **interrupt-driven I/O** method, the CPU informs the I/O device that a transfer is going to happen, but it does not test the status of the I/O device continuously. The I/O device informs (interrupts) the CPU when it is ready. During this time, the CPU can do other jobs such as running other programs or transferring data from or to other I/O devices (Figure 5.21).
In this method, CPU time is not wasted—the CPU can do something else while the slow I/O device is finishing a task. Note that, like programmed I/O, this method also transfers data between the device and the CPU. Data is transferred to memory after the input operation, while data is transferred from memory before the output operation.

**Direct memory access (DMA)**
The third method used for transferring data is **direct memory access (DMA)**. This method transfers a large block of data between a high-speed I/O device, such as a disk, and memory directly without passing it through the CPU. This requires a DMA controller that relieves the CPU of some of its functions. The DMA controller has registers to hold a block of data before and after memory transfer. Figure 5.22 shows the DMA connection to the data, address, and control buses.

Using this method for an I/O operation, the CPU sends a message to the DMA. The message contains the type of transfer (input or output), the beginning address of the memory location, and the number of bytes to be transferred. The CPU is then available for other jobs (Figure 5.23).
When ready to transfer data, the DMA controller informs the CPU that it needs to take control of the buses. The CPU stops using the buses and lets the controller use them. After data transfer directly between the DMA and memory, the CPU continues its normal operation. Note that, in this method, the CPU is idle for a time. However, the duration of this idle period is very short compared to other methods—the CPU is idle only during the data transfer between the DMA and memory, not while the device prepares the data.

## 5.7 DIFFERENT ARCHITECTURES
The architecture and organization of computers have gone through many changes in recent decades. In this section we discuss some common architectures and organizations that differ from the simple computer architecture we discussed earlier.

### 5.7.1 CISC
CISC (pronounced *sisk*) stands for **complex instruction set computer (CISC)**. The strategy behind CISC architectures is to have a large set of instructions, including complex ones. Programming CISC-based computers is easier than in other designs because there is a single instruction for both simple and complex tasks. Programmers therefore do not have to write a set of instructions to do a complex task.

The complexity of the instruction set makes the circuitry of the CPU and the control unit very complicated. The designers of CISC architectures have come up with a solution to reduce this complexity: programming is done on two levels. An instruction in machine language is not executed directly by the CPU—the CPU performs only simple operations, called *microoperations*. A complex instruction is transformed into a set of these simple operations and then executed by the CPU. This necessitates the addition of a special memory called *micromemory* that holds the set of operations for each complex instruction in the instruction set. The type of programming that uses microoperations is called *microprogramming*.
One objection to CISC architecture is the overhead associated with microprogramming and access to micromemory. However, proponents of the architecture argue that this compensates for smaller programs at the machine level. An example of CISC architecture can be seen in the Pentium series of processors developed by Intel.

### 5.7.2 RISC
RISC (pronounced *risk*) stands for **reduced instruction set computer**. The strategy behind RISC architecture is to have a small set of instructions that do a minimum number of simple operations. Complex instructions are simulated using a subset of simple instructions. Programming in RISC is more difficult and time-consuming than in the other design because most of the complex instructions are simulated using simple instructions.

### 5.7.3 Pipelining
We have learned that a computer uses three phases of *fetch*, *decode*, and *execute* for each instruction. In early computers, these three phases needed to be done in series for each instruction. In other words, instruction $n$ needs to finish all of these phases before the instruction $n + 1$ can start its own phases. Modern computers use a technique called **pipelining** to improve the **throughput** (the total number of instructions performed in each period of time). The idea is that if the control unit can do two or three of these phases simultaneously, the next instruction can start before the previous one is finished.
Figure 5.24.a shows how three consecutive instructions are handled in a computer that uses no pipelining. Figure 5.24.b shows how pipelining can increase the throughput of the computer by allowing different types of phases belonging to different instructions to be done simultaneously. In other words, when the CPU is performing the decode phase of the first instruction, it can also perform the fetch phase of the second instruction. The first computer can perform on average 9 phases in the specific period of time, while the pipelined computer can perform 24 phases in the same period of time. If we assume that each phase uses the same amount of time, the first computer has done 9/3 = 3 instructions while the second computer has done 24/3 = 8 instructions. The throughput is therefore increased 8/3 or 266 per cent.
Of course, pipelining is not as easy as this. There are some problems, such as when a jump instruction is encountered. In this case, the instruction in the *pipe* should be discarded. However, new CPU designs have overcome most drawbacks. Some new CPU designs can even do several fetch cycles simultaneously.

### 5.7.4 Parallel processing
Traditionally a computer had a single control unit, a single arithmetic logic unit, and a single memory unit. With the evolution in technology and the drop in the cost of computer hardware, today we can have a single computer with multiple control units, multiple arithmetic logic units and multiple memory units. This idea is referred to as *parallel processing*. Like pipelining, parallel processing can improve throughput.
**Parallel processing** involves many different techniques. A general view of parallel processing is given by the taxonomy proposed by M. J. Flynn. This taxonomy divides the computer’s organization (in term of processing data) into four categories, as shown in Figure 5.25. According to Flynn, parallel processing may occur in the data stream, the instruction stream, or both.

**SISD organization**
A **single instruction-stream, single data-stream (SISD)** organization represents a computer that has one control unit, one arithmetic logic unit, and one multiple memory units. The instructions are executed sequentially and each instruction may access one or more data items in the data stream. Our simple computer introduced earlier in the chapter is an example of SISD organization. Figure 5.26 shows the concept of configuration for an SISD organization.

**SIMD organization**
A **single instruction-stream, multiple data-stream (SIMD)** organization represents a computer that has one control unit, multiple processing units, and multiple memory units. All processor units receive the same instruction from the control unit, but operate on different items of data. An array processor that simultaneously operates on an array of data belongs to this category. Figure 5.27 shows the concept and implementation of an SIMD organization.

**MISD organization**
A **multiple instruction-stream, single data-stream (MISD)** architecture is one in which several instructions belonging to several instruction streams simultaneously operate on the same data stream. Figure 5.28 shows the concept, but it has never been implemented.

**MIMD organization**
A **multiple instruction-stream, multiple data-stream (MIMD)** architecture is one in which several instructions belonging to several instruction streams simultaneously operate on several data streams (each instruction on one data stream). Figure 5.29 shows the concept and implementation. MIMD organization is considered as a true parallel processing architecture by some experts. In this architecture several tasks can be performed simultaneously. The architecture can use a single shared memory or multiple memory sections.

Parallel processing has found some applications, mostly in the scientific community, in which a task may take several hours or days if done using a traditional computer architecture. Some examples of this can be found in multiplication of very large matrices, in simultaneous processing of large amounts of data for weather prediction, or in space flight simulations.

## 5.8 A SIMPLE COMPUTER
To explain the architecture of computers as well as their instruction processing, we introduce a simple (unrealistic) computer, as shown in Figure 5.30. Our simple computer has three components: CPU, memory, and an input/output subsystem.

### 5.8.1 CPU
The CPU itself is divided into three sections: data registers, arithmetic logic unit (ALU), and the control unit.

**Data registers**
There are sixteen 16-bit data registers with hexadecimal addresses $(0, 1, 2, ..., F)_{16}$, but we refer to them as $R_0$ to $R_{15}$. In most instructions, they hold 16-bit data, but in some instructions they may hold other information.

**Control unit**
The control unit has the circuitry to control the operations of the ALU, access to memory, and access to the I/O subsystem. In addition, it has two dedicated registers: program counter and instruction register. The program counter (PC), which can hold only eight bits, keeps track of which instruction is to be executed next. The contents of the PC points to the address of the memory location of the main memory that holds the next program instruction. After each machine cycle the program counter is incremented by one to point to the next program instruction. The instruction register (IR) holds a 16-bit value which is the encoded instruction for the current cycle.

### 5.8.2 Main memory
The main memory has 256 16-bit memory locations with binary addresses $(00000000 \\text{ to } 11111101)_2$ or hexadecimal addresses $(00 \\text{ to } FD)_{16}$. The main memory holds both data and program instruction. The first 64 locations $(00 \\text{ to } 3F)_{16}$ are dedicated to program instructions. Program instructions for any program are stored in consecutive memory locations. Memory locations $(40 \\text{ to } FD)_{16}$ are used for storing data.

### 5.8.3 Input/output subsystem
Our simple computer has a very primitive input/output subsystem. The subsystem consists of a keyboard and a monitor. Although we show the keyboard and monitor in a separate box in Figure 5.30, the subsystem is part of the memory address-wise. These devices have memory-mapped addresses, as discussed earlier in the chapter. We assume that the keyboard (as the input device) and monitor (as the only output device) act like memory locations with addresses $(FE)_{16}$ and $(FF)_{16}$ respectively, as shown in the figure. In other words, we assume that they behave as 16-bit registers that interact with the CPU as a memory location would. These two devices transfer data from the outside world to the CPU and vice versa.

### 5.8.4 Instruction set
Our simple computer is capable of having a set of 16 instructions, although we are using only 14 of these instructions. Each computer instruction consists of two parts: the **operation code (opcode)** and the **operand(s)**. The opcode specifies the type of operation to be performed on the operand(s). Each instruction consists of 16 bits divided into four 4-bit fields. The leftmost field contains the opcode and the other three fields contain the operand or address of operand(s), as shown in Figure 5.31.

The instructions are listed in Table 5.4 below. Note that not every instruction requires three operands. Any operand field not needed is filled with $(0)_{16}$. For example, all three operand fields of the halt instruction, and the last field of the move and NOT instructions, are filled with $(0)_{16}$. Also note that a register address is described by a single hexadecimal digit and thus uses a single field, but a memory location is described by two hexadecimal digits and uses two fields.
There are two add instructions: one for adding integers (ADDI) and one for adding floating points numbers (ADDF). The simple computer can take input from keyboard if we use address $(FE)_{16}$ as the second operand of the LOAD instruction. Similarly, the computer sends output to the monitor if we use the address $(FF)_{16}$ as the second operand of the STORE instruction. If the third operand of the ROTATE instruction is 0, the instruction circularly rotates the bit pattern in R to the right $n$ places: if the third operand is 1, it rotates it to the left. We have also included one increment (INC) and one decrement (DEC) instruction.

**Table 5.4 List of instructions for the simple computer**
| Instruction | Code $d_1$ | Operands $d_2, d_3, d_4$ | Action |
|---|---|---|---|
| HALT | 0 | | Stops the execution of the program |
| LOAD | 1 | $R_D$ $M_S$ | $R_D \\leftarrow M_S$ |
| STORE | 2 | $M_D$ $R_S$ | $M_D \\leftarrow R_S$ |
| ADDI | 3 | $R_D$ $R_{S1}$ $R_{S2}$ | $R_D \\leftarrow R_{S1} + R_{S2}$ |
| ADDF | 4 | $R_D$ $R_{S1}$ $R_{S2}$ | $R_D \\leftarrow R_{S1} + R_{S2}$ |
| MOVE | 5 | $R_D$ $R_S$ | $R_D \\leftarrow R_S$ |
| NOT | 6 | $R_D$ $R_S$ | $R_D \\leftarrow \\overline{R_S}$ |
| AND | 7 | $R_D$ $R_{S1}$ $R_{S2}$ | $R_D \\leftarrow R_{S1} \\text{ AND } R_{S2}$ |
| OR | 8 | $R_D$ $R_{S1}$ $R_{S2}$ | $R_D \\leftarrow R_{S1} \\text{ OR } R_{S2}$ |
| XOR | 9 | $R_D$ $R_{S1}$ $R_{S2}$ | $R_D \\leftarrow R_{S1} \\text{ XOR } R_{S2}$ |
| INC | A | $R$ | $R \\leftarrow R + 1$ |
| DEC | B | $R$ | $R \\leftarrow R - 1$ |
| ROTATE | C | $R$ $n$ 0 or 1 | Rot$_n$ $R$ |
| JUMP | D | $R$ $n$ | IF $R_0 \\neq R$ then PC = $n$, otherwise continue |

Key:
$R_S, R_{S1}, R_{S2}$: Hexadecimal address of source registers
$R_D$: Hexadecimal address of destination register
$M_S$: Hexadecimal address of source memory location
$M_D$: Hexadecimal address of destination memory location
$n$: Hexadecimal number
$d_1, d_2, d_3, d_4$: First, second, third, and fourth hexadecimal digits

### 5.8.5 Processing the instructions
Our simple computer, like most computers, uses machine cycles. A cycle is made of three phases: *fetch*, *decode*, and *execute*. During the fetch phase, the instruction whose address is determined by the PC is obtained from the memory and loaded into the IR. The PC is then incremented to point to the next instruction. During the *decode* phase, the instruction in the IR is decoded and the required operands are fetched from the register or from memory. During the *execute* phase, the instruction is executed and the results are placed in the appropriate memory location or the register. Once the third phase is completed, the control unit starts the cycle again, but now the PC is pointing to the next instruction. The process continues until the CPU reaches a HALT instruction.

**An example**
Let us show how our simple computer can add two integers A and B and create the result as C. We assume that integers are in two’s complement format. Mathematically, we show this operation as:
$C = A + B$
To solve this problem with the simple computer, it is necessary for the first two integers to be held in two registers (for example, $R_0$ and $R_1$) and the result of the operation to be held in a third register (for example $R_2$). The ALU can only operate on the data that is stored in data registers in the CPU. However, most computers, including our simple computer, have a limited number of registers in the CPU. If the number of data items is large and they are supposed to stay in the computer for the duration of the program, it is better to store them in memory and only bring them to the registers temporarily. So we assume that the first two integers are stored in memory locations $(40)_{16}$ and $(41)_{16}$ and the result should be stored in memory location $(42)_{16}$. This means that two integers need to be loaded into the CPU and the result needs to be stored in the memory. Therefore, a simple program to do the simple addition needs five instructions, as shown below:

1.  Load the contents of $M_{40}$ into register $R_0$ ($R_0 \\leftarrow M_{40}$).
2.  Load the contents of $M_{41}$ into register $R_1$ ($R_1 \\leftarrow M_{41}$).
3.  Add the contents of $R_0$ and $R_1$ and place the result in $R_2$ ($R_2 \\leftarrow R_0 + R_1$).
4.  Store the contents $R_2$ in $M_{42}$ ($M_{42} \\leftarrow R_2$).
5.  Halt.

In the language of our simple computer, these five instructions are encoded as:

| Code | Interpretation |
|---|---|
| $(1040)_{16}$ | 1: LOAD 0: $R_0$ 40: $M_{40}$ |
| $(1141)_{16}$ | 1: LOAD 1: $R_1$ 41: $M_{41}$ |
| $(3201)_{16}$ | 3: ADDI 2: $R_2$ 0: $R_0$ 1: $R_1$ |
| $(2422)_{16}$ | 2: STORE 42: $M_{42}$ 2: $R_2$ |
| $(0000)_{16}$ | 0: HALT |

### 5.8.6 Storing program and data
To follow the von Neumann model, we need to store the program and the data in memory. We can store the five-line program in memory starting from location $(00)_{16}$ to $(04)_{16}$. We already know that the data needs to be stored in memory locations $(40)_{16}$, $(41)_{16}$, and $(42)_{16}$.

### 5.8.7 Cycles
Our computer uses one cycle per instruction. If we have a small program with five instructions, we need five cycles. We also know that each cycle is normally made up of three steps: *fetch*, *decode*, *execute*. Assume for the moment that we need to add $161 + 254 = 415$. The numbers are shown in memory in hexadecimal is, $(00A1)_{16}$, $(00FE)_{16}$, and $(019F)_{16}$.

**Cycle 1**
At the beginning of the first cycle (Figure 5.32), the PC points to the first instruction of the program, which is at memory location $(00)_{16}$. The control unit goes through three steps:
1.  The control unit *fetches* the instruction stored in memory location $(00)_{16}$ and puts it in the IR. After this step, the value of the PC is incremented.
2.  The control unit *decodes* the instruction $(1040)_{16}$ as $R_0 \\leftarrow M_{40}$.
3.  The control unit *executes* the instruction, which means that a copy of the integer stored in memory location (40) is loaded into register $R_0$.

**Cycle 2**
At the beginning of the second cycle (Figure 5.33), the PC points to the second instruction of the program, which is at memory location $(01)_{16}$. The control unit goes through three steps:
1.  The control unit *fetches* the instruction stored in memory location $(01)_{16}$ and puts it in the IR. After this step, the value of the PC is incremented.
2.  The control unit *decodes* the instruction $(1141)_{16}$ as $R_1 \\leftarrow M_{41}$.
3.  The control unit *executes* the instruction, which means that a copy of integer stored in memory location $(41)_{16}$ is loaded into register $R_1$.

**Cycle 3**
At the beginning of the third cycle (Figure 5.34), the PC points to the third instruction of the program, which is at memory location $(02)_{16}$. The control unit goes through three steps:
1.  The control unit *fetches* the instruction stored in memory location $(02)_{16}$ and puts it in the IR. After this step, the value of the PC is incremented.
2.  The control unit *decodes* the instruction $(3201)_{16}$ as $R_2 \\leftarrow R_0 + R_1$.
3.  The control unit *executes* the instruction, which means that the contents of $R_0$ is added to the content of $R_1$ (by the ALU) and the result is put in $R_2$.

**Cycle 4**
At the beginning of the fourth cycle (Figure 5.35), the PC points to the fourth instruction of the program, which is at memory location $(03)_{16}$. The control unit goes through three steps:
1.  The control unit *fetches* the instruction stored in memory location $(03)_{16}$ and puts it in the IR. After this step, the value of the PC is incremented.
2.  The control unit *decodes* the instruction $(2422)_{16}$ as $M_{42} \\leftarrow R_2$.
3.  The control unit *executes* the instruction, which means a copy of integer in register $R_2$ is stored in memory location $(42)_{16}$.

**Cycle 5**
At the beginning of the fifth cycle (Figure 5.36), the PC points to the fifth instruction of the program, which is at memory location $(04)_{16}$. The control unit goes through three steps:
1.  The control unit *fetches* the instruction stored in memory location $(04)_{16}$ and puts it in the IR. After this step, the value of the PC is incremented.
2.  The control unit *decodes* the instruction $(0000)_{16}$ as Halt.
3.  The control unit *executes* the instruction, which means that the computer stops.

### 5.8.8 Another example
In the previous example we assumed that the two integers to be added were already in memory. We also assume that the result of addition will be held in memory. You may ask how we can store the two integers we want to add in memory, or how we use the result when it is stored in the memory. In a real situation, we enter the first two integers into memory using an input device such as keyboard, and we display the third integer through an output device such as a monitor. Getting data via an input device is normally called a *read* operation, while sending data to an output device is normally called a *write* operation. To make our previous program more practical, we need to modify it as follows:

1.  Read an integer into $M_{40}$.
2.  $R_0 \\leftarrow M_{40}$.
3.  Read an integer into $M_{41}$.
4.  $R_1 \\leftarrow M_{41}$.
5.  $R_2 \\leftarrow R_0 + R_1$.
6.  $M_{42} \\leftarrow R_2$.
7.  Write the integer from $M_{42}$.
8.  Halt.

There are many ways to implement input and output. Most computers today do direct data transfer from an input device to memory and direct data transfer from memory to an output device. However, our simple computer is not one of them. In our computer we can simulate read and write operations using the LOAD and STORE instruction. Furthermore, LOAD and STORE read data input to the CPU and write data from the CPU. We need two instructions to read data into memory or write data out of memory. The read operation is:

$R \\leftarrow M_{FE}$ Because the keyboard is assumed to be memory location $(FE)_{16}$
$M \\leftarrow R$

The write operation is:

$R \\leftarrow M$
$M_{FF} \\leftarrow R$ Because the monitor is assumed to be memory location $(FF)_{16}$

You may ask, if the operations are supposed to be done in the CPU, why do we transfer the data from the keyboard to the CPU, then to the memory, then to the CPU for processing? Could we directly transfer data to the CPU? The answer is that we can do this for this small problem, but we should not do it in principle. Think what happens if we need to add 1000 numbers or sort 1000000 integers. The number of registers in the CPU is limited (it may be hundreds in a real computer, but still not enough).

**The input operation must always read data from an input device into memory: the output operation must always write data from memory to an output device.**

With this in mind, the program is coded as:
1 $(1FFE)_{16}$   5 $(1040)_{16}$   9 $(1F42)_{16}$
2 $(240F)_{16}$   6 $(1141)_{16}$   10 $(2FFF)_{16}$
3 $(1FFE)_{16}$   7 $(3201)_{16}$   11 $(0000)_{16}$
4 $(241F)_{16}$   8 $(2422)_{16}$

Operations 1 to 4 are for input and operations 9 and 10 are for output. When we run this program, it waits for the user to input two integers on the keyboard and press the enter key. The program then calculates the sum and displays the result on the monitor.

### 5.8.9 Reusability
One of the advantages of a computer over a non-programmable calculator is that we can use the same program over and over. We can run the program several times and each time enter different inputs and obtain a different output.

## 5.9 END-CHAPTER MATERIALS
### 5.9.1 Recommended reading
For more details about subjects discussed in this chapter, the following books are recommended:
- Englander, I. *The Architecture of Computer Hardware and Systems Software*, Hoboken, NJ: Wiley, 2003
- Mano, M. *Computer System Architecture*, Upper Saddle River, NJ: Prentice-Hall, 1993
- Null, L. and Lobur, J. *Computer Organization and Architecture*, Sudbury, MA: Jones and Bartlett, 2003
- Hamacher, C., Vranesic, Z. and Zaky, S. *Computer Organization*, New York: McGraw-Hill, 2002
- Warford, S. *Computer Systems*, Sudbury, MA: Jones and Bartlett, 2005
- Ercegovac, M., Lang, T. and Moreno, J. *Introduction to Digital Systems*, Hoboken, NJ: Wiley, 1998
- Cragon, H. *Computer Architecture and Implementation*, Cambridge: Cambridge University Press, 2000
- Stallings, W. *Computer Organization and Architecture*, Upper Saddle River, NJ: Prentice-Hall, 2002

### 5.9.2 Key terms
- address bus
- address space
- arithmetic logic unit (ALU)
- bus
- cache memory
- central processing unit (CPU)
- compact disk (CD)
- compact disk read-only memory (CD-ROM)
- compact disk recordable (CD-R)
- complex instruction set computer (CISC)
- control bus
- controller
- control unit
- data bus
- decode
- digital versatile disk (DVD)
- direct memory access (DMA)
- dynamic RAM (DRAM)
- electrically erasable programmable read-only memory (EEPROM)
- erasable programmable read-only memory (EPROM)
- execute
- fetch
- FireWire
- HDMI (High-Definition Multimedia Interface)
- hub
- input/output controller
- input/output subsystem
- instruction register
- interrupt-driven I/O
- intersector gap
- intertrack gap
- isolated I/O
- land
- machine cycle
- programmable read-only memory (PROM)
- magnetic disk
- magnetic tape
- main memory
- master disk
- memory mapped I/O
- monitor
- multiple instruction-stream, multiple data stream (MIMD)
- multiple instruction-stream, single data stream (MISD)
- nonstorage device
- optical storage device
- output device
- parallel processing
- pipelining
- pit
- polycarbonate resin
- printer
- program counter
- programmed I/O
- random access memory (RAM)
- read-only memory (ROM)
- read/write head
- reduced instruction set computer (RISC)
- register
- rotational speed
- sector
- seek time
- single instruction-stream, multiple data stream (SIMD)
- static RAM (SRAM)
- storage device
- throughput
- topology
- track
- transfer time
- Universal Serial Bus (USB)
- write once, read many (WORM)

### 5.9.3 Summary
- The parts that make up a computer can be divided into three broad categories or subsystems: the central processing unit (CPU), the main memory, and the input/output subsystem.
- The central processing unit (CPU) performs operations on data. It has three parts: an arithmetic logic unit (ALU), a control unit, and a set of registers. The arithmetic logic unit (ALU) performs logic, shift, and arithmetic operations on data. Registers are fast stand-alone storage locations that hold data temporarily. The control unit controls the operation of each part of the CPU.
- Main memory is a collection of storage locations, each with a unique identifier called the address. Data is transferred to and from memory in groups of bits called words. The total number of uniquely identifiable locations in memory is called the address space. Two types of memory are available: random access memory (RAM) and read-only memory (ROM).
- The collection of devices referred to as the input/output (I/O) subsystem allows a computer to communicate with the outside world and to store programs and data even when the power is off. Input/output devices can be divided into two broad categories: nonstorage and storage devices. Nonstorage devices allow the CPU/memory to communicate with the outside world. Storage devices can store large amounts of information to be retrieved at a later time. Storage devices are categorized as either magnetic or optical.
- The interconnection of the three subsystems of a computer plays an important role, because information needs to be exchanged between these subsystems. The CPU and memory are normally connected by three groups of connections, each called a bus: data bus, address bus, and control bus. Input/output devices are attached to the buses through an input/output controller or interface. Several kinds of controllers are in use. The most common ones today are SCSI, FireWire, and USB.
- There are two methods of handling the addressing of I/O devices: isolated I/O and memory-mapped I/O. In the isolated I/O method, the instructions used to read/write to and from memory are different from the instructions used to read/write to and from input/output devices. In the memory-mapped I/O method, the CPU treats each register in the I/O controller as a word in memory.
- Today, general-purpose computers use a set of instructions called a program to process data. A computer executes the program to create output data from input data. Both the program and the data are stored in memory. The CPU uses repeating machine cycles to execute instructions in the program, one by one, from beginning to end. A simplified cycle can consist of three phases: fetch, decode, and execute.
- Three methods have been devised for synchronization between I/O devices and the CPU: programmed I/O, interrupt-driven I/O, and direct memory access (DMA).
- The architecture and organization of computers have gone through many changes during recent decades. We can divide computer architecture into two broad categories: CISC (complex instruction set computers) and RISC (reduced instruction set computers).
- Modern computers use a technique called pipelining to improve their throughput. The idea is to allow the control unit to perform two or three phases simultaneously, which means that processing of the next instruction can start before the previous one is finished.
- Traditionally, a computer had a single control unit, a single arithmetic logic unit, and a single memory unit. Parallel processing can improve throughput by using multiple instruction streams to handle multiple data streams.
`,zh:`
# 第五章：電腦組織

在本章中，我們討論獨立電腦的組織。我們解釋每台電腦如何由三個子系統組成。我們也展示了一台簡單的、假設的電腦如何運行簡單的程式來執行原始的算術或邏輯運算。

## 學習目標
學完本章後，學生應能：
- 列出電腦的三個子系統。
- 描述中央處理單元 (CPU) 在電腦中的角色。
- 描述典型電腦週期中的提取-解碼-執行階段。
- 描述主記憶體及其位址空間。
- 區分主記憶體和快取記憶體。
- 定義輸入/輸出子系統。
- 了解子系統的互連並列出不同的匯流排系統。
- 描述輸入/輸出定址的不同方法。
- 區分電腦架構設計中的兩大趨勢。
- 了解如何使用管線化提高電腦吞吐量。
- 了解平行處理如何提高電腦的吞吐量。

## 5.1 簡介
我們可以將組成電腦的各個部分分為三大類或子系統：**中央處理單元 (CPU)**、**主記憶體**和**輸入/輸出子系統**。接下來的三節將討論這些子系統以及它們如何連接以構成一台獨立電腦。圖 5.1 顯示了獨立電腦的三個子系統。

## 5.2 中央處理單元
**中央處理單元 (CPU)** 對資料執行操作。在大多數架構中，它由三個部分組成：**算術邏輯單元 (ALU)**、**控制單元**和一組**暫存器**（圖 5.2）。

### 5.2.1 算術邏輯單元 (ALU)
**算術邏輯單元 (ALU)** 對資料執行邏輯、移位和算術運算。

**邏輯運算**
我們在第四章討論了幾種邏輯運算，例如 NOT、AND、OR 和 XOR。這些運算將輸入資料視為位元模式，運算結果也是位元模式。

**移位運算**
我們在第四章討論了兩組資料移位運算：邏輯移位運算和算術移位運算。邏輯移位運算用於將位元模式向左或向右移動，而算術運算應用於整數。它們的主要目的是將整數除以二或乘以二。

**算術運算**
我們在第四章討論了一些整數和實數的算術運算。我們提到有些運算可以在硬體中更有效地實現。

### 5.2.2 暫存器
**暫存器**是快速的獨立儲存位置，用於暫時保存資料。需要多個暫存器來促進 CPU 的運作。圖 5.2 中顯示了其中一些暫存器。

**資料暫存器**
過去的電腦只有少數幾個資料暫存器來保存輸入資料和運算結果。如今，電腦在 CPU 內部使用數十個暫存器來加速運算，因為複雜的運算是使用硬體而不是軟體完成的。這需要幾個暫存器來保存中間結果。圖 5.2 中的資料暫存器命名為 $R_0$ 到 $R_n$。

**指令暫存器**
今天的電腦不僅將資料儲存在記憶體中，還將程式儲存在記憶體中。CPU 負責從記憶體中逐一提取指令，將其儲存在**指令暫存器 (IR)**（圖 5.2 中）中，進行解碼並執行。我們將在本章稍後討論這個問題。

**程式計數器**
CPU 中的另一個常見暫存器是**程式計數器 (PC)**（圖 5.2 中）。程式計數器追蹤當前正在執行的指令。執行完指令後，計數器遞增以指向記憶體中下一條指令的位址。

### 5.2.3 控制單元
任何 CPU 的第三部分都是控制單元。**控制單元**控制每個子系統的操作。控制是透過從控制單元發送到其他子系統的信號來實現的。

## 5.3 主記憶體
**主記憶體**是電腦中的第二大子系統（圖 5.3）。它由一組儲存位置組成，每個位置都有一個唯一的標識符，稱為**位址**。資料以稱為**字 (word)** 的位元組為單位傳輸到記憶體和從記憶體傳輸出來。一個字可以是 8 位元、16 位元、32 位元或 64 位元（且還在增長）。如果字是 8 位元，則稱為**位元組 (byte)**。「位元組」一詞在電腦科學中非常常見，有時 16 位元的字被稱為 2 位元組字，或 32 位元的字被稱為 4 位元組字。

### 5.3.1 位址空間
要存取記憶體中的字，需要一個標識符。雖然程式設計師使用名稱來標識字（或一組字），但在硬體層級，每個字都由位址標識。記憶體中唯一可識別位置的總數稱為**位址空間**。例如，具有 64 KB 和字長為 1 位元組的記憶體，其位址空間範圍從 0 到 65535。

表 5.1 顯示了用於指稱記憶體的單位。請注意，術語具有誤導性：它以 10 的冪次近似位元組數，但實際的位元組數是 2 的冪次。2 的冪次單位便於定址。

**表 5.1 記憶體單位**

| 單位 | 精確位元組數 | 近似值 |
| :--- | :--- | :--- |
| kilobyte (KB) | $2^{10}$ (1024) bytes | $10^3$ bytes |
| megabyte (MB) | $2^{20}$ (1048576) bytes | $10^6$ bytes |
| gigabyte (GB) | $2^{30}$ (1073741824) bytes | $10^9$ bytes |
| terabyte (TB) | $2^{40}$ bytes | $10^{12}$ bytes |

**位址作為位元模式**
因為電腦透過將數字儲存為位元模式來運作，所以記憶體位址也表示為位元模式。因此，如果一台電腦有 64 KB ($2^{16}$) 的記憶體，字長為 1 位元組，我們就需要一個 16 位元的位元模式來定義位址。回想第 3 章，位址可以表示為無符號整數（我們沒有負位址）。換句話說，第一個位置稱為位址 0000000000000000（位址 0），最後一個位置稱為位址 1111111111111111（位址 65535）。一般來說，如果一台電腦有 $N$ 個字的記憶體，我們需要一個大小為 $\\log_2 N$ 位元的無符號整數來引用每個記憶體位置。

**記憶體位址使用無符號二進位整數定義。**

> **範例 5.1**
> 一台電腦有 32 MB (百萬位元組) 的記憶體。需要多少位元來定址記憶體中的任何單一位元組？
>
> **解答**
> 記憶體位址空間為 32 MB，即 $2^{25}$ ($2^5 \\times 2^{20}$)。這意味著我們需要 $\\log_2 2^{25}$，即 25 位元，來定址每個位元組。

> **範例 5.2**
> 一台電腦有 128 MB 的記憶體。這台電腦中的每個字是八個位元組。需要多少位元來定址記憶體中的任何單一字？
>
> **解答**
> 記憶體位址空間為 128 MB，即 $2^{27}$。然而，每個字是八 ($2^3$) 個位元組，這意味著我們有 $2^{24}$ 個字。這意味著我們需要 $\\log_2 2^{24}$，即 24 位元，來定址每個字。

### 5.3.2 記憶體類型
存在兩種主要的記憶體類型：RAM 和 ROM。

**RAM**
**隨機存取記憶體 (RAM)** 構成了電腦中大部分的主記憶體。在隨機存取設備中，可以隨機存取資料項目——使用記憶體位置的位址——而無需存取位於其之前的所有資料項目。然而，這個術語令人困惑，因為 ROM 也可以隨機存取。區分 RAM 和 ROM 的是 RAM 可以讀取和寫入。CPU 可以將某些內容寫入 RAM，稍後再覆寫它。RAM 的另一個特性是它是**揮發性的**：如果電腦斷電，資訊（程式或資料）將會遺失。換句話說，如果你關閉電腦或停電，RAM 中的所有資訊都會被刪除。RAM 技術分為兩大類：SRAM 和 DRAM。

**SRAM**
**靜態 RAM (SRAM)** 技術使用傳統的正反器閘（參見附錄 E）來保存資料。閘保持其狀態（0 或 1），這意味著只要電源開啟，資料就會被儲存，無需刷新記憶體位置。SRAM 速度快但價格昂貴。

**DRAM**
**動態 RAM (DRAM)** 技術使用電容器（一種可以儲存能量的電子元件）來儲存資料。如果電容器充電，狀態為 1；如果放電，狀態為 0。因為電容器會隨時間失去部分電荷，DRAM 記憶體單元需要定期刷新。DRAM 速度慢但價格便宜。

**ROM**
**唯讀記憶體 (ROM)** 的內容由製造商寫入，CPU 可以從 ROM 讀取，但不能寫入。它的優點是它是**非揮發性的**——如果你關閉電腦，其內容不會遺失。通常，它用於儲存即使關閉電腦也不能刪除或更改的程式或資料。例如，有些電腦配備了 ROM，其中包含當我們開啟電腦時運行的啟動程式。

**PROM**
ROM 的一種變體是**可程式化唯讀記憶體 (PROM)**。這種記憶體在電腦出廠時是空白的。電腦使用者可以使用一些特殊設備將程式儲存在其中。當程式被儲存後，它的行為就像 ROM 一樣，不能被覆寫。這允許電腦使用者將特定程式儲存在 PROM 中。

**EPROM**
PROM 的一種變體是**可抹除可程式化唯讀記憶體 (EPROM)**。它可以由使用者編程，也可以用施加紫外線的特殊設備擦除。擦除 EPROM 記憶體需要物理移除並重新安裝 EPROM。

**EEPROM**
EPROM 的一種變體是**電子可抹除可程式化唯讀記憶體 (EEPROM)**。EEPROM 可以使用電子脈衝進行編程和擦除，而無需從電腦中移除。

### 5.3.3 記憶體階層
電腦使用者需要大量的記憶體，尤其是非常快速且便宜的記憶體。這種需求並不總是能夠滿足——非常快速的記憶體通常不便宜。需要做出妥協。解決方案是記憶體的階層級別（圖 5.4）。該階層基於以下幾點：
- 在速度至關重要的地方使用極少量的昂貴高速記憶體。CPU 內部的暫存器屬於此類型。
- 使用適量的中速記憶體來儲存經常存取的資料。接下來討論的快取記憶體屬於此類型。
- 使用大量的低速記憶體來儲存較少存取的資料。主記憶體屬於此類型。

### 5.3.4 快取記憶體
**快取記憶體**比主記憶體快，但比 CPU 及其暫存器慢。快取記憶體通常容量較小，放置在 CPU 和主記憶體之間（圖 5.5）。

快取記憶體在任何時候都包含主記憶體一部分的副本。當 CPU 需要存取主記憶體中的一個字時，它遵循以下程序：
1.  CPU 檢查快取。
2.  如果該字在那裡，它複製該字；如果不在，CPU 存取主記憶體並複製從所需字開始的一塊記憶體。該區塊替換快取記憶體先前的內容。
3.  CPU 存取快取並複製該字。

這個程序可以加快操作速度；如果字在快取中，則立即存取。如果字不在快取中，則將該字和整個區塊複製到快取中。由於 CPU 在下一個週期中很可能需要存取第一個字後面的字，因此快取記憶體的存在加快了處理速度。

我們可能會想，為什麼快取記憶體儘管容量小卻如此有效率。答案在於「80-20 法則」。據觀察，大多數電腦通常花費 80% 的時間存取僅 20% 的資料。換句話說，相同的資料被反覆存取。快取記憶體憑藉其高速度，可以保存這 20% 的資料，使存取速度在至少 80% 的時間內變快。

## 5.4 輸入/輸出子系統
電腦中的第三大子系統是稱為**輸入/輸出 (I/O) 子系統**的設備集合。此子系統允許電腦與外部世界通訊，即使在電源關閉時也能儲存程式和資料。輸入/輸出設備可分為兩大類：非儲存設備和儲存設備。

### 5.4.1 非儲存設備
**非儲存設備**允許 CPU/記憶體與外部世界通訊，但它們不能儲存資訊。

**鍵盤和螢幕**
兩種較常見的非儲存輸入/輸出設備是**鍵盤**和**螢幕**。鍵盤提供輸入，螢幕顯示輸出，同時回顯在鍵盤上輸入的內容。程式、命令和資料使用字元串輸入或輸出。字元使用諸如 ASCII 之類的代碼進行編碼（參見附錄 A）。屬於此類別的其他設備包括滑鼠、搖桿等。

**印表機**
**印表機**是一種產生永久記錄的**輸出設備**。印表機是非儲存設備，因為列印出來的材料無法直接再次輸入電腦，除非有人重新輸入或掃描它。

### 5.4.2 儲存設備
**儲存設備**雖然被歸類為 I/O 設備，但可以儲存大量資訊以供日後檢索。它們比主記憶體便宜，而且其內容是非揮發性的——也就是說，當電源關閉時不會被刪除。它們有時被稱為**輔助儲存設備**。我們可以將它們分類為磁性或光學設備。

**磁性儲存設備**
磁性儲存設備使用磁化來儲存資料位元。如果一個位置被磁化，它代表 1，如果沒有被磁化，它代表 0。

**磁碟**
**磁碟**由一個或多個堆疊在一起的磁盤組成。磁盤塗有一層薄薄的磁性膜。使用每個磁化表面的**讀/寫頭**在磁盤表面儲存和檢索資訊。圖 5.6 顯示了磁碟機的實體佈局和磁碟的組織。
- **表面組織。** 為了組織儲存在磁碟上的資料，每個表面被劃分為**磁軌 (tracks)**，每個磁軌被劃分為**磁區 (sectors)**（圖 5.6）。磁軌由**磁軌間隙**分隔，磁區由**磁區間隙**分隔。
- **資料存取。** 磁碟被認為是隨機存取設備。在隨機存取設備中，可以隨機存取資料項目，而無需存取位於其之前的所有其他資料項目。然而，一次可以存取的最小儲存區域是一個磁區。一塊資料可以儲存在一個或多個磁區中並被檢索，而無需檢索磁碟上的其餘資訊。
- **效能。** 磁碟的效能取決於幾個因素，最重要的是轉速、搜尋時間和傳輸時間。**轉速**定義了磁碟旋轉的速度。**搜尋時間**定義了將讀/寫頭移動到儲存資料的所需磁軌的時間。**傳輸時間**定義了將資料從磁碟移動到 CPU/記憶體的時間。

**磁帶**
**磁帶**有各種尺寸。一種常見的類型是塗有厚磁性膜的半英吋塑膠帶。磁帶安裝在兩個捲軸上，並使用讀/寫頭在磁帶通過時讀取或寫入資訊。圖 5.7 顯示了磁帶機的機械配置。
- **表面組織。** 磁帶的寬度分為九個軌道，每個軌道上的一個位置儲存 1 位元資訊。九個垂直位置可以儲存與一個位元組相關的 8 位元資訊加上一個用於錯誤檢測的位元（圖 5.7）。
- **資料存取。** 磁帶被認為是循序存取設備。雖然表面可以分為區塊，但沒有定址機制來存取每個區塊。要檢索磁帶上的特定區塊，我們需要通過所有先前的區塊。
- **效能。** 雖然磁帶比磁碟慢，但它更便宜。今天，人們使用磁帶備份大量資料。

**光學儲存設備**
**光學儲存設備**是一種相對較新的技術，使用雷射光來儲存和檢索資料。光學儲存技術的使用緊隨用於儲存音訊資訊的**光碟 (CD)** 的發明之後。今天，同樣的技術——稍加改進——用於在電腦中儲存資訊。使用這種技術的設備包括 CD-ROM、CD-R、CD-RW 和 DVD。

**CD-ROM**
**唯讀光碟 (CD-ROM)** 使用與最初由飛利浦和索尼開發用於錄製音樂的音訊 CD 相同的技術。這兩種技術之間的唯一區別是增強：CD-ROM 驅動器更強大並檢查錯誤。圖 5.8 顯示了創建和使用 CD-ROM 所涉及的步驟。
- **創建。** CD-ROM 技術使用三個步驟來創建大量光碟：
  a. 使用高功率紅外雷射在塗層塑膠上創建位元模式來製作**母片 (master disk)**。雷射將位元模式轉換為一系列**凹坑 (pits)**（孔）和**平台 (lands)**（無孔）。凹坑通常代表 0，平台通常代表 1。然而，這只是一個慣例，它可以反過來。其他方案使用過渡（從凹坑到平台或從平台到凹坑）來代表 1，並且沒有過渡來代表 0。
  b. 從母片製作模具。在模具中，凹坑（孔）被凸起取代。
  c. 將熔融的**聚碳酸酯樹脂**注入模具中，以產生與母片相同的凹坑。在聚碳酸酯上添加一層非常薄的鋁以提供反射表面。在此之上，塗上一層保護漆並添加標籤。只有這最後一步需要對每張光碟重複進行。
- **讀取。** 使用低功率雷射束讀取 CD-ROM。當光束通過平台時，會被鋁表面反射。當它遇到凹坑時，會被反射兩次，一次由凹坑邊界反射，一次由鋁邊界反射。這兩次反射具有破壞性效果，因為選擇的凹坑深度正好是光束波長的四分之一。換句話說，安裝在驅動器中的感測器在位置是平台時檢測到更多的光，而在位置是凹坑時檢測到更少的光，因此可以讀取記錄在原始母片上並複製到 CD-ROM 的內容。
- **格式。** CD-ROM 技術使用與磁碟不同的格式（圖 5.9）。CD-ROM 上的資料格式基於：
  a. 一個 8 位元資料區塊使用稱為漢明碼的錯誤更正方法轉換為 14 位元符號。
  b. 由 42 個符號（14 位元/符號）組成的訊框。
  c. 由 98 個訊框（2352 位元組）組成的磁區。
- **速度。** CD-ROM 驅動器有不同的速度。單速稱為 1x，雙速稱為 2x，依此類推。如果驅動器是單速，它每秒最多可以讀取 153,600 位元組。表 5.2 顯示了速度及其對應的資料速率。

**表 5.2 CD-ROM 速度**
| 速度 | 資料速率 | 近似值 |
|---|---|---|
| 1x | 每秒 153600 位元組 | 150 KB/s |
| 2x | 每秒 307200 位元組 | 300 KB/s |
| 4x | 每秒 614400 位元組 | 600 KB/s |
| 6x | 每秒 921600 位元組 | 900 KB/s |
| 8x | 每秒 1228800 位元組 | 1.2 MB/s |
| 12x | 每秒 1843200 位元組 | 1.8 MB/s |
| 16x | 每秒 2457600 位元組 | 2.4 MB/s |
| 24x | 每秒 3688400 位元組 | 3.6 MB/s |
| 32x | 每秒 4915200 位元組 | 4.8 MB/s |
| 40x | 每秒 6144000 位元組 | 6 MB/s |

- **應用。** 如果有大量潛在客戶，那麼創建母片、模具和實際光碟所涉及的費用是合理的。換句話說，如果光碟是大規模生產的，這項技術就是經濟的。

**CD-R**
顯然，只有當製造商能夠創建大量光碟時，CD-ROM 技術才是合理的。另一方面，**可錄式光碟 (CD-R)** 格式允許使用者創建一張或多張光碟，而無需經歷創建 CD-ROM 所涉及的費用。它特別適用於製作備份。您可以寫入 CD-R 光碟一次，但可以讀取多次。這就是為什麼該格式有時被稱為**一次寫入，多次讀取 (WORM)**。
- **創建。** CD-R 技術使用與 CD-ROM 相同的原理來創建光碟（圖 5.10）。以下列出了差異：
  a. 沒有母片或模具。
  b. 反射層由金而不是鋁製成。
  c. 聚碳酸酯中沒有物理凹坑（孔）：凹坑和平台只是模擬的。為了模擬凹坑和平台，在反射層和聚碳酸酯之間添加了一層額外的染料，類似於攝影中使用的材料。
  d. 由驅動器的 CD 燒錄器產生的高功率雷射束在染料中產生黑點，改變其化學成分，從而模擬凹坑。未被光束擊中的區域成為平台。
- **讀取。** CD-R 可以由 CD-ROM 或 CD-R 驅動器讀取。這意味著任何差異對驅動器來說都應該是透明的。相同的低功率雷射束通過模擬的凹坑和平台前方。對於平台，光束到達反射層並被反射。對於模擬凹坑，斑點是不透明的，因此光束無法反射回來。
- **格式和速度。** CD-R 的格式、容量和速度與 CD-ROM 相同。
- **應用。** 這項技術對於創建和分發少量光碟非常有吸引力。它對於製作存檔文件和備份也非常有用。

**CD-RW**
雖然 CD-R 已經非常流行，但它們只能寫入一次。為了覆寫先前的材料，新技術允許一種新型光碟，稱為**可重寫光碟 (CD-RW)**。它有時被稱為*可擦除光碟*。
- **創建。** CD-RW 技術使用與 CD-R 相同的原理來創建光碟（圖 5.11）。以下列出了差異：
  a. 該技術不使用染料，而是使用銀、銦、銻和碲的合金。這種合金有兩種穩定狀態：結晶（透明）和非晶（不透明）。
  b. 驅動器使用高功率雷射在合金中創建模擬凹坑（將其從結晶變為非晶）。
- **讀取。** 驅動器使用與 CD-ROM 和 CD-R 相同類型的低功率雷射束來檢測凹坑和平台。
- **擦除。** 驅動器使用中等功率的雷射束將凹坑變為平台。光束將位置從非晶狀態變為結晶狀態。
- **格式和速度。** CD-RW 的格式、容量和速度與 CD-ROM 相同。
- **應用。** 該技術無疑比 CD-R 技術更具吸引力。然而，CD-R 更受歡迎有兩個原因。首先，空白 CD-R 光碟比空白 CD-RW 光碟便宜。其次，在絕不能更改（無論是意外還是故意）已創建光碟的情況下，CD-R 更可取。

**DVD**
業界感到需要具有更高容量的數位儲存媒體。CD-ROM (650 MB) 的容量不足以儲存視訊資訊。市場上最新的光學記憶體儲存設備稱為**數位多功能光碟 (DVD)**。它使用類似於 CD-ROM 的技術，但有以下區別：
a. 凹坑更小：直徑為 0.4 微米，而不是 CD 中使用的 0.8 微米。
b. 磁軌彼此更靠近。
c. 光束是紅色雷射而不是紅外線。
d. DVD 使用一到兩個記錄層，可以是單面或雙面。
- **容量。** 這些改進導致更高的容量（表 5.3）。

**表 5.3 DVD 容量**
| 特徵 | 容量 |
|---|---|
| 單面，單層 | 4.7 GB |
| 單面，雙層 | 8.5 GB |
| 雙面，單層 | 9.4 GB |
| 雙面，雙層 | 17 GB |

- **壓縮。** DVD 技術使用 MPEG（參見第 15 章）進行壓縮。這意味著單面單層 DVD 可以容納 133 分鐘的高解析度視訊。這也包括音訊和字幕。
- **應用。** 今天，DVD 的高容量吸引了許多需要儲存大量資料的應用程式。

## 5.5 子系統互連
前面的章節概述了獨立電腦中三個子系統（CPU、主記憶體和 I/O）的特徵。在本節中，我們探討這三個子系統是如何互連的。互連扮演著重要的角色，因為資訊需要在這三個子系統之間交換。

### 5.5.1 連接 CPU 和記憶體
CPU 和記憶體通常由三組連接連接，每組稱為**匯流排 (bus)**：資料匯流排、位址匯流排和控制匯流排（圖 5.12）。

**資料匯流排**
**資料匯流排**由數個連接組成，每個連接一次傳輸 1 位元。連接數取決於電腦使用的字長。如果字是 32 位元（4 位元組），我們需要一條有 32 個連接的資料匯流排，以便可以同時傳輸一個字的所有 32 位元。

**位址匯流排**
**位址匯流排**允許存取記憶體中的特定字。位址匯流排中的連接數取決於記憶體的位址空間。如果記憶體有 $2^n$ 個字，位址匯流排需要一次攜帶 $n$ 位元。因此，它必須有 $n$ 個連接。

**控制匯流排**
**控制匯流排**傳遞 CPU 和記憶體之間的通訊。例如，必須有一個從 CPU 發送到記憶體的代碼，以指定讀取或寫入操作。控制匯流排中使用的連接數取決於電腦所需的控制命令總數。如果一台電腦有 $2^m$ 個控制動作，我們需要 $m$ 個連接用於控制匯流排，因為 $m$ 位元可以定義 $2^m$ 種不同的操作。

### 5.5.2 連接 I/O 設備
I/O 設備不能直接連接到連接 CPU 和記憶體的匯流排，因為 I/O 設備的性質與 CPU 和記憶體的性質不同。I/O 設備是機電、磁性或光學設備，而 CPU 和記憶體是電子設備。I/O 設備的運作速度也比 CPU/記憶體慢得多。需要某種中介來處理這種差異。因此，輸入/輸出設備透過**輸入/輸出控制器**或**介面**連接到匯流排。每個輸入/輸出設備都有一個特定的**控制器**（圖 5.13）。

**控制器**
控制器或介面橋接了 I/O 設備與 CPU 和記憶體之間性質的差距。控制器可以是串列或並列設備。串列控制器只有一條資料線，而並列控制器有數條資料連接，以便可以一次傳輸數個位元。
使用了幾種控制器。今天最常見的是 SCSI、FireWire、USB 和 HDMI。

**SCSI**
**小型電腦系統介面 (SCSI)** 最初於 1984 年為麥金塔電腦開發。今天它用於許多系統。它具有 8、16 或 32 個連接的並列介面。SCSI 介面提供菊花鏈連接，如圖 5.14 所示。鏈的兩端必須連接到稱為*終端器*的特殊設備，每個設備必須具有唯一的位址（目標 ID）。

**FireWire**
IEEE 標準 1394 定義了一種通常稱為 **FireWire (火線)** 的串列介面。它是一種高速串列介面，以封包形式傳輸資料，傳輸速率高達 50 MB/sec，最新版本則加倍。它可用於在菊花鏈或樹狀連接（僅使用一個連接）中連接多達 63 個設備。圖 5.15 顯示了輸入/輸出設備到 FireWire 控制器的連接。不需要像 SCSI 那樣的終端器。

**USB**
**通用序列匯流排 (USB)** 是 FireWire 的競爭對手。雖然命名法使用術語*匯流排*，但 USB 是一個串列控制器，將低速和高速設備連接到電腦匯流排。圖 5.16 顯示了 USB 控制器到匯流排的連接以及設備到控制器的連接。

多個設備可以連接到 USB 控制器，該控制器也被稱為*根集線器 (root hub)*。USB-2（USB 2.0 版）允許使用樹狀**拓撲**將多達 127 個設備連接到 USB 控制器，控制器作為樹的根，**集線器 (hubs)** 作為中間節點，設備作為末端節點。控制器（根集線器）與其他集線器的區別在於，控制器知道樹中存在其他集線器，而其他集線器只是簡單傳遞資料的被動設備。
設備可以輕鬆地從樹中移除或連接，而無需關閉電腦電源。這稱為*熱插拔*。當從系統中移除集線器時，與其連接的所有設備和其他集線器也會被移除。
USB 使用四根電線的電纜。兩根電線（+5 伏特和接地）用於為鍵盤或滑鼠等低功率設備提供電源。高功率設備需要連接到電源。集線器從匯流排獲取電力，並可以為低功率設備提供電力。另外兩根電線（絞合在一起以減少雜訊）用於攜帶資料、位址和控制信號。USB 使用兩種不同的連接器：A 和 B。A 連接器（下游連接器）是矩形的，用於連接到 USB 控制器或集線器。B 連接器（上游連接器）接近正方形，用於連接到設備。最近推出了兩種新的連接器，mini A 和 mini B，用於連接小型設備和筆記型電腦。
USB-2 提供三種資料傳輸速率：1.5 Mbps（百萬位元每秒）、12 Mbps 和 480 Mbps。低資料速率可用於鍵盤和滑鼠等慢速設備，中等資料速率用於印表機，高資料速率用於大容量儲存設備。

資料透過 USB 以封包形式傳輸（參見第 6 章）。每個封包包含位址部分（設備標識符）、控制部分和要傳輸到該設備的部分資料。所有設備都會收到相同的封包，但只有封包中定義了位址的那些設備才會接受它。
USB 3.0 是通用序列匯流排 (USB) 標準的另一個修訂版，用於電腦連接。USB 3.0 增加了一種稱為 *SuperSpeed* 的新傳輸模式，能夠以高達 4.8 Gbit/s 的速度傳輸資料。承諾將 USB 3.0 更新至 10 Gbit/s。

**HDMI**
**HDMI (高畫質多媒體介面)** 是現有類比視訊標準的數位替代品。它可用於將視訊資料、數位音訊資料從來源傳輸到相容的電腦顯示器、視訊投影機、數位電視或數位音訊設備。有許多可用的 HDMI 標準電纜，包括標準、增強、高畫質和 3D 視訊信號；多達八個通道的壓縮或未壓縮數位音訊；CEC (消費電子控制) 連接；以及乙太網路資料連接。

### 5.5.3 定址輸入/輸出設備
CPU 通常使用相同的匯流排從主記憶體和 I/O 設備讀取資料或向其寫入資料。唯一的區別在於指令。如果指令引用主記憶體中的字，則資料傳輸發生在主記憶體和 CPU 之間。如果指令標識 I/O 設備，則資料傳輸發生在 I/O 設備和 CPU 之間。有兩種處理 I/O 設備定址的方法：獨立 I/O 和記憶體映射 I/O。

**獨立 I/O**
在**獨立 I/O** 方法中，用於讀/寫記憶體的指令與用於讀/寫 I/O 設備的指令完全不同。有指令用於測試、控制、讀取和寫入 I/O 設備。每個 I/O 設備都有自己的位址。I/O 位址可以與記憶體位址重疊而不會產生任何歧義，因為指令本身是不同的。例如，CPU 可以使用命令「Read 101」從記憶體字 101 讀取，並使用命令「Input 101」從 I/O 設備 101 讀取。不會混淆，因為讀取命令用於從記憶體讀取，輸入命令用於從 I/O 設備讀取（圖 5.17）。

**記憶體映射 I/O**
在**記憶體映射 I/O** 方法中，CPU 將 I/O 控制器中的每個暫存器視為記憶體中的一個字。換句話說，CPU 沒有單獨的指令來從記憶體和 I/O 設備傳輸資料。例如，只有一個「Read」指令。如果位址定義了記憶體中的字，則從該字讀取資料。如果位址定義了 I/O 設備中的暫存器，則從該暫存器讀取資料。記憶體映射配置的優點是指令數量較少：所有記憶體指令都可用於 I/O 設備。缺點是部分記憶體位址空間被分配給 I/O 控制器中的暫存器。例如，如果我們有五個 I/O 控制器，每個有四個暫存器，則 20 個位址用於此目的。記憶體的大小減少了 20 個字。圖 5.18 顯示了記憶體映射 I/O 的概念。

## 5.6 程式執行
今天，通用電腦使用一組稱為*程式*的指令來處理資料。電腦執行程式以從輸入資料產生輸出資料。程式和資料都儲存在記憶體中。

**在本章末尾，我們給出了一些關於假設的簡單電腦如何執行程式的範例。**

### 5.6.1 機器週期
CPU 使用重複的**機器週期**來執行程式中的指令，從頭到尾逐一執行。一個簡化的週期可以由三個階段組成：**提取**、**解碼**和**執行**（圖 5.19）。

**提取**
在**提取**階段，控制單元命令系統將下一個指令複製到 CPU 中的指令暫存器中。要複製的指令位址保存在程式計數器暫存器中。複製後，程式計數器遞增以引用記憶體中的下一個指令。

**解碼**
週期中的第二個階段是**解碼**階段。當指令在指令暫存器中時，它由控制單元解碼。此解碼步驟的結果是系統將執行的某個操作的二進位代碼。

**執行**
指令解碼後，控制單元將任務命令發送到 CPU 中的組件。例如，控制單元可以告訴系統從記憶體載入（讀取）資料項目，或者 CPU 可以告訴 ALU 將兩個輸入暫存器的內容相加並將結果放入輸出暫存器。這是**執行**階段。

### 5.6.2 輸入/輸出操作
需要命令將資料從 I/O 設備傳輸到 CPU 和記憶體。由於 I/O 設備的運作速度比 CPU 慢得多，因此 CPU 的操作必須以某種方式與 I/O 設備同步。已經設計了三種用於此同步的方法：程式控制 I/O、中斷驅動 I/O 和直接記憶體存取 (DMA)。

**程式控制 I/O**
在**程式控制 I/O** 方法中，同步非常原始：CPU 等待 I/O 設備（圖 5.20）。

I/O 設備和 CPU 之間的資料傳輸由程式中的指令完成。當 CPU 遇到 I/O 指令時，在資料傳輸完成之前它不會做任何其他事情。CPU 不斷檢查 I/O 設備的狀態：如果設備準備好傳輸，則將資料傳輸到 CPU。如果設備未準備好，CPU 繼續檢查設備狀態，直到 I/O 設備準備好。這裡的大問題是 CPU 時間浪費在為每個要傳輸的資料單元檢查 I/O 設備的狀態上。請注意，資料在輸入操作後傳輸到記憶體，而資料在輸出操作前從記憶體傳輸。

**中斷驅動 I/O**
在**中斷驅動 I/O** 方法中，CPU 通知 I/O 設備傳輸即將發生，但它不會持續測試 I/O 設備的狀態。I/O 設備在準備好時通知（中斷）CPU。在此期間，CPU 可以做其他工作，例如運行其他程式或將資料從其他 I/O 設備傳輸或傳輸到其他 I/O 設備（圖 5.21）。
在這種方法中，CPU 時間不會浪費——CPU 可以在慢速 I/O 設備完成任務時做其他事情。請注意，像程式控制 I/O 一樣，此方法也在設備和 CPU 之間傳輸資料。資料在輸入操作後傳輸到記憶體，而資料在輸出操作前從記憶體傳輸。

**直接記憶體存取 (DMA)**
用於傳輸資料的第三種方法是**直接記憶體存取 (DMA)**。這種方法在高速 I/O 設備（如磁碟）和記憶體之間直接傳輸大量資料區塊，而無需通過 CPU。這需要一個 DMA 控制器來減輕 CPU 的部分功能。DMA 控制器具有暫存器，用於在記憶體傳輸之前和之後保存資料區塊。圖 5.22 顯示了 DMA 與資料、位址和控制匯流排的連接。

使用此方法進行 I/O 操作時，CPU 向 DMA 發送訊息。訊息包含傳輸類型（輸入或輸出）、記憶體位置的起始位址以及要傳輸的位元組數。然後 CPU 可用於其他工作（圖 5.23）。
準備好傳輸資料時，DMA 控制器通知 CPU 它需要控制匯流排。CPU 停止使用匯流排並讓控制器使用它們。在 DMA 和記憶體之間直接傳輸資料後，CPU 繼續其正常操作。請注意，在這種方法中，CPU 會閒置一段時間。然而，與其他方法相比，此閒置期間非常短——CPU 僅在 DMA 和記憶體之間的資料傳輸期間閒置，而在設備準備資料時不閒置。

## 5.7 不同的架構
最近幾十年，電腦的架構和組織經歷了許多變化。在本節中，我們討論一些與我們前面討論的簡單電腦架構不同的常見架構和組織。

### 5.7.1 CISC
CISC（發音為 *sisk*）代表**複雜指令集電腦 (CISC)**。CISC 架構背後的策略是擁有大量指令集，包括複雜指令。基於 CISC 的電腦編程比其他設計更容易，因為對於簡單和複雜的任務都有單一指令。因此，程式設計師不必編寫一組指令來完成複雜的任務。

指令集的複雜性使得 CPU 和控制單元的電路非常複雜。CISC 架構的設計者想出了解決方案來降低這種複雜性：編程在兩個層次上完成。機器語言中的指令不由 CPU 直接執行——CPU 僅執行簡單的操作，稱為*微操作*。複雜指令被轉換為一組這些簡單操作，然後由 CPU 執行。這需要添加稱為*微記憶體*的特殊記憶體，其中保存指令集中每個複雜指令的操作集。使用微操作的編程類型稱為*微編程*。
對 CISC 架構的一個反對意見是與微編程和存取微記憶體相關的開銷。然而，該架構的支持者認為這補償了機器層級較小的程式。CISC 架構的一個例子可以在 Intel 開發的 Pentium 系列處理器中看到。

### 5.7.2 RISC
RISC（發音為 *risk*）代表**精簡指令集電腦**。RISC 架構背後的策略是擁有一小組指令，這些指令執行最少數量的簡單操作。複雜指令使用簡單指令的子集來模擬。RISC 編程比其他設計更困難且更耗時，因為大多數複雜指令都是使用簡單指令模擬的。

### 5.7.3 管線化 (Pipelining)
我們已經了解到，電腦對每個指令使用三個階段：*提取*、*解碼*和*執行*。在早期的電腦中，每個指令的這三個階段需要串列完成。換句話說，指令 $n$ 需要在指令 $n + 1$ 開始其自己的階段之前完成所有這些階段。現代電腦使用一種稱為**管線化**的技術來提高**吞吐量**（在每個時間段內執行的指令總數）。這個想法是，如果控制單元可以同時執行這些階段中的兩個或三個，那麼下一個指令可以在前一個指令完成之前開始。
圖 5.24.a 顯示了在不使用管線化的電腦中如何處理三個連續指令。圖 5.24.b 顯示了管線化如何透過允許同時完成屬於不同指令的不同類型階段來增加電腦的吞吐量。換句話說，當 CPU 執行第一個指令的解碼階段時，它也可以執行第二個指令的提取階段。第一台電腦在特定時間段內平均可以執行 9 個階段，而管線化電腦在同一時間段內可以執行 24 個階段。如果我們假設每個階段使用相同的時間量，第一台電腦完成了 9/3 = 3 條指令，而第二台電腦完成了 24/3 = 8 條指令。因此，吞吐量增加了 8/3 或 266%。
當然，管線化並不像這樣簡單。存在一些問題，例如遇到跳轉指令時。在這種情況下，*管道*中的指令應該被丟棄。然而，新的 CPU 設計已經克服了大多數缺點。一些新的 CPU 設計甚至可以同時執行多個提取週期。

### 5.7.4 平行處理
傳統上，電腦只有一個控制單元、一個算術邏輯單元和一個記憶體單元。隨著技術的發展和電腦硬體成本的下降，今天我們可以擁有一台具有多個控制單元、多個算術邏輯單元和多個記憶體單元的電腦。這個想法被稱為*平行處理*。像管線化一樣，平行處理可以提高吞吐量。
**平行處理**涉及許多不同的技術。M. J. Flynn 提出的分類法給出了平行處理的一般視圖。這種分類法將電腦的組織（在處理資料方面）分為四類，如圖 5.25 所示。根據 Flynn 的說法，平行處理可能發生在資料流、指令流或兩者中。

**SISD 組織**
**單指令流、單資料流 (SISD)** 組織代表一台具有一個控制單元、一個算術邏輯單元和一個多重記憶體單元的電腦。指令循序執行，每個指令可以存取資料流中的一個或多個資料項目。我們在本章前面介紹的簡單電腦就是 SISD 組織的一個例子。圖 5.26 顯示了 SISD 組織的配置概念。

**SIMD 組織**
**單指令流、多資料流 (SIMD)** 組織代表一台具有一個控制單元、多個處理單元和多個記憶體單元的電腦。所有處理器單元從控制單元接收相同的指令，但對不同的資料項目進行操作。同時對資料陣列進行操作的陣列處理器屬於此類別。圖 5.27 顯示了 SIMD 組織的概念和實作。

**MISD 組織**
**多指令流、單資料流 (MISD)** 架構是一種屬於多個指令流的幾個指令同時在同一資料流上操作的架構。圖 5.28 顯示了這個概念，但從未實作過。

**MIMD 組織**
**多指令流、多資料流 (MIMD)** 架構是一種屬於多個指令流的幾個指令同時在多個資料流上操作（每個指令在一個資料流上）的架構。圖 5.29 顯示了概念和實作。MIMD 組織被一些專家認為是真正的平行處理架構。在這種架構中，可以同時執行多個任務。該架構可以使用單一共享記憶體或多個記憶體區段。

平行處理已發現一些應用，主要是在科學界，如果使用傳統電腦架構完成一項任務可能需要數小時或數天。這方面的一些例子可以在超大型矩陣的乘法、用於天氣預報的大量資料的同時處理或太空飛行模擬中找到。

## 5.8 一台簡單的電腦
為了解釋電腦的架構及其指令處理，我們介紹一台簡單的（不切實際的）電腦，如圖 5.30 所示。我們的簡單電腦有三個組件：CPU、記憶體和輸入/輸出子系統。

### 5.8.1 CPU
CPU 本身分為三個部分：資料暫存器、算術邏輯單元 (ALU) 和控制單元。

**資料暫存器**
有 16 個 16 位元資料暫存器，十六進位位址為 $(0, 1, 2, ..., F)_{16}$，但我們稱之為 $R_0$ 到 $R_{15}$。在大多數指令中，它們保存 16 位元資料，但在某些指令中，它們可能保存其他資訊。

**控制單元**
控制單元具有控制 ALU 操作、存取記憶體和存取 I/O 子系統的電路。此外，它有兩個專用暫存器：程式計數器和指令暫存器。程式計數器 (PC) 只能保存八個位元，它追蹤下一個要執行的指令。PC 的內容指向主記憶體中保存下一個程式指令的記憶體位置的位址。在每個機器週期之後，程式計數器加一以指向下一個程式指令。指令暫存器 (IR) 保存一個 16 位元值，這是當前週期的編碼指令。

### 5.8.2 主記憶體
主記憶體有 256 個 16 位元記憶體位置，二進位位址為 $(00000000 \\text{ 到 } 11111101)_2$ 或十六進位位址為 $(00 \\text{ 到 } FD)_{16}$。主記憶體同時保存資料和程式指令。前 64 個位置 $(00 \\text{ 到 } 3F)_{16}$ 專用於程式指令。任何程式的程式指令都儲存在連續的記憶體位置中。記憶體位置 $(40 \\text{ 到 } FD)_{16}$ 用於儲存資料。

### 5.8.3 輸入/輸出子系統
我們的簡單電腦有一個非常原始的輸入/輸出子系統。該子系統由鍵盤和螢幕組成。雖然我們在圖 5.30 中將鍵盤和螢幕顯示在單獨的方框中，但該子系統在位址方面是記憶體的一部分。這些設備具有記憶體映射位址，如本章前面所討論的。我們假設鍵盤（作為輸入設備）和螢幕（作為唯一的輸出設備）就像記憶體位置一樣，位址分別為 $(FE)_{16}$ 和 $(FF)_{16}$，如圖所示。換句話說，我們假設它們表現為 16 位元暫存器，像記憶體位置一樣與 CPU 互動。這兩個設備將資料從外部世界傳輸到 CPU，反之亦然。

### 5.8.4 指令集
我們的簡單電腦能夠擁有一組 16 個指令，儘管我們只使用其中的 14 個指令。每個電腦指令由兩部分組成：**操作碼 (opcode)** 和 **運算元 (operand(s))**。操作碼指定要對運算元執行的操作類型。每個指令由 16 位元組成，分為四個 4 位元欄位。最左邊的欄位包含操作碼，其他三個欄位包含運算元或運算元的位址，如圖 5.31 所示。

指令列在下表 5.4 中。請注意，並非每個指令都需要三個運算元。任何不需要的運算元欄位都填入 $(0)_{16}$。例如，停止指令的所有三個運算元欄位，以及移動和 NOT 指令的最後一個欄位，都填入 $(0)_{16}$。另請注意，暫存器位址由單個十六進位數字描述，因此使用單個欄位，但記憶體位置由兩個十六進位數字描述，使用兩個欄位。
有兩個加法指令：一個用於加整數 (ADDI)，一個用於加浮點數 (ADDF)。如果我們使用位址 $(FE)_{16}$ 作為 LOAD 指令的第二個運算元，簡單電腦可以從鍵盤獲取輸入。同樣，如果我們使用位址 $(FF)_{16}$ 作為 STORE 指令的第二個運算元，電腦將輸出發送到螢幕。如果 ROTATE 指令的第三個運算元是 0，則指令將 R 中的位元模式循環向右旋轉 $n$ 位：如果第三個運算元是 1，則向左旋轉。我們還包括了一個遞增 (INC) 和一個遞減 (DEC) 指令。

**表 5.4 簡單電腦的指令列表**
| 指令 | 代碼 $d_1$ | 運算元 $d_2, d_3, d_4$ | 動作 |
|---|---|---|---|
| HALT | 0 | | 停止程式執行 |
| LOAD | 1 | $R_D$ $M_S$ | $R_D \\leftarrow M_S$ |
| STORE | 2 | $M_D$ $R_S$ | $M_D \\leftarrow R_S$ |
| ADDI | 3 | $R_D$ $R_{S1}$ $R_{S2}$ | $R_D \\leftarrow R_{S1} + R_{S2}$ |
| ADDF | 4 | $R_D$ $R_{S1}$ $R_{S2}$ | $R_D \\leftarrow R_{S1} + R_{S2}$ |
| MOVE | 5 | $R_D$ $R_S$ | $R_D \\leftarrow R_S$ |
| NOT | 6 | $R_D$ $R_S$ | $R_D \\leftarrow \\overline{R_S}$ |
| AND | 7 | $R_D$ $R_{S1}$ $R_{S2}$ | $R_D \\leftarrow R_{S1} \\text{ AND } R_{S2}$ |
| OR | 8 | $R_D$ $R_{S1}$ $R_{S2}$ | $R_D \\leftarrow R_{S1} \\text{ OR } R_{S2}$ |
| XOR | 9 | $R_D$ $R_{S1}$ $R_{S2}$ | $R_D \\leftarrow R_{S1} \\text{ XOR } R_{S2}$ |
| INC | A | $R$ | $R \\leftarrow R + 1$ |
| DEC | B | $R$ | $R \\leftarrow R - 1$ |
| ROTATE | C | $R$ $n$ 0 或 1 | Rot$_n$ $R$ |
| JUMP | D | $R$ $n$ | 如果 $R_0 \\neq R$ 則 PC = $n$，否則繼續 |

圖例：
$R_S, R_{S1}, R_{S2}$：來源暫存器的十六進位位址
$R_D$：目的暫存器的十六進位位址
$M_S$：來源記憶體位置的十六進位位址
$M_D$：目的記憶體位置的十六進位位址
$n$：十六進位數字
$d_1, d_2, d_3, d_4$：第一、第二、第三和第四個十六進位數字

### 5.8.5 處理指令
我們的簡單電腦，像大多數電腦一樣，使用機器週期。一個週期由三個階段組成：*提取*、*解碼*和*執行*。在提取階段，位址由 PC 決定的指令從記憶體中獲取並載入到 IR 中。然後 PC 遞增以指向下一個指令。在*解碼*階段，IR 中的指令被解碼，所需的運算元從暫存器或記憶體中提取。在*執行*階段，指令被執行，結果被放置在適當的記憶體位置或暫存器中。第三階段完成後，控制單元再次開始週期，但現在 PC 指向下一個指令。該過程持續進行，直到 CPU 達到 HALT 指令。

**一個例子**
讓我們展示我們的簡單電腦如何將兩個整數 A 和 B 相加並產生結果 C。我們假設整數採用二的補數格式。在數學上，我們將此運算表示為：
$C = A + B$
為了解決這個問題，對於簡單電腦來說，必須將前兩個整數保存在兩個暫存器中（例如 $R_0$ 和 $R_1$），並將運算結果保存在第三個暫存器中（例如 $R_2$）。ALU 只能對儲存在 CPU 資料暫存器中的資料進行操作。然而，大多數電腦，包括我們的簡單電腦，CPU 中的暫存器數量有限。如果資料項目數量很大，並且它們應該在程式持續期間留在電腦中，最好將它們儲存在記憶體中，僅暫時將它們帶到暫存器。所以我們假設前兩個整數儲存在記憶體位置 $(40)_{16}$ 和 $(41)_{16}$，結果應儲存在記憶體位置 $(42)_{16}$。這意味著兩個整數需要載入到 CPU，結果需要儲存在記憶體中。因此，一個執行簡單加法的簡單程式需要五個指令，如下所示：

1.  將 $M_{40}$ 的內容載入暫存器 $R_0$ ($R_0 \\leftarrow M_{40}$)。
2.  將 $M_{41}$ 的內容載入暫存器 $R_1$ ($R_1 \\leftarrow M_{41}$)。
3.  將 $R_0$ 和 $R_1$ 的內容相加並將結果放入 $R_2$ ($R_2 \\leftarrow R_0 + R_1$)。
4.  將內容 $R_2$ 儲存在 $M_{42}$ ($M_{42} \\leftarrow R_2$)。
5.  停止。

在我們簡單電腦的語言中，這五個指令編碼為：

| 代碼 | 解釋 |
|---|---|
| $(1040)_{16}$ | 1: LOAD 0: $R_0$ 40: $M_{40}$ |
| $(1141)_{16}$ | 1: LOAD 1: $R_1$ 41: $M_{41}$ |
| $(3201)_{16}$ | 3: ADDI 2: $R_2$ 0: $R_0$ 1: $R_1$ |
| $(2422)_{16}$ | 2: STORE 42: $M_{42}$ 2: $R_2$ |
| $(0000)_{16}$ | 0: HALT |

### 5.8.6 儲存程式和資料
為了遵循馮·諾伊曼模型，我們需要將程式和資料儲存在記憶體中。我們可以將這五行程式儲存在記憶體中，從位置 $(00)_{16}$ 到 $(04)_{16}$ 開始。我們已經知道資料需要儲存在記憶體位置 $(40)_{16}$、$(41)_{16}$ 和 $(42)_{16}$。

### 5.8.7 週期
我們的電腦每個指令使用一個週期。如果我們有一個包含五個指令的小程式，我們需要五個週期。我們也知道每個週期通常由三個步驟組成：*提取*、*解碼*、*執行*。暫時假設我們需要加 $161 + 254 = 415$。數字在記憶體中顯示為十六進位，即 $(00A1)_{16}$、$(00FE)_{16}$ 和 $(019F)_{16}$。

**週期 1**
在第一個週期開始時（圖 5.32），PC 指向程式的第一個指令，位於記憶體位置 $(00)_{16}$。控制單元經歷三個步驟：
1.  控制單元*提取*儲存在記憶體位置 $(00)_{16}$ 的指令並將其放入 IR。此步驟後，PC 的值遞增。
2.  控制單元將指令 $(1040)_{16}$ *解碼*為 $R_0 \\leftarrow M_{40}$。
3.  控制單元*執行*指令，這意味著儲存在記憶體位置 (40) 的整數副本被載入到暫存器 $R_0$。

**週期 2**
在第二個週期開始時（圖 5.33），PC 指向程式的第二個指令，位於記憶體位置 $(01)_{16}$。控制單元經歷三個步驟：
1.  控制單元*提取*儲存在記憶體位置 $(01)_{16}$ 的指令並將其放入 IR。此步驟後，PC 的值遞增。
2.  控制單元將指令 $(1141)_{16}$ *解碼*為 $R_1 \\leftarrow M_{41}$。
3.  控制單元*執行*指令，這意味著儲存在記憶體位置 $(41)_{16}$ 的整數副本被載入到暫存器 $R_1$。

**週期 3**
在第三個週期開始時（圖 5.34），PC 指向程式的第三個指令，位於記憶體位置 $(02)_{16}$。控制單元經歷三個步驟：
1.  控制單元*提取*儲存在記憶體位置 $(02)_{16}$ 的指令並將其放入 IR。此步驟後，PC 的值遞增。
2.  控制單元將指令 $(3201)_{16}$ *解碼*為 $R_2 \\leftarrow R_0 + R_1$。
3.  控制單元*執行*指令，這意味著 $R_0$ 的內容被加到 $R_1$ 的內容（由 ALU 執行），結果放入 $R_2$。

**週期 4**
在第四個週期開始時（圖 5.35），PC 指向程式的第四個指令，位於記憶體位置 $(03)_{16}$。控制單元經歷三個步驟：
1.  控制單元*提取*儲存在記憶體位置 $(03)_{16}$ 的指令並將其放入 IR。此步驟後，PC 的值遞增。
2.  控制單元將指令 $(2422)_{16}$ *解碼*為 $M_{42} \\leftarrow R_2$。
3.  控制單元*執行*指令，這意味著暫存器 $R_2$ 中的整數副本被儲存在記憶體位置 $(42)_{16}$。

**週期 5**
在第五個週期開始時（圖 5.36），PC 指向程式的第五個指令，位於記憶體位置 $(04)_{16}$。控制單元經歷三個步驟：
1.  控制單元*提取*儲存在記憶體位置 $(04)_{16}$ 的指令並將其放入 IR。此步驟後，PC 的值遞增。
2.  控制單元將指令 $(0000)_{16}$ *解碼*為 Halt。
3.  控制單元*執行*指令，這意味著電腦停止。

### 5.8.8 另一個例子
在前面的例子中，我們假設要相加的兩個整數已經在記憶體中。我們也假設加法結果將保存在記憶體中。你可能會問我們如何將想要相加的兩個整數儲存在記憶體中，或者當結果儲存在記憶體中時我們如何使用它。在實際情況中，我們使用鍵盤等輸入設備將前兩個整數輸入到記憶體中，並透過螢幕等輸出設備顯示第三個整數。透過輸入設備獲取資料通常稱為*讀取*操作，而將資料發送到輸出設備通常稱為*寫入*操作。為了使我們之前的程式更實用，我們需要如下修改它：

1.  讀取一個整數到 $M_{40}$。
2.  $R_0 \\leftarrow M_{40}$。
3.  讀取一個整數到 $M_{41}$。
4.  $R_1 \\leftarrow M_{41}$。
5.  $R_2 \\leftarrow R_0 + R_1$。
6.  $M_{42} \\leftarrow R_2$。
7.  從 $M_{42}$ 寫入整數。
8.  停止。

有多種方法可以實現輸入和輸出。今天大多數電腦直接從輸入設備將資料傳輸到記憶體，並直接從記憶體將資料傳輸到輸出設備。然而，我們的簡單電腦不是其中之一。在我們的電腦中，我們可以使用 LOAD 和 STORE 指令模擬讀取和寫入操作。此外，LOAD 和 STORE 讀取資料輸入到 CPU 並從 CPU 寫入資料。我們需要兩個指令將資料讀入記憶體或將資料寫出記憶體。讀取操作是：

$R \\leftarrow M_{FE}$ 因為假設鍵盤是記憶體位置 $(FE)_{16}$
$M \\leftarrow R$

寫入操作是：

$R \\leftarrow M$
$M_{FF} \\leftarrow R$ 因為假設螢幕是記憶體位置 $(FF)_{16}$

你可能會問，如果操作應該在 CPU 中完成，為什麼我們將資料從鍵盤傳輸到 CPU，然後傳輸到記憶體，然後再傳輸到 CPU 進行處理？我們可以直接將資料傳輸到 CPU 嗎？答案是對於這個小問題我們可以這樣做，但原則上我們不應該這樣做。想想如果我們需要加 1000 個數字或排序 1000000 個整數會發生什麼。CPU 中的暫存器數量是有限的（在真實電腦中可能有數百個，但仍然不夠）。

**輸入操作必須始終將資料從輸入設備讀入記憶體：輸出操作必須始終將資料從記憶體寫入輸出設備。**

考慮到這一點，程式編碼為：
1 $(1FFE)_{16}$   5 $(1040)_{16}$   9 $(1F42)_{16}$
2 $(240F)_{16}$   6 $(1141)_{16}$   10 $(2FFF)_{16}$
3 $(1FFE)_{16}$   7 $(3201)_{16}$   11 $(0000)_{16}$
4 $(241F)_{16}$   8 $(2422)_{16}$

操作 1 到 4 是輸入，操作 9 和 10 是輸出。當我們運行這個程式時，它等待使用者在鍵盤上輸入兩個整數並按 Enter 鍵。然後程式計算總和並在螢幕上顯示結果。

### 5.8.9 可重用性
電腦相對於不可程式化計算器的優點之一是我們可以反覆使用同一個程式。我們可以多次運行程式，每次輸入不同的輸入並獲得不同的輸出。

## 5.9 章末材料
### 5.9.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Englander, I. *The Architecture of Computer Hardware and Systems Software*, Hoboken, NJ: Wiley, 2003
- Mano, M. *Computer System Architecture*, Upper Saddle River, NJ: Prentice-Hall, 1993
- Null, L. and Lobur, J. *Computer Organization and Architecture*, Sudbury, MA: Jones and Bartlett, 2003
- Hamacher, C., Vranesic, Z. and Zaky, S. *Computer Organization*, New York: McGraw-Hill, 2002
- Warford, S. *Computer Systems*, Sudbury, MA: Jones and Bartlett, 2005
- Ercegovac, M., Lang, T. and Moreno, J. *Introduction to Digital Systems*, Hoboken, NJ: Wiley, 1998
- Cragon, H. *Computer Architecture and Implementation*, Cambridge: Cambridge University Press, 2000
- Stallings, W. *Computer Organization and Architecture*, Upper Saddle River, NJ: Prentice-Hall, 2002

### 5.9.2 關鍵詞
- 位址匯流排 (address bus)
- 位址空間 (address space)
- 算術邏輯單元 (ALU)
- 匯流排 (bus)
- 快取記憶體 (cache memory)
- 中央處理單元 (CPU)
- 光碟 (CD)
- 唯讀光碟 (CD-ROM)
- 可錄式光碟 (CD-R)
- 複雜指令集電腦 (CISC)
- 控制匯流排 (control bus)
- 控制器 (controller)
- 控制單元 (control unit)
- 資料匯流排 (data bus)
- 解碼 (decode)
- 數位多功能光碟 (DVD)
- 直接記憶體存取 (DMA)
- 動態 RAM (DRAM)
- 電子可抹除可程式化唯讀記憶體 (EEPROM)
- 可抹除可程式化唯讀記憶體 (EPROM)
- 執行 (execute)
- 提取 (fetch)
- FireWire (火線)
- HDMI (高畫質多媒體介面)
- 集線器 (hub)
- 輸入/輸出控制器 (input/output controller)
- 輸入/輸出子系統 (input/output subsystem)
- 指令暫存器 (instruction register)
- 中斷驅動 I/O (interrupt-driven I/O)
- 磁區間隙 (intersector gap)
- 磁軌間隙 (intertrack gap)
- 獨立 I/O (isolated I/O)
- 平台 (land)
- 機器週期 (machine cycle)
- 可程式化唯讀記憶體 (PROM)
- 磁碟 (magnetic disk)
- 磁帶 (magnetic tape)
- 主記憶體 (main memory)
- 母片 (master disk)
- 記憶體映射 I/O (memory mapped I/O)
- 螢幕 (monitor)
- 多指令流、多資料流 (MIMD)
- 多指令流、單資料流 (MISD)
- 非儲存設備 (nonstorage device)
- 光學儲存設備 (optical storage device)
- 輸出設備 (output device)
- 平行處理 (parallel processing)
- 管線化 (pipelining)
- 凹坑 (pit)
- 聚碳酸酯樹脂 (polycarbonate resin)
- 印表機 (printer)
- 程式計數器 (program counter)
- 程式控制 I/O (programmed I/O)
- 隨機存取記憶體 (RAM)
- 唯讀記憶體 (ROM)
- 讀/寫頭 (read/write head)
- 精簡指令集電腦 (RISC)
- 暫存器 (register)
- 轉速 (rotational speed)
- 磁區 (sector)
- 搜尋時間 (seek time)
- 單指令流、多資料流 (SIMD)
- 靜態 RAM (SRAM)
- 儲存設備 (storage device)
- 吞吐量 (throughput)
- 拓撲 (topology)
- 磁軌 (track)
- 傳輸時間 (transfer time)
- 通用序列匯流排 (USB)
- 一次寫入，多次讀取 (WORM)

### 5.9.3 摘要
- 組成電腦的部分可以分為三大類或子系統：中央處理單元 (CPU)、主記憶體和輸入/輸出子系統。
- 中央處理單元 (CPU) 對資料執行操作。它有三個部分：算術邏輯單元 (ALU)、控制單元和一組暫存器。算術邏輯單元 (ALU) 對資料執行邏輯、移位和算術運算。暫存器是快速的獨立儲存位置，用於暫時保存資料。控制單元控制 CPU 每個部分的操作。
- 主記憶體是一組儲存位置，每個位置都有一個唯一的標識符，稱為位址。資料以稱為字的位元組為單位傳輸到記憶體和從記憶體傳輸出來。記憶體中唯一可識別位置的總數稱為位址空間。存在兩種記憶體類型：隨機存取記憶體 (RAM) 和唯讀記憶體 (ROM)。
- 被稱為輸入/輸出 (I/O) 子系統的設備集合允許電腦與外部世界通訊，即使在電源關閉時也能儲存程式和資料。輸入/輸出設備可分為兩大類：非儲存設備和儲存設備。非儲存設備允許 CPU/記憶體與外部世界通訊。儲存設備可以儲存大量資訊以供日後檢索。儲存設備分為磁性或光學設備。
- 電腦的三個子系統的互連扮演著重要的角色，因為資訊需要在這些子系統之間交換。CPU 和記憶體通常由三組連接連接，每組稱為匯流排：資料匯流排、位址匯流排和控制匯流排。輸入/輸出設備透過輸入/輸出控制器或介面連接到匯流排。使用了幾種控制器。今天最常見的是 SCSI、FireWire 和 USB。
- 有兩種處理 I/O 設備定址的方法：獨立 I/O 和記憶體映射 I/O。在獨立 I/O 方法中，用於讀/寫記憶體的指令與用於讀/寫輸入/輸出設備的指令不同。在記憶體映射 I/O 方法中，CPU 將 I/O 控制器中的每個暫存器視為記憶體中的一個字。
- 今天，通用電腦使用一組稱為程式的指令來處理資料。電腦執行程式以從輸入資料產生輸出資料。程式和資料都儲存在記憶體中。CPU 使用重複的機器週期來執行程式中的指令，從頭到尾逐一執行。一個簡化的週期可以由三個階段組成：提取、解碼和執行。
- 已經設計了三種用於 I/O 設備和 CPU 之間同步的方法：程式控制 I/O、中斷驅動 I/O 和直接記憶體存取 (DMA)。
- 最近幾十年，電腦的架構和組織經歷了許多變化。我們可以將電腦架構分為兩大類：CISC（複雜指令集電腦）和 RISC（精簡指令集電腦）。
- 現代電腦使用一種稱為管線化的技術來提高其吞吐量。這個想法是允許控制單元同時執行兩個或三個階段，這意味著下一個指令的處理可以在前一個指令完成之前開始。
- 傳統上，電腦只有一個控制單元、一個算術邏輯單元和一個記憶體單元。平行處理可以透過使用多個指令流來處理多個資料流來提高吞吐量。
`},r={en:`
# Chapter 6: Computer Networks and Internet

The development of the personal computer has brought about tremendous changes for business, industry, science, and education. A similar revolution has occurred in networking. Technological advances are making it possible for communication links to carry more and faster signals. As a result, services are evolving to allow use of this expanded capacity. Research in this area has resulted in new technologies. One goal is to be able to exchange data such as text, audio, and video from all parts of the world. We want to access the Internet to download and upload information quickly and accurately and at any time.

## Objectives
After studying this chapter, the student should be able to:
- Describe local and wide area networks (LANs and WANs).
- Distinguish an internet from the Internet.
- Describe the TCP/IP protocol suite as the network model in the Internet.
- Define the layers in the TCP/IP protocol suite and their relationship.
- Describe some applications at the application layer.
- Describe the services provided by the transport-layer protocols.
- Describe the services provided by the network-layer protocols.
- Describe different protocols used at the data-link layer.
- Describe the duties of the physical layer.
- Describe the different transmission media used in computer networking.

## 6.1 OVERVIEW
Although the goal of this chapter is to discuss the Internet, a system that interconnects billions of computers in the world, we think of the Internet not as a single network, but as an **internetwork**, a combination of networks. Therefore, we start our journey by first defining a network. We then show how we can connect networks to create small internetworks. Finally, we show the structure of the Internet and open the gate to study the Internet in the rest of this chapter.

### 6.1.1 Networks
A **network** is the interconnection of a set of devices capable of communication. In this definition, a device can be a **host** (or an **end system** as it is sometimes called) such as a large computer, desktop, laptop, workstation, cellular phone, or security system. A device in this definition can also be a **connecting device** such as a **router** which connects the network to other networks, a **switch** which connects devices together, a **modem** (modulator-demodulator) that changes the form of data, and so on. These devices in a network are connected using wired or wireless transmission media such as cable or air. When we connect two computers at home using a plug-and-play router, we have created a network, although very small.

**Local area network**
A **local area network (LAN)** is usually privately owned and connects some hosts in a single office, building, or campus. Depending on the needs of an organization, a LAN can be as simple as two PCs and a printer in someone’s home office, or it can extend throughout a company and include audio and video devices. Each host in a LAN has an identifier, an address, that uniquely defines the host in the LAN. A packet sent by a host to another host carries both the source host’s and the destination host’s addresses.

**Wide area network**
A **wide area network (WAN)** is also an interconnection of devices capable of communication. However, there are some differences between a LAN and a WAN. A LAN is normally limited in size, spanning an office, a building, or a campus; a WAN has a wider geographical span, spanning a town, a state, a country, or even the world. A LAN interconnects hosts; a WAN interconnects connecting devices such as switches, routers, or modems. A LAN is normally privately owned by the organization that uses it; a WAN is normally created and run by communication companies and leased by an organization that uses it. We see two distinct examples of WANs today: **point-to-point WANs** and **switched WANs**.

A **point-to-point WAN** is a network that connects two communicating devices through a transmission medium (cable or air).

A **switched WAN** is a network with more than two ends. A switched WAN, as we will see shortly, is used in the backbone of global communication today. We can say that a switched WAN is a combination of several point-to-point WANs that are connected by switches.

**Internetwork**
Today, it is very rare to see a LAN or a WAN in isolation; they are connected to one another. When two or more networks are connected, they make an **internetwork**, or **internet**. As an example, assume that an organization has two offices. Each office has a LAN that allows all employees in the office to communicate with each other. To make the communication between employees at different offices possible, the management leases a point-to-point dedicated WAN from a service provider, such as a telephone company, and connects the two LANs. Now the company has an internetwork, or a private internet (with lowercase i). Communication between offices is now possible.

### 6.1.2 The Internet
As we discussed before, an internet (note the lowercase i) is two or more networks that can communicate with each other. The most notable internet is called the **Internet** (uppercase I), and is composed of thousands of interconnected networks.

The Internet is composed of several **backbones**, **provider networks**, and **customer networks**. At the top level, the **backbones** are large networks owned by some communication companies. The backbone networks are connected through some complex switching systems, called **peering points**. At the second level, there are smaller networks, called **provider networks**, that use the services of the backbones for a fee. The provider networks are connected to backbones and sometimes to other provider networks. The **customer networks** are networks at the edge of the Internet that actually use the services provided by the Internet. They pay fees to provider networks for receiving services.

Backbones and provider networks are also called **internet service providers (ISPs)**. The backbones are often referred to as international ISPs; the provider networks are often referred to as national or regional ISPs.

### 6.1.3 Hardware and software
We have given the overview of the Internet structure, which is made of small and large networks glued together with connecting devices. It should be clear, however, that if we only connect these pieces nothing will happen. For communication to happen, we need both **hardware** and **software**. This is similar to a complex computation in which we need both a computer and a program. In the next section, we show how these combinations of hardware and software are coordinated with each other using *protocol layering*.

### 6.1.4 Protocol layering
A word we hear all the time when we talk about the Internet is *protocol*. A **protocol** defines the rules that both the sender and receiver and all intermediate devices need to follow to be able to communicate effectively. When communication is simple, we may need only one simple protocol; when the communication is complex, we may need to divide the task between different layers, in which case we need a protocol at each layer, or **protocol layering**.

**A scenario**
Let us develop a simple scenario to better understand the need for protocol layering. We assume that Ann and Maria are neighbors with a lot of common ideas. They communicate with each other every time they meet about a project for the time when they will be retired. Suddenly, Ann is offered a higher-level position in her company, but needs to move to another branch located in a city very far from Maria. The two friends still want to continue their communication and exchange ideas because they have come up with an innovative project to start a new business when they both retire. They decide to continue their conversation using regular mail through the post office. However, they do not want their ideas to be revealed to other people if the letters are intercepted. They agree on an encryption/decryption technique. The sender of the letter encrypts it to make it unreadable by an intruder; the receiver of the letter decrypts it to get the original letter. We discuss the encryption/decryption methods in Chapter 16, but for the moment we assume that Maria and Ann use one technique that makes it hard to decrypt the letter if one does not have the key for doing so. Now we can say that the communication between Maria and Ann takes place in three layers. We assume that Ann and Maria each have three machines (or robots) that can perform the task at each layer.

Let us assume that Maria sends the first letter to Ann. Maria talks to the machine at the third layer as though the machine is Ann and is listening to her. The third-layer machine listens to what Maria says and creates the plaintext (a letter in English), which is passed to the second-layer machine. The second-layer machine takes the plaintext, encrypts it, and creates the **ciphertext**, which is passed to the first-layer machine. The first layer machine, presumably a robot, takes the ciphertext, puts it in an envelope, adds the sender and receiver addresses, and mails it.
At Ann’s side, the first-layer machine picks up the letter from Ann’s mail box, recognizing the letter from Maria by the sender address. The machine takes out the ciphertext from the envelope and delivers it to the second-layer machine. The second-layer machine decrypts the message, creates the plaintext, and passes the plaintext to the third-layer machine. The third-layer machine takes the plaintext and reads it as though Maria is speaking.

Protocol layering enables us to divide a complex task into several smaller and simpler tasks. For example, we could have used only one machine to do the job of all three machines. However, if Maria and Ann decide that the encryption/decryption done by the machine is not enough to protect their secrecy, they have to change the whole machine. In the present situation, they need to change only the second-layer machine; the other two can remain the same. This is referred to as **modularity**. Modularity in this case means independent layers. A layer (**module**) can be defined as a black box with inputs and outputs, without concern about how inputs are changed to outputs. If two machines provide the same outputs when given the same inputs, they can replace each other. For example, Ann and Maria can buy the second-layer machine from two different manufacturers. As long as the two machines create the same ciphertext from the same plaintext and vice versa, they do the job.

One of the advantages of protocol layering is that it allows us to separate the services from the implementation. A layer needs to be able to receive a set of services from the lower layer and to give the services to the upper layer; we don’t care about how the layer is implemented. For example, Maria may decide not to buy the machine (robot) for the first layer; she can do the job herself. As long as Maria can do the tasks provided by the first layer, in both directions, the communication system works.

Another advantage of protocol layering, which cannot be seen in our simple examples, but reveals itself when we discuss protocol layering in the Internet, is that communication does not always use only two end systems; there are intermediate systems that need only some layers, but not all layers. If we did not use protocol layering, we would have to make each intermediate system as complex as the end systems, which makes the whole system more expensive.

Is there any disadvantage to protocol layering? One can argue that having a single layer makes the job easier. There is no need for each layer to provide a service to the upper layer and give a service to the lower layer. For example, Ann and Maria could find or build one machine that could do all three tasks. However, as mentioned above, if one day they found that their code was broken, each would have to replace the whole machine with a new one instead of just changing the machine in the second layer.

**Principles of protocol layering**
Let us discuss some principles of protocol layering. The first principle dictates that if we want bidirectional communication, we need to make each layer so that it is able to perform two opposite tasks, one in each direction. For example, the third-layer task is to *listen* (in one direction) and *talk* (in the other direction). The second layer needs to be able to encrypt and decrypt. The first layer needs to send and receive mail.
The second important principle that we need to follow in protocol layering is that the two objects under each layer at both sites should be identical. For example, the object under layer 3 at both sites should be a plaintext letter. The object under layer 2 at both sites should be a ciphertext letter. The object under layer 1 at both sites should be a piece of mail.

**Logical connections**
After following the above two principles, we can think about logical connection between each layer. This means that we have layer-to-layer communication. Maria and Ann can think that there is a logical (imaginary) connection at each layer through which they can send the object created from that layer. We will see that the concept of logical connection will help us better understand the task of layering we encounter in data communication and networking.

### 6.1.5 TCP/IP protocol suite
Now that we know about the concept of protocol layering and the logical communication between layers in our second scenario, we can introduce the **TCP/IP (Transmission Control Protocol/Internet Protocol)**. TCP/IP is a protocol suite (a set of protocols organized in different layers) used in the Internet today. It is a hierarchical protocol made up of interactive modules, each of which provides a specific functionality. The term *hierarchical* means that each upper-level protocol is supported by the services provided by one or more lower-level protocols. The TCP/IP protocol suite is made of five layers:
1.  **Application Layer** (Layer 5)
2.  **Transport Layer** (Layer 4)
3.  **Network Layer** (Layer 3)
4.  **Data link Layer** (Layer 2)
5.  **Physical Layer** (Layer 1)

**Layered architecture**
To show how the layers in the TCP/IP protocol suite are involved in communication between two hosts, we assume that we want to use the suite in a small internet made up of three LANs (links), each with a link-layer switch. We also assume that the links are connected by one router.

Let us assume that computer A communicates with computer B. We have five communicating devices in this communication: source host (computer A), the link-layer switch in link 1, the router, the link-layer switch in link 2, and the destination host (computer B). Each device is involved with a set of layers depending on the role of the device in the internet. The two hosts are involved in all five layers; the source host needs to create a message in the **application layer** and send it down the layers so that it is physically sent to the destination host. The destination host needs to receive the communication at the **physical layer** and then deliver it through the other layers to the application layer.

The router is involved only in three layers; there is no transport or application layer in a router as long as the router is used only for **routing**. Although a router is always involved in one network layer, it is involved in $n$ combinations of link and physical layers in which $n$ is the number of links the router is connected to. The reason is that each link may use its own data-link or physical protocol. Each link may be using different link-layer and physical-layer protocols; the router needs to receive a packet from link 1 based on one pair of protocols and deliver it to link 2 based on another pair of protocols.

A link-layer switch in a link, however, is involved only in two layers, data-link and physical. Although each switch has two different connections, the connections are in the same link, which uses only one set of protocols. This means that, unlike a router, a link-layer switch is involved only in one data-link and one physical layer.

**Addressing and packet names**
It is worth mentioning another two concepts related to protocol layering in the Internet: *addressing* and *packet names*. As we discussed before, we have logical communication between pairs of layers in this model. Any communication that involves two parties needs two addresses: source address and destination address. Although it looks as if we need five pairs of addresses, one pair per layer, we normally have only four because the physical layer does not need addresses; the unit of data exchange at the physical layer is a bit, which definitely cannot have an address.

There is a relationship between the layer, the address used in that layer, and the packet name at that layer. At the application layer, we normally use **names** to define the site that provides services, such as *someorg.com*, or the email address, such as *somebody@coldmail.com*. The packet name at this layer is **message**.
At the transport layer, addresses are called **port numbers**, and these define the application-layer programs at the source and destination. Port numbers are local addresses that distinguish between several programs running at the same time. The packet name at this layer is **segment** or **user datagram**.
At the **network-layer**, the addresses are **logical addresses** (global), with the whole Internet as the scope. A network-layer address uniquely defines the connection of a device to the Internet. The packet name is **datagram**.
The link-layer addresses, sometimes called **MAC addresses** or **link-layer addresses**, are locally defined addresses, each of which defines a specific host or router in a network (LAN or WAN). The packet name is **frame**.
At the physical layer, the unit is a **bit**.

## 6.2 APPLICATION LAYER
After the brief discussion of networks, internetworks, and the Internet, we are ready to give some discussion about each layer of the TCP/IP protocol. We start from the fifth layer and move to the first layer.

The fifth layer of the TCP/IP protocol is called the application layer. The application layer provides services to the user. Communication is provided using a logical connection, which means that the two application layers assume that there is an imaginary direct connection through which they can send and receive messages.

Consider a scenario in which a scientist working in a research company, Sky Research, needs to order a book related to her research from an online bookseller, Scientific Books. Logical connection takes place between the application layer at a computer at Sky Research and the application layer of a server at Scientific Books. We call the first host Alice and the second one Bob. The communication at the application layer is logical, not physical. Alice and Bob assume that there is a two-way logical channel between them through which they can send and receive messages. The actual communication, however, takes place through several devices and several physical channels.

### 6.2.1 Providing services
The application layer is somehow different from other layers in that it is the highest layer in the suite. The protocols in this layer do not provide services to any other protocol in the suite; they only receive services from the protocols in the transport layer. This means that protocols can be removed from this layer easily. New protocols can be also added to this layer as long as the new protocol can use the service provided by one of the transport-layer protocols.

Since the application layer is the only layer that provides services to the Internet user, the flexibility of the application layer, as described above, allows new application protocols to be easily added to the Internet, which has been occurring during the lifetime of the Internet. When the Internet was created, only a few application protocols were available to the users; today we cannot give a number for these protocols because new ones are being added constantly.

### 6.2.2 Application-layer paradigms
It should be clear that to use the Internet we need two application programs to interact with each other: one running on a computer somewhere in the world, the other running on another computer somewhere else in the world. The two programs need to send messages to each other through the Internet infrastructure. However, we have not discussed what the relationship should be between these programs. Should both application programs be able to request services and provide services, or should the application programs just do one or the other? Two paradigms have been developed during the lifetime of the Internet to answer this question: the *client–server paradigm* and the *peer-to-peer paradigm*. We briefly introduce these two paradigms here.

**Traditional paradigm: client–server**
The traditional paradigm is called the **client–server paradigm**. It was the most popular paradigm until a few years ago. In this paradigm, the service provider is an application program, called the **server process**; it runs continuously, waiting for another application program, called the **client process**, to make a connection through the Internet and ask for service. There are normally some server processes that can provide a specific type of service, but there are many clients that request service from any of these server processes. The server process must be running all the time; the client process is started when the client needs to receive service.

Although the communication in the client–server paradigm is between two application programs, the role of each program is totally different. In other words, we cannot run a client program as a server program or vice versa.

One problem with this paradigm is that the concentration of the communication load is on the shoulder of the server, which means the server should be a powerful computer. Even a powerful computer may become overwhelmed if a large number of clients try to connect to the server at the same time. Another problem is that there should be a service provider willing to accept the cost and create a powerful server for a specific service, which means the service must always return some type of income for the server in order to encourage such an arrangement.

Several traditional services are still using this paradigm, including the **World Wide Web (WWW)** and its vehicle **HyperText Transfer Protocol (HTTP)**, file transfer protocol (FTP), secure shell (SSH), email, and so on. We discuss some of these protocols and applications later in the chapter.

**New paradigm: peer-to-peer**
A new paradigm, called the **peer-to-peer paradigm** (often abbreviated **P2P paradigm**) has emerged to respond to the needs of some new applications. In this paradigm, there is no need for a server process to be running all the time and waiting for the client processes to connect. The responsibility is shared between peers. A computer connected to the Internet can provide service at one time and receive service at another time. A computer can even provide and receive services at the same time.

One of the areas that really fits in this paradigm is Internet telephony. Communication by phone is indeed a peer-to-peer activity; no party needs to be running forever waiting for the other party to call. Another area in which the peer-to-peer paradigm can be used is when some computers connected to the Internet have something to share with each other. For example, if an Internet user has a file available to share with other Internet users, there is no need for the file holder to become a server and run a server process all the time waiting for other users to connect and retrieve the file.

Although the peer-to-peer paradigm has been proved to be easily scalable and cost-effective in eliminating the need for expensive servers to be running and maintained all the time, there are also some challenges. The main challenge has been **security**; it is more difficult to create secure communication between distributed services than between those controlled by some dedicated servers. The other challenge is applicability; it appears that not all applications can use this new paradigm. For example, not many Internet users are ready to become involved, if one day the Web can be implemented as a peer-to-peer service.

### 6.2.3 Standard client–server applications
During the lifetime of the Internet, several client–server application programs have been developed. We do not have to redefine them, but we need to understand what they do. We have selected six standard application programs in this section. We start with HTTP and the World Wide Web because they are used by almost all Internet users. We then introduce file transfer and electronic mail applications which have high traffic loads on the Internet. Next, we explain remote logging and how it can be achieved using the TELNET and SSH protocols. Finally, we discuss DNS, which is used by all application programs to map the application layer identifier to the corresponding host IP address.

**World Wide Web and HTTP**
In this section, we first introduce the World Wide Web (abbreviated WWW or Web). We then discuss the HyperText Transfer Protocol (HTTP), the most common client–server application program used in relation to the Web.

**World Wide Web**
The Web today is a repository of information in which the documents, called **Web pages**, are distributed all over the world and related documents are linked together. The popularity and growth of the Web can be related to two terms in the above statement: distributed and linked. Distribution allows the growth of the Web. Each web server in the world can add a new web page to the repository and announce it to all Internet users without overloading a few servers. Linking allows one web page to refer to another web page stored in another server somewhere else in the world. The linking of web pages was achieved using a concept called **hypertext**, which was introduced many years before the advent of the Internet. The idea was to use a machine that automatically retrieved another document stored in the system when a link to it appeared in the document. The Web implemented this idea electronically: to allow the linked document to be retrieved when the link was clicked by the user. Today, the term hypertext, coined to mean linked text documents, has been changed to **hypermedia**, to show that a web page can be a text document, an image, an audio file, or a video file.

The WWW today is a distributed client–server service, in which a client using a **browser** can access a service using a server. However, the service provided is distributed over many locations called *sites*. Each site holds one or more documents, referred to as **web pages**. Each web page, however, can contain some links to other web pages in the same or other sites. In other words, a web page can be simple or composite. A simple web page has no links to other web pages; a composite web page has one or more links to other web pages. Each web page is a file with a name and address.

**Web client (browser)**
A variety of vendors offer commercial **browsers** that interpret and display a web page, and all of them use nearly the same architecture. Each browser usually consists of three parts: a controller, client protocols, and interpreters.
The controller receives input from the keyboard or the mouse and uses the client programs to access the document. After the document has been accessed, the controller uses one of the interpreters to display the document on the screen. The client protocol can be one of the protocols described later, such as HTTP or FTP. The interpreter can be **HyperText Markup Language (HTML)**, Java, or JavaScript, depending on the type of document. Some commercial browsers include Internet Explorer, Netscape Navigator, and Firefox.

**Web server**
The web page is stored at the server. Each time a request arrives, the corresponding document is sent to the client.

**Uniform resource locator (URL)**
A web page, as a file, needs to have a unique identifier to distinguish it from other web pages. To define a web page, we need three identifiers: *host*, *port*, and *path*. However, before defining the web page, we need to tell the browser what client–server application we want to use, which is called the *protocol*. This means we need four identifiers to define the web page. The first is the type of vehicle to be used to fetch the web page; the last three make up the combination that defines the destination object (web page).
- **Protocol**. The first identifier is the abbreviation for the client–server program that we need in order to access the web page.
- **Host identifier**. The host identifier can be the IP address of the server or the unique name given to the server.
- **Port number**. The port, a 16-bit integer, is normally predefined for the client–server application.
- **Path**. The path identifies the location and the name of the file in the underlying operating system. The format of this identifier normally depends on the operating system. In UNIX, a path is a set of directory names followed by the file name, all separated by a slash.
To combine these four pieces together, the **uniform resource locator (URL)** has been designed; it uses three different separators between the four pieces as shown below:
\`protocol://host:port/path\`

**HyperText Transfer Protocol (HTTP)**
The **HyperText Transfer Protocol (HTTP)** is a protocol that is used to define how the client–server programs can be written to retrieve web pages from the Web. An HTTP client sends a request; an HTTP server returns a response. The server uses the port number 80; the client uses a temporary port number.

**6.2.4 File Transfer Protocol (FTP)**
**File Transfer Protocol (FTP)** is the standard protocol provided by TCP/IP for copying a file from one host to another. Although transferring files from one system to another seems simple and straightforward, some problems must be dealt with first. For example, two systems may use different file name conventions. Two systems may have different ways to represent data. Two systems may have different directory structures. All of these problems have been solved by FTP in a very simple and elegant approach.

The client has three components: user interface, client control process, and the client data transfer process. The server has two components: the server control process and the server data transfer process. The control connection is made between the control processes. The data connection is made between the data transfer processes.
Separation of commands and data transfer makes FTP more efficient. The control connection uses very simple rules of communication. We need to transfer only a line of command or a line of response at a time. The data connection, on the other hand, needs more complex rules due to the variety of data types transferred.

**Lifetimes of two connections**
The two connections in FTP have different lifetimes. The control connection remains connected during the entire interactive FTP session. The data connection is opened and then closed for each file transfer activity. It opens each time commands that involve transferring files are used, and it closes when the file is transferred. In other words, when a user starts an FTP session, the control connection opens. While the control connection is open, the data connection can be opened and closed multiple times if several files are transferred.

**6.2.5 Electronic mail**
**Electronic mail** (or **email**) allows users to exchange messages. The nature of this application, however, is different from other applications discussed so far. In an application such as HTTP or FTP, the server program is running all the time, waiting for a request from a client. When the request arrives, the server provides the service. There is a request and there is a response. In the case of electronic mail, the situation is different. First, email is considered a one-way transaction. When Alice sends an email to Bob, she may expect a response, but this is not a mandate. Bob may or may not respond. If he does respond, it is another one-way transaction. Second, it is neither feasible nor logical for Bob to run a server program and wait until someone sends an email to him. Bob may turn off his computer when he is not using it. This means that the idea of client/server programming should be implemented in another way: using some intermediate computers (servers). The users run only client programs when they want and the intermediate servers apply the client/server paradigm.

**Architecture**
To explain the architecture of email, we give a common scenario.
In the common scenario, the sender and the receiver of the email, Alice and Bob respectively, are connected via a LAN or a WAN to two mail servers. The administrator has created one **mailbox** for each user where the received messages are stored. A mailbox is part of a server hard drive, a special file with permission restrictions. Only the owner of the mailbox has access to it. The administrator has also created a queue (spool) to store messages waiting to be sent.
A simple email from Alice to Bob takes nine different steps. Alice and Bob use three different agents: a **user agent (UA)**, a **Mail Transfer Agent (MTA)**, and a **Message Access Agent (MAA)**. When Alice needs to send a message to Bob, she runs a UA program to prepare the message and send it to her mail server. The mail server at her site uses a queue (spool) to store messages waiting to be sent. The message, however, needs to be sent through the Internet from Alice’s site to Bob’s site using an MTA. Here two message transfer agents are needed: one client and one server. Like most client–server programs on the Internet, the server needs to run all the time because it does not know when a client will ask for a connection. The client, on the other hand, can be triggered by the system when there is a message in the queue to be sent. The user agent at Bob’s site allows Bob to read the received message. Bob later uses an MAA client to retrieve the message from an MAA server running on the second server.
Bob needs another pair of client–server programs: message access programs. This is because an MTA client–server program is a *push* program: the client pushes the message to the server. Bob needs a *pull* program. The client needs to pull the message from the server.

**6.2.6 TELNET**
A server program can provide a specific service to its corresponding client program. For example, the FTP server is designed to let the FTP client store or retrieve files on the server site. However, it is impossible to have a client/server pair for each type of service we need; the number of servers soon becomes intractable. The idea is not scalable. Another solution is to have a specific client/server program for a set of common scenarios, but to have some generic client/server programs that allow a user on the client site to log into the computer at the server site and use the services available there. For example, if a student needs to use the Java compiler program at her university lab, there is no need for a Java compiler client and a Java compiler server. The student can use a client logging program to log into the university server and use the compiler program at the university. We refer to these generic client/server pairs as **remote login** applications.
One of the original remote logging protocols is **TELNET**, which is an abbreviation for TErminaL NETwork. Although TELNET requires a logging name and password, it is vulnerable to hacking because it sends all data including the password in plaintext (not encrypted). A hacker can eavesdrop and obtain the logging name and password. Because of this security issue, the use of TELNET has diminished in favor of another protocol, Secure Shell (SSH).

**6.2.7 Secure Shell (SSH)**
Although **Secure Shell (SSH)** is a secure application program that can be used today for several purposes such as remote logging and file transfer, it was originally designed to replace TELNET. There are two versions of SSH: SSH-1 and SSH-2, which are totally incompatible. The first version, SSH-1, is now deprecated because of security flaws in it. The current version is called SSH-2.

**6.2.8 Domain Name System (DNS)**
The last client–server application program we discuss has been designed to help other application programs. To identify an entity, TCP/IP protocols use the IP address, which uniquely identifies the connection of a host to the Internet. However, people prefer to use names instead of numeric addresses. Therefore, the Internet needs to have a directory system that can map a name to an address. This is analogous to the telephone network. A telephone network is designed to use telephone numbers, not names. People can either keep a private file to map a name to the corresponding telephone number or can call the telephone directory to do so.
Since the Internet is so huge today, a central directory system cannot hold all the mapping. In addition, if the central computer fails, the whole communication network will collapse. A better solution is to distribute the information among many computers in the world. In this method, the host that needs mapping can contact the closest computer holding the needed information. The TCP/IP uses a **DNS** client and a DNS server to map a name to an address. A user wants to use a file transfer client to access the corresponding file transfer server running on a remote host. The user knows only the file transfer server name, such as *afilesource.com*. However, the TCP/IP suite needs the IP address of the file transfer server to make the connection. The following six steps map the host name to an IP address:
1.  The user passes the host name to the file transfer client.
2.  The file transfer client passes the host name to the DNS client.
3.  Each computer, after being booted, knows the address of one DNS server. The DNS client sends a message to a DNS server with a query that gives the file transfer server name using the known IP address of the DNS server.
4.  The DNS server responds with the IP address of the desired file transfer server.
5.  The DNS client passes the IP address to the file transfer server.
6.  The file transfer client now uses the received IP address to access the file transfer server.

**Name space**
To be unambiguous, the names assigned to machines must be carefully selected from a name space with complete control over the binding between the names and IP addresses. In other words, the names must be unique because the addresses are unique. A **name space** can map each address to a unique name and is normally organized hierarchically. In a hierarchical *name space*, each name is made of several parts. The first part can define the nature of the organization, the second part can define the name of an organization, the third part can define departments in the organization, and so on. In this case, the authority to assign and control the name spaces can be decentralized. A central authority can assign the part of the name that defines the nature of the organization and the name of the organization. The responsibility for the rest of the name can be given to the organization itself. The organization can add suffixes (or prefixes) to the name to define its host or resources. The management of the organization need not worry that the prefix chosen for a host is taken by another organization because, even if part of an address is the same, the whole address is different.

**DNS in the Internet**
DNS is a protocol that can be used in different platforms. In the Internet, the **domain name space** (tree) was originally divided into three different sections: generic domains, country domains, and the inverse domain. However, due to the rapid growth of the Internet, it became extremely difficult to keep track of the inverse domains, which could be used to find the name of a host when given the IP address. The inverse domains are now deprecated. We, therefore, concentrate on the first two.

**Generic domains**
The **generic domains** define registered hosts according to their generic behavior. Each node in the tree defines a domain, which is an index to the **domain name** space database. Looking at the tree, we see that the first level in the generic domains section allows 14 possible labels. These labels describe the organization types:
*   **aero**: Airlines and aerospace
*   **biz**: Businesses or firms
*   **com**: Commercial organizations
*   **coop**: Cooperative organizations
*   **edu**: Educational institutions
*   **gov**: Government institutions
*   **info**: Information service providers
*   **int**: International organizations
*   **mil**: Military groups
*   **museum**: Museums
*   **name**: Personal names (individuals)
*   **net**: Network support centers
*   **org**: Nonprofit organizations
*   **pro**: Professional organizations

**Country domains**
The **country domains** section uses two-character country abbreviations (e.g., us for United States). Second labels can be organizational, or they can be more specific, national designations. The United States, for example, uses state abbreviations as a subdivision of us (e.g., ca.us.).

**6.2.9 Peer-to-peer paradigm**
We discussed the client–server paradigm early in the chapter. The first instance of peer-to-peer file sharing goes back to December 1987 when Wayne Bell created *WWIVnet*, the network component of WWIV (World War Four) bulletin board software. In July 1999, Ian Clarke designed *Freenet*, a decentralized, censorship-resistant distributed data store, aimed to provide freedom of speech through a peer-to-peer network with strong protection of anonymity.
Peer-to-peer gained popularity with Napster (1999–2001), an online music file sharing service created by Shawn Fanning. Although free copying and distributing of music files by the users led to a copyright violation lawsuit against Napster, and eventually closing of the service, it paved the way for peer-to-peer file-distribution models that came later. Gnutella had its first release in March 2000. It was followed by FastTrack (used by the Kazaa), BitTorrent, WinMX, and GNUnet in March, April, May, and November of 2001 respectively.

Internet users that are ready to share their resources become peers and form a network. When a peer in the network has a file (for example, an audio or video file) to share, it makes it available to the rest of the peers. An interested peer can connect itself to the computer where the file is stored and download it. After a peer downloads a file, it can make it available for other peers to download. As more peers join and download that file, more copies of the file become available to the group. Since lists of peers may grow and shrink, the question is how the paradigm keeps track of loyal peers and the location of the files. To answer this question, we first need to divide the P2P networks into two categories: centralized and decentralized.

**Centralized networks**
In a **centralized P2P network**, the directory system listing of the peers and what they offer uses the client–server paradigm, but the storing and downloading of the files are done using the peer-to-peer paradigm. For this reason, a centralized P2P network is sometimes referred to as a hybrid P2P network. Napster was an example of a centralized P2P. In this type of network, a peer first registers itself with a central server. The peer then provides its IP address and a list of files it has to share. To avoid system collapse, Napster used several servers for this purpose.
A peer, looking for a particular file, sends a query to a central server. The server searches its directory and responds with the IP addresses of nodes that have a copy of the file. The peer contacts one of the nodes and downloads the file. The directory is constantly updated as nodes join or leave the peer.
Centralized networks make the maintenance of the directory simple but have several drawbacks. Accessing the directory can generate huge traffic and slow down the system. The central servers are vulnerable to attack, and if all of them fail, the whole system goes down.

**Decentralized network**
A decentralized P2P network does not depend on a centralized directory system. In this model, peers arrange themselves into an *overlay network*, which is a logical network made on top of the physical network. Depending on how the nodes in the overlay network are linked, a decentralized P2P network is classified as either unstructured or structured.
In an *unstructured* P2P network, the nodes are linked randomly. A search in an unstructured P2P is not very efficient because a query to find a file must be flooded through the network, which produces significant traffic and still the query may not be resolved. Two examples of this type of network are Gnutella and Freenet.
A *structured* network uses a predefined set of rules to link nodes so that a query can be effectively and efficiently resolved. The most common technique used for this purpose is the *Distributed Hash Table (DHT)*. DHT is used in many applications including Distributed Data Structure (DDS), Content Distributed Systems (CDS), Domain Name System (DNS), and P2P file sharing. One popular P2P file sharing protocol that uses the DHT is BitTorrent.

## 6.3 TRANSPORT LAYER
The **transport layer** in the TCP/IP suite is located between the application layer and the network layer. It provides services to the application layer and receives services from the network layer. The transport layer acts as a liaison between a client program and a server program, a **process-to-process** connection. The transport layer is the heart of the TCP/IP protocol suite; it is the end-to-end logical vehicle for transferring data from one point to another in the Internet. Only the two end systems use the service of the transport layer; all intermediate routers use only the first three layers.

### 6.3.1 Transport-layer services
In this section, we discuss the services that can be provided by the transport layer; in the next section, we discuss several transport-layer protocols.

**Process-to-process communication**
The first duty of a transport-layer protocol is to provide *process-to-process communication*. A process is an application-layer entity (running program) that uses the services of the transport layer.
The network layer (discussed later) is responsible for communication at the computer level (host-to-host communication). A network-layer protocol can deliver the message only to the destination computer. However, this is an incomplete delivery. The message still needs to be handed to the correct process. This is where a transport-layer protocol takes over. A transport-layer protocol is responsible for delivery of the message to the appropriate process.

**Addressing: port numbers**
Although there are a few ways to achieve process-to-process communication, the most common is through the client–server paradigm. A process on the local host, called a *client*, needs services from a process usually on the remote host, called a *server*. Both processes (client and server) have the same name. For example, to get the day and time from a remote machine, we need a daytime client process running on the local host and a daytime server process running on a remote machine. A remote computer can run several server programs at the same time, just as several local computers can run one or more client programs at the same time. For communication, we must define the local host, local process, remote host, and remote process. The local host and the remote host are defined using IP addresses (discussed in the next section). To define the processes, we need second identifiers, called **port numbers**. In the TCP/IP protocol suite, the port numbers are integers between 0 and 65535 (16 bits).
The client program defines itself with a port number, called the **ephemeral port number**. The word ephemeral means *short-lived* and is used because the life of a client is normally short. An ephemeral port number is recommended to be greater than 1023 for some client/server programs to work properly. The server process must also define itself with a port number. This port number, however, cannot be chosen randomly. TCP/IP has decided to use universal port numbers for servers; these are called **well-known port numbers**. Every client process knows the well-known port number of the corresponding server process.

### 6.3.2 Transport-layer protocols
Although the Internet uses several transport-layer protocols, we discuss only two in this section: UDP and TCP.

**User Datagram Protocol (UDP)**
The **User Datagram Protocol (UDP)** is a connectionless, unreliable transport protocol. It does not add anything to the services of network layer except for providing process-to-process communication instead of host-to-host communication. If UDP is so powerless, why would a process want to use it? With the disadvantages come some advantages. UDP is a very simple protocol using a minimum of overhead. If a process wants to send a small message and does not care much about reliability, it can use UDP. Sending a small message using UDP takes much less interaction between the sender and receiver than using TCP.

**User datagrams**
UDP packets, called **user datagrams**, have a fixed-size **header** of 8 bytes. However, the total length needs to be less because a UDP user datagram is stored in an **IP datagram** with the total length of 65535 bytes.

**Transmission Control Protocol (TCP)**
**Transmission Control Protocol (TCP)** is a connection-oriented, reliable protocol. TCP explicitly defines connection establishment, data transfer, and connection teardown phases to provide a connection-oriented service. Connection-oriented service here means that there is a connection (relationship) between all packets (segments) belonging to the same message (coming from the application layer). TCP uses sequence numbers to define the order of the segments. The sequence number is related to the number of bytes in each segment. For example, if the message is 6000 bytes, the first segment has a sequence number 0, the second has the sequence number 2000, and the third segment has the sequence number 4000 (the process is more complicated, we try to simplify it). In this way, if a segment is lost, the receiver holds the other two until the lost one is reset by the sender.

**Segments**
At the transport layer, TCP groups a number of bytes together into a packet called a **segment**. TCP adds a header to each segment (for control purposes) and delivers the segment to the network layer for transmission. The segments are encapsulated in an IP datagram.

## 6.4 NETWORK LAYER
The **network layer** in the TCP/IP protocol suite is responsible for the host-to-host delivery of messages.
The network layer is involved at the source host, destination host, and all routers in the path. At the source host, the network layer accepts a packet from a transport layer, encapsulates the packet in a **datagram**, and delivers the packet to the data-link layer. At the destination host, the datagram is decapsulated, the packet is extracted and delivered to the corresponding transport layer. Although the source and destination hosts are involved in all five layers of the TCP/IP suite, the routers use three layers if they are routing packets only; however, they may need the transport and application layers for control purposes. A router in the path is normally shown with two data-link layers and two physical layers, because it receives a packet from one network and delivers it to another network.

### 6.4.1 Services Provided by network layer
The network layer is located under the transport layer; this means that the network layer provides service to the transport layer. We discuss some aspects of this service below.

**Packetizing**
The first duty of the network layer is definitely **packetizing**: encapsulating the payload (data received from the upper layer) in a network-layer packet at the source and decapsulating the payload from the network-layer packet at the destination. In other words, one duty of the network layer is to carry a payload from the source to the destination without changing it or using it. The network layer is doing the service of a carrier such as the post office, which is responsible for delivery of packages from a sender to a receiver without changing or using the contents.
1. The source network-layer protocol receives a packet from the transport-layer protocol, adds a header that contains the source and destination addresses and some other information that is required by the network-layer protocol.
2. The network layer protocol then logically delivers the packet to the network-layer protocol at the destination.
3. The destination host receives the network-layer packet, decapsulates the payload and delivers to the upper-layer protocol.
If the packet is fragmented at the source or at routers along the path, the network layer is responsible for waiting until all fragments arrive, reassembling them, and delivering them to the upper-layer protocol.
A transport-layer payload may be encapsulated in several network-layer packets.

**Packet delivery**
Packet delivery at the network layer is unreliable and connectionless. We briefly discuss these two concepts next.

**Unreliable delivery**
The delivery of packets at the network layer is **unreliable**. This means that the packets can be corrupted, lost, duplicated. In other words, the network layer provides a best-effort delivery, but there is no guarantee that a packet will reach the destination as we expect. This is the same service we receive from the post office when we mail a regular letter. The reason in both cases is the cost. If we need a guarantee from the post office, the cost is higher (registered mail for example). If we need a guarantee from the network layer, the delivery of packets will be delayed. Each packet needs to be checked at each router and destination and resent if corrupted. Checking the lost packets is even more costly. Does it mean that messages we send by the Internet are not reliable? The answer is that if we want to guarantee that the messages are not corrupted, we need to use the TCP protocol at the transport layer. If a payload at the transport layer is corrupted (because of unreliable delivery at the data-link layer), TCP drops the packet and requests resending of the data as we discussed in the previous section.

**Connectionless delivery**
The delivery at the network layer is also **connectionless**, but the word connectionless here does not mean that there is no physical connection between the sender and receiver. It means that the network layer treats each packet independently (like the way the post office does with the letters). In other words, there is no relationship between packets belonging to the same transport-layer payload. If a transport-layer packet results in four network-layer packets, there is no guarantee that the packets arrive in the same order as sent because each packet may follow a different path to reach the destination. A transport-layer packet is divided into four network-layer packets. They are sent in order (1, 2, 3, 4), but they are received out of order (2, 4, 3, 1). The transport layer at the destination is responsible for holding packets until all of them arrive before putting them in order and delivering them to the application layer.

**Routing**
Another duty of the network layer, which is as important as the others, is **routing**. The network layer is responsible for routing the packet from its source to the destination. A physical network is a combination of networks (LANs and WANs) and routers that connect them. This means that there is more than one route from the source to the destination. The network layer is responsible for finding the *best* one among these possible routes. The network layer needs to have some specific strategies for defining the best route. In the Internet today, this is done by running some *routing protocols* to help the routers coordinate their knowledge about the neighborhood and to come up with consistent tables to be used when a packet arrives.

### 6.4.2 Network-layer protocols
Although there are several protocols at the network layer, the main protocol is called the **Internet Protocol (IP)**. Other protocols are auxiliary protocols that help IP. Today, two versions of IP protocol are in use: IPv4 and IPv6. We discuss each in the next two sections.

**Internet Protocol Version 4 (IPv4)**
Today most systems are using the Internet Protocol Version 4 (IPv4), but this will be changed in future because of smaller address space and packet format of this protocol (among other reasons).

**IPv4 addressing**
The identifier used in the IPv4 layer of the TCP/IP protocol suite to identify the connection of each device to the Internet is called the **Internet address** or **IP address**. An IPv4 address is a 32-bit address that uniquely and universally defines the connection of a host or a router to the Internet. The IP address is the address of the connection, not the host or the router, because if the device is moved to another network, the IP address may be changed. IPv4 addresses are unique in the sense that each address defines one, and only one, connection to the Internet. If a device, such as a router, has several connections to the Internet, via several networks, it has several IPv4 addresses. IPv4 addresses are universal in the sense that the addressing system must be accepted by any host that wants to be connected to the Internet.

There are three common notations to show an IPv4 address: binary notation (base 2), dotted-decimal notation (base 256), and hexadecimal notation (base 16). In binary notation, an IPv4 address is displayed as 32 bits. To make the address more readable, one or more spaces are usually inserted between each octet (8 bits). Each octet is often referred to as a byte. To make the IPv4 address more compact and easier to read, it is usually written in decimal form with a decimal point (dot) separating the bytes. This format is referred to as **dotted-decimal notation**. Note that because each byte (octet) is only 8 bits, each number in the dotted-decimal notation is between 0 and 255. We sometimes see an IPv4 address in hexadecimal notation. Each hexadecimal digit is equivalent to four bits. This means that a 32-bit address has 8 hexadecimal digits. This notation is often used in network programming.

In any communication network that involves delivery, such as a telephone network or a postal network, the addressing system is hierarchical. In a postal network, the postal address (mailing address) includes the country, city, street, house number, and the name of the mail recipient. Similarly, a telephone number is divided into the country code, area code, local exchange, and the connection.
A 32-bit IPv4 address is also hierarchical, but divided only into two parts. The first part of the address, called the **prefix**, defines the network; the second part of the address, called the **suffix**, defines the node (connection of a device to the Internet). The prefix length is $n$ bits and the suffix length is $(32 - n)$ bits. The prefix and suffix lengths depend on the site of the network (organization).

**IPv4 datagram**
Packets used by the IP are called *datagrams*. A datagram is a variable-length packet consisting of two parts: header and payload (data). The header is 20 to 60 bytes in length and contains information essential to routing and delivery. Note that a byte is 8 bits.

**Internet Protocol Version 6 (IPv6)**
Some shortcomings of IPv4 such as address depletion prompted a new version of IP protocol in the early 1990s. The new version, which is called **Internet Protocol version 6 (IPv6)** or **IP new generation (IPng)** was a proposal to augment the address space of IPv4 and at the same time redesign the format of the IP packet and revise some auxiliary protocols. It is interesting to know that IPv5 was a proposal that never materialized. The following shows the main changes in the IPv6 protocol.

**IPv6 addressing**
To prevent the address depletion, IPv6 uses 128 bits to define any device connected to the Internet. An address is represented as either binary or colon-hexadecimal form. The first form is used to store an address in the computer; the second form is used by humans.
The address in IPv6 actually defines three levels of hierarchy: site (organization), subnetwork, and connection to the host.

**IPv6 datagram**
A datagram in this version is also a variable-length packet consisting of two parts: header and payload (data). The header is 40 bytes. However, some extension headers are considered part of the payload in this version.

## 6.5 DATA-LINK LAYER
The TCP/IP suite does not define any protocol in the **data-link layer**. This layer is the territory of networks that when connected make up the Internet. These networks, wired or wireless, receive services and provide services to the network layer. This may give us a clue that there are several standard protocols in the market today.
In the previous section, we learned that communication at the network layer is host-to-host. The Internet, however, is a combination of networks glued together by connecting devices (routers or switches). If a datagram is to travel from a host to another host, it needs to pass through these networks.
Communication at the data-link layer is made up of separate logical connections between the data-link layers in the path. Only one data-link layer is involved at the source or the destination, but two data-link layers are involved at each router. The reason is that source and destination computers are each connected to a single network; each router, however, takes input from one network and sends output to another network.

### 6.5.1 Nodes and links
Although communication at the application, transport, and network layers is end-to-end, communication at the data-link layer is **node-to-node**. Data units from one point in the Internet need to pass through many networks (LANs and WANs) to reach another point. These LANs and WANs are connected by routers. It is customary to refer to the two end hosts and the routers as **nodes** and the networks in between as **links**. The link that connects the nodes are either local area networks (LANs) or Wide Area Networks (WANs).

### 6.5.2 Local area networks (LANs)
In the beginning of this chapter, we learned that a local area network (LAN) is a computer network that is designed for a limited geographic area such as a building or a campus. Although a LAN can be used as an isolated network to connect computers in an organization for the sole purpose of sharing resources, most LANs today are also linked to a wide area network (WAN) or the Internet.
LANs can be wired or wireless networks. In the first group, the stations in the LANs are connected by wire; in the second group the stations are logically connected by air. We discuss each group separately.

**Wired LANS: Ethernet**
Although several wired LANs were invented in the past, only one has survived: the Ethernet. Maybe the reason is that Ethernet was upgraded several times according to the needs of the Internet community.
The Ethernet LAN was developed in the 1970s by Robert Metcalfe and David Boggs. Since then, it has gone through four generations: **Standard Ethernet** (10 Mbps), **Fast Ethernet** (100 Mbps), **Gigabit Ethernet** (1 Gbps), and **10-Gigabit Ethernet** (10 Gbps). The data rate, the speed in which bits are sent in each second, has been increased ten times in each generation.

**Standard Ethernet**
We refer to the original Ethernet technology with the data rate of 10 Mbps (ten million bits per second) as the Standard Ethernet. The data rate in this case defines the speed in which data can be sent out of the station to the LAN. In the case of the Ethernet, the speed is 10 million bits per second. The bits, however, are not sent one by one, a group of bits are packaged together and are referred to as a **frame**. A frame does not carry only data from the sender to the destination. It also carries some information such as the source address (48 bits), the destination address (48 bits), the type of data, the actual data, and some other control bits as a guard to help checking the integrity of data during transition. If we can think of a frame as an envelope carrying a letter from the sender to the receiver, the data is inside the envelope, but there is other information, such as addresses on the envelope. In the case of the LAN all are encapsulated in a frame.

**Fast Ethernet (100 Mbps)**
In the 1990s, Ethernet made a big jump by increasing the **transmission rate** to 100 Mbps, and the new generation was called the Fast Ethernet. The designers of the Fast Ethernet needed to make it compatible with the Standard Ethernet. Most of the protocol such as addressing, frame format remained unchanged. By increasing the transmission rate, features of the Standard Ethernet that depend on the transmission rate had to be revised.

**Gigabit Ethernet**
The need for an even higher data rate resulted in the design of the **Gigabit Ethernet Protocol** (1000 Mbps). The goals of the Gigabit Ethernet were to upgrade the data rate to 1 Gbps, but keep the address length, the frame format, and the maximum and minimum frame length the same.

**10-Gigabit Ethernet**
In recent years, there has been another look into the Ethernet for use in metropolitan areas. The idea is to extend the technology, the data rate, and the coverage distance so that the Ethernet can be used as LAN and MAN (**metropolitan area network**). The goals of the 10-Gigabit Ethernet design can be summarized as upgrading the data rate to 10 Gbps, keeping the same frame size and format, and allowing the interconnection of LANs, MANs, and WAN possible. This data rate is possible only with fiber-optic technology at this time.

**Wireless LANs**
Wireless communication is one of the fastest-growing technologies. The demand for connecting devices without the use of cables is increasing everywhere. Wireless LANs can be found on college campuses, in office buildings, and in many public areas. The first difference we can see between a wired and a wireless LAN is the medium. In a wired LAN, we use wires to connect hosts. In a wireless LAN, the medium is air, the signal is generally broadcast. When hosts in a wireless LAN communicate with each other, they are sharing the same medium (multiple access). Two technologies have been instrumental in this area: Wireless Ethernet and Bluetooth.

**Wireless Ethernet (WiFi)**
Institute of Electrical and Electronics Engineers (IEEE) has defined the specifications for a wireless LAN, which sometimes is referred to as wireless Ethernet or **WiFi** (short for wireless fidelity). WiFi, however, is a wireless LAN that is certified by the WiFi Alliance, a global, nonprofit industry association of more than 300 member companies. The standard defines two kinds of services: the **basic service set (BSS)** and the **extended service set (ESS)**. The second service uses an extra device (access point or AP) that serves as a switch for connection to other LANs or WANs.

**Bluetooth**
**Bluetooth** is a wireless LAN technology designed to connect devices of different functions such as telephones, notebooks, computers (desktop and laptop), cameras, printers, and even coffee makers when they are at a short distance from each other. A Bluetooth LAN is an *ad hoc* network, which means that the network is formed spontaneously; the devices, sometimes called *gadgets*, find each other and make a network called a **piconet**. A Bluetooth LAN can even be connected to the Internet if one of the gadgets has this capability. A Bluetooth LAN, by nature, cannot be large. If there are many gadgets that try to connect, there is chaos.
Bluetooth technology has several applications. Peripheral devices such as a wireless mouse or keyboard can communicate with the computer through this technology. Monitoring devices can communicate with sensor devices in a small health care center. Home security devices can use this technology to connect different sensors to the main security controller. Conference attendees can synchronize their laptop computers at a conference.
Bluetooth was originally started as a project by the Ericsson Company. It is named after Harald Blaatand, the King of Denmark (940–981) who united Denmark and Norway. *Blaatand* translates to *Bluetooth* in English.

### 6.5.3 Wide area networks (WANs)
As we discussed before, the networks connecting two nodes in the Internet can be a LAN or a WAN. As in the case of the LANs, WANs can be wired or wireless. We briefly discuss each separately.

**Wired WANs**
We have a variety of wired WANs in today’s Ethernet. Some are point-to-point and some are switched WANs.

**Point-to-point wireless WANs**
Today we can use several point-to-point wireless networks to provide what is called *last-mile* service to connect residents and businesses to the Internet.

**Dial-up service**
A dial-up network or connection uses the services provided by the telephone networks to transmit data. The telephone network had its beginnings in the late 1800s. The entire network was originally a system to transmit voice. With the advent of the computer era, the network, in the 1980s, began to carry data in addition to voice. During the last decade, the telephone network has undergone many technical changes. The need to communicate digital data resulted in the invention of the dial-up modem.
The term **modem** is a composite word that refers to the two functional entities that make up the device: a signal **modulator** and a signal **demodulator**. A modulator creates signal from data. A demodulator recovers the data from the modulated signal.

**Digital subscriber line (DSL)**
After traditional modems reached their peak data rate, telephone companies developed another technology, DSL, to provide higher-speed access to the Internet. **Digital subscriber line (DSL)** technology is one of the most promising for supporting high-speed communication over the existing telephone. DSL technology is a set of technologies, each differing in the first letter (ADSL, VDSL, HDSL, and SDSL). The set is often referred to as *xDSL*, where *x* can be replaced by A, V, H, or S. We just discuss the first, ADSL. The first technology in the set is **asymmetric DSL (ADSL)**. ADSL provides higher speed (**bit rate**) in the downstream direction (from the Internet to the resident) than in the upstream direction (from the resident to the Internet). That is the reason it is called *asymmetric*.
ADSL allows the subscriber to use the voice channel and the data channel at the same time. The rate for the upstream can reach 1.44 Mbps. However, the data rate is normally below 500 kbps because of the high-level noise in this channel. The downstream data rate can reach 13.4 Mbps. However, the data rate is normally below 8 Mbps because of noise in this channel. A very interesting point is that the telephone company in this case serves as the ISP, so services such as email or Internet access are provided by the telephone company itself.

**Cable network**
Cable networks were originally created to provide access to TV programs for those subscribers who had no reception because of natural obstructions such as mountains. Later the cable networks became popular with people who just wanted a better signal. In addition, cable networks enabled access to remote broadcasting stations via microwave connections. Cable TV also found a good market in Internet access provision, using some of the channels originally designed for video.
Cable companies are now competing with telephone companies for the residential customer who wants high-speed data transfer. DSL technology provides high-data-rate connections for residential subscribers over the local loop. However, DSL uses the existing unshielded twisted-pair cable, which is very susceptible to interference. This imposes an upper limit on the data rate. A solution is the use of the cable TV network.

**Switched wired WANs**
It is obvious that the Internet today cannot be operative with only point-to-point wired WANs that provide the last-mile connection. We need switched wired WANs to connect the backbone of the Internet. Several protocols in the past have been designed for this purpose such as SONET or ATM. However, these are complex networks, discussion of which is beyond the scope of this book.

**Wireless WANs**
The service area of the Internet is so large today that sometimes using only wired WANs cannot provide services to each corner of the world. We definitely need wireless WANs. Several technologies have been used for this purpose as described below.

**WiMax**
The **Worldwide Interoperability Access (WiMax)** is the wireless version of DSL or Cable connection to the Internet. It provides two types of services (fixed WiMax) to connect the main station to fixed station or to mobile stations such as cellular phones.

**Cellular telephony network**
Another wireless WAN today is the **cellular telephony** which was originally designed for voice communication, but it is also used today for Internet communication. We all know that the cellular network divides the earth into cells. The mobile stations communicate with the fixed antenna in the cell that they are inside at each moment. When the user moves to another cell, the communication is between the mobile device and the new antenna.

**Satellite networks**
A **satellite network** is a combination of nodes, some of which are satellites, that provides communication from one point on the Earth to another. A node in the network can be a satellite, an Earth station, or an end-user terminal or telephone.
Satellite networks are like cellular networks in that they divide the planet into cells. Satellites can provide transmission capability to and from any location on Earth, no matter how remote. This advantage makes high-quality communication available to less well-developed parts of the world without requiring a huge investment in ground-based infrastructure.

## 6.6 PHYSICAL LAYER
Our discussion of the TCP/IP protocol suite would be incomplete without the discussion of the physical layer. The role of the physical layer is to transfer the bits received from the data-link layer and convert them to electromagnetic signals for transmission. After the bits are converted to signals, the signals are delivered to the transmission media, which are the subject of our discussion in the next section.

### 6.6.1 Data and signals
At the physical layer, the communication is node-to-node, but the nodes exchange electromagnetic signals.
One of the major functions of the physical layer is to route bits between nodes. However, bits, as the representation of two possible values stored in the memory of a node (host, router, or switch), cannot be sent directly to the transmission medium (wire or air); the bits need to be changed to signals before transmission. So the main duty of the physical layer is to efficiently convert these bits into electromagnetic signals. We first need to understand the nature of the data and then the types of signals to see how we can do this conversion efficiently.

**Analog and Digital**
Data can be analog or digital. The term **analog data** refers to information that is continuous. Analog data, such as the sounds made by a human voice, take on continuous values. When someone speaks, an analog wave is created in the air. This can be captured by a microphone and converted to an analog signal or sampled and converted to a digital signal.
**Digital data** take on discrete values. For example, data are stored in computer memory in the form of 0s and 1s. They can be converted to a digital signal or modulated into an analog signal for transmission across a medium.
Like the data they represent, signals can be either analog or digital. An **analog signal** has infinitely many levels of intensity over a period of time. As the wave moves from value A to value B, it passes through and includes an infinite number of values along its path. A **digital signal**, on the other hand, can have only a limited number of defined values. Although each value can be any number, it is often as simple as 1 and 0. The simplest way to show signals is by plotting them on a pair of perpendicular axes. The vertical axis represents the value or strength of a signal. The horizontal axis represents time.

### 6.6.2 Digital transmission
A computer network is designed to send information from one point to another. This information needs to be converted to either a digital signal or an analog signal for transmission. If data is digital, we need to use **digital-to-digital conversion** techniques, methods which convert digital data to digital signals. If data is analog, we need to use **analog-to-digital conversion** techniques, methods which change an analog signal to a digital signal.

**Digital–to–digital conversion**
If our data is digital and we need to transmit digital signal, we can use digital-to-digital conversion to change the digital data to digital signal. Although there are many techniques for doing so, in its simplest form, a bit or group of bits is represented by a signal level.

**Analog-to-digital conversion**
Sometimes we have an analog signal such as one created by a microphone or camera. The tendency today is to change an analog signal to digital data because the digital signal is less susceptible to noise. Although there are several techniques for doing so, the simplest one is to sample the analog signal to create a digital data and convert the digital data to digital signal as discussed before.

### 6.6.3 Analog transmission
While digital transmission is desirable, it needs a dedicated channel; analog transmission is the only choice if we do not have a dedicated channel. For example, if we are broadcasting in the air, the air belongs to everyone, so we can use only part of the channel available. Based on the data type available, we can use either digital-to-analog or analog-to-analog conversion.

**Digital-to-analog conversion**
**Digital-to-analog conversion** is the process of changing one of the characteristics of an analog signal based on the information in digital data.

**Analog-to-analog conversion**
**Analog-to-analog conversion** is the process of changing one of the characteristics of an analog signal based on the information in digital data.

## 6.7 TRANSMISSION MEDIA
Electrical signals created at the physical layer need transmission media to go from one point to another. Transmission media are actually located below the physical layer and are directly controlled by the physical layer. We could say that transmission media belong to layer zero.
A **transmission medium** can be broadly defined as anything that can carry information from a source to a destination. For example, the transmission medium for two people having a dinner conversation is the air. The air can also be used to convey the message in a smoke signal or semaphore. For a written message, the transmission medium might be a mail carrier, a truck, or an airplane.
In telecommunications, transmission media can be divided into two broad categories: guided and unguided. Guided media include twisted-pair cable, coaxial cable, and fiber-optic cable. Unguided medium is free space.

### 6.7.1 Guided media
**Guided media**, which are those that provide a conduit from one device to another, include **twisted-pair cable**, **coaxial cable**, and **fiber-optic cable**.

**Twisted-pair cable**
A twisted-pair consists of two conductors (normally copper), each with its own plastic insulation, twisted together. One of the wires is used to carry signals to the receiver, and the other is used only as a ground reference. The receiver uses the difference between the two.
In addition to the signal from the sender, interference (noise) may affect both wires and create unwanted signals. If the two wires are parallel, the effect of these unwanted signals is not the same in both wires because they are at different locations relative to the noise sources. By twisting the pairs, a balance is maintained.
The DSL lines that are used by the telephone companies to provide high-data-rate connections are also twisted-pair cables.

**Coaxial cable**
Instead of having two wires, coax has a central core conductor of solid or stranded wire (usually copper) enclosed in an insulating sheath, which is, in turn, encased in an outer conductor of metal foil, braid, or a combination of the two. The outer metallic wrapping serves both as a shield against noise and as the second conductor, which completes the circuit. This outer conductor is also enclosed in an insulating sheath, and the whole cable is protected by a plastic cover.
Cable TV networks use coaxial cable. In the traditional cable TV network, the entire network used coaxial cable. Later, however, cable TV providers replaced most of the media with fiber-optic cable; hybrid networks use coaxial cable only at the network boundaries, near the consumer premises.

**Fiber-optic cable**
A fiber-optic cable is made of glass or plastic and transmits signals in the form of light. This technology uses the property of a beam of light that is refracted (comes back) when it encounters a medium of less density. Covering a glass or plastic medium by another less dense medium (called cladding) guides the light through the medium.
Fiber-optic cable is often found in backbone networks because its wide bandwidth is cost-effective.

### 6.7.2 Unguided media: wireless
Unguided media transport electromagnetic waves without using a physical conductor. This type of communication is often referred to as **wireless communication**. Signals are normally broadcast through free space and thus are available to anyone who has a device capable of receiving them.
Communication today uses three different ranges of electromagnetic spectrum: radio waves, microwaves, and infrared.

**Radio waves**
Electromagnetic waves ranging in frequencies between 3 kHz and 1 GHz are normally called **radio waves**. They are used mostly for radio communication.

**Microwaves**
Electromagnetic waves having frequencies between 1 and 300 GHz are called **microwaves**. Microwaves are unidirectional. When an antenna transmits microwaves, they can be narrowly focused. This means that the sending and receiving antennas need to be aligned. The unidirectional property has an obvious advantage. A pair of antennas can be aligned without interfering with another pair of aligned antennas.

**Infrared**
**Infrared waves**, with frequencies from 300 GHz to 400 THz (wavelengths from 1 mm to 770 nm), can be used for short-range communication. Infrared waves, having high frequencies, cannot penetrate walls. This advantageous characteristic prevents interference between one system and another; a short-range communication system in one room cannot be affected by another system in the next room. When we use our infrared remote control, we do not interfere with the use of the remote by our neighbors. However, this same characteristic makes infrared signals useless for long-range communication. In addition, we cannot use infrared waves outside a building because the sun’s rays contain infrared waves that can interfere with the communication.

## 6.8 END-CHAPTER MATERIALS
### 6.8.1 Recommended reading
For more details about subjects discussed in this chapter, the following books are recommended:
- Forouzan, B. and Mosharrf, F. *Computer Networks: A Top-Down Approach*, New York: McGraw-Hill Education, 2012
- Forouzan, B. *Data Communication and Networking*, New York: McGraw-Hill Education, 2013
- Forouzan, B. *TCP/IP Protocol Suite*, New York: McGraw-Hill Education, 2010
- Forouzan, B. *Local Area Networks*, New York: McGraw-Hill Education, 2003
- Kurose, J. and Ross, K. *Computer Networking*, Reading, MA: Addison-Wesley, 2007

### 6.8.2 Key terms
- 10-Gigabit Ethernet
- analog-to-analog conversion
- analog-to-digital conversion
- analog data
- analog signal
- application layer
- bit rate
- Bluetooth
- cellular telephony
- ciphertext
- client–server paradigm
- coaxial cable
- connecting device
- connectionless protocol
- country domain
- demodulator
- digital-to-analog conversion
- digital-to-digital conversion
- digital data
- digital signal
- digital subscriber line (DSL)
- domain name
- Domain Name System (DNS)
- domain name space
- dotted-decimal notation
- electronic mail (email)
- end system
- ephemeral port number
- Fast Ethernet
- fiber-optic cable
- File Transfer Protocol (FTP)
- frame
- generic domain
- Gigabit Ethernet
- guided media
- hardware
- header
- host
- host identifier
- hypertext
- HyperText Markup Language (HTML)
- HyperText Transfer Protocol (HTTP)
- infrared waves
- internet
- Internet
- Internet address
- Internet Protocol
- Internet Protocol version 6 (IPv6)
- internet service provider (ISP)
- Internetwork
- IP address
- IP datagram
- IP new generation (IPng)
- link
- local area network (LAN)
- Message Access Agent (MAA)
- message transfer agent (MTA)
- metropolitan area network (MAN)
- modem
- modularity
- modulator
- module
- name space
- network layer
- node
- packetizing
- peer-to-peer (P2P) paradigm
- physical layer
- port number
- protocol
- protocol layering
- remote login
- router
- Secure Shell (SHH)
- segment
- software
- source to destination delivery
- Standard Ethernet
- switch
- switched WAN
- TCP/IP protocol suite
- TELNET (terminal network)
- Transmission Control Protocol (TCP)
- transmission medium
- transmission rate
- twisted-pair cable
- unguided media
- uniform resource locator (URL)
- user agent (UA)
- user datagram
- User Datagram Protocol (UDP)
- web page
- well-known port number
- wide area network (WAN)
- Worldwide Interoperability Access (WiMAX)
- World Wide Web (WWW)
- write once, read many (WORM)

### 6.8.3 Summary
- A network is a set of devices connected by communication links. Today when we speak of networks, we are generally referring to two primary categories: local area networks and wide area networks. The Internet today is made up of many wide and local area networks joined by connecting devices and switching stations. A protocol is a set of rules that governs communication. TCP/IP is a hierarchical protocol suite made of five layers: application, transport, network, data-link, and physical.
- Applications in the Internet are designed using either a client–server paradigm or a peer-to-peer paradigm. The World Wide Web (WWW) is a repository of information linked together from points all over the world. The HyperText Transfer Protocol (HTTP) is the main protocol used to access data on the World Wide Web (WWW). File Transfer Protocol (FTP) is a TCP/IP client–server application for copying files from one host to another. Electronic mail is one of the most common applications on the Internet. TELNET is a client–server application that allows a user to log into a remote machine, giving the user access to the remote system. The Domain Name System (DNS) is a client–server application that identifies each host on the Internet with a unique name.
- The main duty of a transport-layer protocol is to provide process-to-process communication. UDP is a transport protocol that provides unreliable and connectionless service. Transmission Control Protocol (TCP) is another transport-layer protocol that provides reliable and connection-oriented service.
- The network layer supervises the handling of packets by the underlying physical networks. IPv4 is an unreliable connectionless protocol responsible for source-to-destination delivery. The identifiers used in the IP layer of the TCP/IP protocol suite are called the IP addresses. An IPv4 address is 32 bits long. IPv6, the latest version of the Internet Protocol, has a 128-bit address space.
- The data-link layer involves local and wide area networks (LANs and WANs). LANs and WANs can be wired or wireless. Ethernet is the most widely used wired local area network protocol. Dial-up service, DSL, and cable are mostly used for point-to-point wired WANs. Wireless LANs became formalized with wireless Ethernet. Bluetooth is a wireless LAN technology that connects devices (called gadgets) in a small area. WiMAX is a wireless access network that may replace DSL and cable in the future.
- Data must be transformed to electromagnetic signals to be transmitted. Analog data are continuous and take continuous values. Digital data have discrete states and take discrete values. Digital-to-digital conversion changes digital data to digital signal. Digital-to-analog conversion is the process of changing digital data to analog signal. Analog-to-digital conversion is the process of sampling analog data and changing it to digital signal. Analog-to-analog signal means changing analog data to analog signal.
- Transmission media lie below the physical layer. A guided medium provides a physical conduit from one device to another. Twisted-pair cable, coaxial cable, and optical fiber are the most popular types of guided media. Unguided media (free space) transport electromagnetic waves without the use of a physical conductor.
`,zh:`
# 第六章：電腦網路與網際網路

個人電腦的發展為商業、工業、科學和教育帶來了巨大的變革。網路領域也發生了類似的革命。技術進步使得通訊連結能夠傳輸更多且更快的信號。因此，服務正在演進以允許使用這種擴展的容量。該領域的研究產生了新技術。一個目標是能夠交換來自世界各地的資料，如文字、音訊和視訊。我們希望隨時隨地快速準確地存取網際網路以下載和上傳資訊。

## 學習目標
學完本章後，學生應能：
- 描述區域網路 (LAN) 和廣域網路 (WAN)。
- 區分 internet (互連網) 和 Internet (網際網路)。
- 描述作為網際網路中網路模型的 TCP/IP 協定套件。
- 定義 TCP/IP 協定套件中的各層及其關係。
- 描述應用層的一些應用程式。
- 描述傳輸層協定提供的服務。
- 描述網路層協定提供的服務。
- 描述資料連結層使用的不同協定。
- 描述實體層的職責。
- 描述電腦網路中使用的不同傳輸介質。

## 6.1 概覽
雖然本章的目標是討論網際網路，一個互連世界上數十億台電腦的系統，但我們不將網際網路視為單一網路，而是一個**互連網 (internetwork)**，即網路的組合。因此，我們首先定義網路，開始我們的旅程。然後我們展示如何連接網路以創建小型互連網。最後，我們展示網際網路的結構，並在本章的其餘部分開啟學習網際網路的大門。

### 6.1.1 網路
**網路**是一組能夠通訊的設備的互連。在這個定義中，設備可以是**主機**（或有時稱為**終端系統**），例如大型電腦、桌上型電腦、筆記型電腦、工作站、行動電話或安全系統。這個定義中的設備也可以是**連接設備**，例如連接網路與其他網路的**路由器**、連接設備的**交換器**、改變資料形式的**數據機**（調變解調器）等等。網路中的這些設備使用有線或無線傳輸介質（如電纜或空氣）連接。當我們在家中使用隨插即用的路由器連接兩台電腦時，我們就建立了一個網路，雖然非常小。

**區域網路**
**區域網路 (LAN)** 通常為私人擁有，連接單一辦公室、建築物或校園內的一些主機。根據組織的需求，LAN 可以簡單到某人家庭辦公室中的兩台 PC 和一台印表機，也可以擴展到整個公司並包括音訊和視訊設備。LAN 中的每台主機都有一個標識符，一個位址，唯一地定義了 LAN 中的主機。主機發送給另一台主機的封包包含來源主機和目的主機的位址。

**廣域網路**
**廣域網路 (WAN)** 也是能夠通訊的設備互連。然而，LAN 和 WAN 之間存在一些差異。LAN 通常在規模上受到限制，跨越辦公室、建築物或校園；WAN 的地理範圍更廣，跨越城鎮、州、國家，甚至全世界。LAN 互連主機；WAN 互連連接設備，如交換器、路由器或數據機。LAN 通常由使用它的組織私有；WAN 通常由通訊公司建立和運營，並由使用它的組織租賃。我們今天看到兩種不同的 WAN 範例：**點對點 WAN** 和 **交換式 WAN**。

一個**點對點 WAN** 是一個透過傳輸介質（電纜或空氣）連接兩個通訊設備的網路。

一個**交換式 WAN** 是一個具有兩個以上端點的網路。我們稍後將看到，交換式 WAN 用於當今全球通訊的主幹。我們可以說交換式 WAN 是由交換器連接的數個點對點 WAN 的組合。

**互連網**
今天，很難看到孤立的 LAN 或 WAN；它們彼此連接。當兩個或多個網路連接時，它們構成一個**互連網 (internetwork)** 或 **internet**。舉例來說，假設一個組織有兩個辦公室。每個辦公室都有一個 LAN，允許辦公室內的所有員工相互通訊。為了使不同辦公室的員工能夠通訊，管理層從服務提供商（如電話公司）租賃了一條點對點專用 WAN，並連接了這兩個 LAN。現在該公司擁有一個互連網，或私人 internet（小寫 i）。辦公室之間的通訊現在成為可能。

### 6.1.2 網際網路 (The Internet)
如前所述，internet（注意小寫 i）是可以相互通訊的兩個或多個網路。最著名的互連網稱為 **Internet**（大寫 I），由成千上萬個互連的網路組成。

網際網路主要由**骨幹網路 (backbones)**、**提供者網路 (provider networks)** 和 **客戶網路 (customer networks)** 組成。在頂層，**骨幹網路**是由一些通訊公司擁有的大型網路。骨幹網路透過一些複雜的交換系統連接，稱為**對等點 (peering points)**。在第二層，有較小的網路，稱為**提供者網路**，它們付費使用骨幹網路的服務。提供者網路連接到骨幹網路，有時也連接到其他提供者網路。**客戶網路**是位於網際網路邊緣的網路，實際使用網際網路提供的服務。它們向提供者網路支付費用以接收服務。

骨幹網路和提供者網路也稱為**網際網路服務提供者 (ISPs)**。骨幹網路通常被稱為國際 ISP；提供者網路通常被稱為國家或區域 ISP。

### 6.1.3 硬體與軟體
我們已經概述了網際網路的結構，它由小型和大型網路透過連接設備黏合在一起組成。然而，應該清楚的是，如果我們只連接這些部件，什麼也不會發生。為了進行通訊，我們需要**硬體**和**軟體**。這類似於複雜的計算，我們既需要電腦也需要程式。在下一節中，我們將展示如何使用*協定分層*來協調這些硬體和軟體的組合。

### 6.1.4 協定分層
當我們談論網際網路時，我們一直聽到的一個詞是*協定*。**協定**定義了發送方和接收方以及所有中間設備需要遵循的規則，以便有效地進行通訊。當通訊簡單時，我們可能只需要一個簡單的協定；當通訊複雜時，我們可能需要將任務分配給不同的層，在這種情況下，我們需要在每一層都有一個協定，即**協定分層**。

**一個情境**
讓我們發展一個簡單的情境來更好地理解協定分層的需求。假設 Ann 和 Maria 是鄰居，有很多共同的想法。她們每次見面都會交流關於退休後的一個專案。突然，Ann 在公司獲得了更高層級的職位，但需要搬到離 Maria 很遠的另一個城市的據點。這兩位朋友仍然想繼續溝通並交流想法，因為她們已經想出了一個創新專案，打算在退休後開始新業務。她們決定透過郵局的普通郵件繼續對話。然而，她們不希望如果信件被攔截，想法會洩露給其他人。她們同意使用一種加密/解密技術。發送者加密信件使其對入侵者不可讀；接收者解密信件以獲取原始信件。我們在第 16 章討論加密/解密方法，但目前我們假設 Maria 和 Ann 使用一種技術，如果沒有解密金鑰就很難解密信件。現在我們可以說 Maria 和 Ann 之間的通訊發生在三個層次。我們假設 Ann 和 Maria 各有三台機器（或機器人）可以在每一層執行任務。

假設 Maria 給 Ann 發送了第一封信。Maria 像是在對 Ann 說話一樣對第三層的機器說話。第三層機器聽 Maria 說什麼並創建明文（一封英文信），然後傳遞給第二層機器。第二層機器獲取明文，對其進行加密，並創建**密文 (ciphertext)**，然後傳遞給第一層機器。第一層機器，大概是一個機器人，獲取密文，將其放入信封中，添加發送者和接收者地址，然後郵寄出去。
在 Ann 那邊，第一層機器從 Ann 的信箱中取信，透過發送者地址識別出來自 Maria 的信。機器從信封中取出密文並將其傳遞給第二層機器。第二層機器解密訊息，創建明文，並將明文傳遞給第三層機器。第三層機器獲取明文並像 Maria 在說話一樣讀出它。

協定分層使我們能夠將複雜的任務劃分為幾個更小、更簡單的任務。例如，我們本可以使用一台機器來完成所有三台機器的工作。然而，如果 Maria 和 Ann 決定機器所做的加密/解密不足以保護其機密，她們必須更換整台機器。在目前的情況下，她們只需要更換第二層機器；其他兩台可以保持不變。這稱為**模組化 (modularity)**。在這種情況下，模組化意味著獨立的層。層（**模組**）可以定義為具有輸入和輸出的黑盒子，而不必關心輸入如何變為輸出。如果兩台機器在給定相同輸入時提供相同的輸出，它們就可以相互替換。例如，Ann 和 Maria 可以從不同的製造商購買第二層機器。只要這兩台機器能從相同的明文創建相同的密文，反之亦然，它們就能完成工作。

協定分層的優點之一是它允許我們將服務與實作分開。一層需要能夠從下層接收一組服務並向上層提供服務；我們不關心該層是如何實作的。例如，Maria 可能決定不購買第一層的機器（機器人）；她可以自己做這項工作。只要 Maria 能執行第一層提供的任務，無論是哪個方向，通訊系統就能運作。

協定分層的另一個優點在我們的簡單範例中看不到，但在我們討論網際網路中的協定分層時會顯現出來，那就是通訊並不總是只使用兩個終端系統；有一些中間系統只需要某些層，而不是所有層。如果我們不使用協定分層，我們就必須使每個中間系統都像終端系統一樣複雜，這會使整個系統更加昂貴。

協定分層有什麼缺點嗎？有人可能會說，擁有單一層會讓工作更容易。不需要每一層都向上層提供服務並向下層提供服務。例如，Ann 和 Maria 可以找到或建造一台能完成所有三項任務的機器。然而，如上所述，如果有一天她們發現代碼被破解，她們每個人都必須更換整台機器，而不是僅僅更換第二層的機器。

**協定分層原則**
讓我們討論協定分層的一些原則。第一個原則規定，如果我們想要雙向通訊，我們需要使每一層能夠執行兩個相反的任務，每個方向一個。例如，第三層的任務是*聽*（在一個方向上）和*說*（在另一個方向上）。第二層需要能夠加密和解密。第一層需要發送和接收郵件。
我們在協定分層中需要遵循的第二個重要原則是，雙方每一層下的兩個物件應該是相同的。例如，雙方第 3 層下的物件應該是明文信件。雙方第 2 層下的物件應該是密文信件。雙方第 1 層下的物件應該是一封郵件。

**邏輯連接**
遵循上述兩個原則後，我們可以考慮每一層之間的邏輯連接。這意味著我們有層對層的通訊。Maria 和 Ann 可以認為每一層都有一個邏輯（想像的）連接，透過它她們可以發送從該層創建的物件。我們將看到邏輯連接的概念將幫助我們更好地理解我們在資料通訊和網路中遇到的分層任務。

### 6.1.5 TCP/IP 協定套件
現在我們知道了協定分層的概念和層之間的邏輯通訊，我們可以介紹 **TCP/IP (傳輸控制協定/網際網路協定)**。TCP/IP 是今天網際網路中使用的一組協定（組織在不同層中的一組協定）。它是一個由互動模組組成的分層協定，每個模組提供特定的功能。術語*分層*意味著每個上層協定都由一個或多個下層協定提供的服務所支援。TCP/IP 協定套件由五層組成：
1.  **應用層** (第 5 層)
2.  **傳輸層** (第 4 層)
3.  **網路層** (第 3 層)
4.  **資料連結層** (第 2 層)
5.  **實體層** (第 1 層)

**分層架構**
為了展示 TCP/IP 協定套件中的層如何參與兩台主機之間的通訊，我們假設我們要在一個由三個 LAN（連結）組成的小型互連網中使用該套件，每個 LAN 都有一個連結層交換器。我們還假設這些連結由一個路由器連接。

讓我們假設電腦 A 與電腦 B 通訊。在此通訊中有五個通訊設備：來源主機（電腦 A）、連結 1 中的連結層交換器、路由器、連結 2 中的連結層交換器和目的主機（電腦 B）。每個設備根據其在互連網中的角色參與一組層。兩台主機參與所有五層；來源主機需要在**應用層**建立訊息並將其向下發送，以便實體發送到目的主機。目的主機需要在**實體層**接收通訊，然後透過其他層將其傳遞到應用層。

路由器只參與三層；只要路由器僅用於**路由**，路由器中就沒有傳輸層或應用層。雖然路由器總是參與一個網路層，但它參與 $n$ 個連結層和實體層的組合，其中 $n$ 是路由器連接的連結數。原因是每個連結可能使用自己的資料連結或實體協定。每個連結可能使用不同的連結層和實體層協定；路由器需要根據一對協定從連結 1 接收封包，並根據另一對協定將其傳遞到連結 2。

然而，連結中的連結層交換器只參與兩層：資料連結層和實體層。雖然每個交換器有兩個不同的連接，但這些連接在同一個連結中，只使用一組協定。這意味著，與路由器不同，連結層交換器只參與一個資料連結層和一個實體層。

**定址和封包名稱**
值得一提的是與網際網路中協定分層相關的另外兩個概念：*定址*和*封包名稱*。如前所述，我們在此模型中具有成對層之間的邏輯通訊。任何涉及雙方的通訊都需要兩個位址：來源位址和目的位址。雖然看起來我們需要五對位址，每一層一對，但我們通常只有四對，因為實體層不需要位址；實體層的資料交換單位是位元，這絕對不可能有位址。

層、該層使用的位址和該層的封包名稱之間存在關係。在應用層，我們通常使用**名稱**來定義提供服務的站點，例如 *someorg.com*，或電子郵件地址，例如 *somebody@coldmail.com*。此層的封包名稱是**訊息 (message)**。
在傳輸層，位址稱為**埠號 (port numbers)**，這些定義了來源和目的地的應用層程式。埠號是區分同時運行的多個程式的本地位址。此層的封包名稱是**區段 (segment)** 或**使用者資料包 (user datagram)**。
在**網路層**，位址是**邏輯位址**（全域），範圍是整個網際網路。網路層位址唯一地定義了設備到網際網路的連接。封包名稱是**資料包 (datagram)**。
連結層位址，有時稱為 **MAC 位址**或**連結層位址**，是本地定義的位址，每個位址定義網路（LAN 或 WAN）中的特定主機或路由器。封包名稱是**訊框 (frame)**。
在實體層，單位是**位元 (bit)**。

## 6.2 應用層
在簡要討論了網路、互連網和網際網路之後，我們準備討論 TCP/IP 協定的每一層。我們從第五層開始，向下移動到第一層。

TCP/IP 協定的第五層稱為應用層。應用層為使用者提供服務。通訊是使用邏輯連接提供的，這意味著兩個應用層假設有一個想像的直接連接，透過它它們可以發送和接收訊息。

考慮一個情境，Sky Research 研究公司的科學家需要從線上書店 Scientific Books 訂購一本與其研究相關的書。邏輯連接發生在 Sky Research 的電腦的應用層和 Scientific Books 伺服器的應用層之間。我們稱第一台主機為 Alice，第二台為 Bob。應用層的通訊是邏輯的，而非實體的。Alice 和 Bob 假設他們之間有一個雙向邏輯通道，透過該通道他們可以發送和接收訊息。然而，實際通訊是透過多個設備和多個實體通道進行的。

### 6.2.1 提供服務
應用層與其他層有些不同，它是套件中的最高層。此層中的協定不向套件中的任何其他協定提供服務；它們只接收傳輸層協定提供的服務。這意味著可以輕鬆地從此層移除協定。只要新協定可以使用傳輸層協定之一提供的服務，也可以將新協定新增至此層。

由於應用層是唯一向網際網路使用者提供服務的層，如上所述，應用層的靈活性允許輕鬆地向網際網路添加新的應用協定，這在網際網路的生命週期中一直在發生。當網際網路創建時，只有少數應用協定可供使用者使用；今天我們無法給出這些協定的數量，因為新的協定不斷被添加。

### 6.2.2 應用層範式
顯然，要使用網際網路，我們需要兩個應用程式相互互動：一個在世界某處的電腦上運行，另一個在世界其他地方的另一台電腦上運行。這兩個程式需要透過網際網路基礎設施相互發送訊息。然而，我們尚未討論這些程式之間的關係應該是什麼。兩個應用程式都應該能夠請求服務並提供服務，還是應用程式只應該做其中之一？在網際網路的生命週期中已經開發了兩種範式來回答這個問題：*主從式 (client-server) 範式*和*點對點 (peer-to-peer) 範式*。我們在此簡要介紹這兩種範式。

**傳統範式：主從式**
傳統範式稱為**主從式範式**。直到幾年前，它一直是最流行的範式。在這種範式中，服務提供者是一個應用程式，稱為**伺服器行程 (server process)**；它持續運行，等待另一個應用程式，稱為**客戶端行程 (client process)**，透過網際網路建立連接並請求服務。通常有一些伺服器行程可以提供特定類型的服務，但有許多客戶端請求任何這些伺服器行程的服務。伺服器行程必須一直運行；客戶端行程在客戶端需要接收服務時啟動。

雖然主從式範式中的通訊是在兩個應用程式之間進行的，但每個程式的角色完全不同。換句話說，我們不能將客戶端程式作為伺服器程式運行，反之亦然。

這種範式的一個問題是通訊負載集中在伺服器肩上，這意味著伺服器應該是一台功能強大的電腦。即使是一台功能強大的電腦，如果大量客戶端試圖同時連接到伺服器，也可能會不堪重負。另一個問題是，必須有一個服務提供者願意承擔成本並為特定服務創建一個強大的伺服器，這意味著服務必須始終為伺服器帶來某種類型的收入，以鼓勵這種安排。

一些傳統服務仍在使用這種範式，包括**全球資訊網 (WWW)** 及其載具 **超文本傳輸協定 (HTTP)**、檔案傳輸協定 (FTP)、安全殼層 (SSH)、電子郵件等。我們將在本章稍後討論其中一些協定和應用程式。

**新範式：點對點**
一種稱為**點對點範式**（通常縮寫為 **P2P 範式**）的新範式已經出現，以回應某些新應用程式的需求。在這種範式中，不需要伺服器行程一直運行並等待客戶端行程連接。責任在對等點之間共享。連接到網際網路的電腦可以在某個時間提供服務，在另一個時間接收服務。電腦甚至可以同時提供和接收服務。

真正適合這種範式的一個領域是網際網路電話。電話通訊確實是一種點對點活動；沒有一方需要永遠運行等待另一方呼叫。可以使用點對點範式的另一個領域是當連接到網際網路的一些電腦有東西要彼此分享時。例如，如果一個網際網路使用者有一個檔案可供其他網際網路使用者分享，則無需檔案持有者成為伺服器並一直運行伺服器行程等待其他使用者連接並檢索檔案。

雖然點對點範式已被證明易於擴展且在消除一直運行和維護昂貴伺服器的需求方面具成本效益，但也存在一些挑戰。主要挑戰一直是**安全性**；在分散式服務之間建立安全通訊比在由專用伺服器控制的服務之間建立安全通訊更困難。另一個挑戰是適用性；似乎並非所有應用程式都能使用這種新範式。例如，如果有一天 Web 可以實作為點對點服務，並非許多網際網路使用者都準備好參與其中。

### 6.2.3 標準主從式應用
在網際網路的生命週期中，已經開發了幾個主從式應用程式。我們不必重新定義它們，但我們需要了解它們做什麼。我們在本節中選擇了六個標準應用程式。我們從 HTTP 和全球資訊網開始，因為幾乎所有網際網路使用者都在使用它們。然後我們介紹在網際網路上具有高流量負載的檔案傳輸和電子郵件應用程式。接下來，我們解釋遠端登入以及如何使用 TELNET 和 SSH 協定來實現。最後，我們討論 DNS，所有應用程式都使用它將應用層標識符映射到相應的主機 IP 位址。

**全球資訊網和 HTTP**
在本節中，我們首先介紹全球資訊網（縮寫為 WWW 或 Web）。然後我們討論超文本傳輸協定 (HTTP)，這是與 Web 相關的最常見的主從式應用程式。

**全球資訊網**
今天的 Web 是一個資訊儲存庫，其中的文件（稱為**網頁**）分佈在世界各地，相關文件連結在一起。Web 的流行和增長與上述陳述中的兩個術語有關：分佈式和連結。分佈允許 Web 的增長。世界上的每個網頁伺服器都可以向儲存庫添加新網頁並向所有網際網路使用者宣佈，而不會使少數伺服器過載。連結允許一個網頁引用儲存世界其他地方的另一個伺服器中的另一個網頁。網頁連結是使用稱為**超文本 (hypertext)** 的概念實現的，該概念在網際網路出現之前許多年就已引入。這個想法是使用一台機器，當文件中出現指向另一個文件的連結時，自動檢索儲存在系統中的該文件。Web 以電子方式實現了這個想法：允許在使用者點擊連結時檢索連結的文件。今天，超文本一詞（意指連結的文字文件）已更改為**超媒體 (hypermedia)**，以表明網頁可以是文字文件、圖像、音訊檔案或視訊檔案。

今天的 WWW 是一個分散式主從式服務，其中使用**瀏覽器**的客戶端可以存取使用伺服器的服務。然而，提供的服務分佈在許多稱為*站點*的位置。每個站點持有一份或多份文件，稱為**網頁**。然而，每個網頁都可以包含一些指向相同或不同站點中其他網頁的連結。換句話說，網頁可以是簡單的或複合的。簡單網頁沒有指向其他網頁的連結；複合網頁有一個或多個指向其他網頁的連結。每個網頁都是一個具有名稱和位址的檔案。

**Web 客戶端（瀏覽器）**
各種供應商提供商業**瀏覽器**來解釋和顯示網頁，所有這些瀏覽器都使用幾乎相同的架構。每個瀏覽器通常由三個部分組成：控制器、客戶端協定和直譯器。
控制器接收來自鍵盤或滑鼠的輸入，並使用客戶端程式存取文件。存取文件後，控制器使用其中一個直譯器在螢幕上顯示文件。客戶端協定可以是稍後描述的協定之一，例如 HTTP 或 FTP。直譯器可以是**超文本標記語言 (HTML)**、Java 或 JavaScript，具體取決於文件類型。一些商業瀏覽器包括 Internet Explorer、Netscape Navigator 和 Firefox。

**Web 伺服器**
網頁儲存在伺服器上。每當請求到達時，相應的文件就會發送給客戶端。

**統一資源定位器 (URL)**
網頁作為一個檔案，需要有一個唯一的標識符以區別於其他網頁。為了定義網頁，我們需要三個標識符：*主機*、*埠*和*路徑*。然而，在定義網頁之前，我們需要告訴瀏覽器我們想要使用什麼主從式應用程式，這稱為*協定*。這意味著我們需要四個標識符來定義網頁。第一個是用於獲取網頁的載具類型；後三個組成了定義目的地物件（網頁）的組合。
- **協定**。第一個標識符是我們需要用來存取網頁的主從式程式的縮寫。
- **主機標識符**。主機標識符可以是伺服器的 IP 位址或給予伺服器的唯一名稱。
- **埠號**。埠是一個 16 位元整數，通常為主從式應用程式預定義。
- **路徑**。路徑標識檔案在底層作業系統中的位置和名稱。此標識符的格式通常取決於作業系統。在 UNIX 中，路徑是一組目錄名稱，後跟檔案名稱，全部由斜線分隔。
為了將這四個部分結合在一起，設計了**統一資源定位器 (URL)**；它使用三個不同的分隔符號在四個部分之間，如下所示：
\`protocol://host:port/path\`

**超文本傳輸協定 (HTTP)**
**超文本傳輸協定 (HTTP)** 是一個協定，用於定義如何編寫主從式程式以從 Web 檢索網頁。HTTP 客戶端發送請求；HTTP 伺服器返回回應。伺服器使用埠號 80；客戶端使用臨時埠號。

**6.2.4 檔案傳輸協定 (FTP)**
**檔案傳輸協定 (FTP)** 是 TCP/IP 提供的標準協定，用於將檔案從一台主機複製到另一台主機。雖然將檔案從一個系統傳輸到另一個系統看起來簡單直接，但必須先處理一些問題。例如，兩個系統可能使用不同的檔案命名慣例。兩個系統可能有不同的資料表示方式。兩個系統可能有不同的目錄結構。所有這些問題都由 FTP 以非常簡單優雅的方法解決了。

客戶端有三個組件：使用者介面、客戶端控制行程和客戶端資料傳輸行程。伺服器有兩個組件：伺服器控制行程和伺服器資料傳輸行程。控制連接在控制行程之間建立。資料連接在資料傳輸行程之間建立。
命令和資料傳輸的分離使 FTP 更有效率。控制連接使用非常簡單的通訊規則。我們一次只需要傳輸一行命令或一行回應。另一方面，由於傳輸的資料類型多樣，資料連接需要更複雜的規則。

**兩個連接的生命週期**
FTP 中的兩個連接有不同的生命週期。控制連接在整個互動式 FTP 會話期間保持連接。資料連接在每次檔案傳輸活動中打開然後關閉。每當使用涉及傳輸檔案的命令時，它就會打開，並在檔案傳輸時關閉。換句話說，當使用者啟動 FTP 會話時，控制連接打開。當控制連接打開時，如果傳輸多個檔案，資料連接可以打開和關閉多次。

**6.2.5 電子郵件**
**電子郵件**（或 **email**）允許使用者交換訊息。然而，此應用程式的性質與目前討論的其他應用程式不同。在 HTTP 或 FTP 等應用程式中，伺服器程式一直運行，等待來自客戶端的請求。當請求到達時，伺服器提供服務。有一個請求和一個回應。在電子郵件的情況下，情況有所不同。首先，電子郵件被認為是單向交易。當 Alice 發送電子郵件給 Bob 時，她可能期望回應，但這不是強制性的。Bob 可能回應也可能不回應。如果他回應，那就是另一個單向交易。其次，Bob 運行伺服器程式並等待有人發送電子郵件給他是不可行也不合邏輯的。Bob 在不使用電腦時可能會關閉電腦。這意味著主從式程式設計的想法應該以另一種方式實現：使用一些中間電腦（伺服器）。使用者只在想要時運行客戶端程式，中間伺服器應用主從式範式。

**架構**
為了解釋電子郵件的架構，我們給出一個常見場景。
在常見場景中，電子郵件的發送者和接收者（分別為 Alice 和 Bob）透過 LAN 或 WAN 連接到兩個郵件伺服器。管理員為每個使用者創建了一個**信箱**，用於儲存接收到的訊息。信箱是伺服器硬碟的一部分，是一個具有權限限制的特殊檔案。只有信箱的所有者才有權存取它。管理員還創建了一個佇列（spool）來儲存等待發送的訊息。
一封來自 Alice 給 Bob 的簡單電子郵件需要九個不同的步驟。Alice 和 Bob 使用三種不同的代理：**使用者代理 (UA)**、**郵件傳輸代理 (MTA)** 和 **訊息存取代理 (MAA)**。當 Alice 需要發送訊息給 Bob 時，她運行 UA 程式準備訊息並將其發送到她的郵件伺服器。她站點的郵件伺服器使用佇列（spool）來儲存等待發送的訊息。然而，訊息需要使用 MTA 透過網際網路從 Alice 的站點發送到 Bob 的站點。這裡需要兩個郵件傳輸代理：一個客戶端和一個伺服器。像網際網路上大多數主從式程式一樣，伺服器需要一直運行，因為它不知道客戶端何時會請求連接。另一方面，當佇列中有訊息要發送時，系統可以觸發客戶端。Bob 站點的使用者代理允許 Bob 閱讀接收到的訊息。Bob 隨後使用 MAA 客戶端從在第二個伺服器上運行的 MAA 伺服器檢索訊息。
Bob 需要另一對主從式程式：訊息存取程式。這是因為 MTA 主從式程式是一個*推送*程式：客戶端將訊息推送到伺服器。Bob 需要一個*拉取*程式。客戶端需要從伺服器拉取訊息。

**6.2.6 TELNET**
伺服器程式可以向其對應的客戶端程式提供特定服務。例如，FTP 伺服器旨在讓 FTP 客戶端在伺服器站點儲存或檢索檔案。然而，不可能為我們需要的每種類型的服務都擁有一對主從式程式；伺服器的數量很快就會變得難以處理。這個想法是不可擴展的。另一種解決方案是為一組常見場景擁有特定的主從式程式，但也擁有一些通用的主從式程式，允許客戶端站點的使用者登入伺服器站點的電腦並使用那裡可用的服務。例如，如果學生需要使用她大學實驗室的 Java 編譯器程式，則無需 Java 編譯器客戶端和 Java 編譯器伺服器。學生可以使用客戶端登入程式登入大學伺服器並在大學使用編譯器程式。我們將這些通用的主從式對稱為**遠端登入**應用程式。
最初的遠端登入協定之一是 **TELNET**，它是 TErminaL NETwork 的縮寫。雖然 TELNET 需要登入名稱和密碼，但它很容易受到駭客攻擊，因為它以明文（未加密）發送包括密碼在內的所有資料。駭客可以竊聽並獲取登入名稱和密碼。由於這個安全問題，TELNET 的使用已經減少，取而代之的是另一種協定，安全殼層 (SSH)。

**6.2.7 安全殼層 (SSH)**
雖然**安全殼層 (SSH)** 是一個安全的應用程式，今天可用於多種用途，如遠端登入和檔案傳輸，但它最初設計是用來取代 TELNET。SSH 有兩個版本：SSH-1 和 SSH-2，它們完全不相容。第一個版本 SSH-1 由於其中的安全缺陷現已棄用。目前的版本稱為 SSH-2。

**6.2.8 網域名稱系統 (DNS)**
我們討論的最後一個主從式應用程式旨在幫助其他應用程式。為了識別實體，TCP/IP 協定使用 IP 位址，該位址唯一地標識主機到網際網路的連接。然而，人們更喜歡使用名稱而不是數字位址。因此，網際網路需要一個可以將名稱映射到位址的目錄系統。這類似於電話網路。電話網路設計為使用電話號碼，而不是名稱。人們可以保留一個私人檔案將名稱映射到相應的電話號碼，或者可以撥打電話查號台來做這件事。
由於今天的網際網路如此龐大，中央目錄系統無法容納所有的映射。此外，如果中央電腦故障，整個通訊網路就會崩潰。更好的解決方案是將資訊分佈在世界各地的許多電腦中。在這種方法中，需要映射的主機可以聯繫持有所需資訊的最近電腦。TCP/IP 使用 **DNS** 客戶端和 DNS 伺服器將名稱映射到位址。使用者想要使用檔案傳輸客戶端存取在遠端主機上運行的相應檔案傳輸伺服器。使用者只知道檔案傳輸伺服器名稱，例如 *afilesource.com*。然而，TCP/IP 套件需要檔案傳輸伺服器的 IP 位址來建立連接。以下六個步驟將主機名稱映射到 IP 位址：
1.  使用者將主機名稱傳遞給檔案傳輸客戶端。
2.  檔案傳輸客戶端將主機名稱傳遞給 DNS 客戶端。
3.  每台電腦在啟動後都知道一個 DNS 伺服器的位址。DNS 客戶端向 DNS 伺服器發送一條訊息，其中包含使用 DNS 伺服器已知 IP 位址查詢檔案傳輸伺服器名稱的查詢。
4.  DNS 伺服器回應所需檔案傳輸伺服器的 IP 位址。
5.  DNS 客戶端將 IP 位址傳遞給檔案傳輸伺服器。
6.  檔案傳輸客戶端現在使用接收到的 IP 位址存取檔案傳輸伺服器。

**名稱空間**
為了不模棱兩可，分配給機器的名稱必須從名稱空間中仔細選擇，並且完全控制名稱和 IP 位址之間的綁定。換句話說，名稱必須是唯一的，因為位址是唯一的。**名稱空間**可以將每個位址映射到唯一的名稱，通常按層次結構組織。在分層*名稱空間*中，每個名稱由幾個部分組成。第一部分可以定義組織的性質，第二部分可以定義組織的名稱，第三部分可以定義組織中的部門，依此類推。在這種情況下，分配和控制名稱空間的權限可以分散。中央機構可以分配定義組織性質的部分和組織名稱。名稱其餘部分的責任可以交給組織本身。組織可以向名稱添加後綴（或前綴）以定義其主機或資源。組織的管理層不必擔心為主機選擇的前綴被另一個組織佔用，因為即使位址的一部分相同，整個位址也是不同的。

**網際網路中的 DNS**
DNS 是一個可用於不同平台的協定。在網際網路中，**網域名稱空間**（樹）最初分為三個不同的部分：通用網域、國家網域和反向網域。然而，由於網際網路的快速增長，追蹤反向網域變得極其困難，反向網域可用於在給定 IP 位址時查找主機名稱。反向網域現已棄用。因此，我們專注於前兩個。

**通用網域**
**通用網域**根據其通用行為定義註冊主機。樹中的每個節點定義一個網域，這是**網域名稱**空間資料庫的索引。觀察這棵樹，我們看到通用網域部分的第一層允許 14 個可能的標籤。這些標籤描述了組織類型：
*   **aero**：航空公司和航太
*   **biz**：商業或公司
*   **com**：商業組織
*   **coop**：合作組織
*   **edu**：教育機構
*   **gov**：政府機構
*   **info**：資訊服務提供者
*   **int**：國際組織
*   **mil**：軍事團體
*   **museum**：博物館
*   **name**：個人名稱（個人）
*   **net**：網路支援中心
*   **org**：非營利組織
*   **pro**：專業組織

**國家網域**
**國家網域**部分使用兩個字元的國家縮寫（例如，us 代表美國）。第二個標籤可以是組織性的，也可以是更具體的國家名稱。例如，美國使用州縮寫作為 us 的細分（例如，ca.us.）。

**6.2.9 點對點範式**
我們在本章前面討論了主從式範式。點對點檔案分享的第一個實例可以追溯到 1987 年 12 月，當時 Wayne Bell 創建了 *WWIVnet*，這是 WWIV（第四次世界大戰）電子佈告欄軟體的網路組件。1999 年 7 月，Ian Clarke 設計了 *Freenet*，這是一個分散式、抗審查的分散式資料儲存庫，旨在透過具有強大匿名保護的點對點網路提供言論自由。
點對點隨著 Napster (1999–2001) 的出現而流行起來，這是由 Shawn Fanning 創建的線上音樂檔案分享服務。雖然使用者免費複製和分發音樂檔案導致了針對 Napster 的版權侵犯訴訟，並最終關閉了該服務，但它為後來出現的點對點檔案分發模型鋪平了道路。Gnutella 於 2000 年 3 月首次發布。隨後是 FastTrack（由 Kazaa 使用）、BitTorrent、WinMX 和 GNUnet，分別於 2001 年 3 月、4 月、5 月和 11 月發布。

準備分享資源的網際網路使用者成為對等點並形成網路。當網路中的一個對等點有一個檔案（例如音訊或視訊檔案）要分享時，它會讓其他對等點可以使用。感興趣的對等點可以連接到儲存檔案的電腦並下載它。對等點下載檔案後，可以讓其他對等點下載。隨著更多對等點加入並下載該檔案，該檔案的更多副本可供群組使用。由於對等點列表可能會增長和縮小，問題是該範式如何追蹤忠實的對等點和檔案的位置。為了回答這個問題，我們首先需要將 P2P 網路分為兩類：集中式和分散式。

**集中式網路**
在**集中式 P2P 網路**中，列出對等點及其提供的內容的目錄系統使用主從式範式，但檔案的儲存和下載使用點對點範式。因此，集中式 P2P 網路有時被稱為混合 P2P 網路。Napster 是集中式 P2P 的一個例子。在這種類型的網路中，對等點首先在中央伺服器註冊。然後對等點提供其 IP 位址和要分享的檔案列表。為了避免系統崩潰，Napster 使用了多個伺服器來實現此目的。
尋找特定檔案的對等點向中央伺服器發送查詢。伺服器搜尋其目錄並回應擁有檔案副本的節點的 IP 位址。對等點聯繫其中一個節點並下載檔案。目錄隨著節點加入或離開對等點而不斷更新。
集中式網路使目錄的維護變得簡單，但有幾個缺點。存取目錄會產生巨大的流量並降低系統速度。中央伺服器容易受到攻擊，如果它們全部發生故障，整個系統就會崩潰。

**分散式網路**
分散式 P2P 網路不依賴集中式目錄系統。在這個模型中，對等點將自己安排成*覆蓋網路*，這是在實體網路上建立的邏輯網路。根據覆蓋網路中節點的連結方式，分散式 P2P 網路被歸類為非結構化或結構化。
在*非結構化* P2P 網路中，節點隨機連結。在非結構化 P2P 中搜尋效率不高，因為尋找檔案的查詢必須透過網路氾濫傳播，這會產生大量流量，而且查詢仍可能無法解決。這種類型網路的兩個例子是 Gnutella 和 Freenet。
*結構化*網路使用預定義的規則集來連結節點，以便可以有效地解決查詢。用於此目的的最常見技術是*分散式雜湊表 (DHT)*。DHT 用於許多應用程式，包括分散式資料結構 (DDS)、內容分散式系統 (CDS)、網域名稱系統 (DNS) 和 P2P 檔案分享。**BitTorrent** 是一種使用 DHT 的流行 P2P 檔案分享協定。

## 6.3 傳輸層
TCP/IP 套件中的**傳輸層**位於應用層和網路層之間。它為應用層提供服務並從網路層接收服務。傳輸層充當客戶端程式和伺服器程式之間的聯絡人，即**行程對行程**連接。傳輸層是 TCP/IP 協定套件的核心；它是將資料從網際網路中的一點傳輸到另一點的端對端邏輯載具。只有兩個終端系統使用傳輸層的服務；所有中間路由器只使用前三層。

### 6.3.1 傳輸層服務
在本節中，我們討論傳輸層可以提供的服務；在下一節中，我們討論幾種傳輸層協定。

**行程對行程通訊**
傳輸層協定的第一個職責是提供*行程對行程通訊*。行程是使用傳輸層服務的應用層實體（正在運行的程式）。
網路層（稍後討論）負責電腦層級的通訊（主機對主機通訊）。網路層協定只能將訊息傳遞給目的電腦。然而，這是不完整的傳遞。訊息仍然需要傳遞給正確的行程。這就是傳輸層協定接管的地方。傳輸層協定負責將訊息傳遞給適當的行程。

**定址：埠號**
雖然有幾種方法可以實現行程對行程通訊，但最常見的是透過主從式範式。本地主機上的行程，稱為*客戶端*，需要通常在遠端主機上的行程，稱為*伺服器*的服務。兩個行程（客戶端和伺服器）具有相同的名稱。例如，要從遠端機器獲取日期和時間，我們需要在本地主機上運行 daytime 客戶端行程，在遠端機器上運行 daytime 伺服器行程。遠端電腦可以同時運行多個伺服器程式，就像多個本地電腦可以同時運行一個或多個客戶端程式一樣。為了通訊，我們必須定義本地主機、本地行程、遠端主機和遠端行程。本地主機和遠端主機使用 IP 位址定義（在下一節中討論）。為了定義行程，我們需要第二個標識符，稱為**埠號**。在 TCP/IP 協定套件中，埠號是 0 到 65535 之間的整數（16 位元）。
客戶端程式使用稱為**臨時埠號**的埠號定義自己。詞語 ephemeral 意思是*短暫的*，之所以使用是因為客戶端的壽命通常很短。建議臨時埠號大於 1023，以便某些主從式程式正常運作。伺服器行程也必須使用埠號定義自己。然而，這個埠號不能隨機選擇。TCP/IP 已決定為伺服器使用通用埠號；這些稱為**熟知埠號**。每個客戶端行程都知道相應伺服器行程的熟知埠號。

### 6.3.2 傳輸層協定
雖然網際網路使用多種傳輸層協定，但我們在本節中僅討論兩種：UDP 和 TCP。

**使用者資料包協定 (UDP)**
**使用者資料包協定 (UDP)** 是一種無連接、不可靠的傳輸協定。除提供行程對行程通訊代替主機對主機通訊外，它不向網路層服務添加任何內容。如果 UDP 如此無力，為什麼行程會想要使用它？缺點伴隨著優點。UDP 是一個非常簡單的協定，使用最少的開銷。如果一個行程想要發送一條小訊息並且不太關心可靠性，它可以使用 UDP。使用 UDP 發送小訊息比使用 TCP 需要發送者和接收者之間更少的互動。

**使用者資料包**
UDP 封包稱為**使用者資料包**，具有 8 位元組的固定大小**標頭**。然而，總長度需要更小，因為 UDP 使用者資料包儲存在總長度為 65535 位元組的 **IP 資料包**中。

**傳輸控制協定 (TCP)**
**傳輸控制協定 (TCP)** 是一種連線導向、可靠的協定。TCP 明確定義了連線建立、資料傳輸和連線拆除階段，以提供連線導向服務。這裡的連線導向服務意味著屬於同一訊息（來自應用層）的所有封包（區段）之間存在連接（關係）。TCP 使用序列號來定義區段的順序。序列號與每個區段中的位元組數有關。例如，如果訊息是 6000 位元組，第一個區段的序列號為 0，第二個區段的序列號為 2000，第三個區段的序列號為 4000（過程更複雜，我們試圖簡化它）。這樣，如果一個區段遺失，接收者將保留另外兩個，直到發送者重置遺失的那個。

**區段**
在傳輸層，TCP 將若干位元組組合成一個稱為**區段 (segment)** 的封包。TCP 向每個區段添加一個標頭（用於控制目的）並將該區段傳遞給網路層進行傳輸。這些區段被封裝在 IP 資料包中。

## 6.4 網路層
TCP/IP 協定套件中的**網路層**負責訊息的主機對主機傳遞。
網路層涉及來源主機、目的主機和路徑中的所有路由器。在來源主機，網路層接受來自傳輸層的封包，將封包封裝在**資料包**中，並將封包傳遞給資料連結層。在目的主機，資料包被解封裝，封包被提取並傳遞給相應的傳輸層。雖然來源和目的主機涉及 TCP/IP 套件的所有五層，但如果路由器僅路由封包，則使用三層；然而，它們可能需要傳輸層和應用層用於控制目的。路徑中的路由器通常顯示為具有兩個資料連結層和兩個實體層，因為它從一個網路接收封包並將其傳遞到另一個網路。

### 6.4.1 網路層提供的服務
網路層位於傳輸層之下；這意味著網路層為傳輸層提供服務。我們在下面討論此服務的一些方面。

**封包化**
網路層的第一個職責無疑是**封包化**：在來源將酬載（從上層接收的資料）封裝在網路層封包中，並在目的地從網路層封包解封裝酬載。換句話說，網路層的一個職責是將酬載從來源攜帶到目的地，而不改變或使用它。網路層正在做像郵局這樣的載體服務，郵局負責將包裹從發送者傳遞給接收者，而不改變或使用內容。
1. 來源網路層協定從傳輸層協定接收封包，添加一個包含來源和目的位址以及網路層協定所需的其他資訊的標頭。
2. 然後網路層協定在邏輯上將封包傳遞給目的地的網路層協定。
3. 目的主機接收網路層封包，解封裝酬載並傳遞給上層協定。
如果封包在來源或路徑中的路由器處被分段，網路層負責等待直到所有片段到達，重新組裝它們，並將它們傳遞給上層協定。
一個傳輸層酬載可以封裝在幾個網路層封包中。

**封包傳遞**
網路層的封包傳遞是不可靠和無連接的。我們接下來簡要討論這兩個概念。

**不可靠傳遞**
網路層的封包傳遞是**不可靠的**。這意味著封包可能會損壞、遺失、重複。換句話說，網路層提供盡力而為的傳遞，但不保證封包會像我們預期的那樣到達目的地。這與我們郵寄普通信件時從郵局獲得的服務相同。這兩種情況的原因都是成本。如果我們需要郵局的保證，成本會更高（例如掛號信）。如果我們需要網路層的保證，封包的傳遞將被延遲。每個封包都需要在每個路由器和目的地進行檢查，如果損壞則重新發送。檢查遺失的封包成本更高。這是否意味著我們透過網際網路發送的訊息不可靠？答案是，如果我們想保證訊息不損壞，我們需要在傳輸層使用 TCP 協定。如果傳輸層的酬載損壞（由於資料連結層的不可靠傳遞），TCP 會丟棄封包並請求重新發送資料，如我們在上一節中所討論的。

**無連接傳遞**
網路層的傳遞也是**無連接的**，但這裡的無連接一詞並不意味著發送者和接收者之間沒有實體連接。這意味著網路層獨立處理每個封包（就像郵局處理信件的方式一樣）。換句話說，屬於同一傳輸層酬載的封包之間沒有關係。如果一個傳輸層封包產生四個網路層封包，則不保證封包按發送順序到達，因為每個封包可能遵循不同的路徑到達目的地。一個傳輸層封包分為四個網路層封包。它們按順序 (1, 2, 3, 4) 發送，但它們按亂序 (2, 4, 3, 1) 接收。目的地的傳輸層負責保留封包直到所有封包到達，然後將其按順序排列並傳遞給應用層。

**路由**
網路層的另一個職責，與其他職責一樣重要，是**路由**。網路層負責將封包從其來源路由到目的地。實體網路是網路（LAN 和 WAN）和連接它們的路由器的組合。這意味著從來源到目的地有多條路徑。網路層負責在這些可能路徑中找到*最佳*路徑。網路層需要有一些具體策略來定義最佳路徑。在今天的網際網路中，這是透過運行一些*路由協定*來幫助路由器協調它們對鄰域的了解，並得出一致的表以在封包到達時使用。

### 6.4.2 網路層協定
雖然網路層有幾個協定，但主要協定稱為**網際網路協定 (IP)**。其他協定是幫助 IP 的輔助協定。今天，使用了兩個版本的 IP 協定：IPv4 和 IPv6。我們在接下來的兩節中討論每一個。

**網際網路協定第四版 (IPv4)**
今天大多數系統都在使用網際網路協定第四版 (IPv4)，但由於該協定的位址空間較小和封包格式等原因，將來會有所改變。

**IPv4 定址**
TCP/IP 協定套件的 IPv4 層中用於識別每個設備到網際網路連接的標識符稱為**網際網路位址**或 **IP 位址**。IPv4 位址是一個 32 位元位址，唯一且通用地定義了主機或路由器到網際網路的連接。IP 位址是連接的位址，而不是主機或路由器的位址，因為如果設備移動到另一個網路，IP 位址可能會更改。IPv4 位址在每個位址定義一個且僅一個到網際網路的連接的意義上是唯一的。如果一個設備，如路由器，透過多個網路有多個到網際網路的連接，它就有多個 IPv4 位址。IPv4 位址在定址系統必須被任何想要連接到網際網路的主機接受的意義上是通用的。

有三種常見的表示法來顯示 IPv4 位址：二進位表示法（基底 2）、點分十進位表示法（基底 256）和十六進位表示法（基底 16）。在二進位表示法中，IPv4 位址顯示為 32 位元。為了使位址更具可讀性，通常在每個八位元組（8 位元）之間插入一個或多個空格。每個八位元組通常稱為一個位元組。為了使 IPv4 位址更緊湊且更易於閱讀，通常以十進位形式書寫，並用小數點（點）分隔位元組。這種格式稱為**點分十進位表示法**。請注意，因為每個位元組（八位元組）只有 8 位元，所以點分十進位表示法中的每個數字都在 0 到 255 之間。我們有時會看到十六進位表示法的 IPv4 位址。每個十六進位數字相當於四個位元。這意味著一個 32 位元位址有 8 個十六進位數字。這種表示法常用於網路程式設計。

在任何涉及傳遞的通訊網路中，如電話網路或郵政網路，定址系統都是分層的。在郵政網路中，郵政地址（郵寄地址）包括國家、城市、街道、門牌號碼和郵件收件人的姓名。同樣，電話號碼分為國家代碼、區域代碼、本地交換局和連接號碼。
32 位元 IPv4 位址也是分層的，但只分為兩部分。位址的第一部分稱為**前綴**，定義網路；位址的第二部分稱為**後綴**，定義節點（設備到網際網路的連接）。前綴長度為 $n$ 位元，後綴長度為 $(32 - n)$ 位元。前綴和後綴長度取決於網路（組織）的站點。

**IPv4 資料包**
IP 使用的封包稱為*資料包*。資料包是由兩部分組成的可變長度封包：標頭和酬載（資料）。標頭長度為 20 到 60 位元組，包含對路由和傳遞至關重要的資訊。請注意，一個位元組是 8 位元。

**網際網路協定第六版 (IPv6)**
IPv4 的一些缺點，如位址耗盡，促使在 1990 年代初期推出了新版本的 IP 協定。新版本稱為**網際網路協定第六版 (IPv6)** 或 **IP 新一代 (IPng)**，提議擴充 IPv4 的位址空間，同時重新設計 IP 封包的格式並修訂一些輔助協定。有趣的是，IPv5 是一個從未實現的提議。以下顯示了 IPv6 協定的主要變化。

**IPv6 定址**
為了防止位址耗盡，IPv6 使用 128 位元來定義連接到網際網路的任何設備。位址表示為二進位或冒號十六進位形式。第一種形式用於在電腦中儲存位址；第二種形式供人類使用。
IPv6 中的位址實際上定義了三個層級的結構：站點（組織）、子網路和與主機的連接。

**IPv6 資料包**
此版本中的資料包也是由兩部分組成的可變長度封包：標頭和酬載（資料）。標頭為 40 位元組。然而，一些擴展標頭在此版本中被視為酬載的一部分。

## 6.5 資料連結層
TCP/IP 套件在**資料連結層**中沒有定義任何協定。這一層是網路的領域，這些網路連接起來構成了網際網路。這些網路，無論是有線還是無線，都接收服務並向網路層提供服務。這可能給我們一個線索，即今天市場上有幾種標準協定。
在上一節中，我們了解到網路層的通訊是主機對主機的。然而，網際網路是由連接設備（路由器或交換器）黏合在一起的網路組合。如果資料包要從一台主機傳輸到另一台主機，它需要通過這些網路。
資料連結層的通訊由路徑中資料連結層之間的分離邏輯連接組成。只有一個資料連結層參與來源或目的地，但每個路由器涉及兩個資料連結層。原因是來源和目的電腦各連接到單一網路；然而，每個路由器從一個網路接收輸入並向另一個網路發送輸出。

### 6.5.1 節點與連結
雖然應用層、傳輸層和網路層的通訊是端對端的，但資料連結層的通訊是**節點對節點**的。來自網際網路上一點的資料單元需要通過許多網路（LAN 和 WAN）才能到達另一點。這些 LAN 和 WAN 由路由器連接。習慣上將兩個終端主機和路由器稱為**節點**，將其間的網路稱為**連結**。連接節點的連結可以是區域網路 (LAN) 或廣域網路 (WAN)。

### 6.5.2 區域網路 (LAN)
在本章開頭，我們了解到區域網路 (LAN) 是為有限地理區域（如建築物或校園）設計的電腦網路。雖然 LAN 可以作為獨立網路連接組織中的電腦，僅用於共享資源，但今天大多數 LAN 也連接到廣域網路 (WAN) 或網際網路。
LAN 可以是有線或無線網路。在第一組中，LAN 中的工作站透過電線連接；在第二組中，工作站透過空氣邏輯連接。我們分別討論每一組。

**有線 LAN：乙太網路**
雖然過去發明了幾種有線 LAN，但只有一種倖存下來：乙太網路。也許原因是乙太網路根據網際網路社群的需求進行了多次升級。
乙太網路 LAN 由 Robert Metcalfe 和 David Boggs 於 1970 年代開發。從那時起，它經歷了四代：**標準乙太網路** (10 Mbps)、**快速乙太網路** (100 Mbps)、**十億位元乙太網路** (1 Gbps) 和 **10 十億位元乙太網路** (10 Gbps)。資料速率，即每秒發送位元的速度，在每一代中都增加了十倍。

**標準乙太網路**
我們將資料速率為 10 Mbps（每秒一千萬位元）的原始乙太網路技術稱為標準乙太網路。在這種情況下，資料速率定義了資料從工作站發送到 LAN 的速度。在乙太網路的情況下，速度是每秒 1000 萬位元。然而，位元不是一個接一個地發送的，一組位元被打包在一起，稱為**訊框**。訊框不僅攜帶從發送者到接收者的資料。它還攜帶一些資訊，如來源位址（48 位元）、目的位址（48 位元）、資料類型、實際資料以及一些其他控制位元作為保護，以幫助檢查轉換過程中的資料完整性。如果我們可以將訊框視為攜帶信件從發送者到接收者的信封，資料在信封內，但信封上還有其他資訊，如位址。在 LAN 的情況下，所有這些都封裝在一個訊框中。

**快速乙太網路 (100 Mbps)**
在 1990 年代，乙太網路透過將**傳輸速率**提高到 100 Mbps 做出了巨大的飛躍，新一代被稱為快速乙太網路。快速乙太網路的設計者需要使其與標準乙太網路相容。大多協定如定址、訊框格式保持不變。透過提高傳輸速率，必須修改依賴傳輸速率的標準乙太網路功能。

**十億位元乙太網路**
對更高資料速率的需求導致了**十億位元乙太網路協定** (1000 Mbps) 的設計。十億位元乙太網路的目標是將資料速率升級到 1 Gbps，但保持位址長度、訊框格式以及最大和最小訊框長度不變。

**10 十億位元乙太網路**
近年來，人們重新審視乙太網路在都會區的使用。這個想法是擴展技術、資料速率和覆蓋距離，以便乙太網路可以用作 LAN 和 MAN（**都會區域網路**）。10 十億位元乙太網路設計的目標可以概括為將資料速率升級到 10 Gbps，保持相同的訊框大小和格式，並允許 LAN、MAN 和 WAN 的互連成為可能。目前只有光纖技術才能實現此資料速率。

**無線 LAN**
無線通訊是增長最快的技術之一。在不使用電纜的情況下連接設備的需求隨處可見。無線 LAN 可以在大學校園、辦公樓和許多公共區域找到。我們可以看到有線和無線 LAN 之間的第一個區別是介質。在有線 LAN 中，我們使用電線連接主機。在無線 LAN 中，介質是空氣，信號通常是廣播的。當無線 LAN 中的主機相互通訊時，它們共享相同的介質（多重存取）。兩種技術在該領域發揮了重要作用：無線乙太網路和藍牙。

**無線乙太網路 (WiFi)**
電機電子工程師學會 (IEEE) 定義了無線 LAN 的規格，有時稱為無線乙太網路或 **WiFi**（無線保真的縮寫）。然而，WiFi 是由 WiFi 聯盟認證的無線 LAN，WiFi 聯盟是一個由 300 多家成員公司組成的全球性非營利行業協會。該標準定義了兩種類型的服務：**基本服務集 (BSS)** 和 **擴展服務集 (ESS)**。第二種服務使用額外的設備（存取點或 AP）作為交換器連接到其他 LAN 或 WAN。

**藍牙**
**藍牙**是一種無線 LAN 技術，旨在短距離連接不同功能的設備，如電話、筆記型電腦、電腦（桌上型和筆記型）、相機、印表機，甚至咖啡機。藍牙 LAN 是一個*隨意 (ad hoc)* 網路，這意味著網路是自發形成的；這些設備，有時稱為*小工具*，彼此發現並形成一個稱為**微微網 (piconet)** 的網路。如果其中一個小工具具有此功能，藍牙 LAN 甚至可以連接到網際網路。就本質而言，藍牙 LAN 不能很大。如果有許多小工具試圖連接，就會出現混亂。
藍牙技術有許多應用。無線滑鼠或鍵盤等周邊設備可以透過此技術與電腦通訊。監控設備可以與小型醫療中心的感測器設備通訊。家庭安全設備可以使用此技術將不同的感測器連接到主安全控制器。會議參與者可以在會議上同步他們的筆記型電腦。
藍牙最初是愛立信公司的一個專案。它以丹麥國王哈拉爾·藍牙 (940–981) 的名字命名，他統一了丹麥和挪威。*Blaatand* 翻譯成英文就是 *Bluetooth*。

### 6.5.3 廣域網路 (WAN)
如前所述，連接網際網路中兩個節點的網路可以是 LAN 或 WAN。就像 LAN 的情況一樣，WAN 可以是有線或無線的。我們分別簡要討論每一種。

**有線 WAN**
今天的乙太網路中有各種有線 WAN。有些是點對點的，有些是交換式 WAN。

**點對點有線 WAN**
今天我們可以使用幾種點對點無線網路來提供所謂的*最後一哩*服務，將居民和企業連接到網際網路。

**撥接服務**
撥接網路或連接使用電話網路提供的服務來傳輸資料。電話網路起源於 1800 年代後期。整個網路最初是一個傳輸語音的系統。隨著電腦時代的到來，該網路在 1980 年代開始除了語音之外還傳輸資料。在過去十年中，電話網路經歷了許多技術變革。通訊數位資料的需求導致了撥接數據機的發明。
術語**數據機 (modem)** 是一個複合詞，指的是組成該設備的兩個功能實體：信號**調變器**和信號**解調器**。調變器從資料產生信號。解調器從調變信號中恢復資料。

**數位用戶迴路 (DSL)**
在傳統數據機達到其峰值資料速率後，電話公司開發了另一種技術 DSL，以提供更高速的網際網路存取。**數位用戶迴路 (DSL)** 技術是最有希望支援現有電話高速通訊的技術之一。DSL 技術是一組技術，每種技術的第一個字母不同（ADSL、VDSL、HDSL 和 SDSL）。該集合通常稱為 *xDSL*，其中 *x* 可以替換為 A、V、H 或 S。我們只討論第一個，ADSL。該集合中的第一個技術是**非對稱 DSL (ADSL)**。ADSL 在下行方向（從網際網路到居民）提供比上行方向（從居民到網際網路）更高的速度（**位元率**）。這就是它被稱為*非對稱*的原因。
ADSL 允許訂戶同時使用語音通道和資料通道。上行速率可達 1.44 Mbps。然而，由於此通道中的高電平雜訊，資料速率通常低於 500 kbps。下行資料速率可達 13.4 Mbps。然而，由於此通道中的雜訊，資料速率通常低於 8 Mbps。一個非常有趣的一點是，在這種情況下，電話公司充當 ISP，因此電子郵件或網際網路存取等服務由電話公司本身提供。

**有線電視網路**
有線電視網路最初是為了向那些因為自然障礙（如山脈）而無法接收信號的訂戶提供電視節目存取而創建的。後來，有線電視網路在只想要更好信號的人們中流行起來。此外，有線電視網路透過微波連接實現了對遠端廣播站的存取。有線電視還在網際網路存取提供方面發現了一個很好的市場，使用了一些最初為視訊設計的頻道。
有線電視公司現在正在與電話公司競爭想要高速資料傳輸的住宅客戶。DSL 技術透過本地迴路為住宅訂戶提供高資料速率連接。然而，DSL 使用現有的非遮蔽雙絞線電纜，非常容易受到干擾。這對資料速率施加了上限。解決方案是使用有線電視網路。

**交換式有線 WAN**
顯然，今天的網際網路不能僅靠提供最後一哩連接的點對點有線 WAN 運作。我們需要交換式有線 WAN 來連接網際網路的骨幹。過去已經為此目的設計了幾種協定，如 SONET 或 ATM。然而，這些是複雜的網路，其討論超出了本書的範圍。

**無線 WAN**
今天的網際網路服務區域如此之大，有時僅使用有線 WAN 無法向世界的每個角落提供服務。我們絕對需要無線 WAN。如下所述，已有多種技術用於此目的。

**WiMax**
**全球互通微波存取 (WiMax)** 是 DSL 或有線電視連接到網際網路的無線版本。它提供兩種類型的服務（固定 WiMax）將主站連接到固定站或移動站（如行動電話）。

**行動電話網路**
另一種今天的無線 WAN 是**行動電話**，它最初是為語音通訊設計的，但現在也用於網際網路通訊。我們都知道行動網路將地球劃分為蜂巢。移動站與它們每一刻所在的蜂巢中的固定天線通訊。當使用者移動到另一個蜂巢時，通訊是在移動設備和新天線之間進行的。

**衛星網路**
**衛星網路**是節點的組合，其中一些是衛星，提供從地球上一點到另一點的通訊。網路中的節點可以是衛星、地面站或終端使用者終端或電話。
衛星網路像行動網路一樣，將地球劃分為蜂巢。衛星可以提供往返地球上任何位置的傳輸能力，無論多麼偏遠。這一優勢使得高品質的通訊可以用於世界欠發達地區，而無需在地面基礎設施上進行巨額投資。

## 6.6 實體層
如果不討論實體層，我們對 TCP/IP 協定套件的討論將是不完整的。實體層的作用是傳輸從資料連結層接收到的位元，並將其轉換為電磁信號進行傳輸。在位元轉換為信號後，信號被傳遞到傳輸介質，這是我們在下一節討論的主題。

### 6.6.1 資料與信號
在實體層，通訊是節點對節點的，但節點交換電磁信號。
實體層的主要功能之一是在節點之間路由位元。然而，位元作為儲存在節點（主機、路由器或交換器）記憶體中的兩個可能值的表示，不能直接發送到傳輸介質（電線或空氣）；位元需要在傳輸前更改為信號。所以實體層的主要職責是有效地將這些位元轉換為電磁信號。我們首先需要了解資料的性質，然後了解信號的類型，看看我們如何有效地進行這種轉換。

**類比與數位**
資料可以是類比或數位的。術語**類比資料**是指連續的資訊。類比資料，如人聲發出的聲音，具有連續的值。當有人說話時，空氣中會產生類比波。這可以被麥克風捕獲並轉換為類比信號，或取樣並轉換為數位信號。
**數位資料**採用離散值。例如，資料以 0 和 1 的形式儲存在電腦記憶體中。它們可以轉換為數位信號或調變為類比信號以在介質上傳輸。
像它們所代表的資料一樣，信號可以是類比或數位的。**類比信號**在一段時間內具有無限多個強度等級。隨著波從值 A 移動到值 B，它通過並包括其路徑上的無限多個值。另一方面，**數位信號**只能具有有限數量的定義值。雖然每個值可以是任何數字，但通常簡單如 1 和 0。顯示信號最簡單的方法是在一對垂直軸上繪製它們。垂直軸代表信號的值或強度。水平軸代表時間。

### 6.6.2 數位傳輸
電腦網路旨在將資訊從一點發送到另一點。此資訊需要轉換為數位信號或類比信號進行傳輸。如果資料是數位的，我們需要使用**數位對數位轉換**技術，即將數位資料轉換為數位信號的方法。如果資料是類比的，我們需要使用**類比對數位轉換**技術，即將類比信號更改為數位信號的方法。

**數位對數位轉換**
如果我們的資料是數位的，並且我們需要傳輸數位信號，我們可以使用數位對數位轉換將數位資料更改為數位信號。雖然有許多技術可以做到這一點，但以最簡單的形式，一個位元或一組位元由一個信號電平表示。

**類比對數位轉換**
有時我們有類比信號，例如由麥克風或相機產生的信號。今天的趨勢是將類比信號更改為數位資料，因為數位信號較不容易受到雜訊的影響。雖然有幾種技術可以做到這一點，但最簡單的一種是對類比信號進行取樣以創建數位資料，並將數位資料轉換為數位信號，如前所述。

### 6.6.3 類比傳輸
雖然數位傳輸是可取的，但它需要專用通道；如果我們沒有專用通道，類比傳輸是唯一的選擇。例如，如果我們在空氣中廣播，空氣屬於每個人，所以我們只能使用可用通道的一部分。根據可用的資料類型，我們可以使用數位對類比或類比對類比轉換。

**數位對類比轉換**
**數位對類比轉換**是根據數位資料中的資訊更改類比信號特徵之一的過程。

**類比對類比轉換**
**類比對類比轉換**是根據數位資料中的資訊更改類比信號特徵之一的過程。

## 6.7 傳輸介質
在實體層產生的電信號需要傳輸介質才能從一點到另一點。傳輸介質實際上位於實體層之下，並由實體層直接控制。我們可以說傳輸介質屬於第零層。
**傳輸介質**可以廣義地定義為任何可以將資訊從來源攜帶到目的地的東西。例如，兩個人共進晚餐交談的傳輸介質是空氣。空氣也可以用來傳遞煙霧信號或旗語中的訊息。對於書面訊息，傳輸介質可能是郵遞員、卡車或飛機。
在電信中，傳輸介質可分為兩大類：導引和非導引。導引介質包括雙絞線、同軸電纜和光纖電纜。非導引介質是自由空間。

### 6.7.1 導引介質
**導引介質**提供從一個設備到另一個設備的管道，包括**雙絞線**、**同軸電纜**和**光纖電纜**。

**雙絞線**
雙絞線由兩根導線（通常是銅）組成，每根都有自己的塑膠絕緣層，絞合在一起。其中一根導線用於將信號傳送到接收器，另一根僅用作接地參考。接收器使用兩者之間的差異。
除了來自發送者的信號外，干擾（雜訊）可能會影響兩根導線並產生不需要的信號。如果兩根導線平行，這些不需要的信號在兩根導線中的影響是不一樣的，因為它們相對於雜訊源的位置不同。透過絞合線對，可以保持平衡。
電話公司用來提供高資料速率連接的 DSL 線路也是雙絞線電纜。

**同軸電纜**
同軸電纜不是有兩根導線，而是有一個實心或絞合線（通常是銅）的中心核心導體，封閉在絕緣護套中，該護套又被金屬箔、編織物或兩者組合的外部導體包圍。外部金屬包裹既作為防雜訊屏蔽，又作為完成電路的第二導體。這個外部導體也被封閉在絕緣護套中，整條電纜由塑膠蓋保護。
有線電視網路使用同軸電纜。在傳統的有線電視網路中，整個網路都使用同軸電纜。然而，後來有線電視提供商用光纖電纜替換了大部分介質；混合網路僅在網路邊界，即消費者處所附近使用同軸電纜。

**光纖電纜**
光纖電纜由玻璃或塑膠製成，以光的形式傳輸信號。這項技術利用了光束在遇到密度較低的介質時折射（返回）的特性。用另一種密度較低的介質（稱為包層）覆蓋玻璃或塑膠介質可以引導光通過介質。
光纖電纜經常在骨幹網路中發現，因為其高頻寬具有成本效益。

### 6.7.2 非導引介質：無線
非導引介質在不使用實體導體的情況下傳輸電磁波。這種類型的通訊通常稱為**無線通訊**。信號通常透過自由空間廣播，因此任何擁有能夠接收它們的設備的人都可以使用。
今天的通訊使用三種不同範圍的電磁頻譜：無線電波、微波和紅外線。

**無線電波**
頻率在 3 kHz 到 1 GHz 之間的電磁波通常稱為**無線電波**。它們主要用於無線電通訊。

**微波**
頻率在 1 到 300 GHz 之間的電磁波稱為**微波**。微波是單向的。當天線發射微波時，它們可以被窄聚焦。這意味著發送和接收天線需要對齊。單向特性具有明顯的優勢。一對天線可以對齊而不干擾另一對對齊的天線。

**紅外線**
**紅外線**，頻率從 300 GHz 到 400 THz（波長從 1 毫米到 770 奈米），可用於短距離通訊。具有高頻率的紅外線無法穿透牆壁。這個有利的特性防止了一個系統與另一個系統之間的干擾；一個房間內的短距離通訊系統不會受到隔壁房間另一個系統的影響。當我們使用紅外線遙控器時，我們不會干擾鄰居對遙控器的使用。然而，同樣的特性使得紅外信號無法用於長距離通訊。此外，我們不能在建築物外使用紅外線，因為太陽光包含會干擾通訊的紅外線。

## 6.8 章末材料
### 6.8.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Forouzan, B. and Mosharrf, F. *Computer Networks: A Top-Down Approach*, New York: McGraw-Hill Education, 2012
- Forouzan, B. *Data Communication and Networking*, New York: McGraw-Hill Education, 2013
- Forouzan, B. *TCP/IP Protocol Suite*, New York: McGraw-Hill Education, 2010
- Forouzan, B. *Local Area Networks*, New York: McGraw-Hill Education, 2003
- Kurose, J. and Ross, K. *Computer Networking*, Reading, MA: Addison-Wesley, 2007

### 6.8.2 關鍵詞
- 10 十億位元乙太網路
- 類比對類比轉換
- 類比對數位轉換
- 類比資料
- 類比信號
- 應用層
- 位元率
- 藍牙
- 行動電話
- 密文
- 主從式範式
- 同軸電纜
- 連接設備
- 無連接協定
- 國家網域
- 解調器
- 數位對類比轉換
- 數位對數位轉換
- 數位資料
- 數位信號
- 數位用戶迴路 (DSL)
- 網域名稱
- 網域名稱系統 (DNS)
- 網域名稱空間
- 點分十進位表示法
- 電子郵件 (email)
- 終端系統
- 臨時埠號
- 快速乙太網路
- 光纖電纜
- 檔案傳輸協定 (FTP)
- 訊框
- 通用網域
- 十億位元乙太網路
- 導引介質
- 硬體
- 標頭
- 主機
- 主機標識符
- 超文本
- 超文本標記語言 (HTML)
- 超文本傳輸協定 (HTTP)
- 紅外線
- 互連網 (internet)
- 網際網路 (Internet)
- 網際網路位址
- 網際網路協定
- 網際網路協定第六版 (IPv6)
- 網際網路服務提供者 (ISP)
- 互連網 (Internetwork)
- IP 位址
- IP 資料包
- IP 新一代 (IPng)
- 連結
- 區域網路 (LAN)
- 訊息存取代理 (MAA)
- 郵件傳輸代理 (MTA)
- 都會區域網路 (MAN)
- 數據機
- 模組化
- 調變器
- 模組
- 名稱空間
- 網路層
- 節點
- 封包化
- 點對點 (P2P) 範式
- 實體層
- 埠號
- 協定
- 協定分層
- 遠端登入
- 路由器
- 安全殼層 (SHH)
- 區段
- 軟體
- 來源到目的地傳遞
- 標準乙太網路
- 交換器
- 交換式 WAN
- TCP/IP 協定套件
- TELNET (終端網路)
- 傳輸控制協定 (TCP)
- 傳輸介質
- 傳輸速率
- 雙絞線電纜
- 非導引介質
- 統一資源定位器 (URL)
- 使用者代理 (UA)
- 使用者資料包
- 使用者資料包協定 (UDP)
- 網頁
- 熟知埠號
- 廣域網路 (WAN)
- 全球互通微波存取 (WiMAX)
- 全球資訊網 (WWW)
- 一次寫入，多次讀取 (WORM)

### 6.8.3 摘要
- 網路是一組由通訊連結連接的設備。今天當我們談論網路時，我們通常指的是兩個主要類別：區域網路和廣域網路。今天的網際網路是由許多廣域和區域網路透過連接設備和交換站連接而成的。協定是一組管理通訊的規則。TCP/IP 是一個由五層組成的分層協定套件：應用層、傳輸層、網路層、資料連結層和實體層。
- 網際網路中的應用程式使用主從式範式或點對點範式設計。全球資訊網 (WWW) 是一個資訊儲存庫，從世界各地連結在一起。超文本傳輸協定 (HTTP) 是用於存取全球資訊網 (WWW) 上資料的主要協定。檔案傳輸協定 (FTP) 是一個 TCP/IP 主從式應用程式，用於將檔案從一台主機複製到另一台主機。電子郵件是網際網路上最常見的應用程式之一。TELNET 是一個主從式應用程式，允許使用者登入遠端機器，讓使用者存取遠端系統。網域名稱系統 (DNS) 是一個主從式應用程式，用唯一的名稱識別網際網路上的每台主機。
- 傳輸層協定的主要職責是提供行程對行程通訊。UDP 是一種提供不可靠和無連接服務的傳輸協定。傳輸控制協定 (TCP) 是另一種傳輸層協定，提供可靠和連線導向的服務。
- 網路層監督底層實體網路對封包的處理。IPv4 是一種不可靠的無連接協定，負責來源到目的地的傳遞。TCP/IP 協定套件的 IP 層中使用的標識符稱為 IP 位址。IPv4 位址長 32 位元。IPv6 是網際網路協定的最新版本，具有 128 位元的位址空間。
- 資料連結層涉及區域網路 (LAN) 和廣域網路 (WAN)。LAN 和 WAN 可以是有線或無線的。乙太網路是使用最廣泛的有線區域網路協定。撥接服務、DSL 和電纜主要用於點對點有線 WAN。無線 LAN 透過無線乙太網路正式化。藍牙是一種無線 LAN 技術，連接小區域內的設備（稱為小工具）。WiMAX 是一種無線存取網路，將來可能會取代 DSL 和電纜。
- 資料必須轉換為電磁信號才能傳輸。類比資料是連續的並取連續值。數位資料具有離散狀態並取離散值。數位對數位轉換將數位資料更改為數位信號。數位對類比轉換是將數位資料更改為類比信號的過程。類比對數位轉換是對類比資料進行取樣並將其更改為數位信號的過程。類比對類比信號意味著將類比資料更改為類比信號。
- 傳輸介質位於實體層之下。導引介質提供從一個設備到另一個設備的實體管道。雙絞線、同軸電纜和光纖是最流行的導引介質類型。非導引介質（自由空間）在不使用實體導體的情況下傳輸電磁波。
`},h={en:`
# Chapter 7: Operating Systems

This is the first chapter in this book to deal with computer software. In this chapter we explore the role of the operating system in a computer.

## Objectives
After studying this chapter, the student should be able to:
- Understand the role of the operating system in a computer system.
- Give a definition of an operating system.
- Understand the process of bootstrapping to load the operating system into memory.
- List the components of an operating system.
- Discuss the role of the memory manager in an operating system.
- Discuss the role of the process manager in an operating system.
- Discuss the role of the device manager in an operating system.
- Discuss the role of the file manager in an operating system.
- Understand the main features of three common operating systems: UNIX, Linux, and Windows.

## 7.1 INTRODUCTION
A computer is a system composed of two major components: hardware and software. Computer hardware is the physical equipment. Software is the collection of programs that allows the hardware to do its job. Computer **software** is divided into two broad categories: the **operating system** and **application programs** (Figure 7.1). Application programs use the computer hardware to solve users’ problems. The operating system, on the other hand, controls the access to hardware by users.

### 7.1.1 Operating system
An **operating system** is complex, so it is difficult to give a simple universal definition. Instead, here are some common definitions:
- An operating system is an interface between the hardware of a computer and the user (programs or humans).
- An operating system is a program (or a set of programs) that facilitates the execution of other programs.
- An operating system acts as a general manager supervising the activity of each component in the computer system. As a general manager, the operating system checks that hardware and software resources are used efficiently, and when there is a conflict in using a resource, the operating system mediates to solve it.

**An operating system is an interface between the hardware of a computer and the user (programs or humans) that facilitates the execution of other programs and the access to hardware and software resources.**

Two major design goals of an operating system are:
- Efficient use of hardware.
- Easy use of resources.

### 7.1.2 Bootstrap process
The operating system, based on the above definitions, provides support for other programs. For example, it is responsible for loading other programs into memory for execution. However, the operating system itself is a program that needs to be loaded into the memory and be run. How is this dilemma solved?

The problem can be solved if the operating system is stored (by the manufacturer) in part of memory using ROM technology. The program counter of the CPU (see Chapter 5) can be set to the beginning of this ROM memory. When the computer is turned on, the CPU reads instructions from ROM and executes them. This solution, however, is not very efficient, because a significant part of the memory would need to be composed of ROM and could not therefore be used by other programs. Today’s technology needs to allocate just a small part of memory to part of the operating system.

The solution adopted today is a two-stage process. A very small section of memory is made of ROM and holds a small program called the **bootstrap program**. When the computer is turned on, the CPU counter is set to the first instruction of this bootstrap program and executes the instructions in this program. This program is only responsible for loading the operating system itself, or that part of it required to start up the computer, into RAM memory. When loading is done, the program counter in the CPU is set to the first instruction of the operating system in RAM and the operating system is executed. Figure 7.2 illustrates the bootstrap process.

## 7.2 EVOLUTION
Operating systems have gone through a long history of evolution, which we summarize next.

### 7.2.1 Batch systems
**Batch operating systems** were designed in the 1950s to control mainframe computers. At that time, computers were large machines that used punched cards for input, line printers for output, and tape drives for secondary storage media.

Each program to be executed was called a job. A programmer who wished to execute a job sent a request to the operating room along with punched cards for the program and data. The punched cards were fed into the computer by an operator. If the program was successful, a printout of the result was sent to the programmer—if not, a printout of the error was sent.

Operating systems during this era were very simple: they only ensured that all of the computer’s resources were transferred from one job to the next.

### 7.2.2 Time-sharing systems
To use computer system resources efficiently, **multiprogramming** was introduced. The idea is to hold several jobs in memory at a time, and only assign a resource to a job that needs it on the condition that the resource is available. For example, when one program is using an input/output device, the CPU is free and can be used by another program. We discuss multiprogramming later in this chapter.

Multiprogramming brought the idea of **time sharing**: resources could be shared between different jobs, with each job being allocated a portion of time to use a resource. Because a computer is much faster than a human, time sharing is hidden from the user—each user has the impression that the whole system is serving them exclusively.

Multiprogramming, and eventually time sharing, improved the efficiency of computer systems tremendously. However, they required a more complex operating system. The operating system now had to do **scheduling**: allocating resources to different programs and deciding which program should use which resource, and when. During this era, the relationship between a computer and a user also changed. The user could directly interact with the system without going through an operator. A new term was also coined: **process**. A job is a program to be run, while a process is a program that is in memory and waiting for resources.

### 7.2.3 Personal systems
When personal computers were introduced, there was a need for an operating system for this new type of computer. During this era, **single-user operating systems** such as **DOS (Disk Operating System)** were introduced.

### 7.2.4 Parallel systems
The need for more speed and efficiency led to the design of **parallel systems**: multiple CPUs on the same machine. Each CPU can be used to serve one program or a part of a program, which means that many tasks can be accomplished in parallel instead of serially. The operating systems required for this are more complex than those that support single CPUs.

### 7.2.5 Distributed systems
Networking and internetworking, as we saw in Chapter 6, have created a new dimension in operating systems. A job that was previously done on one computer can now be shared between computers that may be thousands of miles apart. A program can be run partially on one computer and partially on another if they are connected through an internetwork such as the Internet. In addition, resources can be distributed. A program may need files located in different parts of the world. **Distributed systems** combine features of the previous generation with new duties such as controlling security.

### 7.2.6 Real-time systems
A **real-time system** is expected to do a task within specific time constraints. They are used with real-time applications, which monitor, respond to, or control external processes or environments. Examples can be found in traffic control, patient monitoring, or military control systems. The application program can sometimes be an embedded system such as a component of a large system, such as the control system in an automobile.

The requirements for a real-time operating system are often different than those for a general-purpose system. For this reason, we do not discuss them in this chapter.

## 7.3 COMPONENTS
Today’s operating systems are very complex. An operating system needs to manage different resources in a computer system. It resembles an organization with several managers at the top level. Each manager is responsible for managing their department, but also needs to cooperate with others and coordinate activities. A modern operating system has at least four duties: memory manager, process manager, device manager, and file manager. Like many organizations that have a department that is not necessarily under any specific manager, an operating system also has such a component, which is usually called a user interface or a shell. The user interface is responsible for communication outside the operating system. Figure 7.3 shows the typical components of an operating system.

### 7.3.1 User interface
Each operating system has a **user interface**, a program that accepts requests from users (processes) and interprets them for the rest of the operating system. A user interface in some operating systems, such as UNIX, is called a **shell**. In others, it is called a window to denote that it is menu driven and has a **GUI (graphical user interface)** component.

### 7.3.2 Memory manager
One of the responsibilities of a modern computer system is **memory management**. Although the memory size of computers has increased tremendously in recent years, so has the size of the programs and data to be processed. Memory allocation must be managed to prevent applications from running out of memory. Operating systems can be divided into two broad categories of memory management: monoprogramming and multiprogramming.

**Monoprogramming**
**Monoprogramming** belongs to the past, but it is worth mentioning because it helps us to understand multiprogramming. In monoprogramming, most of the memory capacity is dedicated to a single program (we consider the data to be processed by a program as part of the program): only a small part is needed to hold the operating system. In this configuration, the whole program is in memory for execution. When the program finishes running, the program area is occupied by another program (Figure 7.4).

The job of the memory manager is straightforward here. It loads the program into memory, runs it, and replaces it with the next program. However, there are several problems with this technique:
- The program must fit into memory. If the size of memory is less than the size of the program, the program cannot be run.
- When one program is being run, no other program can be executed. A program, during its execution, often needs to receive data from input devices and needs to send data to output devices. Input/output devices are slow compared with the CPU, so when the input/output operations are being carried out, the CPU is idle. It cannot serve another program because this program is not in memory. This is a very inefficient use of memory and CPU time.

**Multiprogramming**
In **multiprogramming**, more than one program is in memory at the same time, and they are executed concurrently, with the CPU switching rapidly between the programs. Figure 7.5 shows memory in a multiprogramming environment.
Since the 1960s, multiprogramming has gone through several improvements that can be seen in the taxonomy in Figure 7.6.

We discuss each scheme very briefly in the next few sections. Two techniques belong to the *nonswapping* category, which means that the program remains in memory for the duration of execution. The other two techniques belong to the *swapping* category. This means that, during execution, the program can be swapped between memory and disk one or more times.

**Partitioning**
The first technique used in multiprogramming is called **partitioning**. In this scheme, memory is divided into variable-length sections. Each section or partition holds one program. The CPU switches between programs. It starts with one program, executing some instructions until it either encounters an input/output operation or the time allocated for that program has expired. The CPU then saves the address of the memory location where the last instruction was executed and moves to the next program. The same procedure is repeated with the second program. After all the programs have been served, the CPU moves back to the first program. Priority levels can also be used to control the amount of CPU time allocated to each program (Figure 7.7).

With this technique, each program is entirely in memory and occupying contiguous locations. Partitioning improves the efficiency of the CPU, but there are still some issues:
- The size of the partitions has to be determined beforehand by the memory manager. If partition sizes are small, some programs cannot be loaded into memory. If partition sizes are large, there might be some ‘holes’ (unused locations) in memory.
- Even if partitioning is perfect when the computer is started, there may be some holes after completed programs are replaced by new ones.
- When there are many holes, the memory manager can compact the partitions to remove the holes and create new partitions, but this creates extra overhead on the system.

**Paging**
**Paging** improves the efficiency of partitioning. In paging, memory is divided into equally sized sections called **frames**. Programs are also divided, into equally sized sections called **pages**. The size of a page and a frame is usually the same and equal to the size of the block used by the system to retrieve information from a storage device (Figure 7.8).

A page is loaded into a frame in memory. If a program has three pages, it occupies three frames in memory. With this technique, the program does not have to be contiguous in memory: two consecutive pages can occupy noncontiguous frames in memory. The advantage of paging over partitioning is that two programs, each using three noncontiguous frames, can be replaced by one program that needs six frames. There is no need for the new program to wait until six contiguous frames are free before being loaded into memory.

Paging improves efficiency to some extent, but the whole program still needs to be in memory before being executed. This means that a program that needs six frames, for example, cannot be loaded into memory if there are currently only four unoccupied frames.

**Demand paging**
Paging does not require that the program be in contiguous memory locations, but it does require that the entire program be in memory for execution. **Demand paging** has removed this last restriction. In demand paging the program is divided into pages, but the pages can be loaded into memory one by one, executed, and replaced by another page. In other words, memory can hold pages from multiple programs at the same time. In addition, consecutive pages from the same program do not have to be loaded into the same frame—a page can be loaded into any free frame. An example of demand paging is shown in Figure 7.9. Two pages from program A, one page from program B, and one page from program C are in the memory.

**Demand segmentation**
A technique similar to paging is **segmentation**. In paging, a program is divided into equally sized pages, which is not the way a programmer thinks—a programmer thinks in terms of modules. As we will see in later chapters, a program is usually made up of a main program and subprograms. In **demand segmentation**, the program is divided into segments that match the programmer’s view. These are loaded into memory, executed, and replaced by another module from the same or a different program. An example of demand segmentation is shown in Figure 7.10. Since segments in memory are of equal size, part of a segment may remain empty.

**Demand paging and segmentation**
Demand paging and segmentation can be combined to further improve the efficiency of the system. A segment may be too large to fit any available free space in memory. Memory can be divided into frames, and a module can be divided into pages. The pages of a module can then be loaded into memory one by one and executed.

**Virtual memory**
Demand paging and demand segmentation mean that, when a program is being executed, part of the program is in memory and part is on disk. This means that, for example, a memory size of 10 MB can execute ten programs, each of size 3 MB, for a total of 30 MB. At any moment, 10 MB of the ten programs are in memory and 20 MB are on disk. There is therefore an actual memory size of 10 MB, but a virtual memory size of 30 MB. Figure 7.11 shows the concept. **Virtual memory**, which implies demand paging, demand segmentation, or both, is used in almost all operating systems today.

### 7.3.3 Process manager
A second function of an operating system is process management, but before discussing this concept, we need to define some terms.

**Program, job, and process**
Modern operating systems use three terms that refer to a set of instructions: program, job, and process. Although the terminology is vague and varies from one operating system to another, we can define these terms informally.

**Program**
A **program** is a nonactive set of instructions stored on disk (or tape). It may or may not become a job.

**Job**
A program becomes a **job** from the moment it is selected for execution until it has finished running and becomes a program again. During this time a job may or may not be executed. It may be located on disk waiting to be loaded to memory, or it may be loaded into memory and waiting for execution by the CPU. It may be on disk or in memory waiting for an input/output event, or it may be in memory while being executed by the CPU. The program is a job in all of these situations. When a job has finished executing (either normally or abnormally), it becomes a program and once again resides on the disk. The operating system no longer governs the program. Note that every job is a program, but not every program is a job.

**Process**
A **process** is a program in execution. It is a program that has started but has not finished. In other words, a process is a job that is being run in memory. It has been selected among other waiting jobs and loaded into memory. A process may be executing or it may be waiting for CPU time. As long as the job is in memory, it is a process. Note that every process is a job, but not every job is a process.

**State diagrams**
The relationship between a program, a job, and a process becomes clearer if we consider how a program becomes a job and how a job becomes a process. This can be illustrated with a **state diagram** that shows the different states of each of these entities. Figure 7.12 is a state diagram using boundaries between a program, a job, and a process.

A program becomes a job when selected by the operating system and brought to the **hold state**. It remains in this state until it can be loaded into memory. When there is memory space available to load the program totally or partially, the job moves to the **ready state**. It now becomes a process. It remains in memory and in this state until the CPU can execute it, moving to the **running state** at this time. When in the running state, one of three things can happen:
- The process executes until it needs I/O resources
- The process exhausts its allocated time slot
- The process terminates
In the first case, the process goes into the **waiting state** and waits until I/O is complete. In the second case, it goes directly to the ready state. In the third case, it goes into the **terminated state** and is no longer a process. A process can move between the running, waiting, and ready states many times before it goes to the terminated state. Note that the diagram can be much more complex if the system uses virtual memory and swaps programs in and out of main memory.

**Schedulers**
To move a job or process from one state to another, the process manager uses two **schedulers**: the job scheduler and the process scheduler.

**Job scheduler**
The **job scheduler** moves a job from the hold state to the ready state or from the running state to the terminated state. In other words, a job scheduler is responsible for creating a process from a job and terminating a process. Figure 7.13 shows the job scheduler.

**Process scheduler**
The **process scheduler** moves a process from one state to another. It moves a process from the running state to the waiting state when the process is waiting for some event to happen. It moves the process from the waiting state to the ready state when the event has occurred. It moves a process from the running state to the ready state if the process’ time allotment has expired. When the CPU is ready to run the process, the process scheduler moves the process from the ready state to the running state. Figure 7.14 shows the process scheduler.

**Other schedulers**
Some operating systems use other types of schedulers to make switching between processes more efficient.

**Queuing**
Our state diagram shows one job or process moving from one state to another. In reality, there are many jobs and many processes competing with each other for computer resources. For example, when some jobs are in memory, others must wait until space is available. Or when a process is running using the CPU, others must wait until the CPU is free. To handle multiple processes and jobs, the process manager uses **queues** (waiting lists). A *job control block* or *process control block* is associated with each job or process. This is a block of memory that stores information about that job or process. The process manager stores the job or process control block in the queues instead of the job or process itself. The job or process itself remains in memory or disk, as it is too big to be duplicated in a queue: the job control block or process control block is the representative of the waiting job or process.
An operating system can have several queues. For example, Figure 7.15 shows the circulation of jobs and processes through three queues: the job queue, the ready queue, and the I/O queue. The job queue holds the jobs that are waiting for memory. The ready queue holds the processes that are in memory, ready to be run and waiting for the CPU. The I/O queue holds the processes that are waiting for an I/O device (there can be several I/O queues, one for each input/output device, but we show only one for simplicity).

The process manager can have different policies for selecting the next job or process from a queue: it could be first in, first out (FIFO), shortest length first, highest priority first, and so on.

**Process synchronization**
The whole idea behind process management is to synchronize different processes with different resources. Whenever resources can be used by more than one user (or process, in this case), we can have two problematic situations: *deadlock* and *starvation*. A brief discussion of these two situations follows.

**Deadlock**
Instead of a formal definition of **deadlock**, we give an example. Assume that there are two processes, A and B. Process A is holding a file, File1 (that is, File1 is assigned to A) and cannot release it until it acquires another file, File2 (that is, A has requested File2). Process B is holding File2 (that is, File2 is assigned to B) and cannot release it until it has File1 (that is, B has requested File1). Files in most systems are not sharable—when in use by one process, a file cannot be used by another process. If there is no provision in this situation to force a process to release a file, deadlock is created (Figure 7.16).

As an analogy, Figure 7.17 shows deadlock on a narrow bridge. The situation is similar because the resource (part of the bridge) is held by a vehicle that does not release it until it gets the other part of the bridge, which is held by the other vehicle, and *vice versa*.

Deadlock occurs if the operating system allows a process to start running without first checking to see if the required resources are ready, and allows a process to hold a resource as long as it wants. There should be some provision in the system to prevent deadlock. One solution is not to allow a process to start running until the required resources are free, but we will see later that this creates another problem. The second solution is to limit the time a process can hold a resource.

**Deadlock occurs when the operating system does not put resource restrictions on processes.**

Deadlock does not always occur. There are four necessary conditions for deadlock as shown below:
- **Mutual exclusion**. Only one process can hold a resource
- **Resource holding**. A process holds a resource even though it cannot use it until other resources are available
- **No preemption**. The operating system cannot temporarily reallocate a resource
- **Circular waiting**. All processes and resources involved form a loop, as in Figure 7.16
All four conditions are required for deadlock to occur. However, these conditions are only necessary preconditions, and are not sufficient to cause deadlock of themselves—they must be present for deadlock, but they might not be enough to cause it. If one of these conditions is missing, deadlock cannot occur. This gives us a method for preventing or avoiding deadlock: do not allow one of these conditions to happen.

**Starvation**
**Starvation** is the opposite of deadlock. It can happen when the operating system puts too many resource restrictions on a process. For example, imagine an operating system that specifies that a process must have possession of its required resources before it can be run.
In Figure 7.18, imagine that process A needs two files, File1 and File2. File1 is being used by process B and File2 is being used by process E. Process B terminates first and releases File1. Process A cannot be started, because File2 is still not available. At this moment, process C, which needs only File1, is allowed to run. Now process E terminates and releases File2, but process A still cannot run because File1 is unavailable.

A classic starvation problem is the one introduced by Edsger Dijkstra. Five philosophers are sitting at a round table (Figure 7.19). Each philosopher needs two chopsticks to eat a bowl of rice. However, one or both chopsticks could be used by a neighbor. A philosopher could starve if two chopsticks are not available at the same time.

### 7.3.4 Device manager
The **device manager**, or input/output manager, is responsible for access to input/output devices. There are limitations on the number and speed of input/output devices in a computer system. Because these devices are slower in speed compared with the CPU and memory, when a process accesses an input/output device, the device is not available to other processes for a period of time. The device manager is responsible for the efficient use of input/output devices.

A detailed discussion of device managers requires advanced knowledge of operating system principles and is beyond the scope of this book. However, we can briefly list the responsibilities of a device manager:
- The device manager monitors every input/output device constantly to ensure that the device is functioning properly. The manager also needs to know when a device has finished serving one process and is ready to serve the next process in the queue.
- The device manager maintains a queue for each input/output device or one or more queues for similar input/output devices. For example, if there are two fast printers in the system, the manager can have one queue for each or one queue for both.
- The device manager controls the different policies for accessing input/output devices. For example, it may use FIFO for one device and shortest length first for another.

### 7.3.5 File manager
Operating systems today use a **file manager** to control access to files. A detailed discussion of the file manager also requires advanced knowledge of operating system principles and file access concepts that are beyond the scope of this book. We discuss some issues related to file access in Chapter 13, but this is not adequate to understand the actual operation of a file manager. Here is a brief list of the responsibilities of a file manager:

- The file manager controls access to files. Access is permitted only by permitted applications and/or users, and the type of access can vary. For example, a process (or a user that calls a process) may be allowed to read from a file but is allowed to write to it (that is, change it). Another process may be allowed to execute a file and a process, but not allowed to read its contents, and so on.
- The file manager supervises the creation, deletion, and modification of files.
- The file manager can control the naming of files.
- The file manager supervises the storage of files: how they are stored, where they are stored, and so on.
- The file manager is responsible for archiving and backups.

## 7.4 A SURVEY OF OPERATING SYSTEMS
In this section we introduce some popular operating systems and encourage you to study them further. We have chosen three operating systems that are familiar to most computer users: UNIX, Linux, and Windows.

### 7.4.1 UNIX
**UNIX** was originally developed in 1969 by Thomson and Ritchie of the Computer Science Research Group at Bell Laboratories. UNIX has gone through many versions since then. It has been a popular operating system among computer programmers and computer scientists. It is a very powerful operating system with three outstanding features. First, UNIX is a portable operating system that can be moved from one platform to another without many changes. The reason is that it is written mostly in the C language (instead of a machine language specific to a particular computer system). Second, UNIX has a powerful set of utilities (commands) that can be combined (in an executable file called a *script*) to solve many problems that require programming in other operating systems. Third, it is device-independent, because it includes device drivers in the operating system itself, which means that it can be easily configured to run any device.
UNIX is a multiuser, multiprocessing, portable operating system designed to facilitate programming, text processing, communication, and many other tasks that are expected from an operating system. It contains hundreds of simple, single-purpose functions that can be combined to do virtually every processing task imaginable. Its flexibility is demonstrated by the fact that it is used in three different computing environments: stand-alone personal environments, time-sharing systems, and client–server systems.

**UNIX is a multiuser, multiprocessing, portable operating system. It is designed to facilitate programming, text processing, and communication.**

**UNIX structure**
UNIX consists of four major components: the *kernel*, the *shell*, a standard set of *utilities*, and *application programs*. These components are shown in Figure 7.20.

**The kernel**
The **kernel** is the heart of the UNIX system. It contains the most basic parts of the operating system: memory management, process management, device management, and file management. All other components of the system call on the kernel to perform these services for them.

**The shell**
The **shell** is the part of UNIX that is most visible to the user. It receives and interprets the commands entered by the user. In many respects, this makes it the most important component of the UNIX structure. It is certainly the part that users get to know best. To do anything in the system, we must give the shell a command. If the command requires a utility, the shell requests that the kernel execute the utility. If the command requires an application program, the shell requests the kernel to run it. Some operating systems, such as UNIX, have several different shells.

**Utilities**
There are literally hundreds of UNIX utilities. A **utility** is a standard UNIX program that provides a support process for users. Three common utilities are text editors, search programs, and sort programs.
Many of the system utilities are actually sophisticated applications. For example, the UNIX email system is considered a utility, as are the three common text editors, **vi**, **emacs**, and **pico**. All four of these utilities are large systems in themselves. Other utilities are shorter, simpler functions. For example, the list (**ls**) utility displays the files in a disk directory.

**Applications**
Applications in UNIX are programs that are not a standard part of the operating system distribution. Written by systems administrators, professional programmers, or users, they provide extended capabilities to the system. In fact, many of the standard utilities started out as applications years ago and proved so useful that they are now part of the system.

### 7.4.2 Linux
In 1991, Linus Torvalds, a Finnish student at the University of Helsinki at the time, developed a new operating system that is known today as **Linux**. The initial kernel, which was similar to a small subset of UNIX, has grown into a full-scale operating system today. The Linus 2.0 kernel, released in 1997, was accepted as a commercial operating system: it has all the features traditionally attributed to UNIX.

**Components**
Linux has the following components.

**Kernel**
The kernel is responsible for all duties attributed to a kernel, such as memory management, process management, device management, and file management.

**System libraries**
The system libraries hold a set of functions used by the application programs, including the shell, to interact with the kernel.

**System utilities**
The system utilities are individual programs that use the services provided by the system libraries to perform management tasks.

**Networking capabilities**
Linux supports the standard Internet protocols discussed in Chapter 6. It supports three layers: the socket interface, protocol drivers, and network device drivers.

**Security**
Linux’ security mechanism provides the security aspects defined traditionally for UNIX, such as **authentication** and access control.

### 7.4.3 Windows
In the late 1980s, Microsoft started development of a new single-user operating system to replace **MS-DOS** (Microsoft Disk Operating System). **Windows** was the result. Several versions of Windows followed. We refer to all of these versions as Windows.

**Design goals**
Design goals released by Microsoft are *extensibility*, *portability*, *reliability*, *compatibility*, and *performance*.

**Extensibility**
Windows is designed as a modular architecture with several layers. The purpose is to let the higher layers to be changed with time without affecting the lower layers.

**Portability**
Windows, like UNIX, is mostly is written in C or C++ and the code is independent of the machine language of the computer on which it is running.

**Reliability**
Windows was designed to handle error conditions including protection from malicious software.

**Compatibility**
Windows was designed to run programs written for other operating systems and the earlier versions of Windows.

**Performance**
Windows was designed to have a fast response time to applications that run on top of the operating system.

**Architecture**
Windows uses a layered architecture, as shown in Figure 7.21.

**HAL**
The **hardware abstraction layer (HAL)** hides hardware differences from the upper layers.

**Kernel**
The kernel is the heart of the operating system. It is an object-oriented piece of software that sees any entity as an object.

**Executive**
The Windows executive provides services for the whole operating system. It is made up of six subsystems: object manager, security reference monitor, process manager, virtual memory manager, local procedure call facility, and the I/O manager. Most of these subsystems are familiar from our previous discussions of operating subsystems. Some subsystems, like the object manager, are added to Windows because of its object-oriented nature. The executive runs in kernel (privileged) mode.

**Environmental subsystems**
These are subsystems designed to allow Windows to run application programs designed for Windows, for other operating systems, or for earlier versions of Windows. The native subsystem that runs applications designed for Windows is called Win32. The environment subsystems run in the user mode (a non-privileged mode).

## 7.5 END-CHAPTER MATERIALS
### 7.5.1 Recommended reading
For more details about the subjects discussed in this chapter, the following books are recommended:
- Bic, L. and Shaw, A. *Operating Systems Principles*, Upper Saddle River, NJ: Prentice- Hall, 2003
- McHoes, A. and Flynn, I. *Understanding Operating Systems*, Boston, MA: Course Technology, 2007
- Nutt, G. *Operating Systems: A Modern Perspective*, Reading, MA: Addison-Wesley, 2001
- Silberschatz, A. and Galvin, P. *Operating System Concepts*, New York: Wiley, 2004

### 7.5.2 Key terms
- authentication
- batch operating system
- bootstrap
- circular waiting
- deadlock
- demand paging
- demand paging and segmentation
- demand segmentation
- device manager
- distributed system
- emacs
- frame
- graphical user interface (GUI)
- hardware abstraction layer (HAL)
- hold state
- job
- job scheduler
- kernel
- Linux
- memory management
- Microsoft Disk Operating System (MS-DOS)
- monoprogramming
- multiprogramming
- mutual exclusion
- no preemption
- operating system
- page
- paging
- parallel system
- partitioning
- pico
- portability
- portability process scheduler
- process
- process manager
- program
- queue
- ready state
- real-time system
- reliability
- resource holding
- running state
- scheduler
- scheduling
- shell
- single-user operating system
- software
- starvation
- state diagram
- terminated state
- time sharing
- UNIX
- user interface
- utility
- vi
- virtual memory
- waiting state
- Windows

### 7.5.3 Summary
- An operating system is an interface between the hardware of a computer and the user that facilitates the execution of programs and access to hardware and software resources. Two major design goals of an operating system are efficient use of hardware and ease of use of resources.
- Operating systems have gone through a long history of evolution: batch systems, time-sharing systems, personal systems, parallel systems, and distributed systems. A modern operating system has at least four functional areas: memory manager, process manager, device manager, and file manager. An operating system also provides a user interface.
- The first responsibility of a modern computer system is memory management. Memory allocation must be controlled by the operating system. Memory management techniques can be divided into two categories: monoprogramming and multiprogramming. In monoprogramming, most of the memory capacity is dedicated to one single program. In multiprogramming, more than one program can be in memory at the same time.
- The second responsibility of an operating system is process management. A process is a program in execution. The process manager uses schedulers and queues to manage processes. Process management involves synchronizing different processes with different resources. This may potentially create resource deadlock or starvation. Deadlock occurs when the operating system does not put resource restrictions on processes: starvation can happen when the operating system puts too many resource restrictions on a process.
- The third responsibility of an operating system is device or input/output management.
- The fourth responsibility of an operating system is file management. An operating system uses a file manager to control access to files. Access is permitted only by processes or users that are allowed access to specific files, and the type of access can vary.
- Two common operating systems with some similarities are UNIX and Linux. UNIX is a multiuser, multiprocessing, portable operating system made up from four parts: the kernel, the shell, a standard set of utilities, and application programs. Linux has three components: a kernel, a system utilities, and a system library.
- A popular family of operating systems from Microsoft is referred to as Windows. Windows is an object-oriented, multi-layer operating system. It uses several layers, including a hardware abstract layer (HAL), executive layer, and environment subsystem layer.
`,zh:`
# 第七章：作業系統

這是本書第一章處理電腦軟體的章節。在本章中，我們將探討作業系統在電腦中的角色。

## 學習目標
學完本章後，學生應能：
- 理解作業系統在電腦系統中的角色。
- 給出作業系統的定義。
- 理解將作業系統載入記憶體的啟動程序 (bootstrapping)。
- 列出作業系統的組件。
- 討論記憶體管理器在作業系統中的角色。
- 討論行程管理器在作業系統中的角色。
- 討論設備管理器在作業系統中的角色。
- 討論檔案管理器在作業系統中的角色。
- 理解三種常見作業系統的主要特性：UNIX、Linux 和 Windows。

## 7.1 簡介
電腦是一個由兩個主要組件組成的系統：硬體和軟體。電腦硬體是實體設備。軟體是讓硬體完成工作的一組程式。電腦**軟體**分為兩大類：**作業系統**和**應用程式**（圖 7.1）。應用程式使用電腦硬體來解決使用者的問題。另一方面，作業系統控制使用者對硬體的存取。

### 7.1.1 作業系統
**作業系統**非常複雜，因此很難給出一個簡單的通用定義。相反，這裡有一些常見的定義：
- 作業系統是電腦硬體與使用者（程式或人類）之間的介面。
- 作業系統是一個（或一組）促進其他程式執行的程式。
- 作業系統充當總經理，監管電腦系統中每個組件的活動。作為總經理，作業系統檢查硬體和軟體資源是否被有效使用，當資源使用發生衝突時，作業系統進行協調以解決衝突。

**作業系統是電腦硬體與使用者（程式或人類）之間的介面，它有助於其他程式的執行以及對硬體和軟體資源的存取。**

作業系統的兩個主要設計目標是：
- 硬體的有效使用。
- 資源的易用性。

### 7.1.2 啟動程序 (Bootstrap process)
根據上述定義，作業系統為其他程式提供支援。例如，它負責將其他程式載入記憶體以執行。然而，作業系統本身就是一個需要載入記憶體並運行的程式。這個困境是如何解決的？

如果作業系統（由製造商）使用 ROM 技術儲存在部分記憶體中，則可以解決此問題。CPU 的程式計數器（見第 5 章）可以設定為此 ROM 記憶體的開頭。當電腦開啟時，CPU 從 ROM 讀取指令並執行它們。然而，這個解決方案效率不高，因為很大一部分記憶體將由 ROM 組成，因此不能被其他程式使用。今天的技術只需要將一小部分記憶體分配給作業系統的一部分。

今天採用的解決方案是一個兩階段的過程。記憶體中一小部分由 ROM 組成，其中存放一個稱為**啟動程式 (bootstrap program)** 的小程式。當電腦開啟時，CPU 計數器被設定為此啟動程式的第一條指令，並執行此程式中的指令。此程式僅負責將作業系統本身，或啟動電腦所需的部分作業系統載入 RAM 記憶體。當載入完成時，CPU 中的程式計數器被設定為 RAM 中作業系統的第一條指令，作業系統隨即執行。圖 7.2 說明了啟動程序。

## 7.2 演進
作業系統經歷了漫長的演進歷史，我們接下來將進行總結。

### 7.2.1 批次系統
**批次作業系統**設計於 1950 年代，用於控制大型主機。當時，電腦是使用打孔卡輸入、行列式印表機輸出和磁帶機作為輔助儲存媒體的大型機器。

每個要執行的程式稱為一個工作 (job)。希望執行工作的程式設計師將請求連同程式和資料的打孔卡發送到操作室。操作員將打孔卡送入電腦。如果程式成功，結果的列印輸出將發送給程式設計師——如果失敗，則發送錯誤的列印輸出。

這個時代的作業系統非常簡單：它們只確保所有電腦資源從一個工作轉移到下一個工作。

### 7.2.2 分時系統
為了有效地利用電腦系統資源，引入了**多重程式設計 (multiprogramming)**。其想法是一次將多個工作保留在記憶體中，並且僅在資源可用的條件下將資源分配給需要它的工作。例如，當一個程式正在使用輸入/輸出設備時，CPU 是空閒的，可以被另一個程式使用。我們將在本章稍後討論多重程式設計。

多重程式設計帶來了**分時 (time sharing)** 的概念：資源可以在不同工作之間共享，每個工作分配一部分時間來使用資源。因為電腦比人類快得多，所以分時對使用者來說是隱藏的——每個使用者都有整個系統專門為他們服務的印象。

多重程式設計，以及最終的分時，極大地提高了電腦系統的效率。然而，它們需要更複雜的作業系統。作業系統現在必須進行**排程 (scheduling)**：將資源分配給不同的程式，並決定哪個程式應該使用哪個資源，以及何時使用。在這個時代，電腦與使用者之間的關係也發生了變化。使用者可以直接與系統互動，而無需通過操作員。還創造了一個新術語：**行程 (process)**。工作是要運行的程式，而行程是在記憶體中並等待資源的程式。

### 7.2.3 個人系統
當個人電腦問世時，需要一種用於這種新型電腦的作業系統。在這個時代，引入了**單使用者作業系統**，如 **DOS (磁碟作業系統)**。

### 7.2.4 平行系統
對更高速度和效率的需求導致了**平行系統**的設計：同一台機器上有多個 CPU。每個 CPU 可用於服務一個程式或程式的一部分，這意味著許多任務可以並行完成而不是串列完成。這所需的作業系統比支援單一 CPU 的作業系統更複雜。

### 7.2.5 分散式系統
網路和互連網，如我們在第 6 章所見，在作業系統中創造了一個新的維度。以前在一台電腦上完成的工作現在可以在相距數千英里的電腦之間共享。如果程式透過網際網路等互連網連接，則可以在一台電腦上部分運行，在另一台電腦上部分運行。此外，資源可以分散式。程式可能需要位於世界不同地區的檔案。**分散式系統**結合了前一代的特性，並增加了新的職責，如控制安全性。

### 7.2.6 即時系統
**即時系統**期望在特定的時間限制內完成任務。它們用於即時應用程式，監控、回應或控制外部過程或環境。例子可以在交通控制、病患監測或軍事控制系統中找到。應用程式有時可以是嵌入式系統，例如大型系統的一個組件，如汽車中的控制系統。

即時作業系統的要求通常不同於通用系統。因此，我們不在本章討論它們。

## 7.3 組件
現代作業系統非常複雜。作業系統需要管理電腦系統中的不同資源。它類似於一個高層有多位經理的組織。每位經理負責管理其部門，但也需要與他人合作並協調活動。現代作業系統至少有四個職責：記憶體管理器、行程管理器、設備管理器和檔案管理器。就像許多組織有一個不一定隸屬於任何特定經理的部門一樣，作業系統也有這樣一個組件，通常稱為使用者介面或 shell。使用者介面負責作業系統外部的通訊。圖 7.3 顯示了作業系統的典型組件。

### 7.3.1 使用者介面
每個作業系統都有一個**使用者介面**，這是一個接受使用者（行程）請求並為作業系統其餘部分解釋這些請求的程式。在某些作業系統（如 UNIX）中，使用者介面稱為 **shell**。在其他系統中，它被稱為視窗，表示它是選單驅動的，並具有 **GUI (圖形使用者介面)** 組件。

### 7.3.2 記憶體管理器
現代電腦系統的職責之一是**記憶體管理**。雖然近年來電腦的記憶體大小急劇增加，但要處理的程式和資料的大小也在增加。必須管理記憶體分配以防止應用程式耗盡記憶體。作業系統可以分為兩大類記憶體管理：單道程式設計和多重程式設計。

**單道程式設計 (Monoprogramming)**
**單道程式設計**屬於過去，但值得一提，因為它有助於我們理解多重程式設計。在單道程式設計中，大部分記憶體容量專用於單個程式（我們將程式處理的資料視為程式的一部分）；只需要一小部分來保存作業系統。在這種配置中，整個程式都在記憶體中執行。當程式執行完畢時，程式區域被另一個程式佔用（圖 7.4）。

這裡記憶體管理器的工作很簡單。它將程式載入記憶體，運行它，然後用下一個程式替換它。然而，這種技術有幾個問題：
- 程式必須適合記憶體。如果記憶體大小小於程式大小，則無法運行該程式。
- 當一個程式正在運行時，不能執行其他程式。程式在執行期間通常需要從輸入設備接收資料並需要向輸出設備發送資料。與 CPU 相比，輸入/輸出設備很慢，因此當執行輸入/輸出操作時，CPU 是空閒的。它不能服務另一個程式，因為該程式不在記憶體中。這是對記憶體和 CPU 時間的一種非常低效的使用。

**多重程式設計 (Multiprogramming)**
在**多重程式設計**中，記憶體中同時有多個程式，並且它們並行執行，CPU 在程式之間快速切換。圖 7.5 顯示了多重程式設計環境中的記憶體。
自 1960 年代以來，多重程式設計經歷了幾次改進，如圖 7.6 的分類法所示。

我們在接下來的幾節中非常簡要地討論每種方案。其中兩種技術屬於*非交換 (nonswapping)* 類別，這意味著程式在執行期間保留在記憶體中。另外兩種技術屬於*交換 (swapping)* 類別。這意味著在執行期間，程式可以在記憶體和磁碟之間交換一次或多次。

**分割 (Partitioning)**
多重程式設計中使用的第一種技術稱為**分割**。在這個方案中，記憶體被劃分為可變長度的區段。每個區段或分割區保存一個程式。CPU 在程式之間切換。它從一個程式開始，執行一些指令，直到遇到輸入/輸出操作或分配給該程式的時間已過。然後 CPU 保存最後執行指令的記憶體位置位址，並移動到下一個程式。對第二個程式重複相同的過程。在所有程式都得到服務後，CPU 移回第一個程式。優先級別也可用於控制分配給每個程式的 CPU 時間量（圖 7.7）。

使用這種技術，每個程式都完全在記憶體中並佔用連續的位置。分割提高了 CPU 的效率，但仍然存在一些問題：
- 分割區的大小必須由記憶體管理器預先決定。如果分割區太小，某些程式將無法載入記憶體。如果分割區太大，記憶體中可能會有一些「洞」（未使用的位置）。
- 即使在電腦啟動時分割是完美的，但在完成的程式被新程式替換後，可能會出現一些洞。
- 當有很多洞時，記憶體管理器可以壓縮分割區以去除洞並建立新的分割區，但這會給系統帶來額外的開銷。

**分頁 (Paging)**
**分頁**提高了分割的效率。在分頁中，記憶體被劃分為大小相等的區段，稱為**頁框 (frames)**。程式也被劃分為大小相等的區段，稱為**頁面 (pages)**。頁面和頁框的大小通常相同，並且等於系統用於從儲存設備檢索資訊的區塊大小（圖 7.8）。

頁面被載入到記憶體中的頁框中。如果一個程式有三個頁面，它佔用記憶體中的三個頁框。使用這種技術，程式不必在記憶體中連續；兩個連續的頁面可以佔用記憶體中的非連續頁框。分頁優於分割的優點是，每個使用三個非連續頁框的兩個程式可以被一個需要六個頁框的程式替換。新程式無需等到有六個連續的頁框空閒才能載入記憶體。

分頁在一定程度上提高了效率，但整個程式在執行前仍需要在記憶體中。這意味著，例如，如果目前只有四個未佔用的頁框，則無法將需要六個頁框的程式載入記憶體。

**請求分頁 (Demand paging)**
分頁不要求程式位於連續的記憶體位置，但它確實要求整個程式在執行時都在記憶體中。**請求分頁**已經消除了這最後一個限制。在請求分頁中，程式被劃分為頁面，但頁面可以逐一載入記憶體，執行，並由另一個頁面替換。換句話說，記憶體可以同時保存來自多個程式的頁面。此外，來自同一程式的連續頁面不必載入到同一頁框中——頁面可以載入到任何空閒頁框中。圖 7.9 顯示了請求分頁的一個例子。來自程式 A 的兩個頁面、來自程式 B 的一個頁面和來自程式 C 的一個頁面在記憶體中。

**請求分段 (Demand segmentation)**
一種類似於分頁的技術是**分段**。在分頁中，程式被劃分為大小相等的頁面，這不是程式設計師思考的方式——程式設計師是以模組來思考的。正如我們將在後面的章節中看到的，程式通常由主程式和子程式組成。在**請求分段**中，程式被劃分為符合程式設計師視圖的區段。這些被載入記憶體，執行，並由來自同一或不同程式的另一個模組替換。圖 7.10 顯示了請求分段的一個例子。由於記憶體中的區段大小相等，部分區段可能會保持空白。

**請求分頁和分段**
請求分頁和分段可以結合起來進一步提高系統的效率。一個區段可能太大而無法適應記憶體中任何可用的空閒空間。記憶體可以劃分為頁框，模組可以劃分為頁面。然後模組的頁面可以逐一載入記憶體並執行。

**虛擬記憶體 (Virtual memory)**
請求分頁和請求分段意味著，當程式正在執行時，部分程式在記憶體中，部分在磁碟上。這意味著，例如，10 MB 的記憶體大小可以執行十個程式，每個程式大小為 3 MB，總共 30 MB。在任何時刻，十個程式的 10 MB 在記憶體中，20 MB 在磁碟上。因此，實際記憶體大小為 10 MB，但虛擬記憶體大小為 30 MB。圖 7.11 顯示了這個概念。**虛擬記憶體**意味著請求分頁、請求分段或兩者兼有，如今幾乎所有作業系統都在使用。

### 7.3.3 行程管理器
作業系統的第二個功能是行程管理，但在討論這個概念之前，我們需要定義一些術語。

**程式、工作和行程**
現代作業系統使用三個術語來指代一組指令：程式、工作和行程。雖然術語含糊不清且因作業系統而異，但我們可以非正式地定義這些術語。

**程式 (Program)**
**程式**是儲存在磁碟（或磁帶）上的非活動指令集。它可能成為也可能不會成為工作。

**工作 (Job)**
程式從被選中執行到運行結束並再次成為程式的這段時間稱為**工作**。它可能位於磁碟上等待載入記憶體，或者可能已載入記憶體並等待 CPU 執行。它可能在磁碟或記憶體中等待輸入/輸出事件，或者可能正在記憶體中由 CPU 執行。在所有這些情況下，程式都是工作。當工作完成執行（正常或異常）時，它變成程式並再次駐留在磁碟上。作業系統不再管理該程式。請注意，每個工作都是程式，但並非每個程式都是工作。

**行程 (Process)**
**行程**是正在執行中的程式。它是一個已開始但尚未完成的程式。換句話說，行程是在記憶體中運行的工作。它已從其他等待的工作中被選中並載入記憶體。行程可能正在執行，也可能正在等待 CPU 時間。只要工作在記憶體中，它就是一個行程。請注意，每個行程都是工作，但並非每個工作都是行程。

**狀態圖**
如果我們考慮程式如何成為工作以及工作如何成為行程，程式、工作和行程之間的關係就會變得更清晰。這可以用顯示這些實體中每一個的不同狀態的**狀態圖**來說明。圖 7.12 是一個使用邊界區分程式、工作和行程的狀態圖。

程式被作業系統選中並帶到**保持狀態 (hold state)** 時成為工作。它保持在這個狀態，直到它可以被載入記憶體。當有記憶體空間可以完全或部分載入程式時，工作移動到**就緒狀態 (ready state)**。它現在變成了一個行程。它保留在記憶體中並處於此狀態，直到 CPU 可以執行它，此時移動到**執行狀態 (running state)**。處於執行狀態時，可能會發生三件事之一：
- 行程執行直到需要 I/O 資源
- 行程用盡了分配給它的時間片
- 行程終止
在第一種情況下，行程進入**等待狀態 (waiting state)** 並等待 I/O 完成。在第二種情況下，它直接回到就緒狀態。在第三種情況下，它進入**終止狀態 (terminated state)**，不再是行程。行程可以在進入終止狀態之前多次在執行、等待和就緒狀態之間移動。請注意，如果系統使用虛擬記憶體並將程式換入和換出主記憶體，則圖表可能會複雜得多。

**排程器**
為了將工作或行程從一種狀態移動到另一種狀態，行程管理器使用兩個**排程器**：工作排程器和行程排程器。

**工作排程器 (Job scheduler)**
**工作排程器**將工作從保持狀態移動到就緒狀態，或從執行狀態移動到終止狀態。換句話說，工作排程器負責從工作創建行程並終止行程。圖 7.13 顯示了工作排程器。

**行程排程器 (Process scheduler)**
**行程排程器**將行程從一種狀態移動到另一種狀態。當行程等待某些事件發生時，它將行程從執行狀態移動到等待狀態。當事件發生時，它將行程從等待狀態移動到就緒狀態。如果行程的時間分配已過期，它將行程從執行狀態移動到就緒狀態。當 CPU 準備好運行行程時，行程排程器將行程從就緒狀態移動到執行狀態。圖 7.14 顯示了行程排程器。

**其他排程器**
一些作業系統使用其他類型的排程器來使行程之間的切換更有效率。

**佇列 (Queuing)**
我們的狀態圖顯示一個工作或行程從一種狀態移動到另一種狀態。實際上，有許多工作和許多行程在爭奪電腦資源。例如，當一些工作在記憶體中時，其他工作必須等待直到空間可用。或者當一個行程正在使用 CPU 運行時，其他行程必須等待直到 CPU 空閒。為了處理多個行程和工作，行程管理器使用**佇列**（等待列表）。*工作控制區塊*或*行程控制區塊*與每個工作或行程相關聯。這是一塊記憶體，儲存有關該工作或行程的資訊。行程管理器將工作或行程控制區塊儲存在佇列中，而不是工作或行程本身。工作或行程本身保留在記憶體或磁碟中，因為它太大而無法在佇列中複製：工作控制區塊或行程控制區塊是等待工作或行程的代表。
一個作業系統可以有幾個佇列。例如，圖 7.15 顯示了工作和行程通過三個佇列的循環：工作佇列、就緒佇列和 I/O 佇列。工作佇列保存等待記憶體的工作。就緒佇列保存記憶體中準備運行並等待 CPU 的行程。I/O 佇列保存等待 I/O 設備的行程（可以有幾個 I/O 佇列，每個輸入/輸出設備一個，但為了簡單起見我們只顯示一個）。

行程管理器可以有不同的策略從佇列中選擇下一個工作或行程：可以是先進先出 (FIFO)、最短長度優先、最高優先順序優先等等。

**行程同步**
行程管理背後的整個想法是使不同的行程與不同的資源同步。每當資源可以被多個使用者（或在這種情況下是行程）使用時，我們可能會遇到兩種有問題的情況：*死結*和*饑餓*。這兩種情況的簡要討論如下。

**死結 (Deadlock)**
我們不給出**死結**的正式定義，而是給出一個例子。假設有兩個行程 A 和 B。行程 A 持有一個檔案 File1（即 File1 分配給 A），並且在獲取另一個檔案 File2 之前無法釋放它（即 A 請求 File2）。行程 B 持有 File2（即 File2 分配給 B），並且在擁有 File1 之前無法釋放它（即 B 請求 File1）。大多數系統中的檔案是不可共享的——當一個行程使用時，另一個行程不能使用。如果在這種情況下沒有強制行程釋放檔案的規定，就會產生死結（圖 7.16）。

作為類比，圖 7.17 顯示了狹窄橋樑上的死結。情況類似，因為資源（橋的一部分）由一輛車持有，直到它獲得由另一輛車持有的橋的另一部分才釋放，反之亦然。

如果作業系統允許行程開始運行而無需先檢查所需資源是否準備就緒，並允許行程隨心所欲地持有資源，則會發生死結。系統中應該有一些規定來防止死結。一種解決方案是在所需資源空閒之前不允許行程開始運行，但我們稍後會看到這會產生另一個問題。第二種解決方案是限制行程持有資源的時間。

**當作業系統不對行程施加資源限制時，就會發生死結。**

死結並不總是發生。死結有四個必要條件，如下所示：
- **互斥 (Mutual exclusion)**。只有一個行程可以持有資源。
- **資源持有 (Resource holding)**。行程持有一個資源，即使它在其他資源可用之前無法使用它。
- **無搶佔 (No preemption)**。作業系統不能暫時重新分配資源。
- **循環等待 (Circular waiting)**。所有涉及的行程和資源形成一個迴圈，如圖 7.16 所示。
死結發生需要所有四個條件。然而，這些條件只是必要的先決條件，本身不足以導致死結——它們必須存在才會發生死結，但可能不足以導致死結。如果缺少這些條件之一，則不會發生死結。這給了我們一種預防或避免死結的方法：不允許這些條件之一發生。

**饑餓 (Starvation)**
**饑餓**是死結的對立面。當作業系統對行程施加過多的資源限制時，就會發生這種情況。例如，想像一個作業系統規定行程必須擁有其所需的資源才能運行。
在圖 7.18 中，想像行程 A 需要兩個檔案 File1 和 File2。File1 正在被行程 B 使用，File2 正在被行程 E 使用。行程 B 先終止並釋放 File1。行程 A 無法啟動，因為 File2 仍然不可用。此時，只需要 File1 的行程 C 被允許運行。現在行程 E 終止並釋放 File2，但行程 A 仍然無法運行，因為 File1 不可用。

一個經典的饑餓問題是由 Edsger Dijkstra 提出的。五位哲學家圍坐在一張圓桌旁（圖 7.19）。每位哲學家需要兩根筷子才能吃一碗飯。然而，一根或兩根筷子可能被鄰居使用。如果兩根筷子不同時可用，哲學家可能會挨餓。

### 7.3.4 設備管理器
**設備管理器**或輸入/輸出管理器負責存取輸入/輸出設備。電腦系統中輸入/輸出設備的數量和速度是有限的。由於這些設備的速度比 CPU 和記憶體慢，當一個行程存取輸入/輸出設備時，該設備在一段時間內對其他行程不可用。設備管理器負責輸入/輸出設備的有效使用。

設備管理器的詳細討論需要作業系統原理的高級知識，超出了本書的範圍。然而，我們可以簡要列出設備管理器的職責：
- 設備管理器持續監控每個輸入/輸出設備，以確保設備正常運作。管理器還需要知道設備何時完成服務一個行程並準備好服務佇列中的下一個行程。
- 設備管理器為每個輸入/輸出設備維護一個佇列，或為類似的輸入/輸出設備維護一個或多個佇列。例如，如果系統中有兩台快速印表機，管理器可以為每台印表機維護一個佇列，或者為兩台印表機維護一個佇列。
- 設備管理器控制存取輸入/輸出設備的不同策略。例如，它可能對一個設備使用 FIFO，對另一個設備使用最短長度優先。

### 7.3.5 檔案管理器
今天的作業系統使用**檔案管理器**來控制對檔案的存取。關於檔案管理器的詳細討論也需要作業系統原理和檔案存取概念的高級知識，這超出了本書的範圍。我們在第 13 章討論一些與檔案存取相關的問題，但這不足以理解檔案管理器的實際運作。以下是檔案管理器職責的簡要列表：

- 檔案管理器控制對檔案的存取。僅允許獲得許可的應用程式和/或使用者存取，並且存取類型可以不同。例如，一個行程（或呼叫行程的使用者）可能被允許從檔案讀取但被允許寫入（即更改）它。另一個行程可能被允許執行檔案和行程，但不允許讀取其內容，依此類推。
- 檔案管理器監督檔案的創建、刪除和修改。
- 檔案管理器可以控制檔案的命名。
- 檔案管理器監督檔案的儲存：它們如何儲存，儲存在哪裡等等。
- 檔案管理器負責存檔和備份。

## 7.4 作業系統概覽
在本節中，我們介紹一些流行的作業系統，並鼓勵您進一步研究它們。我們選擇了大多數電腦使用者熟悉的三種作業系統：UNIX、Linux 和 Windows。

### 7.4.1 UNIX
**UNIX** 最初由貝爾實驗室電腦科學研究小組的 Thomson 和 Ritchie 於 1969 年開發。從那時起，UNIX 經歷了許多版本。它一直是電腦程式設計師和電腦科學家中流行的作業系統。它是一個非常強大的作業系統，具有三個顯著特徵。首先，UNIX 是一個可移植的作業系統，可以從一個平台移動到另一個平台而無需太多更改。原因是它主要用 C 語言編寫（而不是特定於特定電腦系統的機器語言）。其次，UNIX 擁有一組強大的公用程式（命令），可以組合（在稱為*腳本*的可執行檔案中）來解決許多在其他作業系統中需要編程的問題。第三，它與設備無關，因為它在作業系統本身中包含設備驅動程式，這意味著它可以輕鬆配置以運行任何設備。
UNIX 是一個多使用者、多工、可移植的作業系統，旨在促進程式設計、文字處理、通訊和作業系統預期的許多其他任務。它包含數百個簡單的單一用途功能，可以組合成幾乎可以想像到的每個處理任務。它的靈活性體現在它用於三種不同的計算環境：獨立個人環境、分時系統和主從式系統。

**UNIX 是一個多使用者、多工、可移植的作業系統。它旨在促進程式設計、文字處理和通訊。**

**UNIX 架構**
UNIX 由四個主要組件組成：*核心*、*shell*、一組標準*公用程式*和*應用程式*。這些組件如圖 7.20 所示。

**核心 (The kernel)**
**核心**是 UNIX 系統的心臟。它包含作業系統最基本的部分：記憶體管理、行程管理、設備管理和檔案管理。系統的所有其他組件都呼叫核心來為它們執行這些服務。

**Shell**
**Shell** 是 UNIX 中對使用者最可見的部分。它接收並解釋使用者輸入的命令。在許多方面，這使其成為 UNIX 架構中最重要的組件。它當然是使用者最了解的部分。要在系統中做任何事情，我們必須給 shell 一個命令。如果命令需要公用程式，shell 請求核心執行公用程式。如果命令需要應用程式，shell 請求核心運行它。一些作業系統，如 UNIX，有幾個不同的 shell。

**公用程式 (Utilities)**
實際上只有數百個 UNIX 公用程式。**公用程式**是一個標準的 UNIX 程式，為使用者提供支援過程。三種常見的公用程式是文字編輯器、搜尋程式和排序程式。
許多系統公用程式實際上是複雜的應用程式。例如，UNIX 電子郵件系統被認為是一個公用程式，三個常見的文字編輯器 **vi**、**emacs** 和 **pico** 也是如此。這四個公用程式本身就是大型系統。其他公用程式是較短、較簡單的功能。例如，列表 (**ls**) 公用程式顯示磁碟目錄中的檔案。

**應用程式 (Applications)**
UNIX 中的應用程式不是作業系統發行版標準部分的程式。由系統管理員、專業程式設計師或使用者編寫，它們為系統提供了擴展功能。事實上，許多標準公用程式在幾年前也是作為應用程式開始的，並被證明非常有用，以至於它們現在已成為系統的一部分。

### 7.4.2 Linux
1991 年，當時赫爾辛基大學的芬蘭學生 Linus Torvalds 開發了一種新的作業系統，今天被稱為 **Linux**。最初的核心類似於 UNIX 的一小部分，如今已發展成為一個全面的作業系統。Linus 2.0 核心於 1997 年發布，被接受為商業作業系統：它具有傳統上歸因於 UNIX 的所有功能。

**組件**
Linux 具有以下組件。

**核心 (Kernel)**
核心負責歸因於核心的所有職責，例如記憶體管理、行程管理、設備管理和檔案管理。

**系統函式庫 (System libraries)**
系統函式庫保存一組由應用程式（包括 shell）使用的函式，以與核心互動。

**系統公用程式 (System utilities)**
系統公用程式是使用系統函式庫提供的服務來執行管理任務的單獨程式。

**網路功能 (Networking capabilities)**
Linux 支援第 6 章討論的標準網際網路協定。它支援三層：插座介面、協定驅動程式和網路設備驅動程式。

**安全性 (Security)**
Linux 的安全機制提供了傳統上為 UNIX 定義的安全方面，例如**驗證**和存取控制。

### 7.4.3 Windows
在 1980 年代後期，微軟開始開發一種新的單使用者作業系統來取代 **MS-DOS**（微軟磁碟作業系統）。**Windows** 就是結果。隨後發布了幾個版本的 Windows。我們將所有這些版本統稱為 Windows。

**設計目標**
微軟發布的設計目標是*可擴展性*、*可移植性*、*可靠性*、*相容性*和*效能*。

**可擴展性 (Extensibility)**
Windows 設計為具有多層的模組化架構。目的是讓較高層隨時間更改而不影響較低層。

**可移植性 (Portability)**
像 UNIX 一樣，Windows 主要用 C 或 C++ 編寫，代碼獨立於運行它的電腦的機器語言。

**可靠性 (Reliability)**
Windows 旨在處理錯誤條件，包括防止惡意軟體。

**相容性 (Compatibility)**
Windows 旨在運行原本為其他作業系統和早期版本 Windows 編寫的程式。

**效能 (Performance)**
Windows 旨在對在作業系統之上運行的應用程式具有快速的回應時間。

**架構**
Windows 使用分層架構，如圖 7.21 所示。

**HAL**
**硬體抽象層 (HAL)** 向較高層隱藏硬體差異。

**核心 (Kernel)**
核心是作業系統的心臟。它是一個物件導向的軟體，將任何實體視為物件。

**執行層 (Executive)**
Windows 執行層為整個作業系統提供服務。它由六個子系統組成：物件管理器、安全參考監視器、行程管理器、虛擬記憶體管理器、本地過程呼叫設施和 I/O 管理器。我們之前對作業系統子系統的討論中已經熟悉了這些子系統中的大多數。一些子系統，如物件管理器，由於其物件導向的性質而被添加到 Windows 中。執行層在核心（特權）模式下運行。

**環境子系統 (Environmental subsystems)**
這些子系統旨在允許 Windows 運行專為 Windows、其他作業系統或早期版本 Windows 設計的應用程式。運行專為 Windows 設計的應用程式的原生子系統稱為 Win32。環境子系統在使用者模式（非特權模式）下運行。

## 7.5 章末材料
### 7.5.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Bic, L. and Shaw, A. *Operating Systems Principles*, Upper Saddle River, NJ: Prentice- Hall, 2003
- McHoes, A. and Flynn, I. *Understanding Operating Systems*, Boston, MA: Course Technology, 2007
- Nutt, G. *Operating Systems: A Modern Perspective*, Reading, MA: Addison-Wesley, 2001
- Silberschatz, A. and Galvin, P. *Operating System Concepts*, New York: Wiley, 2004

### 7.5.2 關鍵詞
- 驗證 (authentication)
- 批次作業系統 (batch operating system)
- 啟動程序 (bootstrap)
- 循環等待 (circular waiting)
- 死結 (deadlock)
- 請求分頁 (demand paging)
- 請求分頁與分段 (demand paging and segmentation)
- 請求分段 (demand segmentation)
- 設備管理器 (device manager)
- 分散式系統 (distributed system)
- emacs
- 頁框 (frame)
- 圖形使用者介面 (graphical user interface, GUI)
- 硬體抽象層 (hardware abstraction layer, HAL)
- 保持狀態 (hold state)
- 工作 (job)
- 工作排程器 (job scheduler)
- 核心 (kernel)
- Linux
- 記憶體管理 (memory management)
- 微軟磁碟作業系統 (Microsoft Disk Operating System, MS-DOS)
- 單道程式設計 (monoprogramming)
- 多重程式設計 (multiprogramming)
- 互斥 (mutual exclusion)
- 無搶佔 (no preemption)
- 作業系統 (operating system)
- 頁面 (page)
- 分頁 (paging)
- 平行系統 (parallel system)
- 分割 (partitioning)
- pico
- 可移植性 (portability)
- 可移植性行程排程器 (portability process scheduler)
- 行程 (process)
- 行程管理器 (process manager)
- 程式 (program)
- 佇列 (queue)
- 就緒狀態 (ready state)
- 即時系統 (real-time system)
- 可靠性 (reliability)
- 資源持有 (resource holding)
- 執行狀態 (running state)
- 排程器 (scheduler)
- 排程 (scheduling)
- shell
- 單使用者作業系統 (single-user operating system)
- 軟體 (software)
- 饑餓 (starvation)
- 狀態圖 (state diagram)
- 終止狀態 (terminated state)
- 分時 (time sharing)
- UNIX
- 使用者介面 (user interface)
- 公用程式 (utility)
- vi
- 虛擬記憶體 (virtual memory)
- 等待狀態 (waiting state)
- Windows

### 7.5.3 摘要
- 作業系統是電腦硬體與使用者之間的介面，它促進程式的執行以及對硬體和軟體資源的存取。作業系統的兩個主要設計目標是硬體的有效使用和資源的易用性。
- 作業系統經歷了漫長的演進歷史：批次系統、分時系統、個人系統、平行系統和分散式系統。現代作業系統至少有四個功能區域：記憶體管理器、行程管理器、設備管理器和檔案管理器。作業系統還提供使用者介面。
- 現代電腦系統的第一個職責是記憶體管理。記憶體分配必須由作業系統控制。記憶體管理技術可分為兩類：單道程式設計和多重程式設計。在單道程式設計中，大部分記憶體容量專用於單個程式。在多重程式設計中，記憶體中可以同時有多個程式。
- 作業系統的第二個職責是行程管理。行程是正在執行中的程式。行程管理器使用排程器和佇列來管理行程。行程管理涉及同步具有不同資源的不同行程。這可能會產生資源死結或饑餓。當作業系統不對行程施加資源限制時，就會發生死結：當作業系統對行程施加過多的資源限制時，可能會發生饑餓。
- 作業系統的第三個職責是設備或輸入/輸出管理。
- 作業系統的第四個職責是檔案管理。作業系統使用檔案管理器來控制對檔案的存取。僅允許被允許存取特定檔案的行程或使用者存取，並且存取類型可以不同。
- 兩種具有一些相似之處的常見作業系統是 UNIX 和 Linux。UNIX 是一個多使用者、多工、可移植的作業系統，由四個部分組成：核心、shell、一組標準公用程式和應用程式。Linux 有三個組件：核心、系統公用程式和系統函式庫。
- 來自微軟的一個流行的作業系統家族稱為 Windows。Windows 是一個物件導向、多層作業系統。它使用多層，包括硬體抽象層 (HAL)、執行層和環境子系統層。
`},l={en:`
# Chapter 8: Algorithms

In this chapter we introduce the concept of algorithms, step-by-step procedures for solving a problem. We then discuss the tools used to develop algorithms. Finally, we give some examples of common iterative and recursive algorithms.

## Objectives
After studying this chapter, the student should be able to:
- Define an algorithm and relate it to problem solving.
- Define three constructs—sequence, selection, and repetition—and describe their use in algorithms.
- Describe UML diagrams and how they can be used when representing algorithms.
- Describe pseudocode and how it can be used when representing algorithms.
- List basic algorithms and their applications.
- Describe the concept of sorting and understand the mechanisms behind three primitive sorting algorithms.
- Describe the concept of searching and understand the mechanisms behind two common searching algorithms.
- Define subalgorithms and their relations to algorithms.
- Distinguish between iterative and recursive algorithms.

## 8.1 CONCEPT
In this section we informally define an **algorithm** and elaborate on the concept using an example.

### 8.1.1 Informal definition
An informal definition of an algorithm is:

**Algorithm: a step-by-step method for solving a problem or doing a task.**

In this definition, an algorithm is independent of the computer system. More specifically, we should also note that the algorithm accepts **input data** and creates **output data** (Figure 8.1).

### 8.1.2 Example
Let us elaborate on this simple definition with an example. We want to develop an algorithm for finding the largest integer among a list of positive integers. The algorithm should find the largest integer among a list of any size (for example 5, 1000, 10000, 1000000). The algorithm should be general and not depend on the number of integers.

It is obvious that finding the largest integer among many integers is a task that cannot be done in one step, either by a human or a computer. The algorithm needs to test each integer one by one.

To solve this problem, we need an intuitive approach. First use a small number of integers (for example, five), then extend the solution to any number of integers. Our solution for five integers follows the same principles and restrictions for one thousand or one million integers. Assume, even for a five-integer case, that the algorithm handles the integers one by one. It looks at the first integer without knowing the values of the remaining integers. After it handles the first one, it looks at the second integer, and so on. Figure 8.2 shows one way to solve this problem.

We call the algorithm FindLargest. Each algorithm has a name to distinguish it from other algorithms. The algorithm receives a list of five integers as input and gives the largest integer as output.

**Input**
The algorithm accepts the list of five integers as input.

**Processing**
The algorithm uses the following five steps to find the largest integer:
**Step 1**
In this step, the algorithm inspects the first integer (12). Since it does not know the values of other integers, it decides that the largest integer (so far) is the first integer. The algorithm defines a data item, called Largest, and sets its value to the first integer (12).
**Step 2**
The largest integer so far is 12, but the new integer may change the situation. The algorithm makes a comparison between the value of Largest (12) and the value of the second integer (8). It finds that Largest is larger than the second integer, which means that Largest is still holding the largest integer. There is no need to change the value of Largest.
**Step 3**
The largest integer so far is 12, but the new integer (13) is larger than Largest. This means than the value of Largest is no longer valid. The value of Largest should be replaced by the third integer (13). The algorithm changes the value of Largest to 13 and moves to the next step.
**Step 4**
Nothing is changed in this step because Largest is larger than the fourth integer (9).
**Step 5**
Again nothing is changed because Largest is larger than the fifth integer (11).

**Output**
Because there are no more integers to be processed, the algorithm outputs the value of Largest, which is 13.

### 8.1.3 Defining actions
Figure 8.2 does not show what should be done in each step. We can modify the figure to show more details. For example, in step 1, set Largest to the value of the first integer. In steps 2 to 5, however, additional actions are needed to compare the value of Largest with the current integer being processed. If the current integer is larger than Largest, set the value of Largest to the current integer (Figure 8.3).

### 8.1.4 Refinement
This algorithm needs refinement to be acceptable to the programming community. There are two problems. First, the action in the first step is different than those for the other steps. Second, the wording is not the same in steps 2 to 5. We can easily redefine the algorithm to remove these two inconveniences by changing the wording in steps 2 to 5 to ‘If the current integer is greater than Largest, set Largest to the current integer’. The reason that the first step is different than the other steps is because Largest is not initialized.

If we initialize Largest to $-\\infty$ (minus infinity), then the first step can be the same as the other steps, so we add a new step, calling it step 0 to show that it should be done before processing any integers.
Figure 8.4 shows the result of this refinement. Note that we do not have to show all the steps, because they are now the same.

### 8.1.5 Generalization
Is it possible to generalize the algorithm? We want to find the largest of $n$ positive integers, where $n$ can be 1000, 1000000, or more. Of course, we can follow Figure 8.4 and repeat each step. But if we change the algorithm to a program, then we need to actually type the actions for $n$ steps!
There is a better way to do this. We can tell the computer to repeat the steps $n$ times. We now include this feature in our pictorial algorithm (Figure 8.5).

## 8.2 THREE CONSTRUCTS
Computer scientists have defined three constructs for a structured program or algorithm. The idea is that a program must be made of a combination of only these three constructs: *sequence*, *decision*, and *repetition* (Figure 8.6). It has been proven there is no need for any other constructs. Using only these constructs makes a program or an algorithm easy to understand, debug, or change.

### 8.2.1 Sequence
The first construct is called the **sequence**. An algorithm, and eventually a program, is a sequence of instructions, which can be a simple instruction or either of the other two constructs.

### 8.2.2 Decision
Some problems cannot be solved with only a sequence of simple instructions. Sometimes we need to test a condition. If the result of testing is true, we follow a sequence of instructions: if it is false, we follow a different sequence of instructions. This is called the **decision (selection)** construct.

### 8.2.3 Repetition
In some problems, the same sequence of instructions must be repeated. We handle this with the **repetition** or **loop** construct. Finding the largest integer among a set of integers can use a construct of this kind.

## 8.3 ALGORITHM REPRESENTATION
So far, we have used figures to convey the concept of an algorithm. During the last few decades, tools have been designed for this purpose. Two of these tools, UML and pseudocode, are presented here.

### 8.3.1 UML
**Unified Modeling Language (UML)** is a pictorial representation of an algorithm. It hides all the details of an algorithm in an attempt to give the ‘big picture’ and to show how the algorithm flows from beginning to end.
UML is covered in detail in Appendix B. Here we show only how the three constructs are represented using UML (Figure 8.7). Note that UML allows us a lot of flexibility, as shown in Appendix B. For example, the decision construct can be simplified if there are no actions on the false part.

### 8.3.2 Pseudocode
**Pseudocode** is an English-language-like representation of an algorithm. There is no standard for pseudocode—some people use a lot of detail, others use less. Some use a code that is close to English, while others use a syntax like the Pascal programming language. Pseudocode is covered in detail in Appendix C. Here we show only how the three constructs can be represented by pseudocode (Figure 8.8).

> **Example 8.1**
> Write an algorithm in pseudocode that finds the sum of two integers.
>
> **Solution**
> This is a simple problem that can be solved using only the sequence construct. Note also that we name the algorithm, define the input to the algorithm and, at the end, we use a return instruction to return the sum (Algorithm 8.1).
>
> **Algorithm 8.1 Calculating the sum of two integers**
> Algorithm: SumOfTwo (first, second)
> Purpose: Find the sum of two integers
> Pre: Given: two integers (first and second)
> Post: None
> Return: The sum value
> {
>   sum ← first + second
>   return sum
> }

> **Example 8.2**
> Write an algorithm to change a numeric grade to a pass/no pass grade.
>
> **Solution**
> This problem cannot be solved with only the sequence construct. We also need the decision construct. The computer is given an integer between 0 and 100. It returns ‘pass’ if the integer is greater than or equal to 70, and returns ‘no pass’ if the integer is less than 70. Algorithm 8.2 shows the pseudocode for this algorithm.
>
> **Algorithm 8.2 Assigning pass/no pass grade**
> Algorithm: Pass/NoPass (score)
> Purpose: Creates a pass/no pass grade given the score
> Pre: Given: the score to be changed to grade
> Post: None
> Return: The grade
> {
>   if (score ≥ 70)
>     grade ← “pass”
>   else
>     grade ← “nopass”
>   return grade
> }

> **Example 8.3**
> Write an algorithm to change a numeric grade (integer) to a letter grade.
>
> **Solution**
> This problem needs more than one decision. The pseudocode in Algorithm 8.3 shows one way to solve the problem—not the best one, but an easy one to understand. Again, an integer is given between 0 and 100, and we want to change it to a letter grade (A, B, C, D, or F).
>
> **Algorithm 8.3 Assigning a letter grade**
> Algorithm: LetterGrade (score)
> Purpose: Find the letter grade corresponding to the given score
> Pre: Given: a numeric score
> Post: None
> Return: A letter grade
> {
>   if (100 ≥ score ≥ 90)
>     grade ← ’A’
>   if (89 ≥ score ≥ 80)
>     grade ← ’B’
>   if (79 ≥ score ≥ 70)
>     grade ← ’C’
>   if (69 ≥ score ≥ 60)
>     grade ← ’D’
>   if (59 ≥ score ≥ 0)
>     grade ← ’F’
>   return grade
> }
> Note that the decision constructs do not need an else section, because we do nothing if the condition is false.

> **Example 8.4**
> Write an algorithm to find the largest of a set of integers. We do not know the number of integers.
>
> **Solution**
> We use the concept in Figure 8.5 on page 217 to write an algorithm for this problem (see Algorithm 8.4).
>
> **Algorithm 8.4 Finding the largest integer among a set of integers**
> Algorithm: FindLargest (list)
> Purpose: Find the largest integer among a set of integers
> Pre: Given: the set of integers
> Post: None
> Return: The largest integer
> {
>   largest ← –∞
>   while (more integers to check)
>   {
>     current ← next integer
>     if (current > largest)
>       largest ← current
>   }
>   return largest
> }

> **Example 8.5**
> Write an algorithm to find the smallest of the first 1000 integers in a set of integers.
>
> **Solution**
> Here we need a counter to count the number of integers. We initialize the counter to 1 and increment it in each repetition. When the counter is greater than 1000, we exit from the loop (see Algorithm 8.5). Note that there are more than 1000 integers in the list, but we want to find the smallest among the first 1000.
>
> **Algorithm 8.5 Find the smallest integers among 1000 integers**
> Algorithm: FindSmallest (list)
> Purpose: Find and return the smallest integer among the first 1000 integers
> Pre: Given the set of integers with more than 1000 integers
> Post: None
> Return: The smallest integer
> {
>   smallest ← +∞
>   counter ← 1
>   while (counter ≤ 1000)
>   {
>     current ← next integer
>     if (current < smallest)
>       smallest ← current
>     counter ← counter + 1
>   }
>   return smallest
> }

## 8.4 A MORE FORMAL DEFINITION
Now that we have discussed the concept of an algorithm and shown its representation, here is a more formal definition. Let us elaborate on this definition.

**Algorithm: An ordered set of unambiguous steps that produces a result and terminates in a finite time.**

### 8.4.1 Well-Defined
An algorithm must be a well-defined, ordered set of instructions.

### 8.4.2 Unambiguous steps
Each step in an algorithm must be clearly and unambiguously defined. If one step is to *add two integers*, we must define both ‘integers’ as well as the ‘add’ operation: we cannot for example use the same symbol to mean addition in one place and multiplication somewhere else.

### 8.4.3 Produce a result
An algorithm must produce a result, otherwise it is useless. The result can be data returned to the calling algorithm, or some other effect (for example, printing).

### 8.4.4 Terminate in a finite time
An algorithm must terminate (halt). If it does not (that is, it has an infinite loop), we have not created an algorithm. In Chapter 17 we will discuss *solvable* and *unsolvable* problems, and we will see that a solvable problem has a solution in the form of an algorithm that terminates.

## 8.5 BASIC ALGORITHMS
Several algorithms are used in computer science so prevalently that they are considered ‘basic’. We discuss the most common here. This discussion is very general: implementation depends on the language.

### 8.5.1 Summation
One commonly used algorithm in computer science is **summation**. We can add two or three integers very easily, but how can we add many integers? The solution is simple: we use the add operator in a loop (Figure 8.9).
A summation algorithm has three logical parts:
1.  Initialization of the sum at the beginning.
2.  The loop, which in each iteration adds a new integer to the sum.
3.  Return of the result after exiting from the loop.

### 8.5.2 Product
Another common algorithm is finding the **product** of a list of integers. The solution is simple: use the multiplication operator in a loop (Figure 8.10). A product algorithm has three logical parts:
1.  Initialization of the product at the beginning.
2.  The loop, which in each iteration multiplies a new integer with the product.
3.  Return of the result after exiting from the loop.

For example, the preceding algorithm can be used to calculate $x^n$ using a minor modification—this is left as an exercise. As another example, the same algorithm can be used to calculate the factorial of an integer, which is discussed later in the chapter.

### 8.5.3 Smallest and largest
We discussed the algorithm for finding the largest among a list of integers at the beginning of this chapter. The idea was to write a decision construct to find the larger of two integers. If we put this construct in a loop, we can find the largest of a list of integers.
Finding the smallest integer among a list of integers is similar, with two minor differences. First, we use a decision construct to find the smaller of two integers. Second, we initialize with a very large integer instead of a very small one. Figure 8.11 shows the algorithm to find the smallest among a list of integers. The figure to find the largest is similar and left as an exercise.

### 8.5.4 Sorting
One of the most common applications in computer science is **sorting**, which is the process by which data is arranged according to its values. People are surrounded by data. If the data was not ordered, it would take hours and hours to find a single piece of information. Imagine the difficulty of finding someone’s telephone number in a telephone book that is not ordered.
In this section, we introduce three sorting algorithms: selection sort, bubble sort, and insertion sort. These three sorting algorithms are the foundation of faster sorting algorithms used in computer science today.

**Selection sorts**
In a **selection sort**, the list to be sorted is divided into two sublists—sorted and unsorted—which are separated by an imaginary wall. We find the smallest element from the unsorted sublist and swap it with the element at the beginning of the unsorted sublist. After each selection and swap, the imaginary wall between the two sublists moves one element ahead, increasing the number of sorted elements and decreasing the number of unsorted ones. Each time we move one element from the unsorted sublist to the sorted sublist, we have completed a sort pass. A list of $n$ elements requires $n - 1$ passes to completely rearrange the data. Selection sort is presented graphically in Figure 8.12.

Figure 8.13 traces a set of six integers as we sort them.
The figure shows how the wall between the sorted and unsorted sublists moves in each pass. As we study the figure, we will see that the list is sorted after five passes, which is one less than the number of elements in the list. Thus, if we use a loop to control the sorting, the loop will have one less iteration than the number of elements to be sorted.

**A selection sort algorithm**
The algorithm uses two loops, one inside the other. The outer loop is iterated for each pass: the inner loop finds the smallest element in the unsorted list. Figure 8.14 shows the UML for the selection sort algorithm. The inner loop is not explicitly shown in the figure, but the first instruction in the loop is itself a loop. We leave the demonstration of the loop as an exercise.

**Bubble sorts**
In the **bubble sort** method, the list to be sorted is also divided into two sublists—sorted and unsorted. The smallest element is *bubbled up* from the unsorted sublist and moved to the sorted sublist. After the smallest element has been moved to the sorted list, the wall moves one element ahead, increasing the number of sorted elements and decreasing the number of unsorted ones. Each time an element moves from the unsorted sublist to the sorted sublist, one sort pass is completed (Figure 8.15). Given a list of $n$ elements, bubble sort requires up to $n - 1$ passes to sort the data.

Figure 8.16 shows how the wall moves one element in each pass. Looking at the first pass, we start with 56 and compare it to 32. Since 56 is not less than 32, it is not moved, and we step down one element. No exchanges take place until we compare 45 to 8. Since 8 is less than 45, the two elements are exchanged, and we step down one element. Because 8 was moved down, it is now compared to 78, and these two elements are exchanged. Finally, 8 is compared to 23 and exchanged. This series of exchanges places 8 in the first location, and the wall is moved up one position. The algorithm gets its name from the way in which numbers—in this example, 8—appear to move to the start, or top, of the list in the same way that bubbles rise through water.
Note that we have stopped before the wall moves to the end of the list, because the list is already sorted. We can always include an indicator in the algorithm to stop the passes if no number exchanges occur in a pass. This fact can be used to improve the efficiency of the bubble sort by reducing the number of steps.
The bubble sort was originally written to ‘bubble down’ the highest element in the list. From an efficiency point of view, it makes no difference whether high elements are moved or low elements are moved up. From a consistency point of view, however, it makes comparisons between the sort algorithms easier if all of them work in the same manner. For that reason, we have chosen to move the lowest value up in each pass.

**A bubble sort algorithm**
Bubble sorts also use two loops, one inside the other. The outer loop is iterated for each pass, while each iteration of the inner loop tries to bubble one element up to the top (left). We leave the UML and pseudocode as exercises.

**Insertion sorts**
The **insertion sort** algorithm is one of the most common sorting techniques, and it is often used by card players. Each card a player picks up is inserted into the proper place in their hand of cards to maintain a particular sequence. (Card sorting is an example of a sort that uses two criteria for sorting: suit and rank.)
In an insertion sort, as in the other two sorting algorithms discussed above, the list is divided into two parts—sorted and unsorted. In each pass, the first element of the unsorted sublist is transferred to the sorted sublist and inserted at the appropriate place (Figure 8.17). Note that a list of $n$ elements will take $n - 1$ passes to sort the data.

Figure 8.18 traces an insertion sort through our list of six numbers. The wall moves with each pass as an element is removed from the unsorted sublist and inserted into the sorted sublist.

**Insertion sort algorithm**
The design of insertion sort follows the same pattern seen in both selection sort and bubble sort. The outer loop is iterated for each pass, and the inner loop finds the position of insertion. We leave the UML diagram and pseudocode as exercises.

**Other sorting algorithms**
The three sorting algorithms discussed here are the least efficient sorting algorithms, and should not be used if the list to be sorted has more than a few hundred elements. We have discussed these algorithms here for educational purposes, but they are not practical. There are however several reasons for discussing these sorting algorithms in an introductory book:
- They are the simplest algorithms to understand and analyze.
- They are the foundation of more efficient algorithms such as *quicksort, heap sort, Shell sort, bucket sort, merge sort, radix sort*, and so on.
Most such advanced sorting algorithms are discussed in books on data structures.
We may ask why there are so many sorting algorithms. The reason lies in the type of data that needs to be sorted. One algorithm may be more efficient for a list that is partially sorted, whereas another algorithm may be more efficient for a list that is completely unsorted. To decide which algorithm is best suited for a particular application, a measurement called the complexity of algorithms is needed. We discuss this issue in Chapter 17, but a thorough understanding requires additional courses in programming and data structures.

### 8.5.5 Searching
Another common algorithm in computer science is **searching**, which is the process of finding the location of a target among a list of objects. In the case of a list, searching means that given a value, we want to find the location of the first element in the list that contains that value. There are two basic searches for lists: **sequential search** and **binary search**. Sequential search can be used to locate an item in any list, whereas binary search requires the list first to be sorted.

**Sequential search**
**Sequential search** is used if the list to be searched is not ordered. Generally, we use this technique only for small lists, or lists that are not searched often. In other cases, the best approach is to first sort the list and then search it using the binary search discussed later.
In a sequential search, we start searching for the target from the beginning of the list. We continue until we either find the target or reach the end of the list. Figure 8.19 traces the steps to find the value 62. The search algorithm needs to be designed so that the search stops when we find the target or when we reach the end of the list.

**Binary search**
The sequential search algorithm is very slow. If we have a list of a million elements, we must do a million comparisons in the worst case. If the list is not sorted, this is the only solution. If the list is sorted, however, we can use a more efficient algorithm called **binary search**. Generally speaking, programmers use a binary search when a list is large.

A binary search starts by testing the data in the element at the middle of the list. This determines whether the target is in the first half or the second half of the list. If it is in the first half, there is no need to further check the second half. If it is in the second half, there is no need to further check the first half. In other words, we eliminate half the list from further consideration.
We repeat this process until we either find the target or satisfy ourselves that it is not in the list. Figure 8.20 shows how to find the target, 22, in a list of 12 numbers using three references: first, mid, and last.
1.  At the beginning, *first* shows 1 and *last* shows 12. Let *mid* show the middle position, (1 + 12) / 2, or 6 if truncated to an integer. Now compare the target (22) with data at position 6 (21). The target is greater than this value, so we ignore the first half of the list.
2.  Move *first* after *mid*, to position 7. Let *mid* show the middle of the second half, (7 + 12) / 2, or 9. Now compare the target (22) with data at position 9 (62). The target is smaller than this value, so we ignore the integers from this value (62) to the end.
3.  Move *last* before *mid* to position 8. Recalculate *mid* again, (8 + 7) / 2, or 7. Compare the target (22) with the value at this position (22). We have found the target and can quit.

The algorithm for binary search needs to be designed to find the target or to stop if the target is not in the list. It can be shown that if the target is not found in the list, the value of *last* becomes smaller than the value of *first*, an abnormal condition that helps us to know when to come out of the loop.

## 8.6 SUBALGORITHMS
The three programming constructs described in Section 8.2 allow us to create an algorithm for any solvable problem. The principles of structured programming, however, require that an algorithm be broken into small units called **subalgorithms**. Each subalgorithm is in turn divided into smaller subalgorithms. A good example is the algorithm for the selection sort in Figure 8.14. Finding the smallest integer in the unsorted sublist is an independent task that can be considered as a subalgorithm. (Figure 8.21). The algorithm SelectionSort calls the subalgorithm FindSmallest in each iteration.

Using subalgorithms has at least two advantages:
- It is more understandable. Looking at the SelectionSort algorithm, we can immediately see that a task (finding the smallest integer among the unsorted list) is repeated.
- A subalgorithm can be called many times in different parts of the main algorithm without being rewritten.

### 8.6.1 Structure chart
Another tool programmers use is the **structure chart**. A structure chart is a high-level design tool that shows the relationship between algorithms and subalgorithms. It is used mainly at the design level rather than at the programming level. We briefly discuss the structure chart in Appendix D.

## 8.7 RECURSION
In general, there are two approaches to writing algorithms for solving a problem. One uses *iteration*, the other uses *recursion*. **Recursion** is a process in which an algorithm calls itself.

### 8.7.1 Iterative definition
To study a simple example, consider the calculation of a factorial. The factorial of a integer is the product of the integral values from 1 to the integer. The definition is *iterative* (Figure 8.22). An algorithm is iterative whenever the definition does not involve the algorithm itself.
Factorial (n) =
1 if n = 0
n × (n − 1) × (n − 2) × ... × 3 × 2 × 1 if n > 0

### 8.7.2 Recursive definition
An algorithm is defined recursively whenever the algorithm appears within the definition itself. For example, the factorial function can be defined recursively as shown in Figure 8.23.
Factorial (n) =
1 if n = 0
n × Factorial (n − 1) if n > 0

The decomposition of factorial (3), using recursion, is shown in Figure 8.24. If we study the figure carefully, we will note that the recursive solution for a problem involves a two-way journey. First we decompose the problem from top to bottom, and then we solve it from bottom to top.

Judging by this example, it looks as if the recursive calculation is much longer and more difficult. So why would we want to use the recursive method? Although the recursive calculation looks more difficult when using paper and pencil, it is often a much easier and more elegant solution when using computers. Additionally, it offers a conceptual simplicity to the creator and the reader.

**Iterative solution**
Let us write an algorithm to solve the factorial problem iteratively. This solution usually involves a loop such as seen in Algorithm 8.6.

**Algorithm 8.6 Iteration solution to factorial problem**
Algorithm: Factorial (n)
Purpose: Find the factorial of a number using a loop
Pre: Given: n
Post: None
Return: n!
{
  F ← 1
  i ← 1
  while (i ≤ n)
  {
    F ← F × i
    i ← i + 1
  }
  return F
}

**Recursive solution**
The recursive solution to factorials is shown in Algorithm 8.7. It does not need a loop, as the recursion concept itself involves repetition. In the recursive version, we let the algorithm Factorial call itself.

**Algorithm 8.7 A recursive solution of the factorial problem**
Algorithm: Factorial (n)
Purpose: Find the factorial of a number using recursion
Pre: Given: n
Post: None
Return: n!
{
  if (n = 0)
    return 1
  else
    return n × Factorial (n – 1)
}

## 8.8 END-CHAPTER MATERIALS
### 8.8.1 Recommended reading
For more details about the subjects discussed in this chapter, the following books are recommended:
- Aho, A., Hopcroft, J. and Ullman, J. *The Design and Analysis of Computer Algorithms*, Boston, MA: Addison-Wesley, 1974
- Cormen, T., Leiserson, C. and Rivest, R. *Introduction to Algorithms*, New York: McGraw-Hill, 2003
- Gries, D. *The Science of Programming*, New York: Springer, 1998
- Tardos, E. and Kleinberg, J. *Algorithm Design*, Boston, MA: Addison-Wesley, 2006
- Roberts, E. *Thinking Recursively*, New York: Wiley, 1998

### 8.8.2 Key terms
- algorithm
- binary search
- bubble sort
- decision
- input data
- insertion sort
- loop
- output data
- product
- pseudocode
- recursion
- repetition
- searching
- selection
- selection sort
- sequence
- sequential search
- sorting
- structure chart
- subalgorithm
- summation
- Unified Modeling Language (UML)

### 8.8.3 Summary
- An algorithm can be informally defined as ‘a step-by-step method for solving a problem or doing a task’. More formally, an algorithm is defined as ‘an ordered set of unambiguous steps that produces a result and terminates in a finite time’.
- Computer scientists have defined three constructs for a structured program or algorithm: sequence, decision (selection), and repetition (loop).
- Several tools have been designed to show an algorithm: UML, pseudocode, and structure charts. UML is a pictorial representation of an algorithm. Pseudocode is an English-language-like representation of an algorithm. A structure chart is a high-level design tool that shows the relationship between algorithms and subalgorithms.
- Several algorithms are used in computer science so prevalently that they are considered basic. We discussed the most common in this chapter: summation, product, finding the smallest and largest, sorting, and searching.
- One of the most common applications in computer science is sorting, which is the process by which data is arranged according to its value. We introduced three primitive but fundamental, sorting algorithms: selection sort, bubble sort, and insertion sort. These three sorting algorithms are the foundation of the faster sorts used in computer science today.
- Another common algorithm in computer science is searching, which is the process of finding the location of a target among a list of objects. There are two basic searches for lists: sequential search and binary search. Sequential search can be used to locate an item in any list, whereas binary search requires the list to be sorted.
- The principles of structured programming require that an algorithm be broken into small units called subalgorithms. Each subalgorithm is in turn divided into smaller subalgorithms.
- In general, there are two approaches to writing algorithms to solve a problem. One uses iteration, the other uses recursion. An algorithm is iterative whenever the definition does not involve the algorithm itself. An algorithm is defined recursively whenever the algorithm appears within the definition itself.

## 8.9 PRACTICE SET
### 8.9.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 8.9.2 Review questions
1. What is the formal definition of an algorithm?
2. Define the three constructs used in structured programming.
3. How is a UML diagram related to an algorithm?
4. How is pseudocode related to an algorithm?
5. What is the purpose of a sorting algorithm?
6. What are the three basic sorting algorithms discussed in this chapter?
7. What is the purpose of a searching algorithm?
8. What are the two basic searching algorithms discussed in this chapter?
9. Give a definition and an example of an iterative process.
10. Give a definition and an example of a recursive process.

### 8.9.3 Problems
1. Using the summation algorithm, make a table to show the value of the sum after each integer in the following list is processed:
   20 12 70 81 45 13 81
2. Using the product algorithm, make a table to show the value of the product after each integer in the following list is processed:
   2 12 8 11 10 5 20
3. Using the FindLargest algorithm, make a table to show the value of Largest after each integer in the following list is processed:
   18 12 8 20 10 32 5
4. Using the FindSmallest algorithm, make a table to show the value of Smallest after each integer in the following list is processed:
   18 3 11 8 20 1 2
5. Using the selection sort algorithm, manually sort the following list and show your work in each pass using a table:
   14 7 23 31 40 56 78 9 2
6. Using the bubble sort algorithm, manually sort the following list and show your work in each pass using a table:
   14 7 23 31 40 56 78 9 2
7. Using the insertion sort algorithm, manually sort the following list and show your work in each pass:
   7 23 31 40 56 78 9 2
8. A list contains the following elements. The first two elements have been sorted using the selection sort algorithm. What is the value of the elements in the list after three more passes of the selection sort?
   7 8 26 44 13 23 98 57
9. A list contains the following elements. The first two elements have been sorted using the bubble sort algorithm. What is the value of the elements in the list after three more passes of the bubble sort?
   7 8 26 44 13 23 57 98
10. A list contains the following elements. The first two elements have been sorted using the insertion sort algorithm. What is the value of the elements in the list after three more passes of the insertion sort?
    3 13 7 26 44 23 98 57
11. A list contains the following elements. Using the binary search algorithm, trace the steps followed to find 88. At each step, show the values of first, last, and mid:
    8 13 17 26 44 56 88 97
12. A list contains the following elements. Using the binary search algorithm, trace the steps followed to find 20. At each step, show the values of first, last, and mid:
    17 26 44 56 88 97
13. Using Figure 8.19 in section 8.5.1 (sequential search) show all the steps to try to find a target of 11 (which is not in the list).
14. Using Figure 8.20 in section 8.5.5 (binary search) show all the steps try to find a target of 17 (which is not in the list).
15. Apply the iterative definition of the Factorial algorithm to show the value of F in each step when finding the value of 6! (6 factorial).
16. Apply the recursive definition of the Factorial algorithm to show the value of Factorial in each step when finding the value of 6!
17. Write a recursive algorithm in pseudocode to find the greatest common divisor (gcd) of two integers using the definition in Figure 8.25. In this definition, the expression ‘x mod y’ means dividing x by y and using the remainder as the result of the operation.
    gcd (x, y) = x if y = 0
    gcd (x, y) = gcd (y, x mod y) otherwise
18. Using the definition of Figure 8.25, find the following:
    a. gcd (7, 41)
    b. gcd (12, 100)
    c. gcd (80, 4)
    d. gcd (17, 29)
19. Write a recursive algorithm in pseudocode to find the combination of n objects taken k at a time using the definition in Figure 8.26.
    C(n, k) = 1 if k = 0 or n = k
    C(n, k) = C(n-1, k) + C(n-1, k-1) if n > k > 0
20. Using the definition in Figure 8.26, find the following:
    a. C (3, 2)
    b. C (5, 5)
    c. C (2, 7)
    d. C (4, 3)
21. The Fibonacci sequence, Fib (n), is used in science and mathematics as shown in Figure 8.27. Write a recursive algorithm in pseudocode to calculate the value of Fib (n).
    Fib(n) = 0 if n = 0
    Fib(n) = 1 if n = 1
    Fib(n) = Fib(n-1) + Fib(n-2) if n > 1
22. Using the definition of Figure 8.27, find the following:
    a. Fib(2)
    b. Fib(3)
    c. Fib(4)
    d. Fib(5)
23. Draw a UML diagram for the selection sort algorithm that uses two loops. The nested loop is used to find the smallest element in the unsorted sublist.
24. Draw a UML diagram for the bubble sort algorithm that uses two loops. The nested loop is used to swap adjacent items in the unsorted sublist.
25. Draw a UML diagram for the insertion sort algorithm that uses two loops. The nested loop is used to do the insertion into the sorted sublist.
26. Draw a UML diagram for the bubble sort algorithm that uses a subalgorithm. The subalgorithm bubbles the unsorted sublist.
27. Draw a UML diagram for the insertion sort algorithm that uses a subalgorithm. The subalgorithm is used to do the insertion into the sorted sublist.
28. Write an algorithm in pseudocode for the UML diagram in Figure 8.9 in section 8.5.1 (summation).
29. Write an algorithm in pseudocode for the UML diagram in Figure 8.10 in section 8.5.5 (product).
30. Write an algorithm in pseudocode for the selection sort using two nested loops.
31. Write an algorithm in pseudocode for the selection sort using a subalgorithm to find the smallest integer in the unsorted sublist.
32. Write an algorithm in pseudocode for the bubble sort using two nested loop.
33. Write an algorithm in pseudocode for the bubble sort using a subalgorithm to do bubbling in the unsorted sublist.
34. Write an algorithm in pseudocode for the insertion sort using two nested loop.
35. Write an algorithm in pseudocode for the insertion sort using a subalgorithm to do insertion in the sorted sublist.
36. Write an algorithm in pseudocode for the sequential search algorithm. Include the condition for algorithm termination if the target is found or not found.
37. Write an algorithm in pseudocode for the binary search algorithm. Include the condition for algorithm termination if the target is found or not found.
38. Using the UML diagram for the product algorithm, draw a diagram to calculate the value of $x^n$, when $x$ and $n$ are two given integers.
39. Write an algorithm in pseudocode to find the value of $x^n$, when $x$ and $n$ are two given integers.
`,zh:`
# 第八章：演算法

在本章中，我們介紹演算法的概念，即解決問題的逐步程序。然後我們討論開發演算法所使用的工具。最後，我們給出一些常見的迭代和遞迴演算法的範例。

## 學習目標
學完本章後，學生應能：
- 定義演算法並將其與問題解決聯繫起來。
- 定義循序、選擇和重複三個建構，並描述它們在演算法中的應用。
- 描述 UML 圖以及它們如何用於表示演算法。
- 描述偽代碼以及它如何用於表示演算法。
- 列出基本演算法及其應用。
- 描述排序的概念，並理解三種原始排序演算法背後的機制。
- 描述搜尋的概念，並理解兩種常見搜尋演算法背後的機制。
- 定義子演算法及其與演算法的關係。
- 區分迭代和遞迴演算法。

## 8.1 概念
在本節中，我們非正式地定義**演算法**，並使用一個範例來詳細說明該概念。

### 8.1.1 非正式定義
演算法的非正式定義是：

**演算法：解決問題或執行任務的逐步方法。**

在這個定義中，演算法獨立於電腦系統。更具體地說，我們還應該注意，演算法接受**輸入資料**並創建**輸出資料**（圖 8.1）。

### 8.1.2 範例
讓我們用一個例子來詳細說明這個簡單的定義。我們想要開發一個演算法來找出正整數列表中的最大整數。該演算法應該能在任何大小的列表中找到最大整數（例如 5、1000、10000、1000000）。該演算法應該是通用的，不依賴於整數的數量。

顯然，在許多整數中找到最大整數是一項無法一步完成的任務，無論是由人類還是電腦。演算法需要逐一測試每個整數。

為了解決這個問題，我們需要一種直觀的方法。首先使用少量的整數（例如五個），然後將解決方案擴展到任意數量的整數。我們對五個整數的解決方案遵循與一千或一百萬個整數相同的原則和限制。假設，即使對於五個整數的情況，演算法也是逐一處理整數。它查看第一個整數，而不知道其餘整數的值。在處理完第一個整數後，它查看第二個整數，依此類推。圖 8.2 顯示了解決這個問題的一種方法。

我們稱此演算法為 FindLargest。每個演算法都有一個名稱，以區別於其他演算法。該演算法接收五個整數的列表作為輸入，並給出最大整數作為輸出。

**輸入**
演算法接受五個整數的列表作為輸入。

**處理**
演算法使用以下五個步驟來找到最大整數：
**步驟 1**
在此步驟中，演算法檢查第一個整數 (12)。由於它不知道其他整數的值，它決定最大整數（目前為止）是第一個整數。演算法定義一個名為 Largest 的資料項目，並將其值設定為第一個整數 (12)。
**步驟 2**
目前為止的最大整數是 12，但新的整數可能會改變這種情況。演算法比較 Largest 的值 (12) 和第二個整數的值 (8)。它發現 Largest 大於第二個整數，這意味著 Largest 仍然持有最大整數。無需更改 Largest 的值。
**步驟 3**
目前為止的最大整數是 12，但新的整數 (13) 大於 Largest。這意味著 Largest 的值不再有效。Largest 的值應該被第三個整數 (13) 替換。演算法將 Largest 的值更改為 13 並移動到下一步。
**步驟 4**
在此步驟中沒有任何更改，因為 Largest 大於第四個整數 (9)。
**步驟 5**
同樣沒有任何更改，因為 Largest 大於第五個整數 (11)。

**輸出**
因為沒有更多的整數需要處理，演算法輸出 Largest 的值，即 13。

### 8.1.3 定義動作
圖 8.2 沒有顯示每一步應該做什麼。我們可以修改圖形以顯示更多細節。例如，在步驟 1 中，將 Largest 設定為第一個數字的值。然而，在步驟 2 到 5 中，需要額外的動作來將 Largest 的值與當前正在處理的整數進行比較。如果當前整數大於 Largest，則將 Largest 的值設定為當前整數（圖 8.3）。

### 8.1.4 精化
這個演算法需要精化才能被程式設計社群接受。有兩個問題。首先，第一步中的動作與其他步驟不同。其次，步驟 2 到 5 中的措辭不盡相同。我們可以透過將步驟 2 到 5 中的措辭更改為「如果當前整數大於 Largest，則將 Largest 設定為當前整數」來輕鬆地重新定義演算法以消除這兩個不便。第一步與其他步驟不同的原因是 Largest 沒有初始化。

如果我們將 Largest 初始化為 $-\\infty$（負無窮大），那麼第一步就可以與其他步驟相同，因此我們添加一個新步驟，稱為步驟 0，以表明它應該在處理任何整數之前完成。
圖 8.4 顯示了這種精化的結果。請注意，我們不必顯示所有步驟，因為它們現在是相同的。

### 8.1.5 一般化
是否可以將演算法一般化？我們想找出 $n$ 個正整數中的最大值，其中 $n$ 可以是 1000、1000000 或更多。當然，我們可以按照圖 8.4 重複每個步驟。但是如果我們將演算法更改為程式，那麼我們需要實際輸入 $n$ 個步驟的動作！
有一個更好的方法可以做到這一點。我們可以告訴電腦重複這些步驟 $n$ 次。我們現在將此功能包含在我們的圖形演算法中（圖 8.5）。

## 8.2 三個建構
電腦科學家為結構化程式或演算法定義了三個建構。這個想法是程式必須僅由這三個建構的組合組成：*循序*、*決策*和*重複*（圖 8.6）。已經證明不需要任何其他建構。僅使用這些建構使程式或演算法易於理解、除錯或更改。

### 8.2.1 循序 (Sequence)
第一個建構稱為**循序**。一個演算法，以及最終的一個程式，是一系列的指令，可以是一個簡單的指令或是其他兩個建構之一。

### 8.2.2 決策 (Decision)
有些問題不能僅用一系列簡單指令來解決。有時我們需要測試一個條件。如果測試結果為真，我們遵循一系列指令：如果為假，我們遵循另一系列指令。這稱為**決策（選擇）**建構。

### 8.2.3 重複 (Repetition)
在某些問題中，必須重複相同的指令序列。我們使用**重複**或**迴圈**建構來處理這個問題。在一組整數中尋找最大整數可以使用這種建構。

## 8.3 演算法表示法
到目前為止，我們一直使用圖形來傳達演算法的概念。在過去的幾十年裡，已經設計了用於此目的的工具。這裡介紹其中兩個工具：UML 和偽代碼。

### 8.3.1 UML
**統一塑模語言 (UML)** 是演算法的圖形表示。它隱藏了演算法的所有細節，試圖給出「大圖」並展示演算法從開始到結束的流程。
UML 在附錄 B 中有詳細介紹。這裡我們只展示如何使用 UML 表示這三個建構（圖 8.7）。請注意，UML 允許我們有很大的靈活性，如附錄 B 所示。例如，如果假的部分沒有動作，則決策建構可以簡化。

### 8.3.2 偽代碼 (Pseudocode)
**偽代碼**是演算法的類英語表示法。偽代碼沒有標準——有些人使用大量細節，有些人使用較少。有些人使用接近英語的代碼，而有些人使用像 Pascal 程式語言一樣的語法。偽代碼在附錄 C 中有詳細介紹。這裡我們只展示如何用偽代碼表示這三個建構（圖 8.8）。

> **範例 8.1**
> 用偽代碼編寫一個演算法，找出兩個整數之和。
>
> **解答**
>這是一個簡單的問題，可以僅使用循序建構來解決。另請注意，我們命名演算法，定義演算法的輸入，並在最後使用 return 指令回傳總和（演算法 8.1）。
>
> **演算法 8.1 計算兩個整數之和**
> 演算法：SumOfTwo (first, second)
> 目的：找出兩個整數之和
> 前置條件：給定：兩個整數 (first 和 second)
> 後置條件：無
> 回傳：總和值
> {
>   sum ← first + second
>   return sum
> }

> **範例 8.2**
> 編寫一個演算法將數字成績更改為及格/不及格成績。
>
> **解答**
> 這個問題不能僅用循序建構來解決。我們還需要決策建構。電腦被給予一個 0 到 100 之間的整數。如果整數大於或等於 70，它回傳「及格」，如果整數小於 70，則回傳「不及格」。演算法 8.2 顯示了此演算法的偽代碼。
>
> **演算法 8.2 分配及格/不及格成績**
> 演算法：Pass/NoPass (score)
> 目的：根據分數創建及格/不及格成績
> 前置條件：給定：要更改為成績的分數
> 後置條件：無
> 回傳：成績
> {
>   if (score ≥ 70)
>     grade ← “pass”
>   else
>     grade ← “nopass”
>   return grade
> }

> **範例 8.3**
> 編寫一個演算法將數字成績（整數）更改為字母成績。
>
> **解答**
> 這個問題需要多個決策。演算法 8.3 中的偽代碼顯示了解決問題的一種方法——不是最好的方法，但很容易理解。再次，給定一個 0 到 100 之間的整數，我們想將其更改為字母成績（A、B、C、D 或 F）。
>
> **演算法 8.3 分配字母成績**
> 演算法：LetterGrade (score)
> 目的：找出對應於給定分數的字母成績
> 前置條件：給定：一個數字分數
> 後置條件：無
> 回傳：一個字母成績
> {
>   if (100 ≥ score ≥ 90)
>     grade ← ’A’
>   if (89 ≥ score ≥ 80)
>     grade ← ’B’
>   if (79 ≥ score ≥ 70)
>     grade ← ’C’
>   if (69 ≥ score ≥ 60)
>     grade ← ’D’
>   if (59 ≥ score ≥ 0)
>     grade ← ’F’
>   return grade
> }
> 請注意，決策建構不需要 else 部分，因為如果條件為假，我們什麼也不做。

> **範例 8.4**
> 編寫一個演算法來找出一組整數中的最大值。我們不知道整數的數量。
>
> **解答**
> 我們使用 217 頁圖 8.5 中的概念為此問題編寫演算法（見演算法 8.4）。
>
> **演算法 8.4 在一組整數中找出最大整數**
> 演算法：FindLargest (list)
> 目的：在一組整數中找出最大整數
> 前置條件：給定：整數集合
> 後置條件：無
> 回傳：最大整數
> {
>   largest ← –∞
>   while (還有更多整數要檢查)
>   {
>     current ← 下一個整數
>     if (current > largest)
>       largest ← current
>   }
>   return largest
> }

> **範例 8.5**
> 編寫一個演算法來找出一組整數中前 1000 個整數的最小值。
>
> **解答**
> 這裡我們需要一個計數器來計算整數的數量。我們將計數器初始化為 1，並在每次重複中遞增它。當計數器大於 1000 時，我們退出迴圈（見演算法 8.5）。請注意，列表中有超過 1000 個整數，但我們想在前 1000 個整數中找到最小值。
>
> **演算法 8.5 在 1000 個整數中找出最小整數**
> 演算法：FindSmallest (list)
> 目的：找出並回傳前 1000 個整數中的最小整數
> 前置條件：給定具有超過 1000 個整數的整數集合
> 後置條件：無
> 回傳：最小整數
> {
>   smallest ← +∞
>   counter ← 1
>   while (counter ≤ 1000)
>   {
>     current ← 下一個整數
>     if (current < smallest)
>       smallest ← current
>     counter ← counter + 1
>   }
>   return smallest
> }

## 8.4 更正式的定義
現在我們已經討論了演算法的概念並展示了它的表示法，這裡有一個更正式的定義。讓我們詳細說明這個定義。

**演算法：一個有序、無歧義的步驟集合，能在有限時間內產生結果並終止。**

### 8.4.1 定義明確 (Well-Defined)
演算法必須是一組定義明確、有序的指令。

### 8.4.2 無歧義的步驟 (Unambiguous steps)
演算法中的每一步都必須清晰且無歧義地定義。如果一步是*將兩個整數相加*，我們必須定義「整數」以及「加法」操作：我們不能例如在一個地方使用相同的符號表示加法，在另一個地方表示乘法。

### 8.4.3 產生結果 (Produce a result)
演算法必須產生結果，否則它是無用的。結果可以是回傳給呼叫演算法的資料，或其他效果（例如，列印）。

### 8.4.4 在有限時間內終止 (Terminate in a finite time)
演算法必須終止（停止）。如果不終止（即它有一個無限迴圈），我們就沒有創建出演算法。在第 17 章中，我們將討論*可解*和*不可解*問題，我們將看到可解問題具有以終止的演算法形式存在的解決方案。

## 8.5 基本演算法
有幾種演算法在電腦科學中使用得非常普遍，以至於它們被認為是「基本」的。我們在這裡討論最常見的。這個討論非常一般：實作取決於語言。

### 8.5.1 總和 (Summation)
電腦科學中常用的一種演算法是**總和**。我們可以很容易地將兩個或三個整數相加，但是我們如何將許多整數相加？解決方案很簡單：我們在迴圈中使用加法運算子（圖 8.9）。
總和演算法有三個邏輯部分：
1.  開始時總和的初始化。
2.  迴圈，在每次迭代中將一個新整數加到總和中。
3.  退出迴圈後回傳結果。

### 8.5.2 乘積 (Product)
另一個常見的演算法是找出一列整數的**乘積**。解決方案很簡單：在迴圈中使用乘法運算子（圖 8.10）。乘積演算法有三個邏輯部分：
1.  開始時乘積的初始化。
2.  迴圈，在每次迭代中將一個新整數與乘積相乘。
3.  退出迴圈後回傳結果。

例如，前面的演算法可以用稍加修改來計算 $x^n$——這留作練習。另一個例子，同樣的演算法可以用來計算整數的階乘，這將在本章稍後討論。

### 8.5.3 最小與最大 (Smallest and largest)
我們在本章開頭討論了在一列整數中找出最大值的演算法。其想法是編寫一個決策建構來找出兩個整數中較大的一個。如果我們將此建構放在迴圈中，我們可以找出一列整數中的最大值。
在一列整數中找出最小整數是類似的，只有兩個小的區別。首先，我們使用決策建構來找出兩個整數中較小的一個。其次，我們使用一個非常大的整數而不是非常小的整數進行初始化。圖 8.11 顯示了在一列整數中找出最小值的演算法。找出最大值的圖形是類似的，留作練習。

### 8.5.4 排序 (Sorting)
電腦科學中最常見的應用之一是**排序**，這是根據資料的值排列資料的過程。人們被資料包圍。如果資料沒有排序，將需要數小時才能找到單一資訊。想像一下在未排序的電話簿中尋找某人電話號碼的困難。
在本節中，我們介紹三種排序演算法：選擇排序、氣泡排序和插入排序。這三種排序演算法是當今電腦科學中使用的更快速排序演算法的基礎。

**選擇排序 (Selection sorts)**
在**選擇排序**中，要排序的列表被分為兩個子列表——已排序和未排序——它們由一堵想像的牆隔開。我們從未排序子列表中找出最小元素，並將其與未排序子列表開頭的元素交換。每次選擇和交換後，兩個子列表之間的想像牆向前移動一個元素，增加已排序元素的數量並減少未排序元素的數量。每次我們將一個元素從未排序子列表移動到已排序子列表時，我們就完成了一次排序遍歷。一個 $n$ 個元素的列表需要 $n - 1$ 次遍歷才能完全重新排列資料。選擇排序在圖 8.12 中以圖形方式呈現。

圖 8.13 追蹤了一組六個整數的排序過程。
圖中顯示了已排序和未排序子列表之間的牆如何在每次遍歷中移動。當我們研究該圖時，我們會看到列表在五次遍歷後排序完成，這比列表中的元素數量少一個。因此，如果我們使用迴圈來控制排序，迴圈的迭代次數將比要排序的元素數量少一次。

**選擇排序演算法**
該演算法使用兩個迴圈，一個在另一個裡面。外部迴圈為每次遍歷進行迭代：內部迴圈在未排序列表中找出最小元素。圖 8.14 顯示了選擇排序演算法的 UML。內部迴圈在圖中沒有明確顯示，但迴圈中的第一條指令本身就是一個迴圈。我們將迴圈的演示留作練習。

**氣泡排序 (Bubble sorts)**
在**氣泡排序**方法中，要排序的列表也被分為兩個子列表——已排序和未排序。最小的元素從未排序子列表中*冒出來*並移動到已排序子列表。在最小元素移動到已排序列表後，牆向前移動一個元素，增加已排序元素的數量並減少未排序元素的數量。每次元素從未排序子列表移動到已排序子列表時，就完成了一次排序遍歷（圖 8.15）。給定一個 $n$ 個元素的列表，氣泡排序最多需要 $n - 1$ 次遍歷來排序資料。

圖 8.16 顯示了牆如何在每次遍歷中移動一個元素。看第一次遍歷，我們從 56 開始並將其與 32 比較。由於 56 不小於 32，它不移動，我們向下移動一個元素。直到我們將 45 與 8 比較才發生交換。由於 8 小於 45，兩個元素交換，我們向下移動一個元素。因為 8 被向下移動，它現在與 78 比較，這兩個元素交換。最後，8 與 23 比較並交換。這一系列的交換將 8 放置在第一個位置，牆向上移動一個位置。該演算法的名稱來自數字——在這個例子中是 8——看起來像氣泡在水中上升一樣移動到列表的開始或頂部的方式。
請注意，我們在牆移動到列表末尾之前停止了，因為列表已經排序。我們總可以在演算法中包含一個指示器，如果在一次遍歷中沒有發生數字交換，則停止遍歷。這一事實可用於透過減少步驟數來提高氣泡排序的效率。
氣泡排序最初是為了「向下冒泡」列表中的最高元素而編寫的。從效率的角度來看，移動高元素還是移動低元素沒有區別。然而，從一致性的角度來看，如果所有排序演算法都以相同的方式工作，則更容易比較它們。因此，我們選擇在每次遍歷中向上移動最低值。

**氣泡排序演算法**
氣泡排序也使用兩個迴圈，一個在另一個裡面。外部迴圈為每次遍歷進行迭代，而內部迴圈的每次迭代都試圖將一個元素冒泡到頂部（左側）。我們將 UML 和偽代碼留作練習。

**插入排序 (Insertion sorts)**
**插入排序**演算法是最常見的排序技術之一，經常被牌手使用。牌手拿起的每張牌都被插入到手中牌的適當位置以保持特定順序。（撲克牌排序是使用兩個標準進行排序的一個例子：花色和點數。）
在插入排序中，就像上面討論的其他兩種排序演算法一樣，列表分為兩部分——已排序和未排序。在每次遍歷中，未排序子列表的第一個元素被轉移到已排序子列表並插入到適當的位置（圖 8.17）。請注意，一個 $n$ 個元素的列表將需要 $n - 1$ 次遍歷來排序資料。

圖 8.18 追蹤了我們六個數字列表的插入排序過程。隨著元素從未排序子列表移出並插入到已排序子列表，牆在每次遍歷中移動。

**插入排序演算法**
插入排序的設計遵循與選擇排序和氣泡排序相同的模式。外部迴圈為每次遍歷進行迭代，內部迴圈找出插入的位置。我們將 UML 圖和偽代碼留作練習。

**其他排序演算法**
這裡討論的三種排序演算法是效率最低的排序演算法，如果需要排序的列表有超過幾百個元素，則不應使用它們。我們在這裡討論這些演算法是為了教育目的，但它們並不實用。然而，在入門書籍中討論這些排序演算法有幾個原因：
- 它們是最容易理解和分析的演算法。
- 它們是更有效率的演算法（如*快速排序、堆積排序、希爾排序、桶排序、合併排序、基數排序*等）的基礎。
大多數這樣的高級排序演算法在資料結構書籍中討論。
我們可能會問為什麼有這麼多排序演算法。原因在於需要排序的資料類型。一種演算法可能對部分排序的列表更有效率，而另一種演算法可能對完全未排序的列表更有效率。要決定哪種演算法最適合特定應用，需要一種稱為演算法複雜度的度量。我們在第 17 章討論這個問題，但徹底的理解需要程式設計和資料結構的額外課程。

### 8.5.5 搜尋 (Searching)
電腦科學中另一個常見的演算法是**搜尋**，這是在一列物件中找出目標位置的過程。在列表的情況下，搜尋意味著給定一個值，我們想找出列表中包含該值的第一個元素的位置。列表有兩種基本搜尋：**循序搜尋**和**二元搜尋**。循序搜尋可用於在任何列表中定位項目，而二元搜尋要求列表首先被排序。

**循序搜尋 (Sequential search)**
如果要在未排序的列表中搜尋，則使用**循序搜尋**。一般來說，我們只對小列表或不經常搜尋的列表使用這種技術。在其他情況下，最好的方法是先對列表進行排序，然後使用稍後討論的二元搜尋進行搜尋。
在循序搜尋中，我們從列表的開頭開始搜尋目標。我們繼續直到找到目標或到達列表的末尾。圖 8.19 追蹤了尋找值 62 的步驟。搜尋演算法需要設計成當我們找到目標或到達列表末尾時停止搜尋。

**二元搜尋 (Binary search)**
循序搜尋演算法非常慢。如果我們有一百萬個元素的列表，在最壞的情況下我們必須進行一百萬次比較。如果列表未排序，這是唯一的解決方案。然而，如果列表已排序，我們可以使用一種更有效率的演算法，稱為**二元搜尋**。一般來說，程式設計師在列表很大時使用二元搜尋。

二元搜尋從測試列表由中間的元素資料開始。這決定了目標是在列表的前半部分還是後半部分。如果在前半部分，則無需進一步檢查後半部分。如果在後半部分，則無需進一步檢查前半部分。換句話說，我們從進一步考慮中消除了一半的列表。
我們重複這個過程，直到我們找到目標或確信它不在列表中。圖 8.20 顯示了如何使用三個參考：first、mid 和 last 在 12 個數字的列表中找到目標 22。
1.  開始時，*first* 顯示 1，*last* 顯示 12。讓 *mid* 顯示中間位置，(1 + 12) / 2，或 6（如果截斷為整數）。現在將目標 (22) 與位置 6 的資料 (21) 進行比較。目標大於此值，因此我們忽略列表的前半部分。
2.  將 *first* 移到 *mid* 之後，到位置 7。讓 *mid* 顯示後半部分的中間，(7 + 12) / 2，或 9。現在將目標 (22) 與位置 9 的資料 (62) 進行比較。目標小於此值，因此我們忽略從此值 (62) 到末尾的整數。
3.  將 *last* 移到 *mid* 之前，到位置 8。再次重新計算 *mid*，(8 + 7) / 2，或 7。將目標 (22) 與此位置的值 (22) 進行比較。我們找到了目標，可以退出。

二元搜尋的演算法需要設計成找到目標或在目標不在列表中時停止。可以證明，如果在列表中找不到目標，*last* 的值會變得小於 *first* 的值，這是一個異常條件，有助於我們知道何時退出迴圈。

## 8.6 子演算法
8.2 節中描述的三種程式設計建構允許我們為任何可解問題創建演算法。然而，結構化程式設計的原則要求將演算法分解為稱為**子演算法**的小單元。每個子演算法又分為更小的子演算法。一個很好的例子是圖 8.14 中的選擇排序演算法。在未排序子列表中找出最小整數是一個獨立的任務，可以視為一個子演算法。（圖 8.21）。演算法 SelectionSort 在每次迭代中呼叫子演算法 FindSmallest。

使用子演算法至少有兩個優點：
- 它更容易理解。看 SelectionSort 演算法，我們可以立即看到一個任務（在未排序列表中找出最小整數）被重複。
- 子演算法可以在主演算法的不同部分被多次呼叫而無需重寫。

### 8.6.1 結構圖 (Structure chart)
程式設計師使用的另一個工具是**結構圖**。結構圖是一種高階設計工具，顯示演算法和子演算法之間的關係。它主要用於設計層級而不是程式設計層級。我們在附錄 D 中簡要討論結構圖。

## 8.7 遞迴
一般來說，編寫演算法解決問題有兩種方法。一種使用*迭代*，另一種使用*遞迴*。**遞迴**是一個演算法呼叫自身的過程。

### 8.7.1 迭代定義
為了研究一個簡單的例子，考慮階乘的計算。整數的階乘是從 1 到該整數的整數值的乘積。定義是*迭代的*（圖 8.22）。只要定義不涉及演算法本身，演算法就是迭代的。
Factorial (n) =
1 如果 n = 0
n × (n − 1) × (n − 2) × ... × 3 × 2 × 1 如果 n > 0

### 8.7.2 遞迴定義
每當演算法出現在定義本身中時，演算法就被遞迴地定義。例如，階乘函數可以遞迴地定義，如圖 8.23 所示。
Factorial (n) =
1 如果 n = 0
n × Factorial (n − 1) 如果 n > 0

使用遞迴分解 factorial (3) 如圖 8.24 所示。如果我們仔細研究該圖，我們會注意到解決問題的遞迴解決方案涉及雙向旅程。首先我們將問題從上到下分解，然後我們從下到上解決它。

從這個例子來看，遞迴計算似乎更長更困難。那麼我們為什麼要使用遞迴方法呢？雖然在使用紙筆時遞迴計算看起來更困難，但在使用電腦時，它通常是一種更容易、更優雅的解決方案。此外，它為創建者和讀者提供了概念上的簡單性。

**迭代解決方案**
讓我們編寫一個演算法來迭代地解決階乘問題。這個解決方案通常涉及一個迴圈，如演算法 8.6 所示。

**演算法 8.6 階乘問題的迭代解決方案**
演算法：Factorial (n)
目的：使用迴圈找出數字的階乘
前置條件：給定：n
後置條件：無
回傳：n!
{
  F ← 1
  i ← 1
  while (i ≤ n)
  {
    F ← F × i
    i ← i + 1
  }
  return F
}

**遞迴解決方案**
階乘的遞迴解決方案如演算法 8.7 所示。它不需要迴圈，因為遞迴概念本身涉及重複。在遞迴版本中，我們讓演算法 Factorial 呼叫自身。

**演算法 8.7 階乘問題的遞迴解決方案**
演算法：Factorial (n)
目的：使用遞迴找出數字的階乘
前置條件：給定：n
後置條件：無
回傳：n!
{
  if (n = 0)
    return 1
  else
    return n × Factorial (n – 1)
}

## 8.8 章末材料
### 8.8.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Aho, A., Hopcroft, J. and Ullman, J. *The Design and Analysis of Computer Algorithms*, Boston, MA: Addison-Wesley, 1974
- Cormen, T., Leiserson, C. and Rivest, R. *Introduction to Algorithms*, New York: McGraw-Hill, 2003
- Gries, D. *The Science of Programming*, New York: Springer, 1998
- Tardos, E. and Kleinberg, J. *Algorithm Design*, Boston, MA: Addison-Wesley, 2006
- Roberts, E. *Thinking Recursively*, New York: Wiley, 1998

### 8.8.2 關鍵詞
- 演算法 (algorithm)
- 二元搜尋 (binary search)
- 氣泡排序 (bubble sort)
- 決策 (decision)
- 輸入資料 (input data)
- 插入排序 (insertion sort)
- 迴圈 (loop)
- 輸出資料 (output data)
- 乘積 (product)
- 偽代碼 (pseudocode)
- 遞迴 (recursion)
- 重複 (repetition)
- 搜尋 (searching)
- 選擇 (selection)
- 選擇排序 (selection sort)
- 循序 (sequence)
- 循序搜尋 (sequential search)
- 排序 (sorting)
- 結構圖 (structure chart)
- 子演算法 (subalgorithm)
- 總和 (summation)
- 統一塑模語言 (UML)

### 8.8.3 摘要
- 演算法可以非正式地定義為「解決問題或執行任務的逐步方法」。更正式地說，演算法被定義為「一個有序、無歧義的步驟集合，能在有限時間內產生結果並終止」。
- 電腦科學家為結構化程式或演算法定義了三個建構：循序、決策（選擇）和重複（迴圈）。
- 已經設計了幾種工具來顯示演算法：UML、偽代碼和結構圖。UML 是演算法的圖形表示。偽代碼是演算法的類英語表示。結構圖是一種高階設計工具，顯示演算法和子演算法之間的關係。
- 有幾種演算法在電腦科學中使用得非常普遍，以至於它們被認為是基本的。我們在本章中討論了最常見的：總和、乘積、找出最小和最大值、排序和搜尋。
- 電腦科學中最常見的應用之一是排序，這是根據資料的值排列資料的過程。我們介紹了三種原始但基本的排序演算法：選擇排序、氣泡排序和插入排序。這三種排序演算法是當今電腦科學中使用的更快速排序的基礎。
- 電腦科學中另一個常見的演算法是搜尋，這是在一列物件中找出目標位置的過程。列表有兩種基本搜尋：循序搜尋和二元搜尋。循序搜尋可用於在任何列表中定位項目，而二元搜尋要求列表必須先排序。
- 結構化程式設計的原則要求將演算法分解為稱為子演算法的小單元。每個子演算法又分為更小的子演算法。
- 一般來說，編寫演算法解決問題有兩種方法。一種使用迭代，另一種使用遞迴。只要定義不涉及演算法本身，演算法就是迭代的。每當演算法出現在定義本身中時，演算法就被遞迴地定義。

## 8.9 練習題
### 8.9.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 8.9.2 複習問題
1. 演算法的正式定義是什麼？
2. 定義結構化程式設計中使用的三個建構。
3. UML 圖與演算法有何關係？
4. 偽代碼與演算法有何關係？
5. 排序演算法的目的是什麼？
6. 本章討論的三種基本排序演算法是什麼？
7. 搜尋演算法的目的是什麼？
8. 本章討論的兩種基本搜尋演算法是什麼？
9. 給出迭代過程的定義和範例。
10. 給出遞迴過程的定義和範例。

### 8.9.3 問題
1. 使用總和演算法，製作一個表格來顯示在處理下列列表中的每個整數後總和的值：
   20 12 70 81 45 13 81
2. 使用乘積演算法，製作一個表格來顯示在處理下列列表中的每個整數後乘積的值：
   2 12 8 11 10 5 20
3. 使用 FindLargest 演算法，製作一個表格來顯示在處理下列列表中的每個整數後 Largest 的值：
   18 12 8 20 10 32 5
4. 使用 FindSmallest 演算法，製作一個表格來顯示在處理下列列表中的每個整數後 Smallest 的值：
   18 3 11 8 20 1 2
5. 使用選擇排序演算法，手動排序下列列表並使用表格顯示每次遍歷的工作：
   14 7 23 31 40 56 78 9 2
6. 使用氣泡排序演算法，手動排序下列列表並使用表格顯示每次遍歷的工作：
   14 7 23 31 40 56 78 9 2
7. 使用插入排序演算法，手動排序下列列表並顯示每次遍歷的工作：
   7 23 31 40 56 78 9 2
8. 一個列表包含以下元素。前兩個元素已使用選擇排序演算法排序。在選擇排序再進行三次遍歷後，列表中的元素值是什麼？
   7 8 26 44 13 23 98 57
9. 一個列表包含以下元素。前兩個元素已使用氣泡排序演算法排序。在氣泡排序再進行三次遍歷後，列表中的元素值是什麼？
   7 8 26 44 13 23 57 98
10. 一個列表包含以下元素。前兩個元素已使用插入排序演算法排序。在插入排序再進行三次遍歷後，列表中的元素值是什麼？
    3 13 7 26 44 23 98 57
11. 一個列表包含以下元素。使用二元搜尋演算法，追蹤尋找 88 所遵循的步驟。在每一步，顯示 first、last 和 mid 的值：
    8 13 17 26 44 56 88 97
12. 一個列表包含以下元素。使用二元搜尋演算法，追蹤尋找 20 所遵循的步驟。在每一步，顯示 first、last 和 mid 的值：
    17 26 44 56 88 97
13. 使用 8.5.1 節中的圖 8.19（循序搜尋）顯示嘗試尋找目標 11（不在列表中）的所有步驟。
14. 使用 8.5.5 節中的圖 8.20（二元搜尋）顯示嘗試尋找目標 17（不在列表中）的所有步驟。
15. 應用 Factorial 演算法的迭代定義，顯示在尋找 6!（6 的階乘）值時每一步 F 的值。
16. 應用 Factorial 演算法的遞迴定義，顯示在尋找 6! 值時每一步 Factorial 的值。
17. 使用圖 8.25 中的定義，用偽代碼編寫一個遞迴演算法來找出兩個整數的最大公因數 (gcd)。在這個定義中，表達式「x mod y」意味著將 x 除以 y 並使用餘數作為運算結果。
    gcd (x, y) = x 如果 y = 0
    gcd (x, y) = gcd (y, x mod y) 否則
18. 使用圖 8.25 的定義，找出以下內容：
    a. gcd (7, 41)
    b. gcd (12, 100)
    c. gcd (80, 4)
    d. gcd (17, 29)
19. 使用圖 8.26 中的定義，用偽代碼編寫一個遞迴演算法來找出 n 個物件中一次取 k 個的組合。
    C(n, k) = 1 如果 k = 0 或 n = k
    C(n, k) = C(n-1, k) + C(n-1, k-1) 如果 n > k > 0
20. 使用圖 8.26 中的定義，找出以下內容：
    a. C (3, 2)
    b. C (5, 5)
    c. C (2, 7)
    d. C (4, 3)
21. 費氏數列 Fib (n) 用於科學和數學，如圖 8.27 所示。用偽代碼編寫一個遞迴演算法來計算 Fib (n) 的值。
    Fib(n) = 0 如果 n = 0
    Fib(n) = 1 如果 n = 1
    Fib(n) = Fib(n-1) + Fib(n-2) 如果 n > 1
22. 使用圖 8.27 的定義，找出以下內容：
    a. Fib(2)
    b. Fib(3)
    c. Fib(4)
    d. Fib(5)
23. 為使用兩個迴圈的選擇排序演算法繪製 UML 圖。巢狀迴圈用於在未排序子列表中找出最小元素。
24. 為使用兩個迴圈的氣泡排序演算法繪製 UML 圖。巢狀迴圈用於交換未排序子列表中的相鄰項目。
25. 為使用兩個迴圈的插入排序演算法繪製 UML 圖。巢狀迴圈用於執行插入到已排序子列表的操作。
26. 為使用子演算法的氣泡排序演算法繪製 UML 圖。子演算法對未排序子列表進行冒泡。
27. 為使用子演算法的插入排序演算法繪製 UML 圖。子演算法用於執行插入到已排序子列表的操作。
28. 為 8.5.1 節圖 8.9 中的 UML 圖（總和）編寫偽代碼演算法。
29. 為 8.5.5 節圖 8.10 中的 UML 圖（乘積）編寫偽代碼演算法。
30. 使用兩個巢狀迴圈編寫選擇排序的偽代碼演算法。
31. 使用子演算法編寫選擇排序的偽代碼演算法，以在未排序子列表中找出最小整數。
32. 使用兩個巢狀迴圈編寫氣泡排序的偽代碼演算法。
33. 使用子演算法編寫氣泡排序的偽代碼演算法，以在未排序子列表中進行冒泡。
34. 使用兩個巢狀迴圈編寫插入排序的偽代碼演算法。
35. 使用子演算法編寫插入排序的偽代碼演算法，以在已排序子列表中進行插入。
36. 編寫循序搜尋演算法的偽代碼演算法。包括如果找到或未找到目標的演算法終止條件。
37. 編寫二元搜尋演算法的偽代碼演算法。包括如果找到或未找到目標的演算法終止條件。
38. 使用乘積演算法的 UML 圖，繪製一個圖來計算 $x^n$ 的值，其中 $x$ 和 $n$ 是兩個給定的整數。
39. 用偽代碼編寫一個演算法來找出 $x^n$ 的值，其中 $x$ 和 $n$ 是兩個給定的整數。
`},c={en:`
# Chapter 9: Programming Languages

In Chapter 8 we discussed algorithms. We showed how we can write algorithms in UML or pseudocode to solve a problem. In this chapter, we examine programming languages that can implement pseudocode or UML descriptions of a solution into a programming language. This chapter is not designed to teach a particular programming language; it is written to compare and contrast different languages.

## Objectives
After studying this chapter, the student should be able to:
- Describe the evolution of programming languages from machine language to high-level languages.
- Understand how a program in a high-level language is translated into machine language using an interpreter or a compiler.
- Distinguish between four computer language paradigms.
- Understand the procedural paradigm and the interaction between a program unit and data items in the paradigm.
- Understand the object-oriented paradigm and the interaction between a program unit and objects in this paradigm.
- Define functional paradigm and understand its applications.
- Define a declaration paradigm and understand its applications.
- Define common concepts in procedural and object-oriented languages.

## 9.1 EVOLUTION
To write a program for a computer, we must use a computer language. A computer language is a set of predefined words that are combined into a program according to predefined rules (syntax). Over the years, computer languages have evolved from machine language to high-level languages.

### 9.1.1 Machine languages
In the earliest days of computers, the only **programming languages** available were **machine languages**. Each computer had its own machine language, which was made of streams of 0s and 1s. In Chapter 5 we showed that in a primitive hypothetical computer, we need to use 11 lines of code to read two integers, add them, and print the result. These lines of code, when written in machine language, make 11 lines of binary code, each of 16 bits, as shown in Table 9.1.

**Table 9.1 Code in machine language to add two integers**
| Hexadecimal | Code in machine language |
| :--- | :--- |
| (1FEF)16 | 0001 1111 1110 1111 |
| (240F)16 | 0010 0100 0000 1111 |
| (1FEF)16 | 0001 1111 1110 1111 |
| (241F)16 | 0010 0100 0001 1111 |
| (1040)16 | 0001 0000 0100 0000 |
| (1141)16 | 0001 0001 0100 0001 |
| (3201)16 | 0011 0010 0000 0001 |
| (2422)16 | 0010 0100 0010 0010 |
| (1F42)16 | 0001 1111 0100 0010 |
| (2FFF)16 | 0010 1111 1111 1111 |
| (0000)16 | 0000 0000 0000 0000 |

Machine language is the only language understood by the computer hardware, which is made of electronic switches with two states: off (representing 0) and on (representing 1).

**The only language understood by a computer is machine language.**

Although a program written in machine language truly represents how data is manipulated by the computer, it has at least two drawbacks. First, it is machine-dependent. The machine language of one computer is different than the machine language of another computer if they use different hardware. Second, it is very tedious to write programs in this language and very difficult to find errors. The era of machine language is now is referred to as the *first generation* of programming languages.

### 9.1.2 Assembly languages
The next evolution in programming came with the idea of replacing binary code for instruction and addresses with symbols or mnemonics. Because they used symbols, these languages were first known as *symbolic languages*. The set of these mnemonic languages were later referred to as **assembly languages**. The assembly language for our hypothetical computer to replace the machine language in Table 9.1 is shown in Table 9.2.

**Table 9.2 Code in assembly language to add two integers**
| Code in assembly language | Description |
| :--- | :--- |
| LOAD RF Keyboard | Load from keyboard controller to register F |
| STORE Number1 RF | Store register F into Number1 |
| LOAD RF Keyboard | Load from keyboard controller to register F |
| STORE Number2 RF | Store register F into Number2 |
| LOAD R0 Number1 | Load Number1 into register 0 |
| LOAD R1 Number2 | Load Number2 into register 1 |
| ADDI R2 R0 R1 | Add registers 0 and 1 with result in register 2 |
| STORE Result R2 | Store register 2 into Result |
| LOAD RF Result | Load Result into register F |
| STORE Monitor RF | Store register F into monitor controller |
| HALT | Stop |

A special program called an **assembler** is used to translate code in assembly language into machine language.

### 9.1.3 High-level languages
Although assembly languages greatly improved programming efficiency, they still required programmers to concentrate on the hardware they were using. Working with symbolic languages was also very tedious, because each machine instruction had to be individually coded. The desire to improve programmer efficiency and to change the focus from the computer to the problem being solved led to the development of **high-level languages**.

High-level languages are portable to many different computers, allowing the programmer to concentrate on the application rather than the intricacies of the computer’s organization. They are designed to relieve the programmer from the details of assembly language. High-level languages share one characteristic with symbolic languages: they must be converted to machine language. This process is called *interpretation* or *compilation* (described later in the chapter).

Over the years, various languages, most notably BASIC, COBOL, Pascal, Ada, C, C++, and Java, were developed. Program 9-1 shows the code for adding two integers as it would appear in the C++ language. Although the program looks longer, some of the lines are used for documentation (comments).

**Program 9-1 Addition program in C++**
\`\`\`cpp
/* This program reads two integers from keyboard and prints their sum.
   Written by:
   Date:
*/
#include <iostream>
using namespace std;
int main ()
{
    // Local Declarations
    int number1;
    int number2;
    int result;
    // Statements
    cin >> number1;
    cin >> number2;
    result = number1 + number2;
    cout << result;
    return 0;
} // main
\`\`\`

## 9.2 TRANSLATION
Programs today are normally written in one of the high-level languages. To run the program on a computer, the program needs to be translated into the machine language of the computer on which it will run. The program in a high-level language is called the **source program**. The translated program in machine language is called the **object program**. Two methods are used for translation: **compilation** and **interpretation**.

### 9.2.1 Compilation
A **compiler** normally translates the whole source program into the object program.

### 9.2.2 Interpretation
Some computer languages use an **interpreter** to translate the source program into the object program. Interpretation refers to the process of translating each line of the source program into the corresponding line of the object program and executing the line. However, we need to be aware of two trends in interpretation: that used by some languages before Java and the interpretation used by Java.

**First approach to interpretation**
Some interpreted languages prior to Java (such as BASIC and APL) used a kind of interpretation process that we refer to as the *first approach* to interpretation, for the lack of any other name. In this type of interpretation, each line of the source program is translated into the machine language of the computer being used and executed immediately. If there are any errors in translation and execution, the process displays a message and the rest of the process is aborted. The program needs to be corrected and be interpreted and executed again from the beginning. This first approach was considered to be a slow process, which is why most languages use compilation instead of interpretation.

**Second approach to interpretation**
With the advent of Java, a new kind of interpretation process was introduced. The Java language is designed to be portable to any computer. To achieve portability, the translation of the source program to object program is done in two steps: compilation and interpretation. A Java source program is first compiled to create Java **bytecode**, which looks like code in a machine language, but is not the object code for any specific computer: it is the object code for a virtual machine, called the Java Virtual Machine or JVM. The bytecode then can be compiled or interpreted by any computer that runs a JVM emulator—that is, the computer that runs the bytecode needs only a JVM emulator, not the Java compiler.

### 9.2.3 Translation process
Compilation and interpretation differ in that the first translates the whole source code before executing it, while the second translates and executes the source code a line at a time. Both methods, however, follow the same translation process.

**Lexical analyzer**
A **lexical analyzer** reads the source code, symbol by symbol, and creates a list of **tokens** in the source language. For example, the five symbols w, h, i, l, e are read and grouped together as the token *while* in the C, C++, or Java languages.

**Syntax analyzer**
The **syntax analyzer** parses a set of tokens to find instructions. For example, the tokens ‘x’, ‘=’, ‘0’ are used by the syntax analyzer to create the assignment statement in the C language ‘x = 0’.

**Semantic analyzer**
The **semantic analyzer** checks the sentences created by the syntax analyzer to be sure that they contain no ambiguity. Computer languages are normally unambiguous, which means that this stage is either omitted in a **translator**, or its duty is minimal.

**Code generator**
After unambiguous instructions are created by the semantic analyzer, each instruction is converted to a set of machine language instructions for the computer on which the program will run. This is done by the **code generator**.

## 9.3 PROGRAMMING PARADIGMS
Today computer languages are categorized according to the approach they use to solve a problem. A *paradigm*, therefore, is a way in which a computer language looks at the problem to be solved. We divide computer languages into four paradigms: *procedural* (imperative), *object-oriented*, *functional*, and *declarative*.

### 9.3.1 The procedural paradigm
In the **procedural paradigm** (or **imperative paradigm**) we can think of a program as an *active agent* that manipulates *passive objects*. We encounter many passive objects in our daily life: a stone, a book, a lamp, and so on. A passive object cannot initiate an action by itself, but it can receive actions from active agents.

A program in a procedural paradigm is an active agent that uses passive objects that we refer to as *data* or *data items*. Data items, as passive objects, are stored in the memory of the computer, and a program manipulates them. To manipulate a piece of data, the active agent (program) issues an action, referred to as a *procedure*. For example, think of a program that prints the contents of a file. To be printed, the file needs to be stored in memory (or some registers that act as memory). The file is a passive object or a collection of passive objects. To print the file, the program uses a procedure, which we call *print*. The procedure print has usually been written previously to include all the actions required to tell the computer how to print each character in the file. The program invokes or *calls* the procedure *print*. In a procedural paradigm, the object (*file*) and the procedure (*print*) are completely separate entities. The object (*file*) is an independent entity that can receive the *print* action, or some other actions, such as *delete*, *copy*, and so on. To apply any of these actions to the file, we need a procedure to act on the file. The procedure *print* (or *copy* or *delete*) is a separate entity that is written and the program only triggers it.

We need to separate the procedure from its triggering by the program. The program does not define the procedure, it only triggers or calls the procedure. The procedure must already exist.
When we use a procedural high-level language, the program consists of nothing but a lot of procedure calls. Although it is not immediately obvious, even when we use a simple mathematical operator such as the addition operator (+), we are using a procedure call to a procedure that is already written. For example, when we use the expression A + B and expect the expression to add the value of two objects A and B, we are calling the procedure add and passing the name of these two objects to the procedure. The procedure *add* needs two objects to act on. It adds the values of the two objects and returns the result. In other words, the expression A + B is a short cut for add (A, B). The designer of the language has written this procedure and we can call it.

A program in this paradigm is made up of three parts: a part for object creation, a set of procedure calls, and a set of code for each procedure. Some procedures have already been defined in the language itself. By combining this code, the programmer can create new procedures.

**Some procedural languages**
Several high-level imperative (procedural) languages have been developed over the last few decades, such as FORTRAN, COBOL, Pascal, C, and Ada.

**FORTRAN**
**FORTRAN (FORmula TRANslation)**, designed by a group of IBM engineers under the supervision of Jack Backus, became commercially available in 1957. FORTRAN was the first high-level language. FORTRAN has some features that, even after four decades, still make it an ideal language for scientific and engineering applications. These features can be summarized as:
- High-precision arithmetic
- Capability of handling complex numbers
- Exponentiation computation ($a^b$)

**COBOL**
**COBOL (COmmon Business-Oriented Language)** was designed by a group of computer scientists under the direction of Grace Hopper of the US Navy. COBOL had a specific design goal: to be used as a business programming language. The programming needs of the business world can be summarized as follows:
- Fast access to files and databases
- Fast updating of files and databases
- Large amounts of generated reports
- User-friendly formatted output

**Pascal**
**Pascal** was invented by Niklaus Wirth in 1971. Pascal was designed with a specific goal in mind: to teach programming to novices by emphasizing the structured programming approach. Although Pascal became the most popular language in academia, it never attained the same popularity in industry. Today’s **procedural languages** owe a lot to this language.

**C**
The **C language** was developed in the early 1970s by Dennis Ritchie at Bell Laboratories. It was originally intended for writing operating systems and system software—most of the UNIX operating system is written in C. Later, it became popular among programmers for several reasons:
- C has all the high-level instructions a structured high-level programming language should have.
- C also has some low-level instructions that allow the programmer to access the hardware directly and quickly. This makes it a good language for system programmers.
- C is a very efficient language: its instructions are short.

**Ada**
**Ada** was named after Augusta Ada Byron, the daughter of Lord Byron. It was created for the US Department of Defense (DoD). Ada has three features that make it very popular:
- Ada has high-level instructions like other procedural languages.
- Ada has instructions to allow real-time processing.
- Ada has parallel-processing capabilities.

### 9.3.2 The object-oriented paradigm
The **object-oriented paradigm** deals with *active objects* instead of passive objects. We encounter many active objects in our daily life: a vehicle, an automatic door, a dishwasher, and so on. The actions to be performed on these objects are included in the object: the objects need only to receive the appropriate stimulus from outside to perform one of the actions.

Returning to our example in the procedural paradigm, a file in an object-oriented paradigm can be packed with all the procedures—called **methods** in the object-oriented paradigm—to be performed by the file: printing, copying, deleting, and so on. The program in this paradigm just sends the corresponding request to the object (print, delete, copy, and so on) and the file will be printed, copied, or deleted.
The methods are shared by all objects of the same type, and also for other objects that are inherited from these objects. If the program wants to print File1, it just sends the required stimulus to the active objects and File1 will be printed.
Comparing the procedural paradigm with the object-oriented paradigm, we see that the procedures in the procedural paradigm are independent entities, but the methods in object-oriented paradigm belong to the object’s territory.

**Classes**
Objects of the same type (files, for example) need a set of methods that show how an object of this type reacts to stimuli from outside the object’s ‘territories’. To create these methods, object-oriented languages such as C++, Java, and C# (pronounced ‘C sharp’) use a unit called a **class**.

**Methods**
In general, the formats of methods are very similar to the functions used in some procedural languages. Each **method** has its header, its local variables, and its statement. This means that most of the features we discussed for procedural languages are also applied to methods written for an object-oriented program.

**Inheritance**
In the object-oriented paradigm, as in nature, an object can inherit from another object. This concept is called **inheritance**. When a general class is defined, we can define a more specific class that inherits some of the characteristics of the general class, but also has some new characteristics. For example, when an object of the type *GeometricalShapes* is defined, we can define a class called *Rectangles*. Rectangles are geometrical shapes with additional characteristics.

**Polymorphism**
**Polymorphism** means ‘many forms’. Polymorphism in the object-oriented paradigm means that we can define several operations with the same name that can do different things in related classes. For example, assume that we define two classes, *Rectangles* and *Circles*, both inherited from the class *GeometricalShapes*. We define two operations both named *area*, one in Rectangles and one in Circles, that calculate the area of a rectangle or a circle. The two operations have the same name but do different things.

**Some object-oriented languages**
Several **object-oriented languages** have been developed. We briefly discuss the characteristics of two: C++ and Java.

**C++**
The **C++ language** was developed by Bjarne Stroustrup at Bell Laboratory as an improvement of the C language. It uses **classes** to define the general characteristics of similar objects and the operations that can be applied to them. Three principles were used in the design of the C++ language: *encapsulation*, *inheritance*, and *polymorphism*.

**Java**
**Java** was developed at Sun Microsystems, Inc. It is based on C and C++, but some features of C++ were removed to make the language more robust. In addition, the language is totally class-oriented. In C++ one can solve a problem without ever defining a class, but in Java every data item belongs to a class.
A program in Java can either be an application or an applet. An application is a complete stand-alone program that can be run independently. An **applet**, on the other hand, is embedded HTML, stored on a server, and run by a browser.
One interesting feature of Java is support for **multithreading**. A thread is a sequence of actions executed one after another. C++ allows only single threading, but Java allows the concurrent execution of several lines of code.

### 9.3.3 The functional paradigm
In the **functional paradigm** a program is considered a mathematical function. In this context, a **function** is a black box that maps a list of inputs to a list of outputs.
For example, *summation* can be considered as a function with $n$ inputs and only one output. The function takes the $n$ inputs, adds them, and creates the sum. A **functional language** does the following:
- Predefines a set of primitive (atomic) functions that can be used by any programmer.
- Allows the programmer to combine primitive functions to create new functions.

For example, we can define a primitive function called *first* that extracts the first element of a list. It may also have a function called *rest* that extracts all the elements except the first. A program can define a function that extracts the third element of a list by combining these two functions.

**Some functional languages**
We briefly discuss LISP and Scheme as examples of functional languages.

**LISP**
**LISP (LISt Programming)** was designed by a team of researchers at MIT in the early 1960s. It is a list-processing programming language in which everything is considered a list.

**Scheme**
The LISP language suffered from a lack of standardization. The de facto standard is the one developed by MIT in the early 1970s called **Scheme**.
The Scheme language defines a set of primitive functions that solves problems. The function name and the list of inputs to the function are enclosed in parentheses. For example, there is a function, car, that extracts the first element of a list. There is a function, called cdr, that extracts the rest of the elements in a list except the first one. In other words, we have:
\`(car 2 3 7 8 11 17 20) -> 2\`
\`(cdr 2 3 7 8 11 17 20) -> 3 7 8 11 17 20\`
Now we can combine these two functions to extract the third element of any list:
\`(car (cdr (cdr list)))\`

### 9.3.4 The declarative paradigm
A **declarative paradigm** uses the principle of logical reasoning to answer queries. It is based on formal logic defined by Greek mathematicians and later developed into *first-order predicate calculus*.
Logical reasoning is based on deduction. Some statements (facts) are given that are assumed to be true, and the logician uses solid rules of logical reasoning to deduce new statements (facts). For example, the famous rule of deduction in logic is:
If (A is B) and (B is C), then (A is C)
Using this rule and the two following facts:
Fact 1: Socrates is a human -> A is B
Fact 2: A human is mortal -> B is C
we can deduce a new fact:
Fact 3: Socrates is mortal -> A is C

One problem associated with **declarative languages** is that a program is specific to a particular domain. This is the reason why declarative programming is limited so far to specific fields such as artificial intelligence.

**Prolog**
One of the famous declarative languages is **Prolog (PROgramming in LOGic)**, developed by A. Colmerauer in France in 1972. A program in Prolog is made up of facts and rules. For example, the previous facts about human beings can be stated as:
\`human (John)\`
\`mortal (human)\`
The user can then ask:
\`?-mortal (John)\`
and the program will respond with *yes*.

## 9.4 COMMON CONCEPTS
In this section we conduct a quick navigation through some procedural languages to find common concepts. Some of these concepts are also available in most object-oriented languages because an object-oriented paradigm uses the procedural paradigm when creating methods.

### 9.4.1 Identifiers
One feature present in all procedural languages, as well as in other languages, is the **identifier**—that is, the name of objects. Identifiers allow us to name objects in the program. For example, each piece of data in a computer is stored at a unique address. Identifiers allow us to give data names and let the compiler keep track of where they are physically located.

### 9.4.2 Data types
A **data type** defines a set of values and a set of operations that can be applied to those values. The set of values for each type is known as the *domain* for the type. Most languages define two categories of data types: *simple types* and *composite types*.

**Simple data types**
A **simple type** (sometimes called an *atomic type*, *fundamental type*, *scalar type*, or *built-in type*) is a data type that cannot be broken into smaller data types. Several simple data types have been defined in **imperative languages**:
- An *integer* type is a whole number, that is, a number without a fractional part.
- A *real* type is a number with a fractional part.
- A *character* type is a symbol in the underlying character set used by the language, for example, ASCII or Unicode.
- A *Boolean* type is type with only two values, *true* or *false*.

**Composite data types**
A **composite type** is a set of elements in which each element is a simple type or a composite type. Most languages defines the following composite types:
- An *array* is a set of elements each of the same type.
- A *record* is a set of elements in which the element can be of different types.

### 9.4.3 Variables
**Variables** are names for memory locations. A programmer can use a variable, such as *score*, to store the integer value of a score received in a test. Since a variable holds a data item, it has a type.

**Variable declarations**
Most procedural and object-oriented languages required that the variables be declared before being used. Declaration alerts the computer that a variable with a given name and type will be used in the program.
\`char C;\`
\`int num;\`
\`double result;\`

**Variable initialization**
Most procedural languages allow the initialization of the variables when they are declared. Initialization stores a value in the variable.
\`char C = 'Z';\`
\`int num = 123;\`
\`double result = 256,782;\`

### 9.4.4 Literals
A **literal** is a predetermined value used in a program. For example, in the expression 3.14 × r^2, the approximate value of $\\pi$ (pi) is used as a literal. In most programming languages we can have integer, real, character, and Boolean literals. To distinguish the character and string literals from the names of variables, most languages require that the character literals be enclosed in single quotes, such as 'A' and strings to be enclosed in double quotes such as "Anne".

### 9.4.5 Constants
Most programming languages defined **constants**. A constant, like a variable, is a named location that can store a value, but the value cannot be changed after it has been defined at the beginning of the program.
\`const float taxMultiplier = 1.08;\`
\`...\`
\`cost = price * taxMultiplier;\`

### 9.4.6 Input and Output
Almost every program needs to read and/or write data. Most programming languages use a predefined function for input and output.
**Input**: Data is **input** by either a statement or a predefined function. For example, the *scanf* function in C reads data from the keyboard.
**Output**: Data is **output** by either a statement or a predefined function. For example, the *printf* function in C displays a string on the monitor.

### 9.4.7 Expressions
An **expression** is a sequence of operands and operators that reduces to a single value.
**Operator**: An **operator** is a language-specific token that requires an action to be taken. Common operators include arithmetic (+, -, *, /, %), relational (<, <=, >, >=, ==, !=), and logical (!, &&, ||) operators.
**Operand**: An **operand** receives an operator’s action.

### 9.4.8 Statements
A **statement** causes an action to be performed by the program.
**Assignment statements**: An **assignment statement** assigns a value to a variable. The symbol = is common (e.g., x = 1).
**Compound statements**: A **compound statement** is a unit of code consisting of zero or more statements. It is also known as a block. It allows a group of statements to be treated as a single entity.
**Control statements**: A **control statement** is a program in a procedural language that is a set of statements. Control statements are normally executed one after another. However, sometimes it is necessary to change this sequential order.
- **Selection**: Two-way selection is achieved through the *if-else* statement, multi-way selection through the *switch* (or *case*) statement.
- **Repetition**: Most imperative languages define loops like *while*, *do-while*, and *for*.

### 9.4.9 Subprograms
The idea of **subprograms** is crucial in procedural languages. A subprogram is a program unit that can be written once but called many times. Subprograms make programming more structural.
**Local variables**: Local objects or **local variables** are created each time the subprogram is called and destroyed when control returns from the subprogram.
**Parameters**: Subprograms act on objects. These are referred to as **actual parameters** in the main program and **formal parameters** in the subprogram.
- **Pass by value**: The main program sends the value of the actual parameter to the subprogram. The subprogram receives a copy. It cannot change the original variable in the main program.
- **Pass by reference**: The variable is shared by the main program and the subprogram. The subprogram can change the value of the variable in the main program.
**Returning values**: A subprogram can be designed to return a value or values.
**Implementation**: In C and C++, the subprogram is implemented as a function.

## 9.5 END-CHAPTER MATERIALS
### 9.5.1 Recommended reading
- Cooke, D. A. *Concise Introduction to Computer Languages*, Pacific Grove, CA: Brooks/Cole, 2003
- Tucker, A. and Noonan, R. *Programming Languages: Principles and Paradigms*, Burr Ridge, IL: McGraw-Hill, 2002
- Pratt, T. and Zelkowitz, M. *Programming Languages, Design and Implementation*, Englewood Cliffs, NJ: Prentice-Hall, 2001
- Sebesta, R. *Concepts of Programming Languages*, Boston, MA: Addison-Wesley, 2006

### 9.5.2 Key terms
- actual parameter
- Ada
- applet
- arithmetic operator
- assembler
- assembly language
- assignment statement
- bytecode
- C++ language
- C language
- class
- code generator
- COmmon Business-Oriented Language (COBOL)
- compilation
- compiler
- composite type
- compound statement
- computer language
- constant
- control statement
- data type
- declarative language
- declarative paradigm
- expression
- formal parameter
- FORmula TRANslation (FORTRAN)
- functional language
- functional paradigm
- high-level language
- identifier
- imperative language
- imperative paradigm
- inheritance
- input
- interpretation
- interpreter
- Java
- lexical analyzer
- LISt Programming Language (LISP)
- literal
- local variable
- logical operator
- machine language
- method
- multithreading
- object-oriented language
- object-oriented paradigm
- object program
- operand
- operator
- output
- parameter
- Pascal
- pass by reference
- pass by value
- polymorphism
- procedural paradigm
- Programming in LOGic (PROLOG)
- programming language
- relational operator
- Scheme
- semantic analyzer
- simple type
- source program
- statement
- subprogram
- symbolic language
- syntax
- syntax analyzer
- token
- translator
- variable

### 9.5.3 Summary
- A computer language is a set of predefined words that are combined into a program according to predefined rules (syntax).
- High-level languages are portable to many different computers.
- To run a program on a computer, it needs to be translated into the machine language. Compilation translates the whole source program; interpretation translates line by line.
- Four paradigms: procedural, object-oriented, functional, and declarative.
- Common concepts: identifiers, data types, variables, literals, constants, input/output, expressions, statements, and subprograms.
`,zh:`
# 第九章：程式語言

在第八章中，我們討論了演算法。我們展示了如何用 UML 或偽代碼編寫演算法來解決問題。在本章中，我們將探討程式語言，這些語言可以將解決方案的偽代碼或 UML 描述實作為程式語言。本章並非旨在教授特定的程式語言，而是為了比較和對比不同的語言。

## 學習目標
學完本章後，學生應能：
- 描述程式語言從機器語言到高階語言的演進。
- 理解高階語言程式如何使用直譯器或編譯器轉換為機器語言。
- 區分四種電腦語言範式。
- 理解程序化範式以及該範式中程式單元與資料項目之間的互動。
- 理解物件導向範式以及該範式中程式單元與物件之間的互動。
- 定義函數式範式並理解其應用。
- 定義宣告式範式並理解其應用。
- 定義程序化和物件導向語言中的共同概念。

## 9.1 演進
要為電腦編寫程式，我們必須使用電腦語言。電腦語言是一組預先定義的詞彙，根據預先定義的規則（語法）組合成程式。多年來，電腦語言已從機器語言演變為高階語言。

### 9.1.1 機器語言
在電腦最早期的時代，唯一可用的**程式語言**是**機器語言**。每台電腦都有自己的機器語言，由 0 和 1 的串流組成。在第五章中，我們展示了在一台原始的假設電腦中，我們需要使用 11 行代碼來讀取兩個整數，將它們相加，並列印結果。這些代碼行如果用機器語言編寫，會變成 11 行二進位代碼，每行 16 位元，如表 9.1 所示。

**表 9.1 用機器語言編寫的兩個整數相加的代碼**
| 十六進位 | 機器語言代碼 |
| :--- | :--- |
| (1FEF)16 | 0001 1111 1110 1111 |
| (240F)16 | 0010 0100 0000 1111 |
| (1FEF)16 | 0001 1111 1110 1111 |
| (241F)16 | 0010 0100 0001 1111 |
| (1040)16 | 0001 0000 0100 0000 |
| (1141)16 | 0001 0001 0100 0001 |
| (3201)16 | 0011 0010 0000 0001 |
| (2422)16 | 0010 0100 0010 0010 |
| (1F42)16 | 0001 1111 0100 0010 |
| (2FFF)16 | 0010 1111 1111 1111 |
| (0000)16 | 0000 0000 0000 0000 |

機器語言是電腦硬體唯一能理解的語言，硬體由具有兩種狀態的電子開關組成：關（代表 0）和開（代表 1）。

**電腦唯一能理解的語言是機器語言。**

雖然用機器語言編寫的程式真實地代表了電腦如何操作資料，但它至少有兩個缺點。首先，它是依賴機器的。如果兩台電腦使用不同的硬體，它們的機器語言就會不同。其次，用這種語言編寫程式非常繁瑣，而且很難發現錯誤。機器語言時代現在被稱為程式語言的*第一代*。

### 9.1.2 組合語言
程式設計的下一次演進是用符號或助記符取代指令和位址的二進位碼。因為它們使用符號，這些語言最初被稱為*符號語言*。這些助記符語言的集合後來被稱為**組合語言**。用於替換表 9.1 中機器語言的我們假設電腦的組合語言如表 9.2 所示。

**表 9.2 用組合語言編寫的兩個整數相加的代碼**
| 組合語言代碼 | 描述 |
| :--- | :--- |
| LOAD RF Keyboard | 從鍵盤控制器載入到暫存器 F |
| STORE Number1 RF | 將暫存器 F 存入 Number1 |
| LOAD RF Keyboard | 從鍵盤控制器載入到暫存器 F |
| STORE Number2 RF | 將暫存器 F 存入 Number2 |
| LOAD R0 Number1 | 將 Number1 載入到暫存器 0 |
| LOAD R1 Number2 | 將 Number2 載入到暫存器 1 |
| ADDI R2 R0 R1 | 將暫存器 0 和 1 相加，結果存入暫存器 2 |
| STORE Result R2 | 將暫存器 2 存入 Result |
| LOAD RF Result | 將 Result 載入到暫存器 F |
| STORE Monitor RF | 將暫存器 F 存入螢幕控制器 |
| HALT | 停止 |

一種稱為**組譯器**的特殊程式用於將組合語言代碼翻譯成機器語言。

### 9.1.3 高階語言
雖然組合語言大大提高了程式設計效率，但它們仍然要求程式設計師專注於他們正在使用的硬體。使用符號語言工作也非常繁瑣，因為每條機器指令都必須單獨編碼。提高程式設計師效率並將重點從電腦轉移到要解決的問題上的願望導致了**高階語言**的開發。

高階語言可移植到許多不同的電腦上，讓程式設計師可以專注於應用程式，而不是電腦組織的複雜細節。它們旨在讓程式設計師從組合語言的細節中解脫出來。高階語言與符號語言有一個共同特徵：它們必須被轉換為機器語言。這個過程稱為*直譯*或*編譯*（稍後在本章中描述）。

多年來，各種語言被開發出來，最著名的是 BASIC、COBOL、Pascal、Ada、C、C++ 和 Java。程式 9-1 顯示了用 C++ 語言編寫的兩個整數相加的代碼。雖然程式看起來更長，但其中一些行用於文件說明（註解）。

**程式 9-1 C++ 中的加法程式**
\`\`\`cpp
/* 該程式從鍵盤讀取兩個整數並列印它們的總和。
   作者：
   日期：
*/
#include <iostream>
using namespace std;
int main ()
{
    // 區域宣告
    int number1;
    int number2;
    int result;
    // 陳述式
    cin >> number1;
    cin >> number2;
    result = number1 + number2;
    cout << result;
    return 0;
} // main
\`\`\`

## 9.2 轉譯
今天的程式通常是用一種高階語言編寫的。為了在電腦上運行程式，程式需要被翻譯成將要運行的電腦的機器語言。高階語言的程式稱為**原始程式**。翻譯後的機器語言程式稱為**目的程式**。翻譯使用兩種方法：**編譯**和**直譯**。

### 9.2.1 編譯 (Compilation)
**編譯器**通常將整個原始程式翻譯成目的程式。

### 9.2.2 直譯 (Interpretation)
一些電腦語言使用**直譯器**將原始程式翻譯成目的程式。直譯是指逐行將原始程式翻譯成目的程式的對應行並執行該行的過程。然而，我們需要意識到直譯的兩個趨勢：Java 之前的一些語言使用的直譯和 Java 使用的直譯。

**第一種直譯方法**
Java 之前的一些直譯語言（如 BASIC 和 APL）使用一種我們稱之為*第一種方法*的直譯過程，因為沒有其他名稱。在這種類型的直譯中，原始程式的每一行都被翻譯成正在使用的電腦的機器語言並立即執行。如果在翻譯和執行過程中出現任何錯誤，該過程會顯示一條訊息，其餘過程將中止。程式需要被修正，並從頭開始再次直譯和執行。這第一種方法被認為是一個緩慢的過程，這就是為什麼大多數語言使用編譯而不是直譯。

**第二種直譯方法**
隨著 Java 的出現，引入了一種新的直譯過程。Java 語言旨在可移植到任何電腦。為了實現可移植性，原始程式到目的程式的翻譯分兩步完成：編譯和直譯。Java 原始程式首先被編譯以創建 Java **位元組碼 (bytecode)**，它看起來像機器語言代碼，但不是任何特定電腦的目的碼：它是虛擬機器的目的碼，稱為 Java 虛擬機或 JVM。然後，位元組碼可以由任何運行 JVM 模擬器的電腦編譯或直譯——也就是說，運行位元組碼的電腦只需要一個 JVM 模擬器，而不是 Java 編譯器。

### 9.2.3 翻譯過程
編譯和直譯的不同之處在於，前者在執行之前翻譯整個原始程式碼，而後者一次翻譯並執行一行原始程式碼。然而，這兩種方法都遵循相同的翻譯過程。

**詞彙分析器 (Lexical analyzer)**
**詞彙分析器**逐個符號地讀取原始程式碼，並在原始語言中創建**符記 (tokens)** 列表。例如，五個符號 w, h, i, l, e 被讀取並組合在一起作為 C、C++ 或 Java 語言中的符記 *while*。

**語法分析器 (Syntax analyzer)**
**語法分析器**解析一組符記以查找指令。例如，符記 'x', '=', '0' 被語法分析器用來在 C 語言中創建賦值陳述式 'x = 0'。

**語意分析器 (Semantic analyzer)**
**語意分析器**檢查語法分析器生成的句子，以確保它們不包含歧義。電腦語言通常是明確的，這意味著這個階段在**翻譯器**中要麼被省略，要麼其職責很小。

**代碼生成器 (Code generator)**
在語意分析器創建明確的指令後，每條指令都被轉換為一組機器語言指令，用於將運行程式的電腦。這是由**代碼生成器**完成的。

## 9.3 程式設計範式
今天，電腦語言根據它們用來解決問題的方法進行分類。因此，*範式*是電腦語言看待待解決問題的方式。我們將電腦語言分為四種範式：*程序化*（指令式）、*物件導向*、*函數式*和*宣告式*。

### 9.3.1 程序化範式
在**程序化範式**（或**指令式範式**）中，我們可以將程式視為一個*主動的代理者*，它操作*被動的物件*。我們在日常生活中遇到許多被動的物件：石頭、書、燈等等。被動的物件不能自己發起動作，但它可以接受來自主動代理者的動作。

程序化範式中的程式是一個主動的代理者，它使用我們稱為*資料*或*資料項目*的被動物件。資料項目作為被動物件，儲存在電腦的記憶體中，程式操作它們。為了操作一塊資料，主動代理者（程式）發出一個動作，稱為*程序*。例如，想像一個列印檔案內容的程式。要被列印，檔案需要儲存在記憶體中（或一些充當記憶體的暫存器）。檔案是一個被動物件或被動物件的集合。為了列印檔案，程式使用一個程序，我們稱之為 *print*。程序 print 通常已經預先寫好，包含了告訴電腦如何列印檔案中每個字元所需的所有動作。程式調用或*呼叫*程序 *print*。在程序化範式中，物件（*檔案*）和程序（*print*）是完全獨立的實體。物件（*檔案*）是一個獨立的實體，可以接收 *print* 動作，或其他一些動作，如 *delete*、*copy* 等等。要對檔案應用任何這些動作，我們需要一個程序來作用於檔案。程序 *print*（或 *copy* 或 *delete*）是一個單獨的實體，它被寫好，程式只是觸發它。

我們需要將程序與程式對它的觸發分開。程式不定義程序，它只觸發或呼叫程序。程序必須已經存在。
當我們使用程序化高階語言時，程式只不過是由大量的程序呼叫組成。雖然這不是立即顯而易見的，但即使我們使用簡單的數學運算子，如加法運算子 (+)，我們也是在使用對已經寫好的程序的程序呼叫。例如，當我們使用表達式 A + B 並期望表達式將兩個物件 A 和 B 的值相加時，我們是在呼叫程序 add 並將這兩個物件的名稱傳遞給程序。程序 *add* 需要兩個物件來作用。它將兩個物件的值相加並回傳結果。換句話說，表達式 A + B 是 add (A, B) 的捷徑。語言的設計者已經編寫了這個程序，我們可以呼叫它。

這種範式中的程式由三部分組成：物件創建部分、一組程序呼叫和每個程序的代碼集。有些程序已經在語言本身中定義。透過組合這些代碼，程式設計師可以創建新的程序。

**一些程序化語言**
在過去幾十年中，已經開發了幾種高階指令式（程序化）語言，如 FORTRAN、COBOL、Pascal、C 和 Ada。

**FORTRAN**
**FORTRAN (FORmula TRANslation，公式翻譯)** 由 Jack Backus 監督的一組 IBM 工程師設計，於 1957 年商業化。FORTRAN 是第一個高階語言。FORTRAN 具有一些特性，即使在四十年後，仍然使其成為科學和工程應用的理想語言。這些特性可以總結為：
- 高精度算術
- 處理複數的能力
- 指數運算 ($a^b$)

**COBOL**
**COBOL (COmmon Business-Oriented Language，通用商業導向語言)** 由美國海軍 Grace Hopper 指導的一組電腦科學家設計。COBOL 有一個特定的設計目標：用作商業程式語言。商業世界的程式設計需求可以總結如下：
- 快速存取檔案和資料庫
- 快速更新檔案和資料庫
- 大量生成的報告
- 使用者友好的格式化輸出

**Pascal**
**Pascal** 由 Niklaus Wirth 於 1971 年發明。Pascal 的設計有一個特定的目標：透過強調結構化程式設計方法來教導新手程式設計。雖然 Pascal 在學術界成為最受歡迎的語言，但它從未在工業界獲得同樣的普及。今天的**程序化語言**在很大程度上歸功於這種語言。

**C**
**C 語言**由 Dennis Ritchie 於 1970 年代初在貝爾實驗室開發。它最初是為了編寫作業系統和系統軟體而設計的——大部分 UNIX 作業系統都是用 C 編寫的。後來，由於幾個原因，它在程式設計師中流行起來：
- C 具有結構化高階程式語言應具有的所有高階指令。
- C 也有一些低階指令，允許程式設計師直接快速地存取硬體。這使它成為系統程式設計師的好語言。
- C 是一種非常高效的語言：它的指令很短。

**Ada**
**Ada** 以 Lord Byron 的女兒 Augusta Ada Byron 命名。它是為美國國防部 (DoD) 創建的。Ada 有三個特點使它非常受歡迎：
- 像其他程序化語言一樣，Ada 具有高階指令。
- Ada 具有允許即時處理的指令。
- Ada 具有平行處理能力。

### 9.3.2 物件導向範式
**物件導向範式**處理的是*主動的物件*而不是被動的物件。我們在日常生活中遇到許多主動的物件：車輛、自動門、洗碗機等等。對這些物件執行的動作包含在物件中：物件只需要從外部接收適當的刺激來執行其中一個動作。

回到我們在程序化範式中的例子，物件導向範式中的檔案可以包含所有要由檔案執行的程序——在物件導向範式中稱為**方法 (methods)**：列印、複製、刪除等等。這種範式中的程式只是向物件發送相應的請求（列印、刪除、複製等），檔案就會被列印、複製或刪除。
相同類型的所有物件共享這些方法，從這些物件繼承的其他物件也共享這些方法。如果程式想要列印 File1，它只需向主動物件發送所需的刺激，File1 就會被列印。
比較程序化範式與物件導向範式，我們可以看到程序化範式中的程序是獨立的實體，但物件導向範式中的方法屬於物件的領域。

**類別 (Classes)**
相同類型的物件（例如檔案）需要一組方法來顯示這種類型的物件如何對來自物件「領域」外部的刺激做出反應。為了創建這些方法，C++、Java 和 C#（發音為 'C sharp'）等物件導向語言使用稱為**類別**的單元。

**方法 (Methods)**
一般來說，方法的格式與某些程序化語言中使用的函式非常相似。每個**方法**都有其標頭、區域變數和陳述式。這意味著我們討論的程序化語言的大多數特性也適用於為物件導向程式編寫的方法。

**繼承 (Inheritance)**
在物件導向範式中，就像在自然界中一樣，一個物件可以從另一個物件繼承。這個概念稱為**繼承**。當定義了一個一般類別時，我們可以定義一個更具體的類別，它繼承了一般類別的一些特徵，但也具有一些新特徵。例如，當定義了類型為 *GeometricalShapes*（幾何形狀）的物件時，我們可以定義一個名為 *Rectangles*（矩形）的類別。矩形是具有額外特徵的幾何形狀。

**多型 (Polymorphism)**
**多型**意味著「多種形式」。物件導向範式中的多型意味著我們可以定義幾個同名的操作，這些操作在相關類別中可以做不同的事情。例如，假設我們定義了兩個類別 *Rectangles* 和 *Circles*（圓形），都繼承自類別 *GeometricalShapes*。我們定義了兩個都名為 *area*（面積）的操作，一個在 Rectangles 中，一個在 Circles 中，用於計算矩形或圓形的面積。這兩個操作名稱相同但做不同的事情。

**一些物件導向語言**
已經開發了幾種**物件導向語言**。我們簡要討論其中兩種的特徵：C++ 和 Java。

**C++**
**C++ 語言**由貝爾實驗室的 Bjarne Stroustrup 開發，作為 C 語言的改進。它使用**類別**來定義相似物件的一般特徵以及可以應用於它們的操作。C++ 語言的設計使用了三個原則：*封裝*、*繼承*和*多型*。

**Java**
**Java** 由 Sun Microsystems, Inc. 開發。它基於 C 和 C++，但刪除了 C++ 的一些功能以使語言更健壯。此外，該語言完全是類別導向的。在 C++ 中，人們可以解決問題而無需定義類別，但在 Java 中，每個資料項目都屬於一個類別。
Java 程式可以是應用程式或小程式。應用程式是一個可以獨立運行的完整獨立程式。另一方面，**小程式 (applet)** 是嵌入式 HTML，儲存在伺服器上，並由瀏覽器運行。
Java 的一個有趣特徵是支援**多執行緒**。執行緒是依序執行的一系列動作。C++ 只允許單執行緒，但 Java 允許同時執行幾行代碼。

### 9.3.3 函數式範式
在**函數式範式**中，程式被視為數學函數。在這種情況下，**函數**是一個將輸入列表映射到輸出列表的黑盒子。
例如，*總和*可以被視為具有 $n$ 個輸入和只有一個輸出的函數。該函數獲取 $n$ 個輸入，將它們相加，並創建總和。**函數式語言**做以下事情：
- 預先定義一組原始（原子）函數，任何程式設計師都可以使用。
- 允許程式設計師組合原始函數以創建新函數。

例如，我們可以定義一個名為 *first* 的原始函數，它提取列表的第一個元素。它也可能有另一個名為 *rest* 的函數，它提取除第一個之外的所有元素。程式可以透過組合這兩個函數來定義一個提取列表第三個元素的函數。

**一些函數式語言**
我們簡要討論 LISP 和 Scheme 作為函數式語言的例子。

**LISP**
**LISP (LISt Programming，列表程式設計)** 由麻省理工學院的一組研究人員於 1960 年代初設計。它是一種列表處理程式語言，其中一切都被視為列表。

**Scheme**
LISP 語言缺乏標準化。事實上的標準是由麻省理工學院在 1970 年代初開發的，稱為 **Scheme**。
Scheme 語言定義了一組解決問題的原始函數。函數名稱和函數的輸入列表包含在括號中。例如，有一個函數 car，它提取列表的第一個元素。有一個函數，稱為 cdr，它提取列表中除第一個之外的其餘元素。換句話說，我們有：
\`(car 2 3 7 8 11 17 20) -> 2\`
\`(cdr 2 3 7 8 11 17 20) -> 3 7 8 11 17 20\`
現在我們可以組合這兩個函數來提取任何列表的第三個元素：
\`(car (cdr (cdr list)))\`

### 9.3.4 宣告式範式
**宣告式範式**使用邏輯推理原則來回答查詢。它基於希臘數學家定義的形式邏輯，後來發展成*一階謂詞演算*。
邏輯推理基於演繹。給出一些被假定為真的陳述（事實），邏輯學家使用可靠的邏輯推理規則來推導出新的陳述（事實）。例如，邏輯中著名的演繹規則是：
如果 (A 是 B) 且 (B 是 C)，則 (A 是 C)
使用這條規則和以下兩個事實：
事實 1：蘇格拉底是人 -> A 是 B
事實 2：人是會死的 -> B 是 C
我們可以推導出一個新事實：
事實 3：蘇格拉底是會死的 -> A 是 C

與**宣告式語言**相關的一個問題是程式特定於特定領域。這就是為什麼宣告式程式設計目前僅限於特定領域，如人工智慧。

**Prolog**
著名的宣告式語言之一是 **Prolog (PROgramming in LOGic，邏輯程式設計)**，由法國的 A. Colmerauer 於 1972 年開發。Prolog 程式由事實和規則組成。例如，關於人類的先前事實可以陳述為：
\`human (John)\`
\`mortal (human)\`
使用者然後可以問：
\`?-mortal (John)\`
程式將回應 *yes*。

## 9.4 共同概念
在本節中，我們將快速瀏覽一些程序化語言以尋找共同概念。其中一些概念在大多數物件導向語言中也可用，因為物件導向範式在創建方法時使用程序化範式。

### 9.4.1 識別碼 (Identifiers)
所有程序化語言以及其他語言中都存在的一個特徵是**識別碼**——即物件的名稱。識別碼允許我們命名程式中的物件。例如，電腦中的每塊資料都儲存在唯一的位址。識別碼允許我們給資料命名，並讓編譯器追蹤它們的物理位置。

### 9.4.2 資料型別 (Data types)
**資料型別**定義了一組值和一組可以應用於這些值的運算。每種類型的值集合稱為該類型的*域*。大多數語言定義兩類資料型別：*簡單型別*和*複合型別*。

**簡單資料型別**
**簡單型別**（有時稱為*原子型別*、*基本型別*、*純量型別*或*內建型別*）是一種不能分解為更小資料型別的資料型別。在**指令式語言**中定義了幾種簡單資料型別：
- *整數 (integer)* 型別是整數，即沒有小數部分的數字。
- *實數 (real)* 型別是帶有小數部分的數字。
- *字元 (character)* 型別是語言使用的底層字元集中的符號，例如 ASCII 或 Unicode。
- *布林 (Boolean)* 型別是只有兩個值，*真 (true)* 或 *假 (false)* 的型別。

**複合資料型別**
**複合型別**是一組元素，其中每個元素都是簡單型別或複合型別。大多數語言定義以下複合型別：
- *陣列 (array)* 是一組相同型別的元素。
- *記錄 (record)* 是一組元素，其中元素可以是不同的型別。

### 9.4.3 變數 (Variables)
**變數**是記憶體位置的名稱。程式設計師可以使用變數，例如 *score*，來儲存測試中獲得的分數的整數值。由於變數保存資料項目，因此它具有一種類型。

**變數宣告**
大多數程序化和物件導向語言要求在使用變數之前對其進行宣告。宣告提醒電腦將在程式中使用具有給定名稱和類型的變數。
\`char C;\`
\`int num;\`
\`double result;\`

**變數初始化**
大多數程序化語言允許在宣告變數時對其進行初始化。初始化將值儲存在變數中。
\`char C = 'Z';\`
\`int num = 123;\`
\`double result = 256,782;\`

### 9.4.4 字面值 (Literals)
**字面值**是程式中使用的預定值。例如，在表達式 3.14 × r^2 中，$\\pi$ (pi) 的近似值被用作字面值。在大多數程式語言中，我們可以有整數、實數、字元和布林字面值。為了區分字元和字串字面值與變數名稱，大多數語言要求將字元字面值括在單引號中，如 'A'，並將字串括在雙引號中，如 "Anne"。

### 9.4.5 常數 (Constants)
大多數程式語言定義了**常數**。常數像變數一樣，是一個可以儲存值的命名位置，但在程式開頭定義後，該值不能更改。
\`const float taxMultiplier = 1.08;\`
\`...\`
\`cost = price * taxMultiplier;\`

### 9.4.6 輸入和輸出
幾乎每個程式都需要讀取和/或寫入資料。大多數程式語言使用預先定義的函數進行輸入和輸出。
**輸入 (Input)**：資料由陳述式或預先定義的函數**輸入**。例如，C 中的 *scanf* 函數從鍵盤讀取資料。
**輸出 (Output)**：資料由陳述式或預先定義的函數**輸出**。例如，C 中的 *printf* 函數在螢幕上顯示字串。

### 9.4.7 表達式 (Expressions)
**表達式**是由運算元和運算子組成的序列，可化簡為單一值。
**運算子 (Operator)**：**運算子**是語言特定的符號，需要執行動作。常見的運算子包括算術 (+, -, *, /, %)、關係 (<, <=, >, >=, ==, !=) 和邏輯 (!, &&, ||) 運算子。
**運算元 (Operand)**：**運算元**接收運算子的動作。

### 9.4.8 陳述式 (Statements)
**陳述式**使程式執行一個動作。
**賦值陳述式**：**賦值陳述式**將值賦給變數。符號 = 很常見（例如，x = 1）。
**複合陳述式**：**複合陳述式**是由零個或多個陳述式組成的代碼單元。它也被稱為區塊。它允許將一組陳述式視為單個實體。
**控制陳述式**：**控制陳述式**是程序化語言中的一個程式，是一組陳述式。控制陳述式通常一個接一個地執行。然而，有時需要改變這種順序。
- **選擇 (Selection)**：透過 *if-else* 陳述式實現雙向選擇，透過 *switch*（或 *case*）陳述式實現多向選擇。
- **重複 (Repetition)**：大多數指令式語言定義了像 *while*、*do-while* 和 *for* 這樣的迴圈。

### 9.4.9 副程式 (Subprograms)
**副程式**的概念在程序化語言中至關重要。副程式是一個可以編寫一次但多次呼叫的程式單元。副程式使程式設計更具結構性。
**區域變數**：區域物件或**區域變數**在每次呼叫副程式時創建，並在控制權從副程式回傳時銷毀。
**參數**：副程式作用於物件。這些在主程式中稱為**實際參數**，在副程式中稱為**形式參數**。
- **傳值 (Pass by value)**：主程式將實際參數的值發送給副程式。副程式接收副本。它不能更改主程式中的原始變數。
- **傳參考 (Pass by reference)**：變數由主程式和副程式共享。副程式可以更改主程式中變數的值。
**回傳值**：副程式可以設計為回傳一個或多個值。
**實作**：在 C 和 C++ 中，副程式實作為函式。

## 9.5 章末材料
### 9.5.1 推薦閱讀
- Cooke, D. A. *Concise Introduction to Computer Languages*, Pacific Grove, CA: Brooks/Cole, 2003
- Tucker, A. and Noonan, R. *Programming Languages: Principles and Paradigms*, Burr Ridge, IL: McGraw-Hill, 2002
- Pratt, T. and Zelkowitz, M. *Programming Languages, Design and Implementation*, Englewood Cliffs, NJ: Prentice-Hall, 2001
- Sebesta, R. *Concepts of Programming Languages*, Boston, MA: Addison-Wesley, 2006

### 9.5.2 關鍵詞
- 實際參數 (actual parameter)
- Ada
- 小程式 (applet)
- 算術運算子 (arithmetic operator)
- 組譯器 (assembler)
- 組合語言 (assembly language)
- 賦值陳述式 (assignment statement)
- 位元組碼 (bytecode)
- C++ 語言 (C++ language)
- C 語言 (C language)
- 類別 (class)
- 代碼生成器 (code generator)
- 通用商業導向語言 (COBOL)
- 編譯 (compilation)
- 編譯器 (compiler)
- 複合型別 (composite type)
- 複合陳述式 (compound statement)
- 電腦語言 (computer language)
- 常數 (constant)
- 控制陳述式 (control statement)
- 資料型別 (data type)
- 宣告式語言 (declarative language)
- 宣告式範式 (declarative paradigm)
- 表達式 (expression)
- 形式參數 (formal parameter)
- 公式翻譯 (FORTRAN)
- 函數式語言 (functional language)
- 函數式範式 (functional paradigm)
- 高階語言 (high-level language)
- 識別碼 (identifier)
- 指令式語言 (imperative language)
- 指令式範式 (imperative paradigm)
- 繼承 (inheritance)
- 輸入 (input)
- 直譯 (interpretation)
- 直譯器 (interpreter)
- Java
- 詞彙分析器 (lexical analyzer)
- 列表程式設計語言 (LISP)
- 字面值 (literal)
- 區域變數 (local variable)
- 邏輯運算子 (logical operator)
- 機器語言 (machine language)
- 方法 (method)
- 多執行緒 (multithreading)
- 物件導向語言 (object-oriented language)
- 物件導向範式 (object-oriented paradigm)
- 目的程式 (object program)
- 運算元 (operand)
- 運算子 (operator)
- 輸出 (output)
- 參數 (parameter)
- Pascal
- 傳參考 (pass by reference)
- 傳值 (pass by value)
- 多型 (polymorphism)
- 程序化範式 (procedural paradigm)
- 邏輯程式設計 (PROLOG)
- 程式語言 (programming language)
- 關係運算子 (relational operator)
- Scheme
- 語意分析器 (semantic analyzer)
- 簡單型別 (simple type)
- 原始程式 (source program)
- 陳述式 (statement)
- 副程式 (subprogram)
- 符號語言 (symbolic language)
- 語法 (syntax)
- 語法分析器 (syntax analyzer)
- 符記 (token)
- 翻譯器 (translator)
- 變數 (variable)

### 9.5.3 摘要
- 電腦語言是一組預先定義的詞彙，根據預先定義的規則（語法）組合成程式。
- 高階語言可移植到許多不同的電腦上。
- 要在電腦上運行程式，需要將其翻譯成機器語言。編譯翻譯整個原始程式；直譯逐行翻譯。
- 四種範式：程序化、物件導向、函數式和宣告式。
- 共同概念：識別碼、資料型別、變數、字面值、常數、輸入/輸出、表達式、陳述式和副程式。
`},d={en:`
# Chapter 10: Software Engineering

In this chapter we introduce the concept of software engineering. We begin with the idea of the software lifecycle. We then show two models used for the development process: the waterfall model and the incremental model. A brief discussion of four phases in the development process follows.

## Objectives
After studying this chapter, the student should be able to:
- Understand the concept of the software lifecycle in software engineering.
- Describe two major types of development process, the waterfall and incremental models.
- Understand the analysis phase and describe two separate approaches in the analysis phase: procedure-oriented analysis and object-oriented analysis.
- Understand the design phase and describe two separate approaches in the design phase: procedure-oriented design and object-oriented design.
- Describe the implementation phase and recognize the quality issues in this phase.
- Describe the testing phase and distinguish between glass-box testing and black-box testing.
- Recognize the importance of documentation in software engineering and distinguish between user documentation, system documentation, and technical documentation.

**Software engineering** is the establishment and use of sound engineering methods and principles to obtain reliable software. This definition, taken from the first international conference on software engineering in 1969, was proposed 30 years after the first computer was built.

## 10.1 THE SOFTWARE LIFECYCLE
A fundamental concept in **software engineering** is the **software lifecycle**. Software, like many other products, goes through a cycle of repeating phases (Figure 10.1).

Software is first developed by a group of developers. Usually it is in use for a while before modifications are necessary. Modification is often needed due to errors found in the software, changes in the rules or laws governing its design, or changes in the company itself. The software therefore needs to be modified before further use. These two steps, use and modify, continue until the software becomes obsolete. By ‘obsolete’, we mean that the software loses its validity because of inefficiency, obsolescence of the language, major changes in user requirements, or other factors.

### 10.1.1 Development process models
Although software engineering involves all three processes (development, use, modification), in this chapter we discuss only the **development process**. The development process in the software lifecycle involves four phases: *analysis*, *design*, *implementation*, and *testing*. There are several models for the development process. We discuss the two most common here: the waterfall model and the incremental model.

**The waterfall model**
One very popular model for the software development process is known as the **waterfall model** (Figure 10.2). In this model, the development process flows in only one direction. This means that a phase cannot be started until the previous phase is completed.

For example, the analysis phase of the whole project should be completed before its design phase is started. The entire design phase should be finished before the implementation phase can be started.
There are advantages and disadvantages to the waterfall model. One advantage is that each phase is completed before the next phase starts. The group that works on the design phase, for example, knows exactly what to do because they have the complete results of the analysis phase. The testing phase can test the whole system because the entire system under development is ready. However, a disadvantage of the waterfall model is the difficulty in locating a problem: if there is a problem in part of the process, the entire process must be checked.

**The incremental model**
In the **incremental model**, software is developed in a series of steps. The developers first complete a simplified version of the whole system. This version represents the entire system but does not include the details. Figure 10.3 shows the incremental model concept.

In the second version, more details are added, while some are left unfinished, and the system is tested again. If there is a problem, the developers know that the problem is with the new functionality. They do not add more functionality until the existing system works properly. This process continues until all required functionality has been added.

## 10.2 ANALYSIS PHASE
The development process starts with the **analysis phase**. This phase results in a specification document that shows *what* the software will do without specifying *how* it will be done. The analysis phase can use two separate approaches, depending on whether the implementation phase is done using a procedural programming language or an object-oriented language. We briefly discuss both in this section.

### 10.2.1 Procedure-oriented analysis
**Procedure-oriented analysis**—also called *structured analysis* or *classical analysis*—is the analysis process used if the system implementation phase will use a procedural language. The specification in this case may use several modeling tools, but we discuss only a few of them here.

**Data flow diagrams**
**Data flow diagrams** show the movement of data in the system. They use four symbols: a square box shows the source or destination of data, a rectangle with rounded corners shows the process (the action to be performed on the data), an open-ended rectangle shows where data is stored, and arrows show the flow of data.
Figure 10.4 shows a simplified version of a booking system in a small hotel that accepts reservations from potential guests through the Internet and confirms or rejects the reservation based on available vacancies. One of the processes in this diagram (handle reservation) checks the availability using the reservation file and accepts or rejects a reservation. If the reservation is accepted, it will be recorded in the reservation file.

**Entity–relationship diagrams**
Another modeling tool used during the analysis phase is the **entity–relationship diagram**. Since this diagram is also used in database design, we discuss it in Chapter 14.

**State diagrams**
**State diagrams** (see Appendix B) provide another useful tool that is normally used when the state of the entity in the system will change in response to events. As an example of a state diagram, we show the operation of a one-passenger elevator. When a floor button is pushed, the elevator moves in the requested direction. It does not respond to any other request until it reach its destination.
Figure 10.5 shows a state diagram for this old-style elevator. The elevator can be in one of three states: moving up, moving down, or parked. Each of these states is represented by a rounded rectangle in the state diagram. When the elevator is in the parked state, it accepts a request. If the requested floor is the same as the current floor, the request is ignored—the elevator remains in the parked state. If the requested floor is above the current floor, the elevator starts moving up. If the requested floor is lower than the requested floor, the elevator starts moving down. Once moving, the elevator remains in one moving state until it reaches the requested floor.

### 10.2.2 Object-oriented analysis
**Object-oriented analysis** is the analysis process used if the implementation uses an object-oriented language. The specification document in this case may use several tools, but we discuss only a few of them here.

**Use-case diagrams**
A **use-case diagram** gives the user’s view of a system: it shows how the user communicates with the system. A use-case diagram uses four components: system, use cases, actors, and relationships. A system, shown by a rectangle, performs a function. The actions in the system are shown by use cases, which are denoted by rounded rectangles. An actor is someone or something that uses the system. Although actors are represented by stick figures, they do not necessarily represent human beings.
Figure 10.6 shows the use-case diagram for the old-style elevator for which we gave a state diagram in Figure 10.5. The system in this figure is the elevator. The only actor is the user of the elevator. There are two uses cases: pressing the elevator button (in the hall of each floor) and pressing the floor button inside the elevator. The elevator has only one button on each floor that gives the signal to the elevator to move to that floor.

**Class diagrams**
The next step in analysis is to create a **class diagram** for the system. For example, we can create a class diagram for our old-style elevator. To do so, we need to think about the entities involved in the system. In the elevator system we have two classes of entities: the buttons and the elevator itself. At first glance, therefore, it looks as if we have two classes: a button class and an elevator class. However, we have two types of buttons: the elevator buttons in the hallways and the floor buttons inside the elevator. It seems then that we can have a button class and two classes that inherit from the button class: an elevator button class and a floor button class. The first class diagram that we can create for the elevator problem is therefore that shown in Figure 10.7.
Note that the elevator button class and the floor button class are subclasses of the button class. However, the relationship between the elevator class and the two button classes (elevator button and floor button) is a one-to-many relation (see Appendix B). The class diagram for the elevator system can of course be extended, but we leave this to books on software engineering.

**State chart**
After the class diagram is finalized, a **state chart** can be prepared for each class in the class diagram. A state chart in object-oriented analysis plays the same role as the state diagram in procedure-oriented analysis. This means that for the class diagram of Figure 10.7, we need to have a four-state chart.

## 10.3 DESIGN PHASE
The **design phase** defines *how* the system will accomplish *what* was defined in the analysis phase. In the design phase, all components of the system are defined.

### 10.3.1 Procedure-oriented design
In **procedure-oriented design** we have both procedures and data to design. We discuss a category of design methods that concentrate on procedures. In procedure-oriented design, the whole system is divided into a set of procedure or modules.

**Structure charts**
A common tool for illustrating the relations between modules in procedure-oriented design is a **structure chart**. For example, the elevator system whose state diagram is shown in Figure 10.5 can be designed as a set of modules shown in the structure chart in Figure 10.8. Structure charts are discussed in Appendix D.

**Modularity**
**Modularity** means breaking a large project into smaller parts that can be understood and handled easily. In other words, modularity means dividing a large task into small tasks that can communicate with each other. The structure chart discussed in the previous section shows the modularity in the elevator system. There are two main concerns when a system is divided into modules: *coupling* and *cohesion*.

**Coupling**
**Coupling** is a measure of how tightly two modules are bound to each other. The more tightly coupled, the less independent they are. Since the objective is to make modules as independent as possible, we want them to be loosely coupled. There are at least three reasons why loose coupling is desirable.
- Loosely coupled modules are more likely to be reusable.
- Loosely coupled modules are less likely to create errors in related modules.
- When the system needs to be modified, loosely coupled modules allow us to modify only modules that need to be changed without affecting modules that do not need to change.

**Coupling between modules in a software system must be minimized.**

**Cohesion**
Another issue in modularity is cohesion. **Cohesion** is a measure of how closely the modules in a system are related. We need to have maximum possible cohesion between modules in a software system.

**Cohesion between modules in a software system must be maximized.**

### 10.3.2 Object-oriented design
In **object-oriented design**, the design phase continues by elaborating the details of classes. As we mentioned in Chapter 9, a class is made of a set of variables (attributes) and a set of methods (functions). The object-oriented design lists the details of these **attributes** and **methods**. Figure 10.9 shows an example of the details of our four classes used in the design of the old-style elevator.

## 10.4 IMPLEMENTATION PHASE
In the waterfall model, after the design phase is completed, the **implementation phase** can start. In this phase the programmers write the code for the modules in procedure-oriented design, or write the program units to implement classes in object-oriented design. There are several issues to mention in each case.

### 10.4.1 Choice of language
In a procedure-oriented development, the project team needs to choose a language or a set of languages from among the procedural languages discussed in Chapter 9. Although some languages like C++ are considered to be both a procedure—and an object-oriented language—normally an implementation uses a purely procedural language such as C. In object-oriented cases, both C++ and Java are common.

### 10.4.2 Software quality
The quality of software created at the implementation phase is a very important issue. A software system of high quality is one that satisfies the user’s requirements, meets the operating standards of the organization, and runs efficiently on the hardware for which it was developed. However, if we want to achieve a software system of high quality, we must be able to define some attributes of quality.

**Software quality factors**
**Software quality** can be divided into three broad measures: *operability*, *maintainability*, and *transferability*. Each of these measures can be further broken down as shown in Figure 10.10.

**Operability**
**Operability** refers to the basic operation of a system. Several measures can be mentioned for operability, as shown in Figure 10.10: *accuracy, efficiency, reliability, security, timeliness,* and *usability*.
- A system that is not *accurate* is worse than no system at all. Any system that is developed, therefore, must be thoroughly tested both by a system’s test engineer and the user. *Accuracy* can be measured by such metrics as mean time between failures, number of bugs per thousand lines of code, and number of user requests for change.
- *Efficiency* is a subjective term. In some cases, the user will specify a performance standard, such as a real-time response that must be received within 1 second 95 per cent of the time. This is certainly measurable.
- *Reliability* is really the sum of the other factors. If users count on the system to get their job done and are confident in it, then it is most likely reliable. On the other hand, some measures speak directly to a system’s reliability, most notably, mean time between failures.
- How *secure* a system is refers to how easy it is for unauthorized people to access the system’s data. Although this is a subjective area, there are checklists that assist in assessing the system’s security. For example, does the system have and require passwords to identify users?
- *Timeliness* in software engineering can mean several different things. Does the system deliver its output in a timely fashion? For online systems, does the response time satisfy the users’ requirements?
- *Usability* is another area that is highly subjective. The best measure of usability is to watch the users and see how they are using the system. User interviews will often reveal problems with the usability of a system.

**Maintainability**
**Maintainability** refers to the ease with which a system can be kept up to date and running correctly. Many systems require regular changes, not because they were poorly implemented, but because of changes in external factors. For example, the payroll system for a company might have to be changed often to meet changes in government laws and regulations.
- *Changeability* is a subjective factor. Experienced project leaders, however, are able to estimate how long a requested change will take to implement. If too long, it may indicate that the system is difficult to change. This is especially true of older systems. There are software measurement tools in the field today that will estimate a program’s complexity and structure.
- One measure of *correctability* is *mean time to recovery*, which is the time it takes to get a program back into operation after it fails. Although this is a reactive definition, there are currently no predictors of how long it will take to correct a program when it fails.
- Users are constantly requesting changes to systems. *Flexibility* is a qualitative attribute that attempts to measure how easy it is to make these changes. If a program needs to be completely rewritten to effect a change, it is not flexible.
- We might think that *testability* is a highly subjective area, but test engineers have checklists of factors that can assess a program’s testability.

**Transferability**
**Transferability** refers to the ability to move data and/or a system from one platform to another and to reuse code. In many situations this is not an important factor. On the other hand, if we are writing generalized software, it can be critical.
- If modules are written so that they can be reused in other systems, then they have high levels of *reusability*. Good programmers build libraries of functions that they can reuse for solving similar problems.
- *Interoperability* is the capability of sending data to other systems. In today’s highly integrated systems, it is a desirable attribute. In fact, it has become so important that operating systems now support the ability to move data between systems, such as between a word processor and a spreadsheet.
- *Portability* is the ability to move software from one hardware platform to another.

## 10.5 TESTING PHASE
The goal of the **testing phase** is to find errors, which means that a good testing strategy is the one that finds most errors. There are two types of testing: *glass-box* and *black-box* (Figure 10.11).

### 10.5.1 Glass-box testing
**Glass-box testing** (or **white-box testing**) is based on knowing the internal structure of the software. The testing goal is to check to determine whether all components of the software do what they are designed to do. Glass-box testing assumes that the tester knows everything about the software. In this case, the software is like a glass box in which everything inside the box is visible. Glass-box testing is done by the software engineer or a dedicated team. Glass-box testing that uses the structure of the software is required to guarantee that at least the following four criteria are met:
- All independent paths in every module are tested at least once.
- All the decision constructs (two-way and multiway) are tested on each branch.
- Each loop construct is tested.
- All data structures are tested.
Several testing methodologies have been designed in the past. We briefly discuss two of them: *basis path* testing and *control structure* testing.

**Basis path testing**
**Basis path testing** was proposed by Tom McCabe. This method creates a set of test cases that executes *every statement* in the software at least once.

**Basis path testing is a method in which each statement in the software is executed at least once.**

Basis path testing uses *graph theory* (see Chapter 12) and *cyclomatic complexity* to find the independent paths that must be followed to guarantee that each statement is executed at least once.

**Control structure testing**
**Control structure testing** is more comprehensive than basis path testing and includes it. This method uses different categories of test that are briefly described below.
- **Condition testing**: Condition testing applies to any condition expression in the module. A *simple condition* is a relational expression, while a *compound condition* is a combination of simple conditions and logical operators (see Chapter 9). Condition testing is designed to check whether all conditions are set correctly.
- **Data flow testing**: Data flow testing is based on the flow of data through the module. This type of testing selects test cases that involve checking the value of variables when they are used on the left side of the assignment statement.
- **Loop testing**: Loop testing uses test cases to check the validity of loops. All types of loops (*while*, *do*, and *for*) are carefully tested.

### 10.5.2 Black-box testing
**Black-box testing** gets its name from the concept of testing software without knowing what is inside it and without knowing how it works. In other words, the software is like a black box into which the tester cannot see. Black-box testing tests the functionality of the software in terms of what the software is supposed to accomplish, such as its inputs and outputs. Several methods are used in black-box testing, discussed below.

**Exhaustive testing**
The best black-box test method is to test the software for all possible values in the input domain. However, in complex software the input domain is so huge that it is often impractical to do so.

**Random testing**
In random testing, a subset of values in the input domain is selected for testing. It is very important that the subset be chosen in such a way that the values are distributed over the domain input. The use of random number generators can be very helpful in this case.

**Boundary-value testing**
Errors often happen when boundary values are encountered. For example, if a module defines that one of its inputs must be greater than or equal to 100, it is very important that module be tested for the boundary value 100. If the module fails at this boundary value, it is possible that some condition in the module’s code such as x > 100 is written as x >= 100.

## 10.6 DOCUMENTATION
For software to be used properly and maintained efficiently, documentation is needed. Usually, three separate sets of documentation are prepared for software: user documentation, system documentation, and technical documentation. However, note that documentation is an ongoing process. If the software has problems after release, they must be documented too. If the software is modified, all modifications and their relationship to the original package must also be documented. Documentation only stops when the package becomes obsolete.

**Documentation is an ongoing process.**

### 10.6.1 User documentation
To run the software system properly, the users need documentation, traditionally called a *user guide*, that shows how to use the software step by step. User guides usually contain a tutorial section to guide the user through each feature of the software.
A good user guide can be a very powerful marketing tool: the importance of user documentation in marketing cannot be overemphasized. User guides should be written for both the novice and the expert users, and a software system with good user documentation will definitely increase sales.

### 10.6.2 System documentation
**System documentation** defines the software itself. It should be written so that the software can be maintained and modified by people other than the original developers. System documentation should exist for all four phases of system development.
In the analysis phase, the information collected should be carefully documented. In addition, the analysts should define the sources of information. The requirements and methods chosen in this phase must be clearly stated with the rationale behind them.
In the design phase, the tools used in the final copy must be documented. For example, if a chart undergoes several changes, the final copy of the chart should be documented with complete explanations.
In the implementation phase, every module of the code should be documented. In addition, the code should be self-documenting as far as possible using comments and descriptive headers.
Finally, the developers must carefully document the testing phase. Each type of test applied to the final product should be mentioned along with its result. Even unfavorable results and the data that produced them must be documented.

### 10.6.3 Technical documentation
**Technical documentation** describe the installation and the servicing of the software system. Installation documentation defines how the software should be installed on each computer, for example, servers and clients. Service documentation defines how the system should be maintained and updated if necessary.

## 10.7 END-CHAPTER MATERIALS
### 10.7.1 Recommended reading
- Braude, E. *Software Engineering – An Object-Oriented Perspective*, New York: Wiley, 2001
- Gustafson, D. *Software Engineering*, New York: McGraw-Hill, 2002
- Lethbridge, T. and Laganiere, R. *Object-Oriented Software Engineering*, New York: McGraw-Hill, 2005
- Pressman, R. *Software Engineering: A Practitioner’s Approach*, New York: McGraw-Hill, 2005
- Schach, S. *Object-Oriented and Classical Software Engineering*, New York: McGraw-Hill, 2007

### 10.7.2 Key terms
- analysis phase
- attribute
- basis path testing
- black-box testing
- class diagram
- cohesion
- control structure testing
- coupling
- data flow diagram
- design phase
- development process
- entity–relationship diagram
- glass-box testing
- implementation phase
- incremental model
- maintainability
- modularity
- object-oriented analysis
- object-oriented design
- operability
- procedure-oriented analysis
- procedure-oriented design
- software engineering
- software lifecycle
- software quality
- state chart
- state diagram
- structure chart
- technical documentation
- testability
- testing phase
- transferability
- use-case diagram
- waterfall model
- white-box testing

### 10.7.3 Summary
- The software lifecycle is a fundamental concept in software engineering. Software, like many other products, goes through a cycle of repeating phases.
- The development process in the software lifecycle involves four phases: analysis, design, implementation, and testing. Several models have been used in relation to these phases. We discussed the two most common: the waterfall model and the incremental model.
- The development process starts with the analysis phase. The analyst prepares a specification document that shows what the software will do without specifying how it will be done. The analysis phase can be done in two ways: procedure-oriented analysis and object-oriented analysis.
- The design phase defines how the system will accomplish what was defined in the analysis phase. In procedure-oriented design, the whole project is divided into a set of procedure or modules. In object-oriented design, the design phase continues by elaborating the details of classes.
- Modularity means breaking a large project into smaller parts that can be understood and handled easily. Two issues are important when a system is divided into modules: coupling and cohesion. Coupling is a measure of how tightly two modules are bound to each other. Coupling between modules in a software system must be minimized. Cohesion is a measure of how closely the modules in a system are related. Cohesion between modules in a software system should be maximized.
- In the implementation phase, programmers write the code for the modules in procedure-oriented design, or write the program units to implement classes in the object-oriented design.
- The quality of software is important. Software quality can be divided into three broad measures: operability, maintainability, and transferability.
- The goal of the testing phase is to find errors. There are two types of testing: glass-box and black-box. Glass-box testing (or white-box testing) is based on knowing the internal structure of the software. Glass-box testing assumes that the tester knows everything. Black-box testing means testing the software without knowing what is inside it and without knowing how it works.

## 10.8 PRACTICE SET
### 10.8.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 10.8.2 Review questions
1. Define ‘software lifecycle’.
2. Distinguish between the waterfall model and the incremental development models.
3. List the four phases in the development process.
4. Define the purpose of the analysis phase and describe two trends in this phase.
5. Define the purpose of the design phase and describe two trends in this phase.
6. Describe modularity and mention two issues related to modularity.
7. Distinguish between coupling and cohesion.
8. Define the purpose of the implementation phase and describe the issue of quality in this phase.
9. Define the purpose of the testing phase and list two categories of testing.
10. Distinguish between glass-box testing and black-box testing.

### 10.8.3 Problems
1. In Chapter 9 we explained that the use of constant values are preferred to literals. What it the effect of this preference on the software lifecycle?
2. In Chapter 9 we showed that communication between two modules can take place either by pass-by-value or pass-by-reference. Which method provides less coupling between the two modules?
3. In Chapter 9 we showed that communication between two modules can take place either by pass-by-value or pass-by-reference. Which method provides more cohesion between the two modules?
4. Draw a use-case diagram for a simple library.
5. Draw a use-case diagram for a small grocery store.
6. Show the data flow diagram for a simple mathematical formula $x + y$.
7. Show the data flow diagram for a simple mathematical formula $x \\times y + z \\times t$.
8. Show the data flow diagram for a library.
9. Show the data flow diagram for a small groceries store.
10. Create a structure chart for Problem P10-8.
11. Create a structure chart for Problem P10-9.
12. Show a state diagram for a stack of fixed capacity (see Chapter 12).
13. Show a state diagram for a queue of fixed capacity (see Chapter 12).
14. Create a class diagram for a library.
15. Create a class diagram for a small grocery store.
16. Show the details of classes in Problem P10-14.
17. Show the details of classes in Problem P10-15.
18. The input data to a program is made up of a combination of three integers in the range 1000 to 1999 (inclusive). Find the number of exhaustive tests to test all combinations of these numbers.
19. List the boundary-value tests required for the Problem P10-18.
20. A random number generator creates a number between 0 and 0.999. How can this random number generator be used to do random testing for the system described in Problem P10-18.
`,zh:`
# 第十章：軟體工程

在本章中，我們介紹軟體工程的概念。我們從軟體生命週期的概念開始。然後，我們展示了用於開發過程的兩種模型：瀑布模型和增量模型。接下來簡要討論開發過程中的四個階段。

## 學習目標
學完本章後，學生應能：
- 理解軟體工程中軟體生命週期的概念。
- 描述兩種主要的開發過程模型：瀑布模型和增量模型。
- 理解分析階段並描述分析階段的兩種不同方法：程序導向分析和物件導向分析。
- 理解設計階段並描述設計階段的兩種不同方法：程序導向設計和物件導向設計。
- 描述實作階段並認識此階段的品質問題。
- 描述測試階段並區分玻璃箱測試和黑箱測試。
- 認識到文件在軟體工程中的重要性，並區分使用者文件、系統文件和技術文件。

**軟體工程**是建立和使用完善的工程方法和原則以獲得可靠軟體的過程。這個定義取自 1969 年的第一屆軟體工程國際會議，是在第一台電腦建成 30 年後提出的。

## 10.1 軟體生命週期
**軟體工程**中的一個基本概念是**軟體生命週期**。軟體和許多其他產品一樣，會經歷一個重複階段的循環（圖 10.1）。

軟體首先由一組開發人員開發。通常在使用一段時間後才需要修改。修改通常是因為發現軟體中的錯誤、管理其設計的規則或法律發生變化，或公司本身發生變化。因此，軟體在進一步使用之前需要進行修改。這兩個步驟，使用和修改，持續進行，直到軟體過時。所謂「過時」，是指軟體因效率低下、語言過時、使用者需求發生重大變化或其他因素而失去有效性。

### 10.1.1 開發過程模型
雖然軟體工程涉及所有三個過程（開發、使用、修改），但在本章中我們僅討論**開發過程**。軟體生命週期中的開發過程涉及四個階段：*分析*、*設計*、*實作*和*測試*。開發過程有幾種模型。我們在此討論最常見的兩種：瀑布模型和增量模型。

**瀑布模型**
軟體開發過程的一個非常流行的模型稱為**瀑布模型**（圖 10.2）。在這個模型中，開發過程只朝一個方向流動。這意味著一個階段必須在前一個階段完成後才能開始。

例如，整個專案的分析階段應在設計階段開始之前完成。整個設計階段應在實作階段開始之前完成。
瀑布模型有優點也有缺點。一個優點是每個階段都在下一個階段開始之前完成。例如，負責設計階段的小組確切知道該做什麼，因為他們有分析階段的完整結果。測試階段可以測試整個系統，因為開發中的整個系統都已準備就緒。然而，瀑布模型的一個缺點是難以定位問題：如果在過程的一部分出現問題，則必須檢查整個過程。

**增量模型**
在**增量模型**中，軟體分一系列步驟開發。開發人員首先完成整個系統的簡化版本。此版本代表整個系統但不包括細節。圖 10.3 顯示了增量模型的概念。

在第二個版本中，添加了更多細節，同時有些仍未完成，並再次測試系統。如果有問題，開發人員知道問題出在新功能上。在現有系統正常運作之前，他們不會添加更多功能。此過程持續進行，直到添加了所有所需功能。

## 10.2 分析階段
開發過程始於**分析階段**。此階段產生一份規格文件，說明軟體將做*什麼*，但不指定*如何*做。分析階段可以使用兩種不同的方法，具體取決於實作階段是使用程序化程式語言還是物件導向語言。我們在本節簡要討論兩者。

### 10.2.1 程序導向分析
**程序導向分析**——也稱為*結構化分析*或*古典分析*——是如果系統實作階段將使用程序化語言時使用的分析過程。在這種情況下的規格可能使用多種建模工具，但我們在此僅討論其中幾種。

**資料流程圖**
**資料流程圖**顯示系統中資料的移動。它們使用四種符號：方框顯示資料的來源或目的地，圓角矩形顯示處理過程（對資料執行的動作），開口矩形顯示資料儲存的位置，箭頭顯示資料流向。
圖 10.4 顯示了一家小型旅館的預訂系統的簡化版本，該系統透過網際網路接受潛在客人的預訂，並根據可用空房確認或拒絕預訂。此圖中的一個過程（處理預訂）使用預訂檔案檢查可用性並接受或拒絕預訂。如果接受預訂，則將其記錄在預訂檔案中。

**實體關係圖**
分析階段使用的另一種建模工具是**實體關係圖**。由於此圖也用於資料庫設計，我們將在第 14 章討論它。

**狀態圖**
**狀態圖**（見附錄 B）提供了另一個有用的工具，通常用於系統中實體的狀態會因應事件而發生變化的情況。作為狀態圖的一個例子，我們展示了一部單人電梯的操作。當按下樓層按鈕時，電梯向請求的方向移動。在到達目的地之前，它不會回應任何其他請求。
圖 10.5 顯示了這部舊式電梯的狀態圖。電梯可以處於三種狀態之一：向上移動、向下移動或停泊。這些狀態中的每一個都在狀態圖中由圓角矩形表示。當電梯處於停泊狀態時，它接受請求。如果請求的樓層與當前樓層相同，則忽略該請求——電梯保持停泊狀態。如果請求的樓層高於當前樓層，電梯開始向上移動。如果請求的樓層低於請求的樓層，電梯開始向下移動。一旦移動，電梯保持在一種移動狀態，直到到達請求的樓層。

### 10.2.2 物件導向分析
**物件導向分析**是如果實作使用物件導向語言時使用的分析過程。在這種情況下的規格文件可能使用多種工具，但我們在此僅討論其中幾種。

**使用案例圖**
**使用案例圖**給出了系統的使用者視圖：它顯示了使用者如何與系統通訊。使用案例圖使用四個組件：系統、使用案例、參與者和關係。系統由矩形顯示，執行功能。系統中的動作由使用案例顯示，用圓角矩形表示。參與者是使用系統的人或事物。雖然參與者由火柴人表示，但它們不一定代表人類。
圖 10.6 顯示了我們在圖 10.5 中給出狀態圖的舊式電梯的使用案例圖。圖中的系統是電梯。唯一的參與者是電梯的使用者。有兩個使用案例：按下電梯按鈕（在每層樓的大廳）和按下電梯內的樓層按鈕。電梯在每層樓只有一個按鈕，向電梯發出信號以移動到該層。

**類別圖**
分析的下一步是為系統創建**類別圖**。例如，我們可以為我們的舊式電梯創建一個類別圖。為此，我們需要考慮系統中涉及的實體。在電梯系統中，我們有兩類實體：按鈕和電梯本身。因此，乍看之下，我們似乎有兩個類別：按鈕類別和電梯類別。然而，我們有兩種類型的按鈕：大廳裡的電梯按鈕和電梯內的樓層按鈕。那麼看來我們可以有一個按鈕類別和兩個繼承自按鈕類別的類別：電梯按鈕類別和樓層按鈕類別。因此，我們可以為電梯問題創建的第一個類別圖如圖 10.7 所示。
請注意，電梯按鈕類別和樓層按鈕類別是按鈕類別的子類別。然而，電梯類別與兩個按鈕類別（電梯按鈕和樓層按鈕）之間的關係是一對多關係（見附錄 B）。電梯系統的類別圖當然可以擴展，但我們將此留給軟體工程書籍。

**狀態圖 (State chart)**
類別圖定稿後，可以為類別圖中的每個類別準備一個**狀態圖**。物件導向分析中的狀態圖與程序導向分析中的狀態圖扮演相同的角色。這意味著對於圖 10.7 的類別圖，我們需要有一個四狀態圖。

## 10.3 設計階段
**設計階段**定義系統將*如何*完成在分析階段定義的*內容*。在設計階段，定義系統的所有組件。

### 10.3.1 程序導向設計
在**程序導向設計**中，我們既有程序又有資料要設計。我們討論一類專注於程序的設計方法。在程序導向設計中，整個系統被劃分為一組程序或模組。

**結構圖**
在程序導向設計中說明模組之間關係的常用工具是**結構圖**。例如，圖 10.5 中顯示其狀態圖的電梯系統可以設計為圖 10.8 中的結構圖所示的一組模組。結構圖在附錄 D 中討論。

**模組化**
**模組化**意味著將大型專案分解為易於理解和處理的較小部分。換句話說，模組化意味著將大任務劃分為可以相互通訊的小任務。上一節討論的結構圖顯示了電梯系統中的模組化。當系統被劃分為模組時，主要關注兩個問題：*耦合*和*內聚*。

**耦合 (Coupling)**
**耦合**是衡量兩個模組彼此綁定緊密程度的指標。耦合越緊密，它們就越不獨立。由於目標是使模組盡可能獨立，我們希望它們鬆散耦合。鬆散耦合是可取的，至少有三個原因。
- 鬆散耦合的模組更有可能被重複使用。
- 鬆散耦合的模組不太可能在相關模組中產生錯誤。
- 當系統需要修改時，鬆散耦合的模組允許我們僅修改需要更改的模組，而不影響不需要更改的模組。

**軟體系統中模組之間的耦合必須最小化。**

**內聚 (Cohesion)**
模組化的另一個問題是內聚。**內聚**是衡量系統中模組相關程度的指標。我們需要在軟體系統的模組之間擁有最大可能的內聚。

**軟體系統中模組之間的內聚必須最大化。**

### 10.3.2 物件導向設計
在**物件導向設計**中，設計階段透過詳細闡述類別的細節繼續進行。正如我們在第 9 章提到的，類別由一組變數（屬性）和一組方法（函式）組成。物件導向設計列出了這些**屬性**和**方法**的細節。圖 10.9 顯示了我們用於設計舊式電梯的四個類別的細節範例。

## 10.4 實作階段
在瀑布模型中，設計階段完成後，**實作階段**即可開始。在此階段，程式設計師為程序導向設計中的模組編寫程式碼，或編寫程式單元以實作物件導向設計中的類別。每種情況都有幾個問題要提及。

### 10.4.1 語言的選擇
在程序導向開發中，專案團隊需要從第 9 章討論的程序化語言中選擇一種或一組語言。雖然像 C++ 這樣的語言被認為既是程序化語言又是物件導向語言，但實作通常使用純程序化語言，如 C。在物件導向的情況下，C++ 和 Java 都很常見。

### 10.4.2 軟體品質
在實作階段創建的軟體品質是一個非常重要的問題。高品質的軟體系統是滿足使用者需求、符合組織營運標準並在為其開發的硬體上有效運行的系統。然而，如果我們想要獲得高品質的軟體系統，我們必須能夠定義一些品質屬性。

**軟體品質因素**
**軟體品質**可以分為三大類指標：*可操作性*、*可維護性*和*可轉移性*。這些指標中的每一個都可以進一步細分，如圖 10.10 所示。

**可操作性 (Operability)**
**可操作性**是指系統的基本操作。可以提到幾個可操作性的指標，如圖 10.10 所示：*準確性、效率、可靠性、安全性、及時性*和*可用性*。
- 不*準確*的系統比沒有系統更糟糕。因此，開發的任何系統都必須經過系統測試工程師和使用者的徹底測試。*準確性*可以透過平均故障間隔時間、每千行代碼的錯誤數和使用者請求更改的次數等指標來衡量。
- *效率*是一個主觀術語。在某些情況下，使用者會指定效能標準，例如必須在 95% 的時間內在 1 秒內收到即時回應。這當然是可以衡量的。
- *可靠性*實際上是其他因素的總和。如果使用者指望系統完成工作並對其充滿信心，那麼它很可能是可靠的。另一方面，一些指標直接說明了系統的可靠性，最顯著的是平均故障間隔時間。
- 系統的*安全性*是指未經授權的人員存取系統資料的難易程度。雖然這是一個主觀領域，但有一些清單可以協助評估系統的安全性。例如，系統是否擁有並要求密碼來識別使用者？
- 軟體工程中的*及時性*可以意味著幾件不同的事情。系統是否及時交付輸出？對於線上系統，回應時間是否滿足使用者的需求？
- *可用性*是另一個高度主觀的領域。可用性的最佳衡量標準是觀察使用者並看他們如何使用系統。使用者訪談通常會揭示系統可用性的問題。

**可維護性 (Maintainability)**
**可維護性**是指系統保持更新和正確運行的難易程度。許多系統需要定期更改，不是因為它們實作不佳，而是因為外部因素的變化。例如，公司的薪資系統可能需要經常更改以滿足政府法律法規的變化。
- *可變更性*是一個主觀因素。然而，經驗豐富的專案負責人能夠估計實作請求的變更需要多長時間。如果太長，可能表示系統難以更改。對於舊系統尤其如此。目前領域中有軟體測量工具可以估計程式的複雜性和結構。
- *可修正性*的一個衡量標準是*平均恢復時間*，即程式在失敗後恢復運作所需的時間。雖然這是一個被動定義，但目前沒有預測程式失敗時修正需要多長時間的指標。
- 使用者不斷請求更改系統。*靈活性*是一個定性屬性，試圖衡量進行這些更改的難易程度。如果程式需要完全重寫才能實現更改，則它不靈活。
- 我們可能認為*可測試性*是一個高度主觀的領域，但測試工程師有因素清單可以評估程式的可測試性。

**可轉移性 (Transferability)**
**可轉移性**是指將資料和/或系統從一個平台移動到另一個平台以及重複使用程式碼的能力。在許多情況下，這不是一個重要因素。另一方面，如果我們正在編寫通用軟體，它可能是至關重要的。
- 如果編寫模組以便可以在其他系統中重複使用，那麼它們就具有高水準的*可重用性*。優秀的程式設計師會建立函式庫，以便重複使用來解決類似的問題。
- *互操作性*是向其他系統發送資料的能力。在當今高度整合的系統中，這是一個理想的屬性。事實上，它變得如此重要，以至於作業系統現在支援在系統之間移動資料的能力，例如在文字處理器和試算表之間。
- *可移植性*是將軟體從一個硬體平台移動到另一個硬體平台的能力。

## 10.5 測試階段
**測試階段**的目標是找出錯誤，這意味著好的測試策略是能找出最多錯誤的策略。有兩種類型的測試：*玻璃箱*和*黑箱*（圖 10.11）。

### 10.5.1 玻璃箱測試
**玻璃箱測試**（或**白箱測試**）基於了解軟體的內部結構。測試目標是檢查以確定軟體的所有組件是否按設計執行。玻璃箱測試假設測試人員了解軟體的一切。在這種情況下，軟體就像一個玻璃箱，箱內的一切都可見。玻璃箱測試由軟體工程師或專門團隊完成。使用軟體結構的玻璃箱測試需要保證至少滿足以下四個標準：
- 每個模組中的所有獨立路徑至少測試一次。
- 所有決策建構（雙向和多向）在每個分支上都經過測試。
- 每個迴圈建構都經過測試。
- 所有資料結構都經過測試。
過去已經設計了幾種測試方法。我們簡要討論其中兩種：*基本路徑*測試和*控制結構*測試。

**基本路徑測試**
**基本路徑測試**由 Tom McCabe 提出。此方法創建一組測試案例，執行軟體中的*每個陳述式*至少一次。

**基本路徑測試是一種軟體中每個陳述式至少執行一次的方法。**

基本路徑測試使用*圖論*（見第 12 章）和*循環複雜度*來找出必須遵循的獨立路徑，以保證每個陳述式至少執行一次。

**控制結構測試**
**控制結構測試**比基本路徑測試更全面，並包含它。此方法使用不同類別的測試，簡要描述如下。
- **條件測試**：條件測試適用於模組中的任何條件表達式。*簡單條件*是一個關係表達式，而*複合條件*是簡單條件和邏輯運算子的組合（見第 9 章）。條件測試旨在檢查所有條件是否設定正確。
- **資料流測試**：資料流測試基於通過模組的資料流。這種類型的測試選擇涉及在賦值陳述式左側使用變數時檢查變數值的測試案例。
- **迴圈測試**：迴圈測試使用測試案例來檢查迴圈的有效性。所有類型的迴圈（*while*、*do* 和 *for*）都經過仔細測試。

### 10.5.2 黑箱測試
**黑箱測試**得名於在不知道軟體內部是什麼以及不知道它如何工作的情況下測試軟體的概念。換句話說，軟體就像一個黑箱，測試人員看不到裡面。黑箱測試根據軟體應該完成的任務（例如其輸入和輸出）來測試軟體的功能。黑箱測試使用了幾種方法，討論如下。

**窮舉測試**
最好的黑箱測試方法是針對輸入域中的所有可能值測試軟體。然而，在複雜軟體中，輸入域如此巨大，以至於這樣做通常是不切實際的。

**隨機測試**
在隨機測試中，選擇輸入域中的值子集進行測試。非常重要的是，子集的選擇方式應使值分佈在輸入域上。在這種情況下，使用隨機數生成器會非常有幫助。

**邊界值測試**
遇到邊界值時經常發生錯誤。例如，如果模組定義其輸入之一必須大於或等於 100，則測試該模組的邊界值 100 非常重要。如果模組在這個邊界值失敗，可能是模組代碼中的某個條件（如 x > 100）被寫成了 x >= 100。

## 10.6 文件
為了正確使用和有效維護軟體，需要文件。通常，為軟體準備三套獨立的文件：使用者文件、系統文件和技術文件。然而，請注意，文件是一個持續的過程。如果軟體在發布後出現問題，也必須記錄下來。如果修改了軟體，所有修改及其與原始套件的關係也必須記錄下來。只有當套件過時，文件才會停止。

**文件是一個持續的過程。**

### 10.6.1 使用者文件
為了正確運行軟體系統，使用者需要文件，傳統上稱為*使用者指南*，它逐步顯示如何使用軟體。使用者指南通常包含教學部分，引導使用者了解軟體的每個功能。
好的使用者指南可以成為非常強大的行銷工具：使用者文件在行銷中的重要性怎麼強調都不為過。使用者指南應為新手和專家使用者編寫，擁有良好使用者文件的軟體系統肯定會增加銷售量。

### 10.6.2 系統文件
**系統文件**定義了軟體本身。它的編寫應使軟體可以由原始開發人員以外的人員維護和修改。系統開發的所有四個階段都應存在系統文件。
在分析階段，收集的資訊應仔細記錄。此外，分析師應定義資訊來源。此階段選擇的需求和方法必須清楚說明其背後的理由。
在設計階段，必須記錄最終副本中使用的工具。例如，如果圖表經過多次更改，則應記錄圖表的最終副本並附上完整的解釋。
在實作階段，代碼的每個模組都應記錄下來。此外，代碼應盡可能使用註解和描述性標頭進行自我記錄。
最後，開發人員必須仔細記錄測試階段。應用於最終產品的每種測試類型都應連同其結果一起提及。即使是不利的結果和產生它們的資料也必須記錄下來。

### 10.6.3 技術文件
**技術文件**描述軟體系統的安裝和服務。安裝文件定義應如何在每台電腦（例如伺服器和客戶端）上安裝軟體。服務文件定義應如何維護系統並在必要時進行更新。

## 10.7 章末材料
### 10.7.1 推薦閱讀
- Braude, E. *Software Engineering – An Object-Oriented Perspective*, New York: Wiley, 2001
- Gustafson, D. *Software Engineering*, New York: McGraw-Hill, 2002
- Lethbridge, T. and Laganiere, R. *Object-Oriented Software Engineering*, New York: McGraw-Hill, 2005
- Pressman, R. *Software Engineering: A Practitioner’s Approach*, New York: McGraw-Hill, 2005
- Schach, S. *Object-Oriented and Classical Software Engineering*, New York: McGraw-Hill, 2007

### 10.7.2 關鍵詞
- 分析階段 (analysis phase)
- 屬性 (attribute)
- 基本路徑測試 (basis path testing)
- 黑箱測試 (black-box testing)
- 類別圖 (class diagram)
- 內聚 (cohesion)
- 控制結構測試 (control structure testing)
- 耦合 (coupling)
- 資料流程圖 (data flow diagram)
- 設計階段 (design phase)
- 開發過程 (development process)
- 實體關係圖 (entity–relationship diagram)
- 玻璃箱測試 (glass-box testing)
- 實作階段 (implementation phase)
- 增量模型 (incremental model)
- 可維護性 (maintainability)
- 模組化 (modularity)
- 物件導向分析 (object-oriented analysis)
- 物件導向設計 (object-oriented design)
- 可操作性 (operability)
- 程序導向分析 (procedure-oriented analysis)
- 程序導向設計 (procedure-oriented design)
- 軟體工程 (software engineering)
- 軟體生命週期 (software lifecycle)
- 軟體品質 (software quality)
- 狀態圖 (state chart)
- 狀態圖 (state diagram)
- 結構圖 (structure chart)
- 技術文件 (technical documentation)
- 可測試性 (testability)
- 測試階段 (testing phase)
- 可轉移性 (transferability)
- 使用案例圖 (use-case diagram)
- 瀑布模型 (waterfall model)
- 白箱測試 (white-box testing)

### 10.7.3 摘要
- 軟體生命週期是軟體工程中的一個基本概念。軟體像許多其他產品一樣，會經歷一個重複階段的循環。
- 軟體生命週期中的開發過程涉及四個階段：分析、設計、實作和測試。已有多種模型用於這些階段。我們討論了最常見的兩種：瀑布模型和增量模型。
- 開發過程始於分析階段。分析師準備一份規格文件，說明軟體將做什麼，但不指定如何做。分析階段可以通過兩種方式完成：程序導向分析和物件導向分析。
- 設計階段定義系統將如何完成在分析階段定義的內容。在程序導向設計中，整個專案被劃分為一組程序或模組。在物件導向設計中，設計階段透過詳細闡述類別的細節繼續進行。
- 模組化意味著將大型專案分解為易於理解和處理的較小部分。當系統被劃分為模組時，兩個問題很重要：耦合和內聚。耦合是衡量兩個模組彼此綁定緊密程度的指標。軟體系統中模組之間的耦合必須最小化。內聚是衡量系統中模組相關程度的指標。軟體系統中模組之間的內聚應最大化。
- 在實作階段，程式設計師為程序導向設計中的模組編寫程式碼，或編寫程式單元以實作物件導向設計中的類別。
- 軟體品質很重要。軟體品質可以分為三大類指標：可操作性、可維護性和可轉移性。
- 測試階段的目標是找出錯誤。有兩種類型的測試：玻璃箱和黑箱。玻璃箱測試（或白箱測試）基於了解軟體的內部結構。玻璃箱測試假設測試人員了解一切。黑箱測試意味著在不知道軟體內部是什麼以及不知道它如何工作的情況下測試軟體。

## 10.8 練習題
### 10.8.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 10.8.2 複習問題
1. 定義「軟體生命週期」。
2. 區分瀑布模型和增量開發模型。
3. 列出開發過程中的四個階段。
4. 定義分析階段的目的並描述此階段的兩個趨勢。
5. 定義設計階段的目的並描述此階段的兩個趨勢。
6. 描述模組化並提及兩個與模組化相關的問題。
7. 區分耦合和內聚。
8. 定義實作階段的目的並描述此階段的品質問題。
9. 定義測試階段的目的並列出兩類測試。
10. 區分玻璃箱測試和黑箱測試。

### 10.8.3 問題
1. 在第 9 章中，我們解釋了常數值的使用優於字面值。這種偏好對軟體生命週期有什麼影響？
2. 在第 9 章中，我們展示了兩個模組之間的通訊可以透過傳值或傳參考進行。哪種方法在兩個模組之間提供較少的耦合？
3. 在第 9 章中，我們展示了兩個模組之間的通訊可以透過傳值或傳參考進行。哪種方法在兩個模組之間提供更多的內聚？
4. 為一個簡單的圖書館繪製使用案例圖。
5. 為一家小型雜貨店繪製使用案例圖。
6. 顯示簡單數學公式 $x + y$ 的資料流程圖。
7. 顯示簡單數學公式 $x \\times y + z \\times t$ 的資料流程圖。
8. 顯示圖書館的資料流程圖。
9. 顯示小型雜貨店的資料流程圖。
10. 為問題 P10-8 創建結構圖。
11. 為問題 P10-9 創建結構圖。
12. 顯示固定容量堆疊的狀態圖（見第 12 章）。
13. 顯示固定容量佇列的狀態圖（見第 12 章）。
14. 為圖書館創建類別圖。
15. 為小型雜貨店創建類別圖。
16. 顯示問題 P10-14 中類別的詳細資訊。
17. 顯示問題 P10-15 中類別的詳細資訊。
18. 程式的輸入資料由 1000 到 1999（含）範圍內的三個整數組合組成。找出測試這些數字所有組合的窮舉測試數量。
19. 列出問題 P10-18 所需的邊界值測試。
20. 隨機數生成器生成 0 到 0.999 之間的數字。如何使用此隨機數生成器對問題 P10-18 中描述的系統進行隨機測試。
`},m={en:`
# Chapter 11: Data Structure

In the preceding chapters, we used variables that store a single entity. Although single variables are used extensively in programming languages, they cannot be used to solve complex problems efficiently. In this chapter, we introduce data structures. This chapter is a prelude to the next chapter, in which we introduce abstract data types (ADTs).

A **data structure** uses a collection of related variables that can be accessed individually or as a whole. In other words, a data structure represents a set of data items that share a specific relationship. We discuss three data structures in this chapter: *arrays*, *records*, and *linked lists*. Most programming languages have an implicit implementation of the first two. The third, however, is simulated using pointers and records.

## Objectives
After studying this chapter, the student should be able to:
- Define a data structure.
- Define an array as a data structure and how it is used to store a list of data items.
- Distinguish between the name of an array and the names of the elements in an array.
- Describe operations defined for an array.
- Define a record as a data structure and how it is used to store attributes belonging to a single data element.
- Distinguish between the name of a record and the names of its fields.
- Define a linked list as a data structure and how it is implemented using pointers.
- Describe operations defined for a linked list.
- Compare and contrast arrays, records, and linked lists.
- Define the applications of arrays, records, and linked lists.

## 11.1 ARRAYS
Imagine that we have 100 scores. We need to read them, process them, and print them. We must also keep these 100 scores in memory for the duration of the program. We can define a hundred variables, each with a different name, as shown in Figure 11.1.

But having 100 different names creates other problems. We need 100 references to read them, 100 references to process them, and 100 references to write them. Figure 11.2 shows a diagram that illustrates this problem.

The number of instructions we need to handle even this relatively small number of scores is unacceptable. To process large amounts of data, we need a data structure such as an array.

An **array** is a sequenced collection of elements, of the same data type. We can refer to the elements in the array as the first element, the second element, and so forth until we get to the last element. If we were to put our 100 scores into an array, we could designate the elements as scores[1], scores[2], and so on. The **index** indicates the ordinal number of the element, counting from the beginning of the array. The elements of the array are individually addressed through their subscripts (Figure 11.3). The array as a whole has a name, *scores*, but each score can be accessed individually using its subscript.

We can use loops to read and write the elements in an array. We can also use loops to process elements. Now it does not matter if there are 100, 1000, or 10000 elements to be processed—loops make it easy to handle them all. We can use an integer variable to control the loop, and remain in the loop as long as the value of this variable is less than the total number of elements in the array (Figure 11.4).

We have used indexes that start from 1; some modern languages such as C, C++, and Java start indexes from 0.

> **Example 11.1**
> Compare the number of instructions needed to handle 100 individual elements in Figure 11.2 and the array with 100 in Figure 11.4. Assume that processing each score needs only one instruction.
>
> **Solution**
> - In the first case, we need 100 instructions to read, 100 instructions to write, and 100 instructions to process. The total is 300 instructions.
> - In the second case, we have three loops. In each loop we have two instructions, giving a total of six instructions. However, we also need three instructions for initializing the index and three instructions to check the value of the index. In total, we have 12 instructions.

> **Example 11.2**
> The number of cycles (fetch, decode, and execute phases) the computer needs to perform is not reduced if we use an array. The number of cycles is actually increased, because we have the extra overhead of initializing, incrementing, and testing the value of the index. But our concern is not the number of cycles: it is the number of lines we need to write the program.

> **Example 11.3**
> In computer science, one of the big issues is the reusability of programs—for example, how much needs to be changed if the number of data items is changed. Assume we have written two programs to process the scores as shown in Figure 11.2 and Figure 11.4. If the number of scores changes from 100 to 1000, how many changes do we need to make in each program?
> In the first program we need to add 3 × 900 = 2700 instructions. In the second program, we only need to change three conditions (I > 100 to I > 1000). We can actually modify the diagram in Figure 11.4 to reduce the number of changes to one.

### 11.1.1 Array name versus element name
In an array we have two types of identifiers: the name of the array and the name of each individual element. The name of the array is the name of the whole structure, while the name of an element allows us to refer to that element. In the array of Figure 11.3, the name of the array is *scores* and the name of each element is the name of the array followed by the index, for example, scores[1], scores[2], and so on. In this chapter, we mostly need the names of the elements, but in some languages, such as C, we also need to use the name of the array.

### 11.1.2 Multidimensional arrays
The arrays discussed so far are known as **one-dimensional arrays** because the data is organized linearly in only one direction. Many applications require that data be stored in more than one dimension. One common example is a table, which is an array that consists of rows and columns. Figure 11.5 shows a table, which is commonly called a **two-dimensional array**.

The array shown in Figure 11.5 holds the scores of students in a class. There are five students in the class and each student has four different scores for four quizzes. The variable scores[2][3] show the score of the second student in the third quiz. Arranging the scores in a two-dimensional array can help the teacher to find the average of scores for each student (the average over the row values) and find the average for each quiz (the average over the column values), as well as the average of all quizzes (the average of the whole table).

**Multidimensional arrays**—arrays with more than two dimensions—are also possible. However, we do not discuss arrays beyond two dimensions in this book.

### 11.1.3 Memory layout
The indexes in a one-dimensional array directly define the relative positions of the element in actual memory. A two-dimensional array, however, represents rows and columns. How each element is stored in memory depends on the computer. Most computers use **row-major storage**, in which an entire row of an array is stored in memory before the next row. However, a computer may store the array using **column-major storage**, in which the entire column is stored before the next column. Figure 11.6 shows a two-dimensional array and how it is stored in memory using row-major or column-major storage. Row-major storage is more common.

> **Example 11.4**
> We have stored the two-dimensional array *students* in the memory. The array is 100 × 4 (100 rows and 4 columns). Show the address of the element *students*[5][3] assuming that the element *student*[1][1] is stored in the memory location with address 1000 and each element occupies only one memory location. The computer uses row-major storage.
>
> **Solution**
> We can use the following formula to find the location of an element, assuming each element occupies one memory location:
> $y = x + \\text{Cols} \\times (i - 1) + (j - 1)$
> where $x$ defines the start address, Cols defines the number of columns in the array, $i$ defines the row number of the element, $j$ defines the column number of the element, and $y$ is the address we are looking for. In our example, $x$ is 1000, Cols is 4, $i$ is 5 and $j$ is 3. We are looking for the value of $y$:
> $y = x + \\text{Cols} \\times (i - 1) + (j - 1) = 1000 + 4(5 - 1) + (3 - 1) = 1018$
> The answer makes sense because the element is at row 5 and column 3. There are four rows before this element that occupy 16 (4 × 4) memory locations. The previous two elements in row 5 have also occupied two memory locations. This means that all elements before the target elements occupy 18 memory locations. If the first element occupies the location 1000, the target element occupies the location 1018.

### 11.1.4 Operations on array
Although we can apply conventional operations defined for each element of an array (see Chapter 4), there are some operations that we can define on an array as a data structure. The common operations on arrays as structures are *searching*, *insertion*, *deletion*, *retrieval*, and *traversal*.

**Searching for elements**
We often need to find the index of an element when we know the value. This type of search was discussed in Chapter 8. We can use sequential search for unsorted arrays or binary search on sorted arrays. Searching is used for the next three operations.

**Insertion of elements**
Traditionally, computer languages require that the size of an array (the number of elements in the array) be defined at the time the program is written and prevent it from being changed during the execution of the program. Recently, some languages have allowed variable-size arrays. Even when the language allows variable-sized arrays, insertion of an element into an array needs careful attention.

**Insertion at the end**
If the insertion is at the end of an array and the language allows us to increase the size of the array, this can be done easily. For example, if an array has 30 elements, we increase the size of the array to 31 and insert the new item as the 31st item.

**Insertion at the beginning or middle**
If the insertion is to be at the beginning or in the middle of an array, the process is lengthy and time consuming. This happens when we need to insert an element in a sorted array. We first search the array, as described before. After finding the location of the insertion, we insert the new element. For example, if we want to insert an element as the 9th element in an array of 30 elements, elements 9 to 30 should be shifted one element towards the end of the array to open an empty element at position 9 for insertion. The following shows part of the pseudocode that needs to be applied to the array:

\`\`\`
i ← 30
while (i ≥ 9)
{
    array [i + 1] ← array [i]
    i ← i - 1
}
array [i] ← newValue
\`\`\`

Note that the shifting needs to take place from the end of the array to prevent losing the values of the elements. The code first copies the value of the 30th element into the 31st element, then copies the value of the 29th element into the 30th element, and so on. When the code comes out of the loop, the 9th element is already copied to the 10th element. The last line copies the value of the new item into the 9th element.

**Deletion of elements**
Deletion of an element in an array is as lengthy and involved as insertion. For example, if the ninth element should be deleted, we need to shift elements 10 to 30 one position towards the start of the array. We leave the pseudocode for this operation as an exercise, which is similar to the one for addition of an element.

**Retrieving elements**
Retrieving means randomly accessing an element for the purpose of inspecting or copying the data contained in the element. Unlike insertion and deletion operations, retrieving is an easy operation when a data structure is an array. In fact, an array is a *random-access structure*, which means that each element of an array can be accessed randomly without the need to access the elements before or after it. For example, if we want to retrieve the value of the 9th element in the array, we can do so using a single instruction, as shown below:

\`\`\`
RetrievedValue ← array[9]
\`\`\`

**Traversal of arrays**
Array traversal refers to an operation that is applied to all elements of the array, such as reading, writing, applying mathematical operation, and so on.

Algorithm 11.1 gives an example of finding the average of elements in an array whose elements are reals. The algorithm first finds the sum of the elements using a loop. After the loop is terminated, the average is calculated, which is the sum divided by the number of elements. Note that for proper calculation of the sum, the sum needs to be set to 0.0 before the loop.

**Algorithm 11.1 Calculating the average of elements in an array**
\`\`\`
Algorithm: ArrayAverage (Array, n)
Purpose: Find the average value
Pre: Given the array Array and the number of elements, n.
Post: None
Return: The average value
{
    sum ← 0.0
    i ← 1
    while (i ≤ n)
    {
        sum ← sum + Array [i]
        i ← i + 1
    }
    average ← sum / n
    Return ( average )
}
\`\`\`

### 11.1.5 Strings
A **string**, as a set of characters, is treated in different languages differently. In C, a string is an array of characters. In C++, a string can be an array of characters, but there is a type named string. In Java, a string is a type.

### 11.1.6 Application
Thinking about the operations discussed in the previous section gives a clue to the application of arrays. If we have a list in which a lot of insertions and deletions are expected after the original list has been created, we should not use an array. An array is more suitable when the number of deletions and insertions is small, but a lot of *searching* and *retrieval* activities are expected.

**An array is a suitable structure when a small number of insertions and deletions are required, but a lot of searching and retrieval is needed.**

## 11.2 RECORDS
A **record** is a collection of related elements, possibly of different types, having a single name. Each element in a record is called a **field**. A field is the smallest element of named data that has meaning. A field has a type, and exists in memory. Fields can be assigned values, which in turn can be accessed for selection or manipulation. A field differs from a variable primarily in that it is part of a record.

Figure 11.7 contains two examples of records. The first example, *fraction*, has two fields, both of which are integers. The second example, *student*, has three fields made up of three different types.

**The elements in a record can be of the same or different types, but all elements in the record must be related.**

The data in a record should all be related to one object. In Figure 11.7, the integers in the fraction both belong to the same fraction, and the data in the second example all relate to one student. (Note that we have placed string data between two double quotes and a single character between two single quotes. This is the convention used in most programming languages.)

### 11.2.1 Record name versus field name
Just like in an array, we have two types of identifier in a record: the name of the record and the name of each individual field inside the record. The name of the record is the name of the whole structure, while the name of each field allows us to refer to that field. For example, in the student record of Figure 11.7, the name of the record is *student*, the name of the fields are *student.id*, *student.name*, and *student.grade*. Most programming languages use a period (.) to separate the name of the structure (record) from the name of its components (fields). This is the convention we use in this book.

> **Example 11.5**
> The following shows how the value of fields in Figure 11.7 are stored:
> \`student.id ← 2005\` \`student.name ← "G. Boole"\` \`student.grade ← 'A'\`

### 11.2.2 Comparison of records and arrays
We can conceptually compare an array with a record. This helps us to understand when we should use an array and when a record. An array defines a combination of elements, while a record defines the identifiable parts of an element. For example, an array can define a class of students (40 students), but a record defines different attributes of a student, such as id, name, or grade.

### 11.2.3 Array of records
If we need to define a combination of element and at the same time some attributes of each element, we can use an array of records. For example, in a class of 30 students, we can have an array of 30 records, each record representing a student. Figure 11.8 shows an array of 30 student records called *students*.

In an array of records, the name of the array defines the whole structure, the group of students as a whole. To define each element, we need to use the corresponding index. To define the parts (attributes) of each element, we need to use the dot operator. In other words, first we need to define the element, then we can define part of that element. Therefore, the id of the third student is defined as:
\`(student[3]).id\`

Note that we use parentheses to emphasize that first a particular student should be chosen, then the id of that student. In other words, the parentheses tell us that the index operator has precedence over the dot operator. In some languages, there is no need to use parentheses, because the precedence is already established in the language itself, but using parentheses always guarantees the precedence.

> **Example 11.6**
> The following shows how we access the fields of each record in the students array to store values in them.
> \`(students[1]).id ← 1001 (students[1]).name ← "J. Aron" (students[1]).grade ← 'A'\`
> \`(students[2]).id ← 2007 (students[2]).name ← "F. Bush" (students[2]).grade ← 'F'\`
> ...
> \`(students[30]).id ← 3012 (students[30]).name ← "M. Blair" (students[30]).grade ← 'B'\`

> **Example 11.7**
> However, we normally use a loop to read data into an array of record. Algorithm 11.2 shows part of the pseudocode for this process.

**Algorithm 11.2 Part of the pseudocode to read student record**
\`\`\`
i ← 1
while (i < 31)
{
    read (students [i]).id
    read (students [i]).name
    read (students [i]).grade
    i ← i + 1
}
\`\`\`

### 11.2.4 Arrays versus array of records
Both an array and an array of record represents a list of items. An array can be thought of as a special case of an array of records in which each element is a record with only a single field.

## 11.3 LINKED LISTS
A **linked list** is a collection of data in which each element contains the location of the next element—that is, each element contains two parts: data and link. The data part holds the value information: the data to be processed. The link is used to chain the data together, and contains a **pointer** (an address) that identifies the next element in the list. In addition, a pointer variable identifies the first element in the list. The name of the list is the same as the name of this pointer variable.

Figure 11.9 shows a linked list called *scores* that contains four elements. The link in each element, except the last, points to its successor. The link in the last element contains a **null pointer**, indicating the end of the list. We define an empty linked list to be only a null pointer: Figure 11.9 also shows an example of an empty linked list.

The elements in a linked list are traditionally called nodes. A **node** in a linked list is a record that has at least two fields: one contains the data, and the other contains the address of the next node in the sequence (the link). Figure 11.9 also shows a node.

Before further discussion of linked lists, we need to explain the notation we use in the figures. We show the connection between two nodes using a line. One end of the line has an arrowhead, the other end has a solid circle. The arrowhead represents a copy of the address of the node to which the arrow head is pointed. The solid circle shows where this copy of the address is stored (Figure 11.10). The figure also shows that we can store a copy of the address in more than one place. For example, Figure 11.10 shows that two copies of the address are stored in two different locations. Understanding these concepts helps us to understand operations on a linked list better.

### 11.3.1 Arrays versus linked lists
Both an array and a linked list are representations of a list of items in memory. The only difference is the way in which the items are linked together. In an array of records, the *linking tool* is the index. The element scores[3] is linked to the element scores[4] because the integer 4 comes after the integer 3. In a linked list, the *linking tool* is the link that points to the next element—the pointer or the address of the next element. Figure 11.11 compares the two representations for a list of five integers.

The elements of an array are stored one after another in the memory without a gap in between: the list is contiguous. The nodes of a linked list can be stored with gaps between them: the link part of the node ‘glues’ the items together. In other words, the computer has the option to store them contiguously or spread the nodes through the whole memory. This has an advantage: insertion and deletion in a linked list is much easier. The only thing that needs to be changed is the pointer to the address of the next element. However, this comes with an overhead: each node of a linked list has an extra field, the address of the next node in memory.

### 11.3.2 Linked list names versus nodes names
As for arrays and records, we need to distinguish between the name of the linked list and the names of the nodes, the elements of a linked list. A linked list must have a name. The name of a linked list is the name of the head pointer that points to the first node of the list. Nodes, on the other hand, do not have explicit names in a linked list, just implicit ones. The name of a node is related to the name of the pointer that points to the node. Different languages handle the relation between the pointer and the node to which the pointer points differently. We use the convention used in the C language. If the pointer that points to a node is called p, for example, we call the node *p. Since the node is a record, we can access the fields inside the node using the name of the node. For example, the data part and the link part of a node pointed by a pointer p can be called (*p).data and (*p).link. This naming convention implies that a node can have more than one name. Figure 11.12 shows the name of the linked list and the names of the nodes.

### 11.3.3 Operations on linked lists
The same operations we defined for an array can be applied to a linked list.

**Searching a linked list**
The search algorithm for a linked list can only be sequential (see Chapter 8) because the nodes in a linked list have no specific names (unlike the elements in an array) that can be found using a binary search. However, since nodes in a linked list have no names, we use two pointers, *pre* (for previous) and *cur* (for current).

At the beginning of the search, the *pre* pointer is null and the *cur* pointer points to the first node. The search algorithm moves the two pointers together towards the end of the list. Figure 11.13 shows the movement of these two pointers through the list in an extreme case scenario: when the target value is larger than any value in the list. For example, in the five-node list, assume that our target value is 220, which is larger than any value in the list.

However, other situations can occur. The value of the target can be less that data value in the first node, or it can be equal to one of the data values in one of the nodes, and so on. In all situations, however, when the search stops, the *cur* pointer points to the node that stops the search and the *pre* pointer points to the previous node. If the target is found, the *cur* pointer points to the node that holds the target value. If the target value is not found, the *cur* pointer points to the node with a value larger than the target value. In other words, since the list is sorted, and may be very long, we never allow the two pointers to reach the end of the list if we are sure that we have passed the target value. The searching algorithm uses a flag (a variable that can take only *true* or *false* values). When the target is found, the flag is set to *true*: when the target is not found, the flag is set to *false*. When the flag is *true* the *cur* pointer points to the target value: when the flag is *false*, the *cur* pointer points to a value larger than the target value.

Figure 11.14 shows some different situations. In the first case, the target is 98. This value does not exist in the list and is smaller than any value in the list, so the search algorithm stops while *pre* is null and *cur* points to the first node. The value of the flag is *false* because the value was not found. In the second case, the target is 132, which is the value of the second node. The search algorithm stops while *cur* is pointing to the second node and *pre* is pointing to the first node. The value of the flag is *true* because the target is found. In the third and the fourth cases, the targets are not found so the value of the flag is *false*.

Algorithm 11.3 shows a simplified algorithm for the search. We need more conditions on the *while* loop, but we leave that for more advanced discussion of linked lists. Note how we move the two pointers forward together. In each move, we have:

\`pre ← cur\` and \`cur ← (*cur).link\`

This guarantees that the two pointers move together. The first assignment makes a copy of *cur* and stores it in *pre*. This means *pre* is taking the previous value of *cur*. In the second assignment, the node pointed by *cur* is selected and the value of its link field is copied and stored in *cur* (see Figure 11.12 for clarification). The search algorithm is used both by the insertion algorithm (if the target is not found) and by the delete algorithm (if the target is found).

**Algorithm 11.3 Searching a linked list**
\`\`\`
Algorithm: SearchLinkedList
Purpose: Search the list using two pointers: pre and cur.
Pre: The linked list (head pointer) and target value
Post: None
Return: The position of pre and cur pointers and the value of the flag
{
    pre ← null
    cur ← list
    while (target < (*cur).data)
    {
        pre ← cur
        cur ← (*cur).link
    }
    if ((*cur).data = target) flag ← true
    else flag ← false
}
\`\`\`

**Inserting a node**
Before insertion into a linked list, we first apply the searching algorithm. If the flag returned from the searching algorithm is false, we will allow insertion, otherwise we abort the insertion algorithm, because we do not allow data with duplicate values. Four cases can arise:
- Inserting into an empty list.
- Insertion at the beginning of the list.
- Insertion at the end of the list.
- Insertion in the middle of the list.

**Insertion into an empty list**
If the list is empty (list = null), the new item is inserted as the first element. One statement can do the job:
\`list ← new\`

**Insertion at the beginning**
If the searching algorithm returns a flag with value of *false* and the value of the *pre* pointer is null, the data needs to be inserted at the beginning of the list. Two statements are needed to do the job:
\`(*new).link ← cur\` and \`list ← new\`
The first assignment makes the new node become the predecessor of the previous first node. The second statement makes the newly connected node the first node. Figure 11.15 shows the situation.

**Insertion at the end**
If the searching algorithm returns a flag with value of *false* and the value of the *cur* pointer is null, the data needs to be inserted at the end of the list. Two statements are needed to do the job:
\`(*pre).link ← new\` and \`(*new).link ← null\`
The first assignment connects the new node to the previous last node. The second statement makes the newly connected node become the last node. Figure 11.16 shows the situation.

**Insertion in the middle**
If the searching algorithm returns a flag with a value of *false* and none of the returned pointers are null, the new data needs to be inserted at the middle of the list. Two statements are needed to do the job:
\`(*new).link ← cur\` and \`(*pre).link ← new\`
The first assignment connects the new node to its successor. The second statement connects the new node to its predecessor. Figure 11.17 shows the situation.

Algorithm 11.4 shows the pseudocode for inserting a new node in a linked list. The first section just adds a node to an empty list.

**Algorithm 11.4 Inserting a node in a linked list**
\`\`\`
Algorithm: InsertLinkedList (list, target, new)
Purpose: Insert a node in the link list after searching the list
Pre: The linked list and the target data to be inserted
Post: None
Return: The new linked list
{
    searchlinkedlist (list, target, pre, cur, flag)
    // Given target and returning pre, cur, and flag
    if (flag = true) // No duplicate
    {
        return list
    }
    if (list = null // Insert into empty list
    {
        list ← new
    }
    if (pre = null) // Insertion at the beginning
    {
        (*new).link ← cur
        list ← new
        return list
    }
    if (cur = null) // Insertion at the end
    {
        (*pre).link ← new
        (*new).link ← null
        return list
    }
    (*new).link ← cur // Insertion in the middle
    (*pre).link ← new
    return list
}
\`\`\`

**Deleting a node**
Before deleting a node in a linked list, we apply the search algorithm. If the flag returned from the search algorithm is true (the node is found), we can delete the node from the linked list. However, deletion is simpler than insertion: we have only two cases—deleting the first node and deleting any other node. In other words, the deletion of the last and the middle nodes can be done by the same process.

**Deleting the first node**
If the *pre* pointer is null, the first node is to be deleted. The *cur* pointer points to the first node and deleting can be done by one statement:
\`list ← (*cur).link\`
The statement connects the second node to the list pointer, which means that the first node is deleted. Figure 11.18 shows the case.

**Deleting the middle or the last node**
If neither of the pointers is null, the node to be deleted is either a middle node or the last node. The *cur* pointer points to the corresponding node and deleting can be done by one statement:
\`(*pre).link ← (*cur).link\`
The statement connects the successor node to the predecessor node, which means that the current node is deleted. Figure 11.19 shows the case.

Algorithm 11.5 shows the pseudocode for deleting a node. The algorithm is much simpler than the one for inserting. We have only two cases and each case needs only one statement.

**Algorithm 11.5 Deleting a node in a linked list**
\`\`\`
Algorithm: DeleteLinkedList (list, target)
Purpose: Delete a node in a linked list after searching the list for the right node
Pre: The linked list and the target data to be deleted
Post: None
Return: The new linked list
{
    // Given target and returning pre, cur, and flag
    searchlinkedlist (list, target, pre, cur, flag)
    if (flag = false)
    {
        return list // The node to be deleted not found
    }
    if (pre = null) // Deleting the first node
    {
        list ← (*cur).link
        return list
    }
    (*pre).link ← (*cur).link // Deleting other nodes
    return list
}
\`\`\`

**Retrieving a node**
Retrieving means randomly accessing a node for the purpose of inspecting or copying the data contained in the node. Before retrieving, the linked list needs to be searched. If the data item is found, it is retrieved, otherwise the process is aborted. Retrieving uses only the *cur* pointer, which points to the node found by the search algorithm. Algorithm 11.6 shows the pseudocode for retrieving the data in a node. The algorithm is much simpler than the insertion or deletion algorithm.

**Algorithm 11.6 Retrieving a node in a linked list**
\`\`\`
Algorithm: RetrieveLinkedList (list, target)
Purpose: Retrieves the data in a node after searching the list for the right node
Pre: The linked list (head pointer) and the target (data to be retrieved)
Post: None
Return: Return the data retrieved
{
    searchlinkedlist (list, target, pre, cur, flag)
    if (flag = false) // The node not found
    {
        return error
    }
    return (*cur).data
}
\`\`\`

**Traversing a linked list**
To traverse the list, we need a ‘walking’ pointer, which is a pointer that moves from node to node as each element is processed. We start traversing by setting the walking pointer to the first node in the list. Then, using a loop, we continue until all of the data has been processed. Each iteration of the loop processes the current node, then advances the walking pointer to the next node. When the last node has been processed, the walking pointer becomes null and the loop terminates (Figure 11.20).

Algorithm 11.7 shows the pseudocode for traversing a linked list.

**Algorithm 11.7 Traversing a linked list**
\`\`\`
Algorithm: TraverseLinkedList (list)
Purpose: Traverse a linked list and process each data item
Pre: The linked list (head pointer)
Post: None
Return: The list
{
    walker ← list
    while (walker ≠ null)
    {
        Process (*walker).data
        walker ← (*walker).link
    }
    return list
}
\`\`\`

### 11.3.4 Applications of linked lists
A linked list is a very efficient data structure for storing data that will go through many insertions and deletions. A linked list is a dynamic data structure in which the list can start with no nodes and then grow as new nodes are needed. A node can be easily deleted without moving other nodes, as would be the case with an array. For example, a linked list could be used to hold the records of students in a school. Each quarter or semester, new students enroll in the school and some students leave or graduate.

A linked list can grow infinitely and can shrink to an empty list. The overhead is to hold an extra field for each node. A linked list, however, is not a good candidate for data that must be searched often. This appears to be a dilemma, because each deletion or insertion needs a search. We will see that some abstract data types, discussed in the next chapter, have the advantages of an array for searching and the advantages of a link list for insertion and deletion.

**A linked list is a suitable structure if a large number of insertions and deletions are needed, but searching a linked list is slower that searching an array.**

## 11.4 END-CHAPTER MATERIALS

### 11.4.1 Recommended reading
For more details about the subjects discussed in this chapter, the following books are recommended:
- Gilberg, R. and Forouzan, B. *Data Structures – A Pseudocode Approach with C*, Boston, MA: Course Technology, 2005
- Goodrich, M. and Tamassia, R. *Data Structures and Algorithms in Java*, New York: Wiley, 2005
- Neapolitan, R. and Naimipour, K. *Foundations of Algorithms Using C++ Pseudocode*, Sudbury, MA: Jones and Bartlett, 2004
- Main, M. and Savitch, W. *Data Structures and Other Objects Using C++*, Reading, MA: Addison-Wesley, 2004
- Standish, T. *Data Structures, Algorithms, and Software Principles*, Reading, MA: Addison-Wesley, 1994

### 11.4.2 Key terms
- array
- column-major storage
- data structure
- field
- index
- link
- linked list
- multidimensional array
- node
- null pointer
- one-dimensional array
- pointer
- record
- retrieval
- row-major storage
- searching
- two-dimensional array
- string

### 11.4.3 Summary
- A data structure uses a collection of related variables that can be accessed individually or as a whole. In other words, a data structure represents a set of data items that share a specific relationship. We discussed three data structures in this chapter: arrays, records, and linked lists.
- An array is a sequenced collection of elements normally of the same data type. We use indexes to refer to the elements of an array. In an array we have two types of identifiers: the name of the array and the name of each individual element.
- Many applications require that data is stored in more than one dimension. One common example is a table, which is an array that consists of rows and columns. Two-dimensional arrays can be stored in memory using either row-major or column-major storage. The first is more common.
- The common operations on arrays as a structure are searching, insertion, deletion, retrieval, and traversal. An array is a suitable structure in applications where the number of deletions and insertions is small but a lot of searching and retrieval operations are required. An array is normally a static data structure and so is more suitable when the number of data items is fixed.
- A record is a collection of related elements, possibly of different types, having a single name. Each element in a record is called a field. A field is the smallest element of named data that has meaning in a record.
- A string is a set of characters that is treated like an array in some languages and as a type in others.
- A linked list is a collection of data in which each element contains the location of the next element; that is, each element contains two parts: data and link. The data part holds the useful information: the data to be processed. The link is used to chain the data together.
- The same operations defined for an array can be applied to a linked list. A linked list is a very efficient structure for data that will go through many insertions and deletions. A linked list is a dynamic data structure in which the list can start with no nodes and grow as new nodes are needed.

## 11.5 PRACTICE SET

### 11.5.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 11.5.2 Review questions
1. Name three types of data structures.
2. How is an element in an array different from an element in a record?
3. How is an element in an array different from an element in a linked list?
4. Why should we use indexes rather than subscripts to identify array elements?
5. How are the elements of an array stored in memory?
6. What is the definition of a field in a record?
7. What are the fields of a node in a linked list?
8. What is the function of the pointer in a linked list?
9. How do you point to the first node in a linked list?
10. What is the value of the link field in the last node of a linked list?

### 11.5.3 Problems
1. There are two arrays, A and B, each of 10 integers. Write an algorithm that tests if every element of array A is equal to its corresponding element in array B.
2. Write an algorithm that reverses the elements of an array so that the last element becomes the first, the second to the last becomes the second, and so forth.
3. Write an algorithm to print the contents of a two-dimensional array of R rows and C columns.
4. Write an algorithm to apply sequential search on an array of N elements.
5. Write an algorithm to apply binary search on an array of N elements.
6. Write an algorithm to insert an element into a sorted array. The algorithm must call a search algorithm to find the location for insertion.
7. Write an algorithm to delete an element in a sorted array. The algorithm must call a search algorithm to find the location of insertion.
8. Write an algorithm to multiply each element of an array by a constant.
9. Write an algorithm to add a fraction (Fr1) to another fraction (Fr2).
10. Write an algorithm to subtract a fraction (Fr1) from another fraction (Fr2).
11. Write an algorithm to multiply a fraction (Fr1) by another fraction (Fr2).
12. Write an algorithm to divide a fraction (Fr1) by another fraction (Fr2).
13. Draw a diagram to show a linked list in which the data part is a student record with three fields: id, name, and grade.
14. Show how the delete algorithm for a linked list (Algorithm 11.4, in section 11.3.3) can delete the only node in a linked list.
15. Show how the insertion algorithm for a linked list (Algorithm 11.3, in section 11.3.3) can add a node to an empty linked list.
16. Show how we can build a linked list from scratch using the insertion algorithm (Algorithm 11.3, in section 11.3.3).
17. Write an algorithm to find the average of the numbers in a linked list of numbers.
18. Show what happens if we apply the following statements to the linked list in Figure 11.9.
   \`scores ← (*scores).link\`
19. Show what happens if we apply the following statements to the linked list in Figure 11.13.
   \`cur ← (*cur).link\` and \`pre ← (*pre).link\`
`,zh:`
# 第十一章：資料結構

在前面的章節中，我們使用了儲存單個實體的變數。雖然單一變數在程式語言中被廣泛使用，但它們無法有效地解決複雜的問題。在本章中，我們介紹資料結構。本章是下一章的序幕，在下一章我們將介紹抽象資料型別（ADT）。

**資料結構**使用一組相關的變數，這些變數可以單獨存取，也可以作為一個整體存取。換句話說，資料結構代表一組共享特定關係的資料項目。我們在本章討論三種資料結構：*陣列*、*記錄*和*鏈結串列*。大多數程式語言都對前兩者有隱含的實作。然而，第三種是使用指標和記錄來模擬的。

## 學習目標
學完本章後，學生應能：
- 定義資料結構。
- 定義陣列為一種資料結構以及如何使用它來儲存資料項目列表。
- 區分陣列名稱和陣列中元素名稱。
- 描述為陣列定義的操作。
- 定義記錄為一種資料結構以及如何使用它來儲存屬於單個資料元素的屬性。
- 區分記錄名稱及其欄位名稱。
- 定義鏈結串列為一種資料結構以及如何使用指標來實作它。
- 描述為鏈結串列定義的操作。
- 比較和對比陣列、記錄和鏈結串列。
- 定義陣列、記錄和鏈結串列的應用。

## 11.1 陣列
想像我們有 100 個分數。我們需要讀取它們，處理它們，並列印它們。我們還必須在程式執行期間將這 100 個分數保留在記憶體中。我們可以定義一百個變數，每個變數都有不同的名稱，如圖 11.1 所示。

但是擁有 100 個不同的名稱會產生其他問題。我們需要 100 個引用來讀取它們，100 個引用來處理它們，以及 100 個引用來寫入它們。圖 11.2 顯示了一個說明此問題的圖表。

即使處理這相對較少的分數，我們需要的指令數量也是不可接受的。為了處理大量資料，我們需要像陣列這樣的資料結構。

**陣列**是相同資料類型元素的序列集合。我們可以將陣列中的元素稱為第一個元素、第二個元素，依此類推，直到最後一個元素。如果我們將 100 個分數放入一個陣列中，我們可以將元素指定為 scores[1]、scores[2] 等等。**索引**表示元素的序數，從陣列的開頭開始計數。陣列的元素是通過其下標單獨定址的（圖 11.3）。陣列作為一個整體有一個名稱，*scores*，但每個分數都可以使用其下標單獨存取。

我們可以使用迴圈來讀取和寫入陣列中的元素。我們還可以使用迴圈來處理元素。現在不管是要處理 100、1000 還是 10000 個元素都沒有關係——迴圈使處理它們變得容易。我們可以使用一個整數變數來控制迴圈，只要該變數的值小於陣列中元素的總數，就保持在迴圈中（圖 11.4）。

我們使用了從 1 開始的索引；一些現代語言如 C、C++ 和 Java 從 0 開始索引。

> **範例 11.1**
> 比較圖 11.2 中處理 100 個單獨元素和圖 11.4 中處理 100 個元素的陣列所需的指令數量。假設處理每個分數只需要一個指令。
>
> **解答**
> - 在第一種情況下，我們需要 100 個指令來讀取，100 個指令來寫入，以及 100 個指令來處理。總共是 300 個指令。
> - 在第二種情況下，我們有三個迴圈。在每個迴圈中我們有兩個指令，總共六個指令。然而，我們還需要三個指令來初始化索引，以及三個指令來檢查索引的值。總共，我們有 12 個指令。

> **範例 11.2**
> 如果我們使用陣列，電腦需要執行的週期數（提取、解碼和執行階段）並不會減少。週期數實際上增加了，因為我們有初始化、遞增和測試索引值的額外開銷。但我們關注的不是週期數：而是我們編寫程式所需的行數。

> **範例 11.3**
> 在電腦科學中，最大的問題之一是程式的可重用性——例如，如果資料項目的數量發生變化，需要更改多少。假設我們編寫了兩個程式來處理分數，如圖 11.2 和圖 11.4 所示。如果分數數量從 100 變為 1000，我們需要在每個程式中進行多少更改？
> 在第一個程式中，我們需要增加 3 × 900 = 2700 個指令。在第二個程式中，我們只需要更改三個條件（I > 100 改為 I > 1000）。我們實際上可以修改圖 11.4 中的圖表，將更改次數減少到一次。

### 11.1.1 陣列名稱與元素名稱
在陣列中，我們有兩種類型的識別碼：陣列的名稱和每個單獨元素的名稱。陣列的名稱是整個結構的名稱，而元素的名稱允許我們引用該元素。在圖 11.3 的陣列中，陣列的名稱是 *scores*，每個元素的名稱是陣列名稱後跟索引，例如 scores[1]、scores[2] 等等。在本章中，我們主要需要元素的名稱，但在某些語言中，如 C，我們也需要使用陣列的名稱。

### 11.1.2 多維陣列
到目前為止討論的陣列被稱為**一維陣列**，因為資料僅在一個方向上線性組織。許多應用程式要求資料儲存在多個維度中。一個常見的例子是表格，它是一個由列和行組成的陣列。圖 11.5 顯示了一個表格，通常稱為**二維陣列**。

圖 11.5 中顯示的陣列保存了一個班級學生的分數。班上有五名學生，每名學生有四個不同的測驗分數。變數 scores[2][3] 顯示了第二名學生在第三次測驗中的分數。將分數排列在二維陣列中可以幫助老師找到每位學生的平均分數（列值的平均值）和每次測驗的平均分數（行值的平均值），以及所有測驗的平均值（整個表格的平均值）。

**多維陣列**——具有超過兩個維度的陣列——也是可能的。然而，我們在本書中不討論超過二維的陣列。

### 11.1.3 記憶體佈局
一維陣列中的索引直接定義了元素在實際記憶體中的相對位置。然而，二維陣列代表列和行。每個元素如何儲存在記憶體中取決於電腦。大多數電腦使用**以列為主 (row-major) 的儲存**，其中陣列的一整列在下一列之前儲存在記憶體中。然而，電腦可以使用**以行為主 (column-major) 的儲存**來儲存陣列，其中整行在下一行之前儲存。圖 11.6 顯示了一個二維陣列以及它是如何使用以列為主或以行為主的儲存方式儲存在記憶體中的。以列為主的儲存更為常見。

> **範例 11.4**
> 我們已將二維陣列 *students* 儲存在記憶體中。陣列是 100 × 4（100 列和 4 行）。假設元素 *student*[1][1] 儲存在位址 1000 的記憶體位置，且每個元素只佔用一個記憶體位置，顯示元素 *students*[5][3] 的位址。電腦使用以列為主的儲存。
>
> **解答**
> 我們可以使用以下公式找到元素的位置，假設每個元素佔用一個記憶體位置：
> $y = x + \\text{Cols} \\times (i - 1) + (j - 1)$
> 其中 $x$ 定義起始位址，Cols 定義陣列中的行數，$i$ 定義元素的列號，$j$ 定義元素的行號，$y$ 是我們要尋找的位址。在我們的例子中，$x$ 是 1000，Cols 是 4，$i$ 是 5，$j$ 是 3。我們正在尋找 $y$ 的值：
> $y = x + \\text{Cols} \\times (i - 1) + (j - 1) = 1000 + 4(5 - 1) + (3 - 1) = 1018$
> 這個答案是有道理的，因為元素位於第 5 列第 3 行。在此元素之前有四列，佔用 16 (4 × 4) 個記憶體位置。第 5 列的前兩個元素也佔用了兩個記憶體位置。這意味著目標元素之前的所有元素佔用了 18 個記憶體位置。如果第一個元素佔用位置 1000，則目標元素佔用位置 1018。

### 11.1.4 陣列上的操作
雖然我們可以應用為陣列每個元素定義的常規操作（見第 4 章），但有些操作我們可以定義在作為資料結構的陣列上。陣列作為結構的常見操作是*搜尋*、*插入*、*刪除*、*檢索*和*遍歷*。

**搜尋元素**
當我們知道值時，我們經常需要找到元素的索引。這種類型的搜尋在第 8 章中討論過。我們可以對未排序的陣列使用循序搜尋，或對已排序的陣列使用二元搜尋。搜尋用於接下來的三個操作。

**插入元素**
傳統上，電腦語言要求在編寫程式時定義陣列的大小（陣列中的元素數量），並防止在程式執行期間更改它。最近，一些語言允許變長陣列。即使語言允許變長陣列，將元素插入陣列也需要仔細注意。

**在末尾插入**
如果插入是在陣列的末尾，並且語言允許我們增加陣列的大小，這可以很容易地完成。例如，如果一個陣列有 30 個元素，我們將陣列的大小增加到 31，並將新項目作為第 31 個項目插入。

**在開頭或中間插入**
如果插入要在陣列的開頭或中間進行，過程是漫長且耗時的。當我們需要在已排序的陣列中插入元素時，就會發生這種情況。我們首先搜尋陣列，如前所述。找到插入位置後，我們插入新元素。例如，如果我們想在 30 個元素的陣列中插入一個元素作為第 9 個元素，則第 9 到第 30 個元素應向陣列末尾移動一個位置，以便在位置 9 打開一個空元素進行插入。以下顯示了需要應用於陣列的部分偽代碼：

\`\`\`
i ← 30
while (i ≥ 9)
{
    array [i + 1] ← array [i]
    i ← i - 1
}
array [i] ← newValue
\`\`\`

請注意，移動需要從陣列的末尾進行，以防止丟失元素的值。代碼首先將第 30 個元素的值複製到第 31 個元素，然後將第 29 個元素的值複製到第 30 個元素，依此類推。當代碼跳出迴圈時，第 9 個元素已經複製到第 10 個元素。最後一行將新項目的值複製到第 9 個元素中。

**刪除元素**
刪除陣列中的元素與插入一樣漫長且複雜。例如，如果應該刪除第九個元素，我們需要將第 10 到第 30 個元素向陣列的開始方向移動一個位置。我們將此操作的偽代碼留作練習，它與添加元素的偽代碼類似。

**檢索元素**
檢索意味著為了檢查或複製元素中包含的資料而隨機存取一個元素。與插入和刪除操作不同，當資料結構是陣列時，檢索是一個簡單的操作。事實上，陣列是一個*隨機存取結構*，這意味著陣列的每個元素都可以隨機存取，而無需存取它之前或之後的元素。例如，如果我們想檢索陣列中第 9 個元素的值，我們可以使用單個指令來完成，如下所示：

\`\`\`
RetrievedValue ← array[9]
\`\`\`

**遍歷陣列**
陣列遍歷是指應用於陣列所有元素的操作，例如讀取、寫入、應用數學運算等等。

演算法 11.1 給出了一個範例，用於找出元素為實數的陣列中元素的平均值。演算法首先使用迴圈找出元素的總和。迴圈終止後，計算平均值，即總和除以元素數量。請注意，為了正確計算總和，需要在迴圈之前將總和設定為 0.0。

**演算法 11.1 計算陣列中元素的平均值**
\`\`\`
演算法：ArrayAverage (Array, n)
目的：找出平均值
前置條件：給定陣列 Array 和元素數量 n。
後置條件：無
回傳：平均值
{
    sum ← 0.0
    i ← 1
    while (i ≤ n)
    {
        sum ← sum + Array [i]
        i ← i + 1
    }
    average ← sum / n
    Return ( average )
}
\`\`\`

### 11.1.5 字串
**字串**作為一組字元，在不同的語言中處理方式不同。在 C 中，字串是字元陣列。在 C++ 中，字串可以是字元陣列，但有一個名為 string 的類型。在 Java 中，字串是一種類型。

### 11.1.6 應用
思考上一節討論的操作可以為陣列的應用提供線索。如果我們有一個列表，在創建原始列表後預計會有大量的插入和刪除，我們就不應該使用陣列。當刪除和插入的數量很少，但預計會有大量的*搜尋*和*檢索*活動時，陣列更合適。

**當需要少量的插入和刪除，但需要大量的搜尋和檢索時，陣列是一個合適的結構。**

## 11.2 記錄
**記錄**是相關元素的集合，可能具有不同的類型，擁有單一名稱。記錄中的每個元素稱為**欄位**。欄位是具有意義的命名資料的最小元素。欄位具有類型，並存在於記憶體中。可以為欄位賦值，進而可以存取這些值進行選擇或操作。欄位與變數的主要區別在於它是記錄的一部分。

圖 11.7 包含兩個記錄範例。第一個範例 *fraction* 有兩個欄位，都是整數。第二個範例 *student* 有三個由三種不同類型組成的欄位。

**記錄中的元素可以是相同或不同的類型，但記錄中的所有元素必須相關。**

記錄中的資料應該都與一個物件相關。在圖 11.7 中，分數中的整數都屬於同一個分數，第二個範例中的資料都與一名學生有關。（請注意，我們將字串資料放在雙引號之間，單個字元放在單引號之間。這是大多數程式語言中使用的慣例。）

### 11.2.1 記錄名稱與欄位名稱
就像在陣列中一樣，我們在記錄中有兩種類型的識別碼：記錄的名稱和記錄內每個單獨欄位的名稱。記錄的名稱是整個結構的名稱，而每個欄位的名稱允許我們引用該欄位。例如，在圖 11.7 的學生記錄中，記錄的名稱是 *student*，欄位的名稱是 *student.id*、*student.name* 和 *student.grade*。大多數程式語言使用句點 (.) 來分隔結構（記錄）的名稱與其組件（欄位）的名稱。這是我們在本書中使用的慣例。

> **範例 11.5**
> 以下顯示圖 11.7 中欄位的值是如何儲存的：
> \`student.id ← 2005\` \`student.name ← "G. Boole"\` \`student.grade ← 'A'\`

### 11.2.2 記錄和陣列的比較
我們可以概念性地比較陣列和記錄。這有助於我們理解何時應該使用陣列，何時應該使用記錄。陣列定義了元素的組合，而記錄定義了元素的可識別部分。例如，陣列可以定義一個班級的學生（40 名學生），但記錄定義了學生的不同屬性，如 id、姓名或成績。

### 11.2.3 記錄陣列
如果我們需要定義元素的組合，同時定義每個元素的一些屬性，我們可以使用記錄陣列。例如，在一個 30 名學生的班級中，我們可以有一個包含 30 個記錄的陣列，每個記錄代表一名學生。圖 11.8 顯示了一個名為 *students* 的 30 個學生記錄的陣列。

在記錄陣列中，陣列的名稱定義了整個結構，即學生群體。要定義每個元素，我們需要使用相應的索引。要定義每個元素的部分（屬性），我們需要使用點運算子。換句話說，首先我們需要定義元素，然後我們可以定義該元素的一部分。因此，第三名學生的 id 定義為：
\`(student[3]).id\`

請注意，我們使用括號來強調首先應該選擇特定學生，然後是該學生的 id。換句話說，括號告訴我們索引運算子的優先順序高於點運算子。在某些語言中，不需要使用括號，因為優先順序已經在語言本身中建立，但使用括號總是能保證優先順序。

> **範例 11.6**
> 以下顯示我們如何存取 students 陣列中每個記錄的欄位以在其中儲存值。
> \`(students[1]).id ← 1001 (students[1]).name ← "J. Aron" (students[1]).grade ← 'A'\`
> \`(students[2]).id ← 2007 (students[2]).name ← "F. Bush" (students[2]).grade ← 'F'\`
> ...
> \`(students[30]).id ← 3012 (students[30]).name ← "M. Blair" (students[30]).grade ← 'B'\`

> **範例 11.7**
> 然而，我們通常使用迴圈將資料讀入記錄陣列。演算法 11.2 顯示了此過程的部分偽代碼。

**演算法 11.2 讀取學生記錄的部分偽代碼**
\`\`\`
i ← 1
while (i < 31)
{
    read (students [i]).id
    read (students [i]).name
    read (students [i]).grade
    i ← i + 1
}
\`\`\`

### 11.2.4 陣列與記錄陣列
陣列和記錄陣列都代表項目列表。陣列可以被認為是記錄陣列的一種特殊情況，其中每個元素是只有一個欄位的記錄。

## 11.3 鏈結串列
**鏈結串列**是資料的集合，其中每個元素包含下一個元素的位置——也就是說，每個元素包含兩個部分：資料和連結。資料部分保存值資訊：要處理的資料。連結用於將資料鏈接在一起，並包含一個**指標**（位址），該指標標識列表中的下一個元素。此外，一個指標變數標識列表中的第一個元素。列表的名稱與此指標變數的名稱相同。

圖 11.9 顯示了一個名為 *scores* 的鏈結串列，其中包含四個元素。除了最後一個元素外，每個元素中的連結都指向其後繼者。最後一個元素中的連結包含一個**空指標 (null pointer)**，表示列表的結束。我們將空鏈結串列定義為僅一個空指標：圖 11.9 也顯示了一個空鏈結串列的例子。

鏈結串列中的元素傳統上稱為節點。鏈結串列中的**節點**是一個至少有兩個欄位的記錄：一個包含資料，另一個包含序列中下一個節點的位址（連結）。圖 11.9 也顯示了一個節點。

在進一步討論鏈結串列之前，我們需要解釋我們在圖中使用的符號。我們使用一條線顯示兩個節點之間的連接。線的一端有一個箭頭，另一端有一個實心圓。箭頭代表箭頭指向的節點位址的副本。實心圓顯示此位址副本儲存的位置（圖 11.10）。該圖還顯示我們可以將位址副本儲存在多個位置。例如，圖 11.10 顯示兩個位址副本儲存在兩個不同的位置。理解這些概念有助於我們更好地理解鏈結串列上的操作。

### 11.3.1 陣列與鏈結串列
陣列和鏈結串列都是記憶體中項目列表的表示形式。唯一的區別在於項目鏈接在一起的方式。在記錄陣列中，*鏈接工具*是索引。元素 scores[3] 鏈接到元素 scores[4]，因為整數 4 在整數 3 之後。在鏈結串列中，*鏈接工具*是指向下一個元素的連結——指標或下一個元素的位址。圖 11.11 比較了五個整數列表的兩種表示形式。

陣列的元素在記憶體中一個接一個地儲存，中間沒有間隙：列表是連續的。鏈結串列的節點可以儲存為中間有間隙：節點的連結部分將項目「黏」在一起。換句話說，電腦可以選擇將它們連續儲存或將節點分散在整個記憶體中。這有一個優點：鏈結串列中的插入和刪除要容易得多。唯一需要更改的是指向下一個元素位址的指標。然而，這也帶來了開銷：鏈結串列的每個節點都有一個額外的欄位，即記憶體中下一個節點的位址。

### 11.3.2 鏈結串列名稱與節點名稱
對於陣列和記錄，我們需要區分鏈結串列的名稱和節點（鏈結串列的元素）的名稱。鏈結串列必須有一個名稱。鏈結串列的名稱是指向列表第一個節點的頭指標的名稱。另一方面，節點在鏈結串列中沒有顯式名稱，只有隱含名稱。節點的名稱與指向該節點的指標名稱有關。不同的語言以不同的方式處理指標與指標所指向的節點之間的關係。我們使用 C 語言中使用的慣例。例如，如果指向節點的指標稱為 p，我們稱該節點為 *p。由於節點是一個記錄，我們可以使用節點的名稱存取節點內部的欄位。例如，由指標 p 指向的節點的資料部分和連結部分可以稱為 (*p).data 和 (*p).link。這種命名慣例意味著一個節點可以有多個名稱。圖 11.12 顯示了鏈結串列的名稱和節點的名稱。

### 11.3.3 鏈結串列上的操作
我們為陣列定義的相同操作可以應用於鏈結串列。

**搜尋鏈結串列**
鏈結串列的搜尋演算法只能是循序的（見第 8 章），因為鏈結串列中的節點沒有特定名稱（不像陣列中的元素），無法使用二元搜尋找到。然而，由於鏈結串列中的節點沒有名稱，我們使用兩個指標，*pre*（前一個）和 *cur*（當前）。

在搜尋開始時，*pre* 指標為空，*cur* 指標指向第一個節點。搜尋演算法將兩個指標一起向列表末尾移動。圖 11.13 顯示了這兩個指標在極端情況下的移動：當目標值大於列表中的任何值時。例如，在五個節點的列表中，假設我們的目標值是 220，它大於列表中的任何值。

然而，可能會發生其他情況。目標值可能小於第一個節點中的資料值，或者它可能等於其中一個節點中的資料值，依此類推。然而，在所有情況下，當搜尋停止時，*cur* 指標指向停止搜尋的節點，*pre* 指標指向前一個節點。如果找到目標，*cur* 指標指向保存目標值的節點。如果未找到目標值，*cur* 指標指向值大於目標值的節點。換句話說，由於列表是已排序的，並且可能很長，如果我們確定已經過了目標值，我們絕不允許兩個指標到達列表的末尾。搜尋演算法使用一個旗標（一個只能取 *true* 或 *false* 值的變數）。當找到目標時，旗標設定為 *true*：當未找到目標時，旗標設定為 *false*。當旗標為 *true* 時，*cur* 指標指向目標值：當旗標為 *false* 時，*cur* 指標指向大於目標值的數值。

圖 11.14 顯示了一些不同的情況。在第一種情況下，目標是 98。此值在列表中不存在，且小於列表中的任何值，因此搜尋演算法在 *pre* 為空且 *cur* 指向第一個節點時停止。旗標的值為 *false*，因為未找到該值。在第二種情況下，目標是 132，這是第二個節點的值。搜尋演算法在 *cur* 指向第二個節點且 *pre* 指向第一個節點時停止。旗標的值為 *true*，因為找到了目標。在第三和第四種情況下，未找到目標，因此旗標的值為 *false*。

演算法 11.3 顯示了一個簡化的搜尋演算法。我們需要在 *while* 迴圈上增加更多條件，但我們將其留給鏈結串列的更進階討論。請注意我們如何將兩個指標一起向前移動。在每次移動中，我們有：

\`pre ← cur\` 和 \`cur ← (*cur).link\`

這保證了兩個指標一起移動。第一個賦值製作 *cur* 的副本並將其儲存在 *pre* 中。這意味著 *pre* 正在獲取 *cur* 的先前值。在第二個賦值中，選擇由 *cur* 指向的節點，並將其連結欄位的值複製並儲存在 *cur* 中（見圖 11.12 進行說明）。搜尋演算法由插入演算法（如果未找到目標）和刪除演算法（如果找到目標）使用。

**演算法 11.3 搜尋鏈結串列**
\`\`\`
演算法：SearchLinkedList
目的：使用兩個指標 pre 和 cur 搜尋列表。
前置條件：鏈結串列（頭指標）和目標值
後置條件：無
回傳：pre 和 cur 指標的位置以及旗標的值
{
    pre ← null
    cur ← list
    while (target < (*cur).data)
    {
        pre ← cur
        cur ← (*cur).link
    }
    if ((*cur).data = target) flag ← true
    else flag ← false
}
\`\`\`

**插入節點**
在插入鏈結串列之前，我們先應用搜尋演算法。如果搜尋演算法回傳的旗標為 false，我們將允許插入，否則我們中止插入演算法，因為我們不允許有重複值的資料。可能會出現四種情況：
- 插入空列表。
- 在列表開頭插入。
- 在列表末尾插入。
- 在列表由間插入。

**插入空列表**
如果列表為空（list = null），新項目將作為第一個元素插入。一個語句可以完成這項工作：
\`list ← new\`

**在開頭插入**
如果搜尋演算法回傳值為 *false* 的旗標且 *pre* 指標的值為空，則需要在列表開頭插入資料。需要兩個語句來完成這項工作：
\`(*new).link ← cur\` 和 \`list ← new\`
第一個賦值使新節點成為先前第一個節點的前驅。第二個語句使新連接的節點成為第一個節點。圖 11.15 顯示了這種情況。

**在末尾插入**
如果搜尋演算法回傳值為 *false* 的旗標且 *cur* 指標的值為空，則需要在列表末尾插入資料。需要兩個語句來完成這項工作：
\`(*pre).link ← new\` 和 \`(*new).link ← null\`
第一個賦值將新節點連接到先前的最後一個節點。第二個語句使新連接的節點成為最後一個節點。圖 11.16 顯示了這種情況。

**在中間插入**
如果搜尋演算法回傳值為 *false* 的旗標且回傳的指標都不為空，則需要在列表由間插入新資料。需要兩個語句來完成這項工作：
\`(*new).link ← cur\` 和 \`(*pre).link ← new\`
第一個賦值將新節點連接到其後繼者。第二個語句將新節點連接到其前驅。圖 11.17 顯示了這種情況。

演算法 11.4 顯示了在鏈結串列中插入新節點的偽代碼。第一部分只是將節點添加到空列表。

**演算法 11.4 在鏈結串列中插入節點**
\`\`\`
演算法：InsertLinkedList (list, target, new)
目的：在搜尋列表後在鏈結串列中插入節點
前置條件：鏈結串列和要插入的目標資料
後置條件：無
回傳：新的鏈結串列
{
    searchlinkedlist (list, target, pre, cur, flag)
    // 給定目標並回傳 pre, cur 和 flag
    if (flag = true) // 無重複
    {
        return list
    }
    if (list = null // 插入空列表
    {
        list ← new
    }
    if (pre = null) // 在開頭插入
    {
        (*new).link ← cur
        list ← new
        return list
    }
    if (cur = null) // 在末尾插入
    {
        (*pre).link ← new
        (*new).link ← null
        return list
    }
    (*new).link ← cur // 在中間插入
    (*pre).link ← new
    return list
}
\`\`\`

**刪除節點**
在刪除鏈結串列中的節點之前，我們應用搜尋演算法。如果搜尋演算法回傳的旗標為真（找到節點），我們可以從鏈結串列中刪除該節點。然而，刪除比插入簡單：我們只有兩種情況——刪除第一個節點和刪除任何其他節點。換句話說，最後一個和中間節點的刪除可以通過相同的過程完成。

**刪除第一個節點**
如果 *pre* 指標為空，則要刪除的是第一個節點。*cur* 指標指向第一個節點，刪除可以通過一個語句完成：
\`list ← (*cur).link\`
該語句將第二個節點連接到列表指標，這意味著第一個節點被刪除。圖 11.18 顯示了這種情況。

**刪除中間或最後一個節點**
如果兩個指標都不為空，則要刪除的節點是中間節點或最後一個節點。*cur* 指標指向相應的節點，刪除可以通過一個語句完成：
\`(*pre).link ← (*cur).link\`
該語句將後繼節點連接到前驅節點，這意味著當前節點被刪除。圖 11.19 顯示了這種情況。

演算法 11.5 顯示了刪除節點的偽代碼。該演算法比插入演算法簡單得多。我們只有兩種情況，每種情況只需要一個語句。

**演算法 11.5 在鏈結串列中刪除節點**
\`\`\`
演算法：DeleteLinkedList (list, target)
目的：在搜尋列表找到正確節點後刪除鏈結串列中的節點
前置條件：鏈結串列和要刪除的目標資料
後置條件：無
回傳：新的鏈結串列
{
    // 給定目標並回傳 pre, cur 和 flag
    searchlinkedlist (list, target, pre, cur, flag)
    if (flag = false)
    {
        return list // 未找到要刪除的節點
    }
    if (pre = null) // 刪除第一個節點
    {
        list ← (*cur).link
        return list
    }
    (*pre).link ← (*cur).link // 刪除其他節點
    return list
}
\`\`\`

**檢索節點**
檢索意味著隨機存取節點以檢查或複製節點中包含的資料。在檢索之前，需要搜尋鏈結串列。如果找到資料項目，則檢索它，否則中止該過程。檢索僅使用 *cur* 指標，該指標指向搜尋演算法找到的節點。演算法 11.6 顯示了檢索節點中資料的偽代碼。該演算法比插入或刪除演算法簡單得多。

**演算法 11.6 在鏈結串列中檢索節點**
\`\`\`
演算法：RetrieveLinkedList (list, target)
目的：在搜尋列表找到正確節點後檢索節點中的資料
前置條件：鏈結串列（頭指標）和目標（要檢索的資料）
後置條件：無
回傳：回傳檢索到的資料
{
    searchlinkedlist (list, target, pre, cur, flag)
    if (flag = false) // 未找到節點
    {
        return error
    }
    return (*cur).data
}
\`\`\`

**遍歷鏈結串列**
要遍歷列表，我們需要一個「行走」指標，這是一個在處理每個元素時從一個節點移動到另一個節點的指標。我們通過將行走指標設定為列表中的第一個節點來開始遍歷。然後，使用迴圈，我們繼續直到處理完所有資料。迴圈的每次迭代處理當前節點，然後將行走指標推進到下一個節點。當處理完最後一個節點時，行走指標變為空，迴圈終止（圖 11.20）。

演算法 11.7 顯示了遍歷鏈結串列的偽代碼。

**演算法 11.7 遍歷鏈結串列**
\`\`\`
演算法：TraverseLinkedList (list)
目的：遍歷鏈結串列並處理每個資料項目
前置條件：鏈結串列（頭指標）
後置條件：無
回傳：列表
{
    walker ← list
    while (walker ≠ null)
    {
        Process (*walker).data
        walker ← (*walker).link
    }
    return list
}
\`\`\`

### 11.3.4 鏈結串列的應用
鏈結串列是一種非常有效的資料結構，用於儲存將經歷許多插入和刪除的資料。鏈結串列是一種動態資料結構，列表可以從沒有節點開始，然後隨著需要新節點而增長。可以輕鬆刪除節點而無需移動其他節點，而在陣列中則需要這樣做。例如，鏈結串列可用於保存學校學生的記錄。每個季度或學期，新學生入學，一些學生離開或畢業。

鏈結串列可以無限增長，也可以縮小到空列表。開銷是為每個節點保留一個額外的欄位。然而，對於必須經常搜尋的資料，鏈結串列不是一個好的候選者。這似乎是一個兩難境地，因為每次刪除或插入都需要搜尋。我們將看到，下一章討論的一些抽象資料型別具有陣列搜尋的優點和鏈結串列插入和刪除的優點。

**如果需要大量的插入和刪除，鏈結串列是一個合適的結構，但搜尋鏈結串列比搜尋陣列慢。**

## 11.4 章末材料

### 11.4.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Gilberg, R. and Forouzan, B. *Data Structures – A Pseudocode Approach with C*, Boston, MA: Course Technology, 2005
- Goodrich, M. and Tamassia, R. *Data Structures and Algorithms in Java*, New York: Wiley, 2005
- Neapolitan, R. and Naimipour, K. *Foundations of Algorithms Using C++ Pseudocode*, Sudbury, MA: Jones and Bartlett, 2004
- Main, M. and Savitch, W. *Data Structures and Other Objects Using C++*, Reading, MA: Addison-Wesley, 2004
- Standish, T. *Data Structures, Algorithms, and Software Principles*, Reading, MA: Addison-Wesley, 1994

### 11.4.2 關鍵詞
- 陣列 (array)
- 以行為主儲存 (column-major storage)
- 資料結構 (data structure)
- 欄位 (field)
- 索引 (index)
- 連結 (link)
- 鏈結串列 (linked list)
- 多維陣列 (multidimensional array)
- 節點 (node)
- 空指標 (null pointer)
- 一維陣列 (one-dimensional array)
- 指標 (pointer)
- 記錄 (record)
- 檢索 (retrieval)
- 以列為主儲存 (row-major storage)
- 搜尋 (searching)
- 二維陣列 (two-dimensional array)
- 字串 (string)

### 11.4.3 摘要
- 資料結構使用一組相關的變數，這些變數可以單獨存取，也可以作為一個整體存取。換句話說，資料結構代表一組共享特定關係的資料項目。我們在本章討論了三種資料結構：陣列、記錄和鏈結串列。
- 陣列是通常具有相同資料類型的元素的序列集合。我們使用索引來引用陣列的元素。在陣列中，我們有兩種類型的識別碼：陣列的名稱和每個單獨元素的名稱。
- 許多應用程式要求資料儲存在多個維度中。一個常見的例子是表格，它是一個由列和行組成的陣列。二維陣列可以使用以列為主或以行為主的儲存方式儲存在記憶體中。第一種更常見。
- 陣列作為結構的常見操作是搜尋、插入、刪除、檢索和遍歷。在刪除和插入次數較少但需要大量搜尋和檢索操作的應用中，陣列是一個合適的結構。陣列通常是一個靜態資料結構，因此當資料項目數量固定時更合適。
- 記錄是相關元素的集合，可能具有不同的類型，擁有單一名稱。記錄中的每個元素稱為欄位。欄位是記錄中具有意義的命名資料的最小元素。
- 字串是一組字元，在某些語言中被視為陣列，在其他語言中被視為一種類型。
- 鏈結串列是資料的集合，其中每個元素包含下一個元素的位置；也就是說，每個元素包含兩個部分：資料和連結。資料部分保存有用的資訊：要處理的資料。連結用於將資料鏈接在一起。
- 為陣列定義的相同操作可以應用於鏈結串列。鏈結串列是一種非常有效的結構，適用於將經歷許多插入和刪除的資料。鏈結串列是一種動態資料結構，列表可以從沒有節點開始，並隨著需要新節點而增長。

## 11.5 練習題

### 11.5.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 11.5.2 複習問題
1. 說出三種資料結構的名稱。
2. 陣列中的元素與記錄中的元素有何不同？
3. 陣列中的元素與鏈結串列中的元素有何不同？
4. 為什麼我們應該使用索引而不是下標來識別陣列元素？
5. 陣列的元素如何儲存在記憶體中？
6. 記錄中欄位的定義是什麼？
7. 鏈結串列中節點的欄位是什麼？
8. 鏈結串列中指標的功能是什麼？
9. 你如何指向鏈結串列中的第一個節點？
10. 鏈結串列中最後一個節點的連結欄位的值是什麼？

### 11.5.3 問題
1. 有兩個陣列 A 和 B，每個都有 10 個整數。編寫一個演算法，測試陣列 A 的每個元素是否等於陣列 B 中的對應元素。
2. 編寫一個演算法，反轉陣列的元素，使最後一個元素成為第一個，倒數第二個成為第二個，依此類推。
3. 編寫一個演算法來列印 R 列 C 行的二維陣列的內容。
4. 編寫一個演算法，對 N 個元素的陣列應用循序搜尋。
5. 編寫一個演算法，對 N 個元素的陣列應用二元搜尋。
6. 編寫一個演算法，將一個元素插入已排序的陣列中。該演算法必須呼叫搜尋演算法以找到插入位置。
7. 編寫一個演算法，刪除已排序陣列中的一個元素。該演算法必須呼叫搜尋演算法以找到插入位置。
8. 編寫一個演算法，將陣列的每個元素乘以一個常數。
9. 編寫一個演算法，將一個分數 (Fr1) 加到另一個分數 (Fr2) 上。
10. 編寫一個演算法，從另一個分數 (Fr2) 中減去一個分數 (Fr1)。
11. 編寫一個演算法，將一個分數 (Fr1) 乘以另一個分數 (Fr2)。
12. 編寫一個演算法，將一個分數 (Fr1) 除以另一個分數 (Fr2)。
13. 畫一個圖表來顯示一個鏈結串列，其中資料部分是一個具有三個欄位的學生記錄：id、name 和 grade。
14. 說明鏈結串列的刪除演算法（11.3.3 節中的演算法 11.4）如何刪除鏈結串列中唯一的節點。
15. 說明鏈結串列的插入演算法（11.3.3 節中的演算法 11.3）如何將節點添加到空鏈結串列中。
16. 說明我們如何使用插入演算法（11.3.3 節中的演算法 11.3）從頭開始建立一個鏈結串列。
17. 編寫一個演算法來找出數字鏈結串列中數字的平均值。
18. 說明如果我們對圖 11.9 中的鏈結串列應用以下語句會發生什麼。
   \`scores ← (*scores).link\`
19. 說明如果我們對圖 11.13 中的鏈結串列應用以下語句會發生什麼。
   \`cur ← (*cur).link\` 和 \`pre ← (*pre).link\`
`},u={en:`
# Chapter 12: Abstract Data Types

In this chapter we discuss abstract data types (ADTs), which are data types at a higher level of abstraction than the data structures we discussed in Chapter 11. ADTs use data structures for implementation. We begin this chapter with a brief background on ADTs. We then give a definition and propose a model. The remainder of the chapter discusses various ADTs, such as stacks, queues, general linear lists, trees, binary trees, binary search trees, and graphs.

## Objectives
After studying this chapter, the student should be able to:
- Define the concept of an abstract data type (ADT).
- Define a stack, the basic operations on stacks, their applications, and how they can be implemented.
- Define a queue, the basic operations on queues, their applications, and how they can be implemented.
- Define a general linear list, the basic operations on lists, their applications, and how they can be implemented.
- Define a general tree and its application.
- Define a binary tree—a special kind of tree—and its applications.
- Define a binary search tree (BST) and its applications.
- Define a graph and its applications.

## 12.1 BACKGROUND
Problem solving with a computer means processing data. To process data, we need to define the data type and the operation to be performed on the data. For example, to find the sum of a list of numbers, we should select the type for the number (integer or real) and define the operation (addition). The definition of the data type and the definition of the operation to be applied to the data is part of the idea behind an **abstract data type (ADT)**—to hide how the operation is performed on the data. In other word, the user of an ADT needs only to know that a set of operations are available for the data type, but does not need to know how they are applied.

### 12.1.1 Simple ADTs
Many programming languages already define some simple ADTs as integral parts of the language. For example, the C language defines a simple ADT called an *integer*. The type of this ADT is integer with predefined ranges. C also defines several operations that can be applied on this data type (addition, subtraction, multiplication, division, and so on). C explicitly defines these operations on integers and what we expect as the results. A programmer who writes a C program to add two integers should know about the integer ADT and the operations that can be applied to it.

The programmer, however, does not need to know *how* these operations are actually implemented. For example, the programmer uses the expression $z \\leftarrow x + y$ and expects the value of $x$ (an integer) to be added to the value of $y$ (an integer) and the result to be named $z$ (an integer). The programmer does not need to know how the addition is performed. We learned in previous chapters that the way this addition is done by a computer is to store the two integers in two memory locations in two’s complement format, to load them into the CPU register, to add them in binary, and to store the result back to another memory location. The programmer, however, does not need to know this. An integer in C is a simple abstract data type with predefined operations. How the operations are performed is not a concern for the programmer.

### 12.1.2 Complex ADTs
Although several simple ADTs, such as integer, real, character, pointer, and so on, have been implemented and are available for use in most languages, many useful complex ADTs are not. As we will see in this chapter, we need a list ADT, a stack ADT, a queue ADT, and so on. To be efficient, these ADTs should be created and stored in the library of the computer to be used. The user of a *list*, for example, should only need to know what operations are available for the list, not how these operations are performed.

Therefore, with an ADT, users are not concerned with *how* the task is done, but rather with *what* it can do. In other words, the ADT consists of a set of definitions that allow programmers to use the operation while their implementation is hidden. This generalization of operations with unspecified implementations is known as abstraction. We abstract the essence of the process and leave the implementation details hidden.

**The concept of abstraction means:**
1. **We know what a data type can do.**
2. **How it is done is hidden.**

### 12.1.3 Definition
Let us now define an ADT. An abstract data type is a data type packaged with the operations that are meaningful for the data type. We then encapsulate the data and the operations on the data and hide them from the user.

**Abstract Data Type**
1. **Definition of data**
2. **Definition of operations**
3. **Encapsulation of data and operation**

### 12.1.4 Model for an abstract data type
The ADT model is shown in Figure 12.1. The colored area with an irregular outline represents the ADT. Inside the ADT are two different parts of the model: *data structure* and *operations* (public and private). The application program can only access the public operations through the **interface**. An interface is a list of public operations and data to be passed to or returned from those operations. The private operations are for internal use by the ADT. The data structures, such as arrays and linked lists, are inside the ADT and are used by the public and private operations.

Although the public operations and the interface should be independent of the implementation, the private operations are dependent on the data structures chosen during the implementation of the ADT. We will elaborate on this issue when we discuss some of the ADTs.

### 12.1.5 Implementation
Computer languages do not provide ADT packages. To use an ADT, it is first implemented and kept in a library. The main purpose of this chapter is to introduce some common ADTs and their applications. However, we also give a brief discussion of each ADT implementation for the interested reader. We leave the pseudocode algorithms of the implementations as challenging exercises.

## 12.2 STACKS
A **stack** is a restricted **linear list** in which all additions and deletions are made at one end, the top. If we insert a series of data into a stack and then remove it, the order of the data is reversed. Data input as 5, 10, 15, 20, for example, would be removed as 20, 15, 10, and 5. This reversing attribute is why stacks are known as a **last in, first out (LIFO)** data structure.

We use many different types of stacks in our daily lives. We often talk of a stack of coins or a stack of books. Any situation in which we can only add or remove an object at the top is a stack. If we want to remove an object other than the one at the top, we must first remove all objects above it. Figure 12.2 shows three representations of stacks.

### 12.2.1 Operations on stacks
Although we can define many operations for a stack, there are four basic operations, *stack*, *push*, *pop*, and *empty*, which we define in this chapter.

**The stack operation**
The *stack* operation creates an empty stack. The following shows the format:
\`stack (stackName)\`
*stackName* is the name of the stack to be created. This operation returns an empty stack. Figure 12.3 shows the pictorial representation of this operation.

**The push operation**
The *push* operation inserts an item at the top of the stack. The following shows the format:
\`push (stackName, dataItem)\`
*stackName* is the name of the stack and *dataItem* is the data to be inserted at the top of the stack. After the push operation, the new item becomes the top item in the stack. This operation returns the new stack with *dataItem* inserted at the top. Figure 12.4 shows the pictorial representation of this operation.

**The pop operation**
The *pop* operation deletes the item at the top of the stack. The following shows the format:
\`pop (stackName, dataItem)\`
*stackName* is the name of the stack and *dataItem* is the data that is deleted from the stack. Figure 12.5 shows the pictorial representation of this operation.
The deleted item can be used by the application program or can be just discarded. After the pop operation, the item that was under the top element before the deletion becomes the top element. This operation returns the new stack with one less element.

**The empty operation**
The *empty* operation checks the status of the stack. The following shows the format:
\`empty (stackName)\`
The *stackName* is the name of the stack. This operation returns *true* if the stack is empty and *false* if the stack is not empty.

### 12.2.2 Stack ADT
We define a stack as an ADT as shown below:

**Stack ADT**
**Definition**
A list of data items that can only be accessed at one end, called the top.
**Operations**
*stack*: Creates an empty stack.
*push*: Inserts an element at the top.
*pop*: Deletes the top element.
*empty*: Checks the status of the stack.

> **Example 12.1**
> Figure 12.6 shows a segment of an algorithm that applies the previously defined operations on a stack S. The fourth operation checks the status of the stack before trying to pop the top element. The value of the top element is stored in the variable x. However, we do not use this value: it will be automatically discarded at the end of the algorithm segment.

### 12.2.3 Stack applications
Stack applications can be classified into four broad categories: reversing data, pairing data, postponing data usage, and backtracking steps. We discuss the first two in the sections that follow.

**Reversing data items**
Reversing data items requires that a given set of data items be reordered so that the first and last items are exchanged, with all of the positions between the first and last being relatively exchanged also. For example, the list (2, 4, 7, 1, 6, 8) becomes (8, 6, 1, 7, 4, 2).

> **Example 12.2**
> In Chapter 2 (Figure 2.6 in section 2.2.6) we gave a simple UML diagram to convert an integer from decimal to any base. Although the algorithm is very simple, if we print the digits of the converted integer as they are created, we will get the digits in reverse order. The print instruction in any computer language prints characters from left to right, but the algorithm creates the digits from right to left. We can use the reversing characteristic of a stack (LIFO structure) to solve the problem.
> Algorithm 12.1 shows the pseudocode to convert a decimal integer to binary and print the result.

**Algorithm 12.1 Example 2.2**
\`\`\`
Algorithm: DecimalToBinary (number)
Purpose: Print the binary equivalent of a given integer (absolute value)
Pre: Given the integer to be converted (number)
Post: The binary integer is printed
Return: None
{
    stack (S)
    while (number ≠ 0)
    {
        remainder ← number mod 2
        push (S, remainder)
        number ← number / 2
    }
    while (not empty (S))
    {
        pop (S, x)
        print (x)
    }
    return
}
\`\`\`
We create an empty stack first. Then we use a *while* loop to create the bits, but instead of printing them, we push them into the stack. When all bits are created, we exit the loop. Now we use another loop to pop the bits from the stack and print them. Note that the bits are printed in the reverse order to that in which they have been created.

**Pairing data items**
We often need to pair some characters in an expression. For example, when we write a mathematical expression in a computer language, we often need to use parentheses to change the precedence of operators. The following two expressions are evaluated differently because of the parentheses in the second expression:
3 × 6 + 2 = 20     3 × (6 + 2) = 24
In the first expression, the multiplication operator has precedence over the addition operator—it is calculated first. In the second expression, the parentheses ignore the precedence, so the addition is calculated first. When we type an expression with a lot of parentheses, we often forget to pair the parentheses. One of the duties of a compiler is to do the checking for us. The compiler uses a stack to check that all opening parentheses are paired with a closing parentheses.

> **Example 12.3**
> Algorithm 12.2 shows how we can check if every opening parenthesis is paired with a closing parenthesis.

**Algorithm 12.2 Example 12.3**
\`\`\`
Algorithm: CheckingParentheses (expression)
Purpose: Check the pairing of parentheses in an expression
Pre: Given the expression to be checked
Post: Error messages if unpaired parentheses are found
Return: None
{
    stack (S)
    while (more character in the expression)
    {
        Char ← next character
        if (Char = '(')
        {
            push (S, Char)
        }
        else
        {
            if (Char = ')')
            {
                if (empty (S))
                {
                    print (unmatched opening parenthesis)
                }
                else
                {
                    pop (S, x)
                }
            }
        }
    }
    if (not empty (S))
    {
        print (a closing parenthesis not matched)
    }
    return
}
\`\`\`

### 12.2.4 Stack implementation
In this section we describe the general ideas behind the implementation of a stack ADT. At the ADT level, we use the stack and its four operations (*stack*, *push*, *pop*, and *empty*): at the implementation level, we need to choose a data structure to implement it. Stack ADT can be implemented using either an array or a linked list. Figure 12.7 shows an example of a stack ADT with five items. The figure also shows how we can implement the stack.

In our array implementation, we have a record that has two fields. The first field can be used to store information about the array: we have used it as the count field, which at each moment shows the number of data items in the stack. The second field is an integer that holds the index of the top element. Note that the array is shown upside down to match the linked list implementation.

The linked list implementation is similar: we have an extra node that has the name of the stack. This node also has two fields: a counter and a pointer that points to the top element.

**Algorithms**
We can write four algorithms in pseudocode for the four operations we defined for stack in each implementation. We showed algorithms to handle arrays and linked lists in Chapter 11: these algorithms can be modified to create the four algorithms we need for stacks: *stack*, *push*, *pop*, and *empty*. These algorithms are even easier than those presented in Chapter 11, because the insertion and deletion is done only at the top of stack. We leave the writing of these algorithms as exercises.

## 12.3 QUEUES
A **queue** is a linear list in which data can only be inserted at one end, called the **rear**, and deleted from the other end, called the **front**. These restrictions ensure that the data are processed through the queue in the order in which it is received. In other words, a queue is a **first in, first out (FIFO)** structure.

Queues are familiar from everyday life. A line of people waiting for the bus at a bus station is a queue, a list of calls put on hold to be answered by a telephone operator is a queue, and a list of waiting jobs to be processed by a computer is a queue.

Figure 12.8 shows two representations of queues, one a queue of people and the other a computer queue. Both people and data enter the queue at the rear and progress through the queue until they arrive at the front. Once they are at the front of the queue, they leave the queue and are served.

### 12.3.1 Operations on queues
Although we can define many operations for a queue, four are basic: *queue*, *enqueue*, *dequeue*, and *empty*, as defined below.

**The queue operation**
The *queue* operation creates an empty queue. The following shows the format:
\`queue (queueName)\`
*queueName* is the name of the queue to be created. This operation returns an empty queue. Figure 12.9 shows a pictorial representation of this operation.

**The enqueue operation**
The *enqueue* operation inserts an item at the rear of the queue. The following shows the format:
\`enqueue (queueName, dataItem)\`
*queueName* is the name of the queue and *dataItem* is the data to be inserted at the rear of the queue. After the enqueue operation, the new item becomes the last item in the queue. This operation returns the new queue with *dataItem* inserted at the rear. Figure 12.10 shows the pictorial representation of this operation.

**The dequeue operation**
The *dequeue* operation deletes the item at the front of the queue. The following shows the format:
\`dequeue (queueName, dataItem)\`
*queueName* is the name of the queue and *dataItem* is the data that is deleted from the queue. The deleted item can be used by the application program or can be just discarded. After the dequeue operation, the item that followed the front element becomes the front element. This operation returns the new queue with one less element. Figure 12.11 shows the pictorial representation of this operation.

**The empty operation**
The *empty* operation checks the status of the queue. The following shows the format:
\`empty (queueName)\`
The *queueName* is the name of the queue. This operation returns *true* if the queue is empty and *false* if the queue is not empty.

### 12.3.2 Queue ADT
We define a queue as an ADT as shown below:

**Queue ADT**
**Definition**
A list of data items in which an item can be deleted from one end, called the front and an item can be inserted at the other end called the rear.
**Operations**
*queue*: Creates an empty queue.
*enqueue*: Inserts an element at the rear.
*dequeue*: Deletes an element from the front.
*empty*: Checks the status of the queue.

> **Example 12.4**
> Figure 12.12 shows a segment of an algorithm that applies the previously defined operations on a queue Q. The fourth operation checks the status of the queue before trying to dequeue the front element. The value of the front element is stored in the variable x. However, we do not use this value—it will automatically be discarded at the end of the algorithm segment.

### 12.3.3 Queue applications
Queues are one of the most common of all data processing structures. They are found in virtually every operating system and network and in countless other areas. For example, queues are used in online business applications such as processing customer requests, jobs, and orders. In a computer system, a queue is needed to process jobs and for system services such as print spools.

> **Example 12.5**
> Queues can be used to organize databases by some characteristic of the data. For example, imagine we have a list of sorted data stored in the computer belonging to two categories: less than 1000, and greater than 1000. We can use two queues to separate the categories and at the same time maintain the order of data in their own category. Algorithm 12.3 shows the pseudocode for this operation.

**Algorithm 12.3 Example 12.5**
\`\`\`
Algorithm: Categorizer (list)
Purpose: Categorize data into two categories and create two separate lists.
Pre: Given: original list
Post: Prints the two lists
Return: None
{
    queue (Q1)
    queue (Q2)
    while (more data in the list)
    {
        if (data < 1000)
        {
            enqueue (Q1, data)
        }
        if (data ≥ 1000)
        {
            enqueue (Q2, data)
        }
    }
    while (not empty (Q1))
    {
        dequeue (Q1, x)
        print (x)
    }
    while (not empty (Q2))
    {
        dequeue (Q2, x)
        print (x)
    }
    return
}
\`\`\`

> **Example 12.6**
> Another common application of a queue is to adjust and create a balance between a fast producer of data and a slow consumer of data. For example, assume that a CPU is connected to a printer. The speed of a printer is not comparable with the speed of a CPU. If the CPU waits for the printer to print some data created by the CPU, the CPU would be idle for a long time. The solution is a queue. The CPU creates as many chunks of data as the queue can hold and sends them to the queue. The CPU is now free to do other jobs. The chunks are dequeued slowly and printed by the printer. The queue used for this purpose is normally referred to as a *spool queue*.

### 12.3.4 Queue implementation
At the ADT level, we use the queue and its four operations (*queue*, *enqueue*, *dequeue*, and *empty*): at the implementation level, we need to choose a data structure to implement it. A queue ADT can be implemented using either an array or a linked list. Figure 12.13 on page 331 shows an example of a queue ADT with five items. The figure also shows how we can implement it.

In the array implementation we have a record with three fields. The first field can be used to store information about the queue: we have used this as a count field that shows the current number of data items in the queue. The second field is an integer that holds the index of the front element. The third field is also an integer, which holds the index of the rear element.

The linked list implementation is similar: we have an extra node that has the name of the queue. This node also has three fields: a count, a pointer that points to the front element, and a pointer that points to the rear element.

**Algorithms**
We can write four algorithms in pseudocode for the four operations we defined for queues in each implementation. We described algorithms to handle arrays and linked lists in Chapter 11: we can modify those algorithms to create the four algorithms we need for queues: *queue*, *enqueue*, *dequeue*, and *empty*. These algorithms are easier than those presented in Chapter 11, because insertion is done only at the end of the queue and deletion is done only at the front of the queue. We leave the writing of these algorithms as exercises.

## 12.4 GENERAL LINEAR LISTS
Stacks and queues defined in the two previous sections are *restricted linear lists*. A general linear list is a list in which operations, such as insertion and deletion, can be done anywhere in the list—at the beginning, in the middle, or at the end. Figure 12.14 shows a general linear list.

We define a **general linear list** as a collection of elements with the following properties:
- The elements are of the same type.
- The elements are arranged sequentially, which means that there is a first element and a last element.
- Each element except the first has a unique predecessor, each element except the last has a unique successor.
- Each element is a record with a key field.
- The elements are sorted based on the key value.

### 12.4.1 Operations on general linear lists
Although we can define many operations on a general linear list, we discuss only six common operations in this chapter: *list*, *insert*, *delete*, *retrieve*, *traverse*, and *empty*.

**The list operation**
The *list* operation creates an empty list. The following shows the format:
\`list (listName)\`
*listName* is the name of the general linear list to be created. This operation returns an empty list.

**The insert operation**
Since we assume that data in a general linear list is sorted, insertion must be done in such a way that the ordering of the elements is maintained. To determine where the elements are to be placed, searching is needed. However, searching is done at the implementation level, not at the ADT level. In addition, we assume for simplicity that duplicate data is not allowed in a general linear list. Therefore we insert an element in a location that preserves the order of the keys. The following shows the format:
\`insert (listName, element)\`
Insertion is shown graphically in Figure 12.15.

**The delete operation**
Deletion from a general list (Figure 12.16) also requires that the list be searched to locate the data to be deleted. After the location of the data is found, deletion can be done. The following shows the format:
\`delete (listName, target, element)\`
*target* is a data value of the same type as the key of the elements in the list. If an element with the key value equal to the target is found, that element is deleted. The **delete operation** is shown graphically in Figure 12.16.

Note that this operation returns the deleted element. This is necessary if we want, say, to change the value of some fields and reinsert the item into the list again—we have not defined any operation that changes the value of the fields in the list.

**The retrieve operation**
By retrieval, we mean access of a single element. Like insertion and deletion, the general list should be first searched, and if the data is found, it can be retrieved. The format of the retrieve operation is:
\`retrieve (listName, target, element)\`
*target* is a data value of the same type as the key of the elements in the list. Figure 12.17 shows the retrieve operation graphically. If an element with the key value equal to the target is found, a copy of the element is retrieved, but the element still remains in the list.

**The traverse operation**
Each of the previous operations involves a single element in the list, randomly accessing the list. List traversal, on the other hand, involves sequential access. It is an operation in which all elements in the list are processed one by one. The following shows the format:
\`traverse (listName, action)\`
The traverse operation accesses the elements of the list sequentially, while the action specifies the operation to be performed on each element. Some examples of actions are printing the data, applying some mathematical operation on the data, and so on.

**The empty operation**
The *empty* operation checks the status of the list. The following shows the format:
\`empty (listName)\`
*listName* is the name of the list. This operation returns *true* if the list is empty, or *false* if the list is not empty.

### 12.4.2 General linear list ADT
We define a general linear list as an ADT as shown below:

**General Linear List ADT**
**Definition**
A list of sorted data items, all of the same type.
**Operations**
*list*: Creates an empty list.
*insert*: Inserts an element in the list.
*delete*: Deletes an element from the list.
*retrieve*: Retrieves an element from the list.
*traverse*: Traverses the list sequentially.
*empty*: Checks the status of the list.

> **Example 12.7**
> Figure 12.18 shows a segment of an algorithm that applies the previously defined operations on a list L. Note that the third operation inserts the new data at the correct position because the insert operation calls the search algorithm at the implementation level to find where the new data should be inserted.
> The fourth operation is required to delete the data item 3 from the list. It calls the *empty* operation to be sure that the list is not empty. Since the list is not empty, this operation can proceed, but when it calls the search operation at the implementation level, the data item is not found in the list. The list is therefore returned without a change. Finally the final operation inserts 6 at the appropriate location.

### 12.4.3 General linear list applications
General linear lists are used in situations in which the elements are accessed randomly or sequentially. For example, in a college a linear list can be used to store information about students who are enrolled in each semester.

> **Example 12.8**
> Assume that a college has a general linear list that holds information about the students and that each data element is a record with three fields: *ID*, *Name*, and *Grade*. Algorithm 12.4 shows an algorithm that helps a professor to change the grade for a student. The delete operation removes an element from the list, but makes it available to the program to allow the grade to be changed. The insert operation inserts the changed element back into the list. The element holds the whole record for the student, and the target is the *ID* used to search the list.

**Algorithm 12.4 Example 12.8**
\`\`\`
Algorithm: ChangeGrade (StudentList, target, grade)
Purpose: Change the grade of a student
Pre: Given the list of students and the grade
Post: None
Return: None
{
    delete (StudentList, target, element)
    (element.data).Grade ← grade
    insert (StudentList, element)
    return
}
\`\`\`

> **Example 12.9**
> Continuing with Example 12.8, assume that the tutor wants to print the record of all students at the end of the semester. Algorithm 12.5 can do this job.

**Algorithm 12.5 Example 12.9**
\`\`\`
Algorithm: PrintRecord (StudentList)
Purpose: Print the record of all students in the StudentList
Pre: Given the list of students
Post: None
Return: None
{
    traverse (StudentList, Print)
    return
}
\`\`\`
We assume that there is an algorithm called *Print* that prints the contents of the record. For each node, the list traverse calls the *Print* algorithm and passes the data to be printed to it.

### 12.4.4 General linear list implementation
At the ADT level, we use the list and its six operations (*list*, *insert*, *delete*, *retrieve*, *traverse*, and *empty*), but at the implementation level we need to choose a data structure to implement it. A general list ADT can be implemented using either an array or a linked list. Figure 12.19 shows an example of a list ADT with five items. The figure also shows how we can implement it.

In our array implementation we have a record with two fields. The first field can be used to store information about the array: we have used it as a count field that shows the current number of data item in a list. The second field is an integer that holds the index of the first element.

The linked list implementation is similar: we have an extra node that has the name of the list. This node also has two fields, a counter and a pointer that points to the first element.

**Algorithms**
We can write six algorithms in pseudocode for the six operations we defined for a list in each implementation. We showed algorithms to handle arrays and linked lists in Chapter 11: these algorithms can be slightly modified to create the algorithms we need for a list. We leave these as an exercise.

## 12.5 TREES
A **tree** consists of a finite set of elements, called **nodes** (or **vertices**), and a finite set of directed lines, called **arcs**, that connect pairs of the nodes. If the tree is not empty, one of the nodes, called the **root**, has no incoming arcs. The other nodes in a tree can be reached from the root by following a unique **path**, which is a sequence of consecutive arcs. Tree structures are normally drawn upside down with the root at the top (see Figure 12.20).

We can divide the vertices in a tree into three categories: the root, **leaves**, and the **internal nodes**.
Table 12.1 shows the number of outgoing and incoming arcs allowed for each type of node.

**Table 12.1 Number of incoming and outgoing arcs**
| Type of node | Incoming arc | Outgoing arc |
| :--- | :--- | :--- |
| root | 0 | 0 or more |
| leaf | 1 | 0 |
| internal | 1 | 1 or more |

A node that is directly accessible (through a single arc) from a given node is called the **child**: the node from which the child is directly accessible is called a **parent**. Nodes with a common parent are called **siblings**. **Descendents** of a node are all nodes that can be reached by that node, and a node from which all descendents can be reached is called an **ancestor**. Each node in a tree may have a **subtree**.

The subtree of each node includes one of its children and all descendents of that child. Figure 12.21 shows all subtrees for the tree in Figure 12.20.

Although trees have many applications in computer science, such as index files, their study is beyond the scope of this book. We introduce trees as a prelude to discussing one special type of tree, *binary trees*.

### 12.5.1 Binary trees
A **binary tree** is a tree in which no node can have more than two subtrees. In other words, a node can have zero, one, or two subtrees. These subtrees are designated as the **left subtree** and the **right subtree**. Figure 12.22 shows a binary tree with its two subtrees. Note that each subtree is itself a binary tree.

**Recursive definition of binary trees**
In Chapter 8 we introduced the recursive definition of an algorithm. We can also define a structure or an ADT recursively. The following gives the recursive definition of a binary tree. Note that, based on this definition, a binary tree can have a root, but each subtree can also have a root.

**A binary tree is either empty or consists of a node, root, with two subtrees, in which each subtree is also a binary tree.**

Figure 12.23 shows eight trees, the first of which is an empty binary tree (sometimes called a *null* binary tree).

### 12.5.2 Operations on binary trees
The six most common operations defined for a binary tree are *tree* (creates an empty tree) *insert*, *delete*, *retrieve*, *empty* and *traversal*. The first five are complex and beyond the scope of this book. We discuss binary tree traversal in this section.

**Binary tree traversals**
A *binary tree traversal* requires that each node of the tree be processed once and only once in a predetermined sequence. The two general approaches to the traversal sequence are *depth-first* and *breadth-first* traversal.

**Depth-first traversals**
Given that a binary tree consists of a root, a left subtree, and a right subtree, we can define six different **depth-first traversal** sequences. Computer scientists have assigned standard names to three of these sequences in the literature: the other three are unnamed but are easily derived. The standard traversals are shown in Figure 12.24.
- **Preorder traversal**. In **preorder traversal** the root node is processed first, followed by the left subtree and then the right subtree. The prefix *pre* indicates that the root node is processed *before* the subtrees.
- **Inorder traversal**. In **inorder traversal** the left subtree is processed first, then the root node, and finally the right subtree. The prefix *in* indicates that the root node is processed *between* the subtrees.
- **Postorder traversal**. In **postorder traversal** the root node is processed after the left and right subtrees have been processed. The prefix *post* indicates that the root is processed *after* the subtrees.

> **Example 12.10**
> Figure 12.25 shows how we visit each node in a tree using preorder traversal. The figure also shows the *walking order*. In preorder traversal we visit a node when we pass from its left side. The nodes are visited in this order: A, B, C, D, E, F.

**Breadth-first traversals**
In **breadth-first traversal** of a binary tree we process all the children of a node before proceeding with the next generation. As with depth-first traversals, we can trace the traversal with a walk.

> **Example 12.11**
> Figure 12.26 shows how we visit each node in a tree using breadth-first traversal. The figure also shows the walking order. The traversal order is A, B, E, C, D, F.

### 12.5.3 Binary tree applications
Binary trees have many applications in computer science. In this section we mention only two of them: Huffman coding and expression trees.

**Huffman coding**
**Huffman coding** is a compression technique that uses binary trees to generate a variable length binary code from a string of symbols. We discuss Huffman coding in detail in Chapter 15.

**Expression trees**
An arithmetic expression can be represented in three different formats: **infix**, **postfix**, and **prefix**. In an **infix** notation, the operator comes between the two operands. In **postfix** notation, the operator comes after its two operands, and in **prefix** notation it comes before the two operands. These formats are shown below for the addition of two operands A and B.
**Prefix**: + A B    **Infix**: A + B    **Postfix**: A B +

Although we use infix notation in our algorithms and in programming languages, the compiler often changes them to postfix notation before evaluating them. One way to do this conversion is to create an **expression tree**. In an expression tree, the root and the internal nodes are operators and the leaves are the operands. The three standard traversals (preorder, inorder, and postorder: Figure 12.4) then represent the three different expression formats: infix, postfix, and prefix. The inorder traversal produces the infix expression, the postorder traversal produces the postfix expression, and the preorder traversal produces the prefix expression. Figure 12.27 shows an expression and its expression tree. Note that only the infix notation needs parentheses.

### 12.5.4 Binary tree implementation
Binary trees can be implemented using arrays or linked list. Link list implementation is more efficient for deletion and insertion and is more prevalent.

### 12.5.5 Binary search trees
A **binary search tree (BST)** is a binary tree with one extra property: the key value of each node is greater than the key values of all nodes in each left subtree and smaller than the value of all nodes in each right subtree. Figure 12.28 shows the idea.

> **Example 12.12**
> Figure 12.29 shows some binary trees that are BSTs and some that are not. Note that a tree is a BST if all its subtrees are BSTs and the whole tree is also a BST.

A very interesting property of a BST is that if we apply the inorder traversal of a binary tree, the elements that are visited are sorted in ascending order. For example, the three BSTs in Figure 12.29, when traversed in the order gives the list (3, 6, 17), (17, 19), and (3, 6, 14, 17, 19).

**An inorder traversal of a BST creates a list that is sorted in ascending order.**

Another feature that makes a BST interesting is that we can use a version of the binary search we used in Chapter 8 for a binary search tree. Figure 12.30 shows the UML for a BST search.

**Binary search tree ADTs**
The ADT for a binary search tree is similar to the one we defined for a general linear list with the same operation. As a matter of fact, we see more BST lists than general linear lists today. The reason is that searching a BST is more efficient that searching a linear list: a general linear list uses sequential searching, but BSTs use a version of binary search.

**BST implementation**
BSTs can be implemented using either arrays or linked lists. However, linked list structures are more common and more efficient. A linear implementation uses nodes with two pointers, *left* and *right*. The left pointer points to the left subtree and the right pointer points to the right subtree. If the left subtree is empty, the left pointer is null: if the right subtree is empty, the right pointer is null. Like a linked-list implementation of a general linear list, a BST linked-list implementation uses a dummy node that has the same name as the BST. The data section of this dummy node can hold information about the tree, such as the number of nodes in the tree. The pointer section points to the root of the tree. Figure 12.31 shows a BST in which the data field of each node is a record.

## 12.6 GRAPHS
A **graph** is an ADT made of a set of nodes, called vertices, and set of lines connecting the vertices, called **edges** or arcs. Whereas a tree defines a hierarchical structure in which a node can have only one single parent, each node in a graph can have one or more parents. Graphs may be either **directed** or **undirected**. In a **directed graph**, or **digraph**, each edge, which connects two vertices, has a direction (shown in the figure by an arrowhead) from one vertex to the other. In an **undirected graph**, there is no direction. Figure 12.32 shows an example of both a directed graph (a) and an undirected graph (b).

The vertices in a graph can represent objects or concepts and the edges or arcs can represent a relationship between those objects or concepts. If a graph is directed, the relations are one-way: if a graph is undirected, the relation is two-way.

> **Example 12.13**
> A map of cities and the roads connecting the cities can be represented in a computer using an undirected graph. The cities are vertices and the undirected edges are the roads that connect them. If we want to show the distances between the cities, we can use *weighted graphs*, in which each edge has a weight that represent the distance between two cities connected by that edge.

> **Example 12.14**
> Another application of graphs is in computer networks (Chapter 6). The vertices can represent the nodes or hubs; the edges can represent the route. Each edge can have a weight that defines the cost of reaching from one hub to the adjacent hub. A router can use graph algorithms to find the shortest path between itself and the final destination of a packet.

## 12.7 END-CHAPTER MATERIALS

### 12.7.1 Recommended reading
For more details about subjects discussed in this chapter, the following books are recommended:
- Gilberg, R. and Forouzan, B. *Data Structures – A Pseudocode Approach with C*, Boston, MA: Course Technology, 2005
- Goodrich, M. and Tamassia, R. *Data Structures and Algorithms in Java*, New York: Wiley, 2005
- Nyhoff, L. *ADTs, Data Structures, and Problem Solving with C++*, Upper Saddle River, NJ: Prentice-Hall, 2005

### 12.7.2 Key terms
- abstract data type (ADT)
- ancestor
- arc
- binary search tree (BST)
- binary tree
- breadth-first traversal
- child
- delete operation
- depth-first traversal
- dequeue
- descendent
- digraph
- directed graph
- edge
- enqueue
- expression tree
- first in, first out (FIFO)
- front
- general linear list
- graph
- Huffman coding
- infix
- inorder traversal
- interface
- internal node
- last in, first out (LIFO)
- leaf
- linear list
- node
- parent
- path
- pop
- postfix
- postorder traversal
- prefix
- preorder traversal
- push
- queue
- rear
- root
- sibling
- stack
- subtree
- traversal
- tree
- undirected graph
- vertex

### 12.7.3 Summary
Although several simple data types have been implemented in all programming languages, most languages do not define complex data types. An abstract data type (ADT) is a package that defines a new data type, defines operations on that data type, and encapsulates the data and the operations.
- A stack is a restricted linear list in which all additions and deletions are made at one end, called the top. If we inserted a series of data items into a stack and then removed them, the order of the data is reversed. This reversing attribute is why stacks are known as a last in, first out (LIFO) structure. We defined four basic operations on a stack: stack, push, pop, and empty.
- A queue is a linear list in which data can only be inserted at one end, called the rear, and deleted from the other end, called the front. These restrictions ensure that data is processed through the queue in the order in which it is received. In other words, a queue is a first in, first out (FIFO) structure. We defined four basic operations for a queue: queue, enqueue, dequeue, and empty. A general linear list is a list in which operations, such as insertion and deletion, can be done anywhere in the list—at the beginning, in the middle, or at the end. We defined six operations for a general linear list: list, insert, delete, retrieve, traverse, and empty.
- A tree consists of a finite set of elements, called nodes (or vertices), and a finite set of directed lines, called arcs, that connect pairs of nodes. If the tree is not empty, one of the nodes, called the root, has no incoming arcs. A binary tree is a tree in which no node can have more than two subtrees. In other words, a node can have zero, one, or two subtrees. A binary tree traversal requires that each node of the tree be processed once and only once in a predetermined sequence. The two general approaches to the traversal sequence are depth first and breadth first. A binary search tree (BST) is a binary tree with one extra property: the key value of each node is greater than the key values of all nodes in each left subtree and smaller than the value of all nodes in each right subtree.
- A graph is an ADT made up of a set of nodes, called vertices, and set of lines connecting the vertices, called edges or arcs. Whereas a tree defines a hierarchical structure in which a node can only have a single parent, each node in a graph can have one or more parents. Graphs may be either directed or undirected.

## 12.8 PRACTICE SET

### 12.8.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 12.8.2 Review questions
1. What is an abstract data type? In an ADT, what is known and what is hidden?
2. What is a stack? What are the four basic stack operations defined in this chapter?
3. What is a queue? What are the four basic queue operations defined in this chapter?
4. What is a general linear list? What are the six basic operations defined for a general linear list in this chapter?
5. Define a tree. Distinguish between a tree and a binary tree. Distinguish between a binary tree and a binary search tree.
6. Distinguish between a depth-first traversal and breadth-first traversal of a binary tree.
7. What is a graph? Distinguish between a directed graph and an undirected graph.
8. List some applications of stacks and queues.
9. List some applications of general linear lists.
10. List some applications of binary trees and binary search trees.

### 12.8.3 Problems
1. Write an algorithm segment using while loops to empty the contents of stack S2.
2. Write an algorithm segment using while loops to move the contents of stack S1 to S2. After the operation, stack S1 should be empty.
3. Write an algorithm segment using while loops to copy the contents of stack S1 to S2. After the operation, the contents of stacks S1 and S2 should be the same.
4. Write an algorithm segment using while loops to concatenate the contents of stack S2 with the contents of stack S1. After the concatenation, the elements of stack S2 should be above the elements of stack S1 and stack S2 should be empty.
5. Show the contents of stack S1 and the value of variables x and y after the following algorithm segment is executed.
   \`stack (S1)\`
   \`push (S1, 5)\`
   \`push (S1, 3)\`
   \`push (S1, 2)\`
   \`if (not empty (S1))\`
   \`{\`
       \`pop (S1, x)\`
   \`}\`
   \`if (not empty (S1))\`
   \`{\`
       \`pop (S1, y)\`
   \`}\`
   \`push (S1, 6)\`
6. A palindrome is a string that can be read backwards and forwards with the same result. For example, the following is a palindrome if we ignore spaces:
   *Able was I ere I saw Elba*
   Write an algorithm in pseudocode using a stack to test whether a string is a palindrome.
7. Write an algorithm in pseudocode to compare the contents of two stacks.
8. Use a while loop to empty the contents of queue Q.
9. Use while loops to move the contents of queue Q1 to queue Q2. After the operation, queue Q1 should be empty.
10. Use while loops to copy the contents of queue Q1 to queue Q2. After the operation, the contents of queue Q1 and queue Q2 should be the same.
11. Use while loops to concatenate the contents of queue Q2 to the contents of queue Q1. After the concatenation, the elements of queue Q2 should be at the end of the elements of queue Q1. Queue Q2 should be empty.
12. Write an algorithm to compare the contents of two queues.
13. Find the root of each of the following binary trees:
    a. Tree with postorder traversal: FCBDG
    b. Tree with preorder traversal: IBCDFEN
    c. Tree with postorder traversal: CBIDFGE
14. A binary tree has ten nodes. The inorder and preorder traversal of the tree are shown below:
    Preorder: JCBADEFIGH    Inorder: ABCEDFJGIH
    Draw the tree.
15. A binary tree has eight nodes. The inorder and postorder traversal of the tree follow:
    Postorder: FECHGDBA    Inorder: FECABHDG
    Draw the tree.
16. A binary tree has seven nodes. The following shows the inorder and postorder traversal of a tree. Can we draw the tree? If not, explain why not:
    Postorder: GFDABEC    Inorder: ABDCEFG
17. Create the ADT package in pseudocode to implement the four operations defined for a stack in this chapter using an array as the data structure.
18. Create the ADT package in pseudocode to implement the four operations defined for a stack in this chapter using a linked list as the data structure.
19. Create the ADT package in pseudocode to implement the four operations defined for a queue in this chapter using an array as the data structure.
20. Create the ADT package in pseudocode to implement the four operations defined for a queue in this chapter using a linked list as the data structure.
21. Create the ADT package in pseudocode to implement the six operations defined for a general linear list in this chapter using an array as the data structure.
22. Create the ADT package in pseudocode to implement the six operations defined for a general linear list in this chapter using a linked list as the data structure.
`,zh:`
# 第十二章：抽象資料型別

在本章中，我們將討論抽象資料型別 (ADT)，這是一種比我們在第 11 章討論的資料結構具有更高抽象層級的資料類型。ADT 使用資料結構來實作。我們在本章開始時簡要介紹 ADT 的背景。然後我們給出一個定義並提出一個模型。本章的其餘部分討論各種 ADT，如堆疊、佇列、一般線性串列、樹、二元樹、二元搜尋樹和圖形。

## 學習目標
學完本章後，學生應能：
- 定義抽象資料型別 (ADT) 的概念。
- 定義堆疊、堆疊的基本操作、其應用以及如何實作。
- 定義佇列、佇列的基本操作、其應用以及如何實作。
- 定義一般線性串列、串列的基本操作、其應用以及如何實作。
- 定義一般樹及其應用。
- 定義二元樹——一種特殊的樹——及其應用。
- 定義二元搜尋樹 (BST) 及其應用。
- 定義圖形及其應用。

## 12.1 背景
用電腦解決問題意味著處理資料。為了處理資料，我們需要定義資料類型和要對資料執行的操作。例如，要找出一列數字的總和，我們應該選擇數字的類型（整數或實數）並定義操作（加法）。資料類型的定義和應用於資料的操作的定義是**抽象資料型別 (ADT)** 背後思想的一部分——隱藏操作是如何在資料上執行的。換句話說，ADT 的使用者只需要知道有一組操作可用於該資料類型，而不需要知道它們是如何應用的。

### 12.1.1 簡單 ADT
許多程式語言已經定義了一些簡單的 ADT 作為語言的組成部分。例如，C 語言定義了一個稱為*整數*的簡單 ADT。此 ADT 的類型是具有預定義範圍的整數。C 還定義了可以應用於此資料類型的幾種操作（加、減、乘、除等）。C 明確定義了這些對整數的操作以及我們預期的結果。編寫 C 程式將兩個整數相加的程式設計師應該了解整數 ADT 以及可以應用於它的操作。

然而，程式設計師不需要知道這些操作實際上是*如何*實作的。例如，程式設計師使用表達式 $z \\leftarrow x + y$ 並期望將 $x$（一個整數）的值加到 $y$（一個整數）的值上，並將結果命名為 $z$（一個整數）。程式設計師不需要知道加法是如何執行的。我們在前幾章中了解到，電腦執行此加法的方式是將兩個整數以二的補數格式儲存在兩個記憶體位置中，將它們載入到 CPU 暫存器中，以二進位形式相加，並將結果儲存回另一個記憶體位置。然而，程式設計師不需要知道這一點。C 中的整數是一個具有預定義操作的簡單抽象資料型別。操作如何執行不是程式設計師關心的問題。

### 12.1.2 複雜 ADT
雖然一些簡單的 ADT，如整數、實數、字元、指標等，已經被實作並可在大多數語言中使用，但許多有用的複雜 ADT 卻沒有。正如我們將在本章中看到的，我們需要列表 ADT、堆疊 ADT、佇列 ADT 等等。為了提高效率，這些 ADT 應該被創建並儲存在要使用的電腦的函式庫中。例如，*列表*的使用者應該只需要知道有哪些操作可用於列表，而不是這些操作是如何執行的。

因此，對於 ADT，使用者不關心任務是*如何*完成的，而是關心它能做*什麼*。換句話說，ADT 由一組定義組成，允許程式設計師使用操作，而其實作被隱藏。這種具有未指定實作的操作泛化稱為抽象。我們抽象出過程的本質，並將實作細節隱藏起來。

**抽象的概念意味著：**
1. **我們知道資料類型能做什麼。**
2. **它是如何完成的是隱藏的。**

### 12.1.3 定義
現在讓我們定義一個 ADT。抽象資料型別是一種與對該資料類型有意義的操作打包在一起的資料類型。然後我們將資料和對資料的操作封裝起來，並對使用者隱藏它們。

**抽象資料型別**
1. **資料的定義**
2. **操作的定義**
3. **資料和操作的封裝**

### 12.1.4 抽象資料型別的模型
ADT 模型如圖 12.1 所示。具有不規則輪廓的彩色區域代表 ADT。ADT 內部有模型的兩個不同部分：*資料結構*和*操作*（公開和私有）。應用程式只能透過**介面**存取公開操作。介面是公開操作以及傳遞給這些操作或從這些操作回傳的資料的列表。私有操作供 ADT 內部使用。資料結構，如陣列和鏈結串列，位於 ADT 內部，並由公開和私有操作使用。

雖然公開操作和介面應該獨立於實作，但私有操作取決於在 ADT 實作期間選擇的資料結構。我們將在討論一些 ADT 時詳細說明這個問題。

### 12.1.5 實作
電腦語言不提供 ADT 套件。要使用 ADT，首先要實作它並將其保存在函式庫中。本章的主要目的是介紹一些常見的 ADT 及其應用。然而，我們也為感興趣的讀者簡要討論每個 ADT 的實作。我們將實作的偽代碼演算法留作具有挑戰性的練習。

## 12.2 堆疊
**堆疊**是一種受限的**線性串列**，其中所有的新增和刪除都在一端進行，即頂部。如果我們將一系列資料插入堆疊然後將其移除，資料的順序是反轉的。例如，輸入為 5、10、15、20 的資料將以 20、15、10 和 5 的順序移除。這種反轉屬性就是為什麼堆疊被稱為**後進先出 (LIFO)** 資料結構。

我們在日常生活中使用許多不同類型的堆疊。我們經常談論一疊硬幣或一疊書。任何我們只能在頂部添加或移除物件的情況都是堆疊。如果我們想移除頂部以外的物件，我們必須先移除其上方的所有物件。圖 12.2 顯示了堆疊的三種表示形式。

### 12.2.1 堆疊上的操作
雖然我們可以為堆疊定義許多操作，但有四個基本操作：*stack*、*push*、*pop* 和 *empty*，我們在本章中定義它們。

**stack 操作**
*stack* 操作創建一個空堆疊。格式如下：
\`stack (stackName)\`
*stackName* 是要創建的堆疊名稱。此操作回傳一個空堆疊。圖 12.3 顯示了此操作的圖形表示。

**push 操作**
*push* 操作在堆疊頂部插入一個項目。格式如下：
\`push (stackName, dataItem)\`
*stackName* 是堆疊的名稱，*dataItem* 是要插入堆疊頂部的資料。在 push 操作後，新項目成為堆疊中的頂部項目。此操作回傳頂部插入了 *dataItem* 的新堆疊。圖 12.4 顯示了此操作的圖形表示。

**pop 操作**
*pop* 操作刪除堆疊頂部的項目。格式如下：
\`pop (stackName, dataItem)\`
*stackName* 是堆疊的名稱，*dataItem* 是從堆疊中刪除的資料。圖 12.5 顯示了此操作的圖形表示。
刪除的項目可以由應用程式使用，也可以直接丟棄。在 pop 操作後，刪除前位於頂部元素下方的項目成為頂部元素。此操作回傳少了一個元素的新堆疊。

**empty 操作**
*empty* 操作檢查堆疊的狀態。格式如下：
\`empty (stackName)\`
*stackName* 是堆疊的名稱。如果堆疊為空，此操作回傳 *true*，如果堆疊不為空，則回傳 *false*。

### 12.2.2 堆疊 ADT
我們將堆疊定義為 ADT，如下所示：

**堆疊 ADT**
**定義**
只能在一端（稱為頂部）存取的資料項目列表。
**操作**
*stack*：創建一個空堆疊。
*push*：在頂部插入一個元素。
*pop*：刪除頂部元素。
*empty*：檢查堆疊的狀態。

> **範例 12.1**
> 圖 12.6 顯示了一段演算法片段，該片段對堆疊 S 應用了先前定義的操作。第四個操作在嘗試彈出頂部元素之前檢查堆疊的狀態。頂部元素的值儲存在變數 x 中。然而，我們不使用這個值：它將在演算法片段結束時自動丟棄。

### 12.2.3 堆疊應用
堆疊應用可分為四大類：反轉資料、配對資料、延遲資料使用和回溯步驟。我們在接下來的部分討論前兩類。

**反轉資料項目**
反轉資料項目要求將給定的一組資料項目重新排序，以便交換第一個和最後一個項目，並且第一個和最後一個之間的所有位置也相對交換。例如，列表 (2, 4, 7, 1, 6, 8) 變為 (8, 6, 1, 7, 4, 2)。

> **範例 12.2**
> 在第 2 章（2.2.6 節中的圖 2.6）中，我們給出了一個簡單的 UML 圖，將整數從十進位轉換為任意基底。雖然演算法非常簡單，但如果我們在創建轉換後的整數的數字時列印它們，我們將得到反序的數字。任何電腦語言中的列印指令都是從左到右列印字元，但演算法是從右到左創建數字。我們可以使用堆疊（LIFO 結構）的反轉特性來解決這個問題。
> 演算法 12.1 顯示了將十進位整數轉換為二進位並列印結果的偽代碼。

**演算法 12.1 範例 2.2**
\`\`\`
演算法：DecimalToBinary (number)
目的：列印給定整數（絕對值）的二進位等價值
前置條件：給定要轉換的整數 (number)
後置條件：列印二進位整數
回傳：無
{
    stack (S)
    while (number ≠ 0)
    {
        remainder ← number mod 2
        push (S, remainder)
        number ← number / 2
    }
    while (not empty (S))
    {
        pop (S, x)
        print (x)
    }
    return
}
\`\`\`
我們先創建一個空堆疊。然後我們使用 *while* 迴圈來創建位元，但不是列印它們，而是將它們推入堆疊。當創建完所有位元後，我們退出迴圈。現在我們使用另一個迴圈從堆疊中彈出位元並列印它們。請注意，位元是以與創建順序相反的順序列印的。

**配對資料項目**
我們經常需要配對表達式中的某些字元。例如，當我們用電腦語言編寫數學表達式時，我們經常需要使用括號來改變運算子的優先順序。以下兩個表達式的計算結果因第二個表達式中的括號而異：
3 × 6 + 2 = 20     3 × (6 + 2) = 24
在第一個表達式中，乘法運算子的優先順序高於加法運算子——它先被計算。在第二個表達式中，括號忽略了優先順序，因此先計算加法。當我們輸入帶有大量括號的表達式時，我們經常忘記配對括號。編譯器的職責之一就是為我們進行檢查。編譯器使用堆疊來檢查所有左括號是否與右括號配對。

> **範例 12.3**
> 演算法 12.2 顯示了我們如何檢查每個左括號是否與右括號配對。

**演算法 12.2 範例 12.3**
\`\`\`
演算法：CheckingParentheses (expression)
目的：檢查表達式中括號的配對
前置條件：給定要檢查的表達式
後置條件：如果發現未配對的括號，則顯示錯誤訊息
回傳：無
{
    stack (S)
    while (more character in the expression)
    {
        Char ← next character
        if (Char = '(')
        {
            push (S, Char)
        }
        else
        {
            if (Char = ')')
            {
                if (empty (S))
                {
                    print (unmatched opening parenthesis)
                }
                else
                {
                    pop (S, x)
                }
            }
        }
    }
    if (not empty (S))
    {
        print (a closing parenthesis not matched)
    }
    return
}
\`\`\`

### 12.2.4 堆疊實作
在本節中，我們描述實作堆疊 ADT 背後的一般想法。在 ADT 層級，我們使用堆疊及其四個操作（*stack*、*push*、*pop* 和 *empty*）：在實作層級，我們需要選擇一種資料結構來實作它。堆疊 ADT 可以使用陣列或鏈結串列來實作。圖 12.7 顯示了一個包含五個項目的堆疊 ADT 範例。該圖還顯示了我們如何實作堆疊。

在我們的陣列實作中，我們有一個包含兩個欄位的記錄。第一個欄位可用於儲存有關陣列的資訊：我們用它作為計數欄位，隨時顯示堆疊中資料項目的數量。第二個欄位是一個整數，保存頂部元素的索引。請注意，陣列是倒置顯示的，以匹配鏈結串列的實作。

鏈結串列的實作類似：我們有一個額外的節點，其中包含堆疊的名稱。此節點也有兩個欄位：一個計數器和一個指向頂部元素的指標。

**演算法**
我們可以為每個實作中為堆疊定義的四個操作編寫四個偽代碼演算法。我們在第 11 章展示了處理陣列和鏈結串列的演算法：可以修改這些演算法以創建我們需要的堆疊四個演算法：*stack*、*push*、*pop* 和 *empty*。這些演算法甚至比第 11 章中介紹的更簡單，因為插入和刪除僅在堆疊頂部進行。我們將這些演算法的編寫留作練習。

## 12.3 佇列
**佇列**是一種線性串列，其中資料只能在一端（稱為**尾端**）插入，並從另一端（稱為**前端**）刪除。這些限制確保資料按接收順序在佇列中處理。換句話說，佇列是一種**先進先出 (FIFO)** 結構。

佇列在日常生活中很常見。公車站等公車的人排成的隊伍是佇列，電話接線員等待接聽的電話列表是佇列，電腦等待處理的工作列表是佇列。

圖 12.8 顯示了佇列的兩種表示形式，一種是人的佇列，另一種是電腦佇列。人和資料都從尾端進入佇列，並在佇列中前進，直到到達前端。一旦到達佇列的前端，他們就會離開佇列並得到服務。

### 12.3.1 佇列上的操作
雖然我們可以為佇列定義許多操作，但有四個基本操作：*queue*、*enqueue*、*dequeue* 和 *empty*，如下所定義。

**queue 操作**
*queue* 操作創建一個空佇列。格式如下：
\`queue (queueName)\`
*queueName* 是要創建的佇列名稱。此操作回傳一個空佇列。圖 12.9 顯示了此操作的圖形表示。

**enqueue 操作**
*enqueue* 操作在佇列的尾端插入一個項目。格式如下：
\`enqueue (queueName, dataItem)\`
*queueName* 是佇列的名稱，*dataItem* 是要插入佇列尾端的資料。在 enqueue 操作之後，新項目成為佇列中的最後一個項目。此操作回傳尾端插入了 *dataItem* 的新佇列。圖 12.10 顯示了此操作的圖形表示。

**dequeue 操作**
*dequeue* 操作刪除佇列前端的項目。格式如下：
\`dequeue (queueName, dataItem)\`
*queueName* 是佇列的名稱，*dataItem* 是從佇列中刪除的資料。刪除的項目可以由應用程式使用，也可以直接丟棄。在 dequeue 操作之後，跟隨前端元素的項目成為前端元素。此操作回傳少了一個元素的新佇列。圖 12.11 顯示了此操作的圖形表示。

**empty 操作**
*empty* 操作檢查佇列的狀態。格式如下：
\`empty (queueName)\`
*queueName* 是佇列的名稱。如果佇列為空，此操作回傳 *true*，如果佇列不為空，則回傳 *false*。

### 12.3.2 佇列 ADT
我們將佇列定義為 ADT，如下所示：

**佇列 ADT**
**定義**
一種資料項目列表，其中項目可以從一端（稱為前端）刪除，並且項目可以插入另一端（稱為尾端）。
**操作**
*queue*：創建一個空佇列。
*enqueue*：在尾端插入一個元素。
*dequeue*：從前端刪除一個元素。
*empty*：檢查佇列的狀態。

> **範例 12.4**
> 圖 12.12 顯示了一段演算法片段，該片段對佇列 Q 應用了先前定義的操作。第四個操作在嘗試從前端刪除元素之前檢查佇列的狀態。前端元素的值儲存在變數 x 中。然而，我們不使用這個值——它將在演算法片段結束時自動丟棄。

### 12.3.3 佇列應用
佇列是所有資料處理結構中最常見的一種。它們存在於幾乎每個作業系統和網路以及無數其他領域中。例如，佇列用於線上商業應用程式，如處理客戶請求、工作和訂單。在電腦系統中，需要佇列來處理工作和系統服務，如列印多工緩衝處理。

> **範例 12.5**
> 佇列可用於根據資料的某些特徵組織資料庫。例如，想像我們在電腦中儲存了一個已排序的資料列表，屬於兩類：小於 1000 和大於 1000。我們可以使用兩個佇列來分開這兩類，同時保持各自類別中資料的順序。演算法 12.3 顯示了此操作的偽代碼。

**演算法 12.3 範例 12.5**
\`\`\`
演算法：Categorizer (list)
目的：將資料分為兩類並創建兩個單獨的列表。
前置條件：給定：原始列表
後置條件：列印兩個列表
回傳：無
{
    queue (Q1)
    queue (Q2)
    while (more data in the list)
    {
        if (data < 1000)
        {
            enqueue (Q1, data)
        }
        if (data ≥ 1000)
        {
            enqueue (Q2, data)
        }
    }
    while (not empty (Q1))
    {
        dequeue (Q1, x)
        print (x)
    }
    while (not empty (Q2))
    {
        dequeue (Q2, x)
        print (x)
    }
    return
}
\`\`\`

> **範例 12.6**
> 佇列的另一個常見應用是在快速的資料生產者和慢速的資料消費者之間進行調整和建立平衡。例如，假設 CPU 連接到印表機。印表機的速度無法與 CPU 的速度相比。如果 CPU 等待印表機列印 CPU 創建的一些資料，CPU 將長時間處於閒置狀態。解決方案是佇列。CPU 創建盡可能多的資料塊以填滿佇列，並將其發送到佇列。CPU 現在可以自由地做其他工作。資料塊被緩慢地從佇列中取出並由印表機列印。用於此目的的佇列通常稱為*多工緩衝處理佇列 (spool queue)*。

### 12.3.4 佇列實作
在 ADT 層級，我們使用佇列及其四個操作（*queue*、*enqueue*、*dequeue* 和 *empty*）：在實作層級，我們需要選擇一種資料結構來實作它。佇列 ADT 可以使用陣列或鏈結串列來實作。第 331 頁的圖 12.13 顯示了一個包含五個項目的佇列 ADT 範例。該圖還顯示了我們如何實作它。

在陣列實作中，我們有一個包含三個欄位的記錄。第一個欄位可用於儲存有關佇列的資訊：我們用它作為計數欄位，顯示佇列中目前資料項目的數量。第二個欄位是一個整數，保存前端元素的索引。第三個欄位也是一個整數，保存尾端元素的索引。

鏈結串列的實作類似：我們有一個額外的節點，其中包含佇列的名稱。此節點也有三個欄位：一個計數，一個指向前端元素的指標，和一個指向尾端元素的指標。

**演算法**
我們可以為每個實作中為佇列定義的四個操作編寫四個偽代碼演算法。我們在第 11 章描述了處理陣列和鏈結串列的演算法：我們可以修改這些演算法以創建我們需要的佇列四個演算法：*queue*、*enqueue*、*dequeue* 和 *empty*。這些演算法比第 11 章中介紹的更容易，因為插入僅在佇列末尾進行，刪除僅在佇列前端進行。我們將這些演算法的編寫留作練習。

## 12.4 一般線性串列
前兩節定義的堆疊和佇列是*受限線性串列*。一般線性串列是一種可以在列表中的任何位置（開頭、中間或結尾）進行插入和刪除等操作的列表。圖 12.14 顯示了一般線性串列。

我們將**一般線性串列**定義為具有以下屬性的元素集合：
- 元素類型相同。
- 元素按順序排列，這意味著有第一個元素和最後一個元素。
- 除第一個元素外，每個元素都有唯一的前驅，除最後一個元素外，每個元素都有唯一的後繼。
- 每個元素都是一個帶有鍵欄位的記錄。
- 元素根據鍵值排序。

### 12.4.1 一般線性串列上的操作
雖然我們可以對一般線性串列定義許多操作，但我們在本章中僅討論六個常見操作：*list*、*insert*、*delete*、*retrieve*、*traverse* 和 *empty*。

**list 操作**
*list* 操作創建一個空列表。格式如下：
\`list (listName)\`
*listName* 是要創建的一般線性串列的名稱。此操作回傳一個空列表。

**insert 操作**
由於我們假設一般線性串列中的資料是排序的，因此插入必須以保持元素順序的方式進行。為了確定元素放置的位置，需要進行搜尋。然而，搜尋是在實作層級完成的，而不是在 ADT 層級。此外，為了簡單起見，我們假設一般線性串列中不允許有重複資料。因此，我們在保持鍵順序的位置插入元素。格式如下：
\`insert (listName, element)\`
插入操作如圖 12.15 所示。

**delete 操作**
從一般列表中刪除（圖 12.16）也需要搜尋列表以定位要刪除的資料。找到資料的位置後，即可進行刪除。格式如下：
\`delete (listName, target, element)\`
*target* 是與列表中元素鍵相同類型的資料值。如果找到鍵值等於目標的元素，則刪除該元素。**delete 操作**如圖 12.16 所示。

請注意，此操作回傳已刪除的元素。如果我們想要更改某些欄位的值並將項目再次插入列表中，這是必要的——我們沒有定義任何更改列表中欄位值的操作。

**retrieve 操作**
所謂檢索，是指存取單個元素。像插入和刪除一樣，應首先搜尋一般列表，如果找到資料，則可以檢索它。檢索操作的格式為：
\`retrieve (listName, target, element)\`
*target* 是與列表中元素鍵相同類型的資料值。圖 12.17 以圖形方式顯示了檢索操作。如果找到鍵值等於目標的元素，則檢索該元素的副本，但該元素仍保留在列表中。

**traverse 操作**
前面的每個操作都涉及列表中的單個元素，隨機存取列表。另一方面，列表遍歷涉及順序存取。這是一個逐一處理列表中所有元素的操作。格式如下：
\`traverse (listName, action)\`
遍歷操作按順序存取列表的元素，而 action 指定要對每個元素執行的操作。操作的一些例子是列印資料，對資料應用一些數學運算等等。

**empty 操作**
*empty* 操作檢查列表的狀態。格式如下：
\`empty (listName)\`
*listName* 是列表的名稱。如果列表為空，此操作回傳 *true*，如果列表不為空，則回傳 *false*。

### 12.4.2 一般線性串列 ADT
我們將一般線性串列定義為 ADT，如下所示：

**一般線性串列 ADT**
**定義**
已排序資料項目的列表，類型均相同。
**操作**
*list*：創建一個空列表。
*insert*：在列表中插入一個元素。
*delete*：從列表中刪除一個元素。
*retrieve*：從列表中檢索一個元素。
*traverse*：按順序遍歷列表。
*empty*：檢查列表的狀態。

> **範例 12.7**
> 圖 12.18 顯示了一段演算法片段，該片段對列表 L 應用了先前定義的操作。請注意，第三個操作將新資料插入到正確位置，因為插入操作呼叫實作層級的搜尋演算法來查找應插入新資料的位置。
> 第四個操作需要從列表中刪除資料項目 3。它呼叫 *empty* 操作以確保列表不為空。由於列表不為空，此操作可以繼續，但是當它呼叫實作層級的搜尋操作時，在列表中未找到資料項目。因此，列表在未更改的情況下回傳。最後，最後一個操作在適當位置插入 6。

### 12.4.3 一般線性串列應用
一般線性串列用於隨機或順序存取元素的情況。例如，在大學中，線性串列可用於儲存每個學期註冊學生的資訊。

> **範例 12.8**
> 假設一所大學有一個一般線性串列，其中包含有關學生的資訊，每個資料元素都是一個具有三個欄位的記錄：*ID*、*Name* 和 *Grade*。演算法 12.4 顯示了一個幫助教授更改學生成績的演算法。刪除操作從列表中移除元素，但使其可用於程式以允許更改成績。插入操作將更改後的元素插回列表中。元素包含學生的完整記錄，目標是用於搜尋列表的 *ID*。

**演算法 12.4 範例 12.8**
\`\`\`
演算法：ChangeGrade (StudentList, target, grade)
目的：更改學生的成績
前置條件：給定學生列表和成績
後置條件：無
回傳：無
{
    delete (StudentList, target, element)
    (element.data).Grade ← grade
    insert (StudentList, element)
    return
}
\`\`\`

> **範例 12.9**
> 延續範例 12.8，假設導師想在學期末列印所有學生的記錄。演算法 12.5 可以完成這項工作。

**演算法 12.5 範例 12.9**
\`\`\`
演算法：PrintRecord (StudentList)
目的：列印 StudentList 中所有學生的記錄
前置條件：給定學生列表
後置條件：無
回傳：無
{
    traverse (StudentList, Print)
    return
}
\`\`\`
我們假設有一個名為 *Print* 的演算法可以列印記錄的內容。對於每個節點，列表遍歷呼叫 *Print* 演算法並將要列印的資料傳遞給它。

### 12.4.4 一般線性串列實作
在 ADT 層級，我們使用列表及其六個操作（*list*、*insert*、*delete*、*retrieve*、*traverse* 和 *empty*），但在實作層級，我們需要選擇一種資料結構來實作它。一般列表 ADT 可以使用陣列或鏈結串列來實作。圖 12.19 顯示了一個包含五個項目的列表 ADT 範例。該圖還顯示了我們如何實作它。

在我們的陣列實作中，我們有一個包含兩個欄位的記錄。第一個欄位可用於儲存有關陣列的資訊：我們用它作為計數欄位，顯示列表中目前資料項目的數量。第二個欄位是一個整數，保存第一個元素的索引。

鏈結串列的實作類似：我們有一個額外的節點，其中包含列表的名稱。此節點也有兩個欄位，一個計數器和一個指向第一個元素的指標。

**演算法**
我們可以為每個實作中為列表定義的六個操作編寫六個偽代碼演算法。我們在第 11 章展示了處理陣列和鏈結串列的演算法：可以稍微修改這些演算法以創建我們需要的列表演算法。我們將這些留作練習。

## 12.5 樹
**樹**由一組有限的元素（稱為**節點**或**頂點**）和一組有限的連接節點對的有向線（稱為**弧**）組成。如果樹不為空，則其中一個節點（稱為**根**）沒有傳入弧。樹中的其他節點可以從根透過唯一的**路徑**到達，該路徑是一系列連續的弧。樹結構通常倒置繪製，根在頂部（見圖 12.20）。

我們可以將樹中的頂點分為三類：根、**葉**和**內部節點**。
表 12.1 顯示了每種類型節點允許的傳出和傳入弧的數量。

**表 12.1 傳入和傳出弧的數量**
| 節點類型 | 傳入弧 | 傳出弧 |
| :--- | :--- | :--- |
| 根 | 0 | 0 或更多 |
| 葉 | 1 | 0 |
| 內部 | 1 | 1 或更多 |

從給定節點直接可存取（透過單個弧）的節點稱為**子節點**：可以直接存取子節點的節點稱為**父節點**。具有共同父節點的節點稱為**兄弟節點**。節點的**後代**是可以從該節點到達的所有節點，可以從中到達所有後代的節點稱為**祖先**。樹中的每個節點都可以有一個**子樹**。

每個節點的子樹包括其一個子節點和該子節點的所有後代。圖 12.21 顯示了圖 12.20 中樹的所有子樹。

雖然樹在電腦科學中有許多應用，例如索引檔案，但其研究超出了本書的範圍。我們介紹樹是為了作為討論一種特殊類型樹——*二元樹*的序幕。

### 12.5.1 二元樹
**二元樹**是其中沒有節點可以有超過兩個子樹的樹。換句話說，一個節點可以有零、一或兩個子樹。這些子樹被指定為**左子樹**和**右子樹**。圖 12.22 顯示了一個帶有兩個子樹的二元樹。請注意，每個子樹本身也是一個二元樹。

**二元樹的遞迴定義**
在第 8 章中，我們介紹了演算法的遞迴定義。我們也可以遞迴地定義結構或 ADT。以下給出了二元樹的遞迴定義。請注意，根據此定義，二元樹可以有一個根，但每個子樹也可以有一個根。

**二元樹要麼為空，要麼由一個節點（根）和兩個子樹組成，其中每個子樹也是一個二元樹。**

圖 12.23 顯示了八棵樹，其中第一棵是空二元樹（有時稱為*空 (null)* 二元樹）。

### 12.5.2 二元樹上的操作
為二元樹定義的最常見的六個操作是 *tree*（創建空樹）、*insert*、*delete*、*retrieve*、*empty* 和 *traversal*。前五個很複雜，超出了本書的範圍。我們在本節中討論二元樹遍歷。

**二元樹遍歷**
*二元樹遍歷*要求樹的每個節點以預定順序被處理一次且僅一次。遍歷序列的兩種一般方法是*深度優先*和*廣度優先*遍歷。

**深度優先遍歷**
鑑於二元樹由根、左子樹和右子樹組成，我們可以定義六種不同的**深度優先遍歷**序列。電腦科學家在文獻中為其中三種序列指定了標準名稱：其他三種沒有名稱，但很容易推導出來。標準遍歷如圖 12.24 所示。
- **前序遍歷 (Preorder traversal)**。在**前序遍歷**中，首先處理根節點，然後是左子樹，然後是右子樹。前綴 *pre* 表示根節點在子樹*之前*處理。
- **中序遍歷 (Inorder traversal)**。在**中序遍歷**中，首先處理左子樹，然後是根節點，最後是右子樹。前綴 *in* 表示根節點在子樹*之間*處理。
- **後序遍歷 (Postorder traversal)**。在**後序遍歷**中，根節點在處理完左子樹和右子樹後處理。前綴 *post* 表示根在子樹*之後*處理。

> **範例 12.10**
> 圖 12.25 顯示了我們如何使用前序遍歷訪問樹中的每個節點。該圖還顯示了*行走順序*。在前序遍歷中，當我們從節點的左側通過時，我們訪問該節點。節點按此順序訪問：A, B, C, D, E, F。

**廣度優先遍歷**
在二元樹的**廣度優先遍歷**中，我們處理節點的所有子節點，然後再繼續下一代。與深度優先遍歷一樣，我們可以通過行走來追蹤遍歷。

> **範例 12.11**
> 圖 12.26 顯示了我們如何使用廣度優先遍歷訪問樹中的每個節點。該圖還顯示了行走順序。遍歷順序為 A, B, E, C, D, F。

### 12.5.3 二元樹應用
二元樹在電腦科學中有許多應用。在本節中，我們僅提及其中兩個：霍夫曼編碼和表達式樹。

**霍夫曼編碼**
**霍夫曼編碼**是一種壓縮技術，它使用二元樹從符號字串生成可變長度的二進位代碼。我們在第 15 章詳細討論霍夫曼編碼。

**表達式樹**
算術表達式可以用三種不同的格式表示：**中綴**、**後綴**和**前綴**。在**中綴**表示法中，運算子位於兩個運算元之間。在**後綴**表示法中，運算子位於其兩個運算元之後，而在**前綴**表示法中，它位於兩個運算元之前。以下顯示了兩個運算元 A 和 B 相加的這些格式。
**前綴**：+ A B    **中綴**：A + B    **後綴**：A B +

雖然我們在演算法和程式語言中使用中綴表示法，但編譯器通常在評估之前將它們更改為後綴表示法。進行這種轉換的一種方法是創建**表達式樹**。在表達式樹中，根和內部節點是運算子，葉子是運算元。三種標準遍歷（前序、中序和後序：圖 12.4）然後代表三種不同的表達式格式：中綴、後綴和前綴。中序遍歷產生中綴表達式，後序遍歷產生後綴表達式，前序遍歷產生前綴表達式。圖 12.27 顯示了一個表達式及其表達式樹。請注意，只有中綴表示法需要括號。

### 12.5.4 二元樹實作
二元樹可以使用陣列或鏈結串列來實作。鏈結串列實作對於刪除和插入更有效率，並且更為普遍。

### 12.5.5 二元搜尋樹
**二元搜尋樹 (BST)** 是一種具有一個額外屬性的二元樹：每個節點的鍵值大於每個左子樹中所有節點的鍵值，並小於每個右子樹中所有節點的鍵值。圖 12.28 顯示了這個想法。

> **範例 12.12**
> 圖 12.29 顯示了一些是 BST 和一些不是 BST 的二元樹。請注意，如果所有子樹都是 BST 且整棵樹也是 BST，則該樹是 BST。

BST 的一個非常有趣的屬性是，如果我們對二元樹應用中序遍歷，則訪問的元素將按升序排序。例如，圖 12.29 中的三個 BST，按順序遍歷時給出列表 (3, 6, 17), (17, 19), 和 (3, 6, 14, 17, 19)。

**BST 的中序遍歷創建一個按升序排序的列表。**

使 BST 有趣的另一個特徵是我們可以使用我們在第 8 章中用於二元搜尋樹的二元搜尋版本。圖 12.30 顯示了 BST 搜尋的 UML。

**二元搜尋樹 ADT**
二元搜尋樹的 ADT 類似於我們為具有相同操作的一般線性串列定義的 ADT。事實上，我們今天看到的 BST 列表比一般線性串列更多。原因是搜尋 BST 比搜尋線性串列更有效率：一般線性串列使用循序搜尋，但 BST 使用二元搜尋的版本。

**BST 實作**
BST 可以使用陣列或鏈結串列來實作。然而，鏈結串列結構更常見也更有效率。線性實作使用帶有兩個指標 *left* 和 *right* 的節點。左指標指向左子樹，右指標指向右子樹。如果左子樹為空，則左指標為空：如果右子樹為空，則右指標為空。像一般線性串列的鏈結串列實作一樣，BST 鏈結串列實作使用一個與 BST 同名的虛擬節點。此虛擬節點的資料部分可以保存有關樹的資訊，例如樹中的節點數。指標部分指向樹的根。圖 12.31 顯示了一個 BST，其中每個節點的資料欄位是一個記錄。

## 12.6 圖形
**圖形**是由一組稱為頂點的節點和一組連接頂點的線（稱為**邊**或弧）組成的 ADT。樹定義了一種階層結構，其中一個節點只能有一個父節點，而圖形中的每個節點可以有一個或多個父節點。圖形可以是**有向**或**無向**的。在**有向圖**或**digraph**中，連接兩個頂點的每條邊都有一個方向（圖中用箭頭顯示），從一個頂點指向另一個頂點。在**無向圖**中，沒有方向。圖 12.32 顯示了有向圖 (a) 和無向圖 (b) 的範例。

圖形中的頂點可以代表物件或概念，邊或弧可以代表這些物件或概念之間的關係。如果圖形是有向的，關係是單向的：如果圖形是無向的，關係是雙向的。

> **範例 12.13**
> 城市地圖和連接城市的道路可以使用無向圖在電腦中表示。城市是頂點，無向邊是連接它們的道路。如果我們想顯示城市之間的距離，我們可以使用*加權圖*，其中每條邊都有一個權重，代表由該邊連接的兩個城市之間的距離。

> **範例 12.14**
> 圖形的另一個應用是在電腦網路中（第 6 章）。頂點可以代表節點或集線器；邊可以代表路徑。每條邊可以有一個權重，定義從一個集線器到達相鄰集線器的成本。路由器可以使用圖形演算法找到自身與封包最終目的地之間的最短路徑。

## 12.7 章末材料

### 12.7.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Gilberg, R. and Forouzan, B. *Data Structures – A Pseudocode Approach with C*, Boston, MA: Course Technology, 2005
- Goodrich, M. and Tamassia, R. *Data Structures and Algorithms in Java*, New York: Wiley, 2005
- Nyhoff, L. *ADTs, Data Structures, and Problem Solving with C++*, Upper Saddle River, NJ: Prentice-Hall, 2005

### 12.7.2 關鍵詞
- 抽象資料型別 (ADT)
- 祖先 (ancestor)
- 弧 (arc)
- 二元搜尋樹 (BST)
- 二元樹 (binary tree)
- 廣度優先遍歷 (breadth-first traversal)
- 子節點 (child)
- 刪除操作 (delete operation)
- 深度優先遍歷 (depth-first traversal)
- dequeue
- 後代 (descendent)
- 有向圖 (digraph)
- 有向圖 (directed graph)
- 邊 (edge)
- enqueue
- 表達式樹 (expression tree)
- 先進先出 (FIFO)
- 前端 (front)
- 一般線性串列 (general linear list)
- 圖形 (graph)
- 霍夫曼編碼 (Huffman coding)
- 中綴 (infix)
- 中序遍歷 (inorder traversal)
- 介面 (interface)
- 內部節點 (internal node)
- 後進先出 (LIFO)
- 葉 (leaf)
- 線性串列 (linear list)
- 節點 (node)
- 父節點 (parent)
- 路徑 (path)
- pop
- 後綴 (postfix)
- 後序遍歷 (postorder traversal)
- 前綴 (prefix)
- 前序遍歷 (preorder traversal)
- push
- 佇列 (queue)
- 尾端 (rear)
- 根 (root)
- 兄弟節點 (sibling)
- 堆疊 (stack)
- 子樹 (subtree)
- 遍歷 (traversal)
- 樹 (tree)
- 無向圖 (undirected graph)
- 頂點 (vertex)

### 12.7.3 摘要
雖然所有程式語言都實作了幾種簡單的資料類型，但大多數語言並未定義複雜的資料類型。抽象資料型別 (ADT) 是一個套件，它定義新的資料類型，定義該資料類型上的操作，並封裝資料和操作。
- 堆疊是一種受限的線性串列，其中所有的新增和刪除都在一端進行，即頂部。如果我們將一系列資料項目插入堆疊然後將其移除，資料的順序是反轉的。這種反轉屬性就是為什麼堆疊被稱為後進先出 (LIFO) 結構。我們在堆疊上定義了四個基本操作：stack、push、pop 和 empty。
- 佇列是一種線性串列，其中資料只能在一端（稱為尾端）插入，並從另一端（稱為前端）刪除。這些限制確保資料按接收順序在佇列中處理。換句話說，佇列是一種先進先出 (FIFO) 結構。我們為佇列定義了四個基本操作：queue、enqueue、dequeue 和 empty。一般線性串列是一種可以在列表中的任何位置（開頭、中間或結尾）進行插入和刪除等操作的列表。我們為一般線性串列定義了六個操作：list、insert、delete、retrieve、traverse 和 empty。
- 樹由一組有限的元素（稱為節點或頂點）和一組有限的連接節點對的有向線（稱為弧）組成。如果樹不為空，則其中一個節點（稱為根）沒有傳入弧。二元樹是其中沒有節點可以有超過兩個子樹的樹。換句話說，一個節點可以有零、一或兩個子樹。二元樹遍歷要求樹的每個節點以預定順序被處理一次且僅一次。遍歷序列的兩種一般方法是深度優先和廣度優先。二元搜尋樹 (BST) 是一種具有一個額外屬性的二元樹：每個節點的鍵值大於每個左子樹中所有節點的鍵值，並小於每個右子樹中所有節點的鍵值。
- 圖形是由一組節點（稱為頂點）和一組連接頂點的線（稱為邊或弧）組成的 ADT。樹定義了一種階層結構，其中一個節點只能有一個父節點，而圖形中的每個節點可以有一個或多個父節點。圖形可以是有向或無向的。

## 12.8 練習題

### 12.8.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 12.8.2 複習問題
1. 什麼是抽象資料型別？在 ADT 中，什麼是已知的，什麼是隱藏的？
2. 什麼是堆疊？本章定義的四個基本堆疊操作是什麼？
3. 什麼是佇列？本章定義的四個基本佇列操作是什麼？
4. 什麼是一般線性串列？本章為一般線性串列定義的六個基本操作是什麼？
5. 定義樹。區分樹和二元樹。區分二元樹和二元搜尋樹。
6. 區分二元樹的深度優先遍歷和廣度優先遍歷。
7. 什麼是圖形？區分有向圖和無向圖。
8. 列出堆疊和佇列的一些應用。
9. 列出一般線性串列的一些應用。
10. 列出二元樹和二元搜尋樹的一些應用。

### 12.8.3 問題
1. 使用 while 迴圈編寫一段演算法片段以清空堆疊 S2 的內容。
2. 使用 while 迴圈編寫一段演算法片段以將堆疊 S1 的內容移動到 S2。操作後，堆疊 S1 應為空。
3. 使用 while 迴圈編寫一段演算法片段以將堆疊 S1 的內容複製到 S2。操作後，堆疊 S1 和 S2 的內容應相同。
4. 使用 while 迴圈編寫一段演算法片段以將堆疊 S2 的內容連接到堆疊 S1 的內容。連接後，堆疊 S2 的元素應在堆疊 S1 的元素之上，並且堆疊 S2 應為空。
5. 顯示執行以下演算法片段後堆疊 S1 的內容以及變數 x 和 y 的值。
   \`stack (S1)\`
   \`push (S1, 5)\`
   \`push (S1, 3)\`
   \`push (S1, 2)\`
   \`if (not empty (S1))\`
   \`{\`
       \`pop (S1, x)\`
   \`}\`
   \`if (not empty (S1))\`
   \`{\`
       \`pop (S1, y)\`
   \`}\`
   \`push (S1, 6)\`
6. 迴文是一個可以向後和向前讀取並具有相同結果的字串。例如，如果我們忽略空格，以下是一個迴文：
   *Able was I ere I saw Elba*
   使用堆疊編寫偽代碼演算法以測試字串是否為迴文。
7. 用偽代碼編寫一個演算法來比較兩個堆疊的內容。
8. 使用 while 迴圈清空佇列 Q 的內容。
9. 使用 while 迴圈將佇列 Q1 的內容移動到佇列 Q2。操作後，佇列 Q1 應為空。
10. 使用 while 迴圈將佇列 Q1 的內容複製到佇列 Q2。操作後，佇列 Q1 和 Q2 的內容應相同。
11. 使用 while 迴圈將佇列 Q2 的內容連接到佇列 Q1 的內容。連接後，佇列 Q2 的元素應在佇列 Q1 的元素的末尾。佇列 Q2 應為空。
12. 編寫一個演算法來比較兩個佇列的內容。
13. 找出以下每個二元樹的根：
    a. 具有後序遍歷的樹：FCBDG
    b. 具有前序遍歷的樹：IBCDFEN
    c. 具有後序遍歷的樹：CBIDFGE
14. 二元樹有十個節點。樹的中序和前序遍歷如下所示：
    前序：JCBADEFIGH    中序：ABCEDFJGIH
    畫出這棵樹。
15. 二元樹有八個節點。樹的中序和後序遍歷如下：
    後序：FECHGDBA    中序：FECABHDG
    畫出這棵樹。
16. 二元樹有七個節點。以下顯示了樹的中序和後序遍歷。我們可以畫出這棵樹嗎？如果不能，請解釋原因：
    後序：GFDABEC    中序：ABDCEFG
17. 用偽代碼創建 ADT 套件，使用陣列作為資料結構實作本章為堆疊定義的四個操作。
18. 用偽代碼創建 ADT 套件，使用鏈結串列作為資料結構實作本章為堆疊定義的四個操作。
19. 用偽代碼創建 ADT 套件，使用陣列作為資料結構實作本章為佇列定義的四個操作。
20. 用偽代碼創建 ADT 套件，使用鏈結串列作為資料結構實作本章為佇列定義的四個操作。
21. 用偽代碼創建 ADT 套件，使用陣列作為資料結構實作本章為一般線性串列定義的六個操作。
22. 用偽代碼創建 ADT 套件，使用鏈結串列作為資料結構實作本章為一般線性串列定義的六個操作。
`},p={en:`
# Chapter 13: File Structure

In this chapter we discuss file structures. Based on the application, files are stored in auxiliary storage devices using various methods. We also discuss how individual records are retrieved. This chapter is a prelude to the following chapter, which discusses how a collection of related files, called a database, is organized and accessed.

## Objectives
After studying this chapter, the student should be able to:
- Define two categories of access methods: sequential access and random access.
- Understand the structure of sequential files and how they are updated.
- Understand the structure of indexed files and the relation between the index and the data file.
- Understand the idea behind hashed files and describe some hashing methods.
- Describe address collisions and how they can be resolved.
- Define directories and how they can be used to organize files.
- Distinguish between text and binary files.

## 13.1 INTRODUCTION
Files are stored on **auxiliary** or **secondary storage devices**. The two most common forms of secondary storage are disk and tape. Files in secondary storage can be both read from and written to. Files can also exist in forms that the computer can write to but not read. For example, the display of information on the system monitor is a form of file, as is data sent to a printer. In a general sense, the keyboard is also a file, although it cannot store data.

For our purposes, a file is a collection of data records in which each record consists of one or more fields, as defined in Chapter 11.

When we design a file, the important issue is how we will retrieve information (a specific record) from the file. Sometimes we need to process records one after another, whereas sometimes we need to access a specific record quickly without retrieving the preceding records. The **access method** determines how records can be retrieved: *sequentially* or *randomly*.

### 13.1.1 Sequential access
If we need to access a file sequentially—that is, one record after another, from beginning to end—we use a **sequential file** structure.

### 13.1.2 Random access
If we need to access a specific record without having to retrieve all records before it, we use a file structure that allows **random access**. Two file structures allow this: *indexed files* and *hashed files*.

## 13.2 SEQUENTIAL FILES
A sequential file is one in which records can only be accessed one after another from beginning to end. Records are stored one after another in auxiliary storage, such as tape or disk, and there is an **EOF (end-of-file)** marker after the last record. The operating system has no information about the record addresses, it only knows where the whole file is stored. The only thing known to the operating system is that the records are sequential.

Algorithm 13.1 shows how records in a sequential file are processed. We process the records one by one. After the operating system processes the last record, the EOF is detected and the loop is exited.

**Algorithm 13.1 Pseudocode for processing records in a sequential file**
\`\`\`text
Algorithm: SequentialFileProcessing (file)
Purpose: Process all records in a sequential file
Pre: Given the beginning address of the file on the auxiliary storage
Post: None
Return: None
{
    while (Not EOF)
    {
        Read the next record from the auxiliary storage into memory
        Process the record
    }
}
\`\`\`

Sequential files are used in applications that need to access all records from beginning to end. For example, if personal information about each employee in a company is stored in a file, we can use **sequential access** to retrieve each record at the end of the month to print the paychecks. Because we have to process each record, sequential access is more efficient and easier than random access.

However, the sequential file is not efficient for random access. For example, if all customer records in a bank can only be accessed sequentially, a customer who needs to get money from an ATM would have to wait as the system checks each record from the beginning of the file until it reaches the customer’s record. If this bank has a million customers, the system, on average, would retrieve half a million records before reaching the customer’s record. This is very inefficient.

### 13.2.1 Updating sequential files
Sequential files must be updated periodically to reflect changes in information. The updating process is very involved because all the records need to be checked and updated (if necessary) sequentially.

**Files involved in updating**
There are four files associated with an update program: the new master file, the old master file, the transaction file, and the error report file. All these files are sorted based on key values.
- **New master file**: The new permanent data file or, as it is commonly known, the **new master file**, contains the most current data. Note that after the update program completes, the new master file is sent to offline storage, where it is kept until needed again.
- **Old master file**: The **old master file** is the permanent file that should be updated. Even after updating, the old master file is normally kept for reference.
- **Transaction file**: The third file is the **transaction file**. This contains the changes to be applied to the master file. There are three basic types of changes in all file updates:
    - *Add transactions* contain data about a new record to be added to the master file.
    - *Delete transactions* identify records to be deleted from the file.
    - *Change transactions* contain revisions to specific records in the file.
    To process any of these transactions, we need a **key**. A key is one or more fields that uniquely identify the data in the file. For example, in a file of students, the key could be student ID.
- **Error report file**: The fourth file needed in an update program is an **error report file**. It is very rare that an update process does not produce at least one error. When an error occurs, we need to report it. The error report contains a listing of all errors discovered during the update process and is presented for corrective action.

**Processing file updates**
To make the updating process efficient, all files are sorted on the same key. The update process requires that we compare the keys on the transaction and master files and, assuming that there are no errors, follow one of three actions:
1.  If the transaction file key is less than the master file key and the transaction is an add (A), add the transaction to the new master.
2.  If the transaction file key is equal to the master file key, either:
    a.  Change the contents of the master file data if the transaction is a change (C).
    b.  Remove the data from the master file if the transaction is a deletion (D).
3.  If the transaction file key is greater than the master file key, write the old master file record to the new master file.
4.  Several cases may create an error and be reported in the error file:
    a.  If the transaction defines adding a record that already exists in the old master file (same key values).
    b.  If the transaction defines deleting or changing a record that does not exist in the old master file.

## 13.3 INDEXED FILES
To access a record in a file randomly, we need to know the address of the record. For example, suppose a customer wants to check their bank account. Neither the customer nor the teller knows the address of the customer’s record. The customer can only give the teller their account number (key). Here, an indexed file can relate the account number (key) to the record address.

An **indexed file** is made of a **data file**, which is a sequential file, and an **index**. The index itself is a very small file with only two fields: the key of the sequential file and the address of the corresponding record on the disk. The index is sorted based on the key values of the data files.

Accessing a record in the file requires these steps:
1.  The entire index file is loaded into main memory (the file is small and uses little memory).
2.  The index entries are searched, using an efficient search algorithm such as a binary search, to find the desired key.
3.  The address of the record is retrieved.
4.  Using the address, the data record is retrieved and passed to the user.

### 13.3.1 Inverted files
One of the advantages of indexed files is that we can have more than one index, each with a different key. For example, an employee file can be retrieved based on either social security number or last name. This type of indexed file is usually called an **inverted file**.

## 13.4 HASHED FILES
In an indexed file, the index maps the key to the address. A **hashed file** uses a mathematical function to accomplish this mapping. The user gives the key, the function maps the key to the address and passes it to the operating system, and the record is retrieved.

The hashed file eliminates the need for an extra file (the index). In an indexed file, we must keep the index on file in the disk, and when we need to process the data file, we must first load the index into memory, search it to find the address of the data record, and then access the data file to access the record. In a hashed file, finding the address is done through the use of a function, so there is no need for an index and all of the overhead associated with it. However, we will see that hashed files have their own drawbacks.

### 13.4.1 Hashing methods
For key-address mapping, we can select one of several **hashing methods**. We discuss a few of them here.

**Direct hashing**
In **direct hashing**, the key is the data file address without any algorithmic manipulation. The file must therefore contain a record for every possible key. Although situations suitable for direct hashing are limited, it can be very powerful because it guarantees that there are no *synonyms* or *collisions* (discussed later in this chapter), as with other methods.
Although this is the ideal method, its application is very limited. For example, it is very inefficient to use long identifiers as keys, because they must have several digits. Let’s turn our attention, therefore, to hashing techniques that map a large population of possible keys to a small address space.

**Modulo division hashing**
Also known as **division remainder hashing**, the modulo division method divides the key by the file size and uses the remainder plus 1 for the address. This gives the simple hashing algorithm that follows, where *list_size* is the number of elements in the file. The reason for adding a 1 to the mod operation result is that our list starts with 1 instead of 0:
\`address = key mod list_size + 1\`

Although this algorithm works with any list size, a list size that is a **prime number** produces fewer collisions than other list sizes. Therefore, whenever possible, try to make the file size a prime number.

**Digit extraction hashing**
Using **digit extraction hashing**, selected digits are extracted from the key and used as the address. For example, using a six-digit employee number to hash to a three-digit address (000–999), we could select the first, third, and fourth digits (from the left) and use them as the address.

**Other hashing methods**
Other popular methods exist, such as the midsquare method, folding methods, the rotational method, and the pseudorandom method.

### 13.4.2 Collision
Generally, the population of keys for a hashed list is greater than the number of records in the data file. Because there are many keys for each address in the file, there is a possibility that more than one key will hash to the same address in the file. We call the set of keys that hash to the same address in our list **synonyms**.

If the actual data that we insert into our list contains two or more synonyms, we will have collisions. A **collision** is the event that occurs when a hashing algorithm produces an address for an insertion key but that address is already occupied. The address produced by the hashing algorithm is known as the **home address**. The part of the file that contains all the home addresses is known as the **prime area**. When two keys collide at a home address, we must resolve the collision by placing one of the keys and its data in another location, outside the prime area.

**Collision resolution**
With the exception of the direct method, none of the methods we have discussed for hashing creates one-to-one mappings. This means that when we hash a new key to an address, we may create a collision. There are several methods for handling collisions, each of them independent of the hashing algorithm.

**Open addressing**
The first collision resolution method, **open addressing resolution**, resolves collisions in the prime area. When a collision occurs, the prime area addresses are searched for an open or unoccupied record where the new data can be placed. One simple strategy for data that cannot be stored in the home address is to store it in the next address (home address + 1).

**Linked list resolution**
A major disadvantage of open addressing is that each collision resolution increases the probability of future collisions. This disadvantage is eliminated in another approach to collision resolution, **linked list resolution**. In this method, the first record is stored in the home address, but contains a pointer to the second record.

**Bucket hashing**
Another approach to handling the problem of collisions is to hash to buckets. A **bucket** is a node that can accommodate more than one record. The disadvantage of this method is that there may be a lot of wasted (unoccupied) locations.

## 13.5 DIRECTORIES
**Directories** are provided by most operating systems for organizing files. A directory performs the same function as a folder in a filing cabinet. However, a directory in most operating systems is represented as a special type of file that holds information about other files. A directory not only serves as a kind of index that tells the operating system where files are located on an auxiliary storage device, but can also contain other information about the files it contains, such as who has access to each file, or the date when each file was created, accessed, or modified.
Directories in most operating systems are organized like the tree abstract data type (ADT), in which each directory except the root directory has a parent. A directory contained in another directory is called a **subdirectory** of the container directory.

### 13.5.1 Directories in the UNIX operating system
In UNIX the directory system is organized as a tree structure. At the top of the directory structure is a directory called the **root**. Although its name is root, in commands related to directories it is typed as one slash (/). In turn, each directory can contain subdirectories and files.

**Special directories**
There are four special types of directory that play an important role in the directory structure in UNIX: the root directory, home directories, working directories, and parent directories.
- **Root directory**: The root directory is the highest level in the file system hierarchy. It is the root of the whole file structure, and therefore does not have a parent directory. The root directory belongs to the system administrator and can be changed only by the system administrator.
- **Home directory**: We use our **home directory** when we first log into the system. This contains any files we create while in it and may contain personal system files. Each user has a home directory.
- **Working directory**: The **working directory** (or **current directory**) is the directory we are ‘in’ at any point in a user session. When we first log in, the working directory is our home directory. When we change directory, our working directory changes automatically.
- **Parent directory**: The **parent directory** is the directory immediately above the working directory.

**Paths and pathnames**
Every directory and file in a file system must have a name. To uniquely identify a file, we need to specify the file’s **path** from the root directory to the file. The file’s path is specified by its **absolute pathname**, a list of all directories separated by a slash character (/).
The absolute pathname for a file or a directory is like an address of a person. UNIX also provides a shorter pathname under certain circumstances, known as a **relative pathname**, which is the path relative to the working directory.

## 13.6 TEXT VERSUS BINARY
Before closing this chapter, we discuss two terms used to categorize files: *text files* and *binary files*. A file stored on a storage device is a sequence of bits that can be interpreted by an application program as a text file or a binary file.

### 13.6.1 Text files
A **text file** is a file of characters. It cannot contain integers, floating-point numbers, or any other data structures in their internal memory format. To store these data types, they must be converted to their character equivalent formats.
Some files can only use character data types. Most notable are file streams (input/output objects in some object-oriented language like C++) for keyboards, monitors, and printers. This is why we need special functions to format data that is input from or output to these devices.

### 13.6.2 Binary files
A **binary file** is a collection of data stored in the internal format of the computer. In this definition, data can be an integer (including other data types represented as unsigned integers, such as image, audio, or video), a floating-point number, or any other structured data (except a file).
Unlike text files, binary files contain data that is meaningful only if it is properly interpreted by a program. If the data is textual, one byte is used to represent one character. But if the data is numeric, two or more bytes are considered a data item.
`,zh:`
# 第十三章：檔案結構

在本章中，我們將討論檔案結構。根據應用程式的需求，檔案會使用各種方法儲存在輔助儲存裝置上。我們也將討論如何檢索個別記錄。本章是下一章的序幕，下一章將討論如何組織和存取相關檔案的集合，即資料庫。

## 學習目標
學完本章後，學生應能：
- 定義兩種存取方法的類別：循序存取和隨機存取。
- 理解循序檔案的結構及其更新方式。
- 理解索引檔案的結構以及索引與資料檔之間的關係。
- 理解雜湊檔案背後的思想並描述一些雜湊方法。
- 描述位址碰撞及其解決方法。
- 定義目錄以及如何使用它們來組織檔案。
- 區分文字檔和二進位檔。

## 13.1 簡介
檔案儲存在**輔助**或**次級儲存裝置**上。最常見的兩種輔助儲存形式是磁碟和磁帶。輔助儲存中的檔案既可以讀取也可以寫入。檔案也可以以電腦可以寫入但不能讀取的形式存在。例如，系統監視器上的資訊顯示是一種檔案形式，發送到印表機的資料也是。從廣義上講，鍵盤也是一個檔案，儘管它不能儲存資料。

就我們的目的而言，檔案是資料記錄的集合，其中每個記錄由一個或多個欄位組成，如第 11 章所定義。

當我們設計檔案時，重要的問題是我們將如何從檔案中檢索資訊（特定記錄）。有時我們需要一個接一個地處理記錄，而有時我們需要快速存取特定記錄，而無需檢索前面的記錄。**存取方法**決定了記錄如何被檢索：*循序*或*隨機*。

### 13.1.1 循序存取 (Sequential access)
如果我們需要循序存取檔案——即從頭到尾一個接一個地存取記錄——我們使用**循序檔案**結構。

### 13.1.2 隨機存取 (Random access)
如果我們需要存取特定記錄而無需檢索其前的所有記錄，我們使用允許**隨機存取**的檔案結構。有兩種檔案結構允許這樣做：*索引檔案*和*雜湊檔案*。

## 13.2 循序檔案 (SEQUENTIAL FILES)
循序檔案是一種記錄只能從頭到尾一個接一個地存取的檔案。記錄在輔助儲存（如磁帶或磁碟）中一個接一個地儲存，並且在最後一個記錄之後有一個 **EOF (檔案結束)** 標記。作業系統沒有關於記錄位址的資訊，它只知道整個檔案儲存在哪裡。作業系統唯一知道的是記錄是循序的。

演算法 13.1 顯示了如何處理循序檔案中的記錄。我們逐一處理記錄。作業系統處理完最後一個記錄後，檢測到 EOF 並退出迴圈。

**演算法 13.1 處理循序檔案中記錄的偽代碼**
\`\`\`text
演算法：SequentialFileProcessing (file)
目的：處理循序檔案中的所有記錄
前置條件：給定輔助儲存上檔案的起始位址
後置條件：無
回傳：無
{
    while (Not EOF)
    {
        從輔助儲存讀取下一個記錄到記憶體
        處理記錄
    }
}
\`\`\`

循序檔案用於需要從頭到尾存取所有記錄的應用程式中。例如，如果公司中每個員工的個人資訊都儲存在檔案中，我們可以使用**循序存取**在月底檢索每個記錄以列印工資單。因為我們必須處理每個記錄，所以循序存取比隨機存取更有效率且更容易。

然而，循序檔案對於隨機存取效率不高。例如，如果銀行的所有客戶記錄只能循序存取，那麼需要從 ATM 取款的客戶將不得不等待系統從檔案開頭檢查每個記錄，直到到達客戶的記錄。如果這家銀行有一百萬個客戶，系統平均將檢索五十萬個記錄才能到達客戶的記錄。這是非常沒有效率的。

### 13.2.1 更新循序檔案
循序檔案必須定期更新以反映資訊的變化。更新過程非常複雜，因為所有記錄都需要按順序檢查和更新（如有必要）。

**涉及更新的檔案**
更新程式涉及四個檔案：新主檔、舊主檔、交易檔和錯誤報告檔。所有這些檔案都根據鍵值進行排序。
- **新主檔 (New master file)**：新的永久資料檔，或通常稱為**新主檔**，包含最新的資料。請注意，更新程式完成後，新主檔將被發送到離線儲存，保存在那裡直到再次需要。
- **舊主檔 (Old master file)**：**舊主檔**是應該更新的永久檔案。即使更新後，舊主檔通常也會保留以供參考。
- **交易檔 (Transaction file)**：第三個檔案是**交易檔**。這包含要應用於主檔的更改。所有檔案更新中都有三種基本的更改類型：
    - *新增交易*包含要添加到主檔的新記錄的資料。
    - *刪除交易*標識要從檔案中刪除的記錄。
    - *更改交易*包含對檔案中特定記錄的修訂。
    要處理任何這些交易，我們需要一個**鍵 (key)**。鍵是一個或多個唯一標識檔案中資料的欄位。例如，在學生檔案中，鍵可以是學生 ID。
- **錯誤報告檔 (Error report file)**：更新程式所需的第四個檔案是**錯誤報告檔**。更新過程不產生至少一個錯誤的情況非常罕見。發生錯誤時，我們需要報告它。錯誤報告包含更新過程中發現的所有錯誤的列表，並提交以採取糾正措施。

**處理檔案更新**
為了使更新過程有效率，所有檔案都按相同的鍵排序。更新過程要求我們比較交易檔和主檔上的鍵，並假設沒有錯誤，採取以下三個動作之一：
1.  如果交易檔鍵小於主檔鍵且交易是新增 (A)，則將交易添加到新主檔。
2.  如果交易檔鍵等於主檔鍵，則：
    a.  如果交易是更改 (C)，則更改主檔資料的內容。
    b.  如果交易是刪除 (D)，則從主檔中刪除資料。
3.  如果交易檔鍵大於主檔鍵，則將舊主檔記錄寫入新主檔。
4.  有幾種情況可能會產生錯誤並在錯誤檔中報告：
    a.  如果交易定義新增一個已存在於舊主檔中的記錄（鍵值相同）。
    b.  如果交易定義刪除或更改一個不存在於舊主檔中的記錄。

## 13.3 索引檔案 (INDEXED FILES)
要隨機存取檔案中的記錄，我們需要知道記錄的位址。例如，假設客戶想要檢查他們的銀行帳戶。客戶和櫃員都不知道客戶記錄的位址。客戶只能給櫃員他們的帳號（鍵）。在這裡，索引檔案可以將帳號（鍵）關聯到記錄位址。

**索引檔案**由**資料檔**（這是一個循序檔案）和**索引**組成。索引本身是一個非常小的檔案，只有兩個欄位：循序檔案的鍵和磁碟上相應記錄的位址。索引根據資料檔的鍵值進行排序。

存取檔案中的記錄需要以下步驟：
1.  將整個索引檔載入主記憶體（檔案很小，佔用的記憶體很少）。
2.  使用有效的搜尋演算法（如二元搜尋）搜尋索引條目以找到所需的鍵。
3.  檢索記錄的位址。
4.  使用位址檢索資料記錄並傳遞給使用者。

### 13.3.1 倒排檔案 (Inverted files)
索引檔案的優點之一是我們可以有多個索引，每個索引具有不同的鍵。例如，可以根據社會安全號碼或姓氏檢索員工檔案。這種類型的索引檔案通常稱為**倒排檔案**。

## 13.4 雜湊檔案 (HASHED FILES)
在索引檔案中，索引將鍵映射到位址。**雜湊檔案**使用數學函數來完成這種映射。使用者給出鍵，函數將鍵映射到位址並將其傳遞給作業系統，然後檢索記錄。

雜湊檔案消除了對額外檔案（索引）的需求。在索引檔案中，我們必須將索引保留在磁碟檔案中，當我們需要處理資料檔時，我們必須先將索引載入記憶體，搜尋它以找到資料記錄的位址，然後再存取資料檔以存取記錄。在雜湊檔案中，查找位址是通過使用函數完成的，因此不需要索引及其相關的所有開銷。然而，我們將看到雜湊檔案有其自身的缺點。

### 13.4.1 雜湊方法 (Hashing methods)
對於鍵-位址映射，我們可以選擇幾種**雜湊方法**之一。我們在這裡討論其中幾種。

**直接雜湊 (Direct hashing)**
在**直接雜湊**中，鍵是沒有任何演算法操作的資料檔位址。因此，檔案必須包含每個可能鍵的記錄。雖然適合直接雜湊的情況有限，但它可能非常強大，因為它保證沒有*同義詞*或*碰撞*（本章稍後討論），這與其他方法不同。
雖然這是理想的方法，但其應用非常有限。例如，使用長標識符作為鍵是非常沒有效率的，因為它們必須有幾位數。因此，讓我們將注意力轉向將大量可能的鍵映射到小位址空間的雜湊技術。

**模數除法雜湊 (Modulo division hashing)**
也稱為**除法餘數雜湊**，模數除法方法將鍵除以檔案大小，並使用餘數加 1 作為位址。這給出了以下簡單的雜湊演算法，其中 *list_size* 是檔案中的元素數量。將 1 加到模運算結果的原因是我們的列表從 1 開始而不是 0：
\`address = key mod list_size + 1\`

雖然此演算法適用於任何列表大小，但**質數**的列表大小比其他列表大小產生的碰撞更少。因此，只要可能，盡量使檔案大小成為質數。

**數字提取雜湊 (Digit extraction hashing)**
使用**數字提取雜湊**，從鍵中提取選定的數字並將其用作位址。例如，使用六位數的員工編號雜湊到三位數的位址 (000–999)，我們可以選擇第一、第三和第四位數字（從左邊算起）並將其用作位址。

**其他雜湊方法**
還存在其他流行的方法，如平方取中法、折疊法、旋轉法和偽隨機法。

### 13.4.2 碰撞 (Collision)
通常，雜湊列表的鍵總體大於資料檔中的記錄數。因為檔案中每個位址有許多鍵，所以存在多個鍵雜湊到檔案中相同位址的可能性。我們將雜湊到列表中相同位址的鍵集稱為**同義詞 (synonyms)**。

如果我們插入列表的實際資料包含兩個或更多同義詞，我們將發生碰撞。**碰撞**是指當雜湊演算法為插入鍵產生一個位址但該位址已被佔用時發生的事件。雜湊演算法產生的位址稱為**主位址 (home address)**。包含所有主位址的檔案部分稱為**主要區域 (prime area)**。當兩個鍵在主位址發生碰撞時，我們必須通過將其中一個鍵及其資料放置在主要區域之外的另一個位置來解決碰撞。

**碰撞解決**
除了直接方法外，我們討論的雜湊方法都沒有創建一對一的映射。這意味著當我們將新鍵雜湊到位址時，我們可能會產生碰撞。有幾種處理碰撞的方法，每種方法都獨立於雜湊演算法。

**開放定址 (Open addressing)**
第一種碰撞解決方法，**開放定址解決**，在主要區域中解決碰撞。當發生碰撞時，搜尋主要區域位址以尋找可以放置新資料的開放或未佔用記錄。對於無法儲存在主位址的資料，一種簡單的策略是將其儲存在下一個位址（主位址 + 1）。

**鏈結串列解決 (Linked list resolution)**
開放定址的一個主要缺點是每次碰撞解決都會增加未來碰撞的可能性。這種缺點在另一種碰撞解決方法**鏈結串列解決**中被消除。在這種方法中，第一條記錄儲存在主位址中，但包含指向第二條記錄的指標。

**桶式雜湊 (Bucket hashing)**
另一種處理碰撞問題的方法是雜湊到桶。**桶 (bucket)** 是一個可以容納多個記錄的節點。這種方法的缺點是可能會有大量浪費（未佔用）的位置。

## 13.5 目錄 (DIRECTORIES)
大多數作業系統提供**目錄**來組織檔案。目錄執行的功能與檔案櫃中的文件夾相同。然而，大多數作業系統中的目錄表示為一種特殊類型的檔案，其中包含有關其他檔案的資訊。目錄不僅作為一種索引，告訴作業系統檔案位於輔助儲存裝置上的位置，還可以包含有關其包含的檔案的其他資訊，例如誰有權存取每個檔案，或每個檔案創建、存取或修改的日期。
大多數作業系統中的目錄組織成樹狀抽象資料型別 (ADT)，其中除根目錄外，每個目錄都有一個父目錄。包含在另一個目錄中的目錄稱為容器目錄的**子目錄**。

### 13.5.1 UNIX 作業系統中的目錄
在 UNIX 中，目錄系統組織成樹狀結構。目錄結構的頂部是一個稱為**根 (root)** 的目錄。雖然它的名字是 root，但在與目錄相關的命令中，它被鍵入為一個斜線 (/)。反過來，每個目錄都可以包含子目錄和檔案。

**特殊目錄**
有四種特殊類型的目錄在 UNIX 的目錄結構中扮演重要角色：根目錄、家目錄、工作目錄和父目錄。
- **根目錄**：根目錄是檔案系統階層中的最高層級。它是整個檔案結構的根，因此沒有父目錄。根目錄屬於系統管理員，只能由系統管理員更改。
- **家目錄 (Home directory)**：當我們首次登入系統時使用我們的**家目錄**。這包含我們在其中創建的任何檔案，並可能包含個人系統檔案。每個使用者都有一個家目錄。
- **工作目錄 (Working directory)**：**工作目錄**（或**當前目錄**）是我們在使用者會話中任何時候「所在」的目錄。當我們首次登入時，工作目錄是我們的家目錄。當我們更改目錄時，我們的工作目錄會自動更改。
- **父目錄 (Parent directory)**：**父目錄**是工作目錄正上方的目錄。

**路徑和路徑名稱**
檔案系統中的每個目錄和檔案都必須有一個名稱。為了唯一標識一個檔案，我們需要指定從根目錄到該檔案的**路徑**。檔案的路徑由其**絕對路徑名稱**指定，這是由斜線字元 (/) 分隔的所有目錄的列表。
檔案或目錄的絕對路徑名稱就像一個人的地址。UNIX 還在某些情況下提供了一種較短的路徑名稱，稱為**相對路徑名稱**，它是相對於工作目錄的路徑。

## 13.6 文字與二進位 (TEXT VERSUS BINARY)
在結束本章之前，我們討論用於分類檔案的兩個術語：*文字檔*和*二進位檔*。儲存在儲存裝置上的檔案是一系列位元，應用程式可以將其解釋為文字檔或二進位檔。

### 13.6.1 文字檔 (Text files)
**文字檔**是字元的檔案。它不能包含整數、浮點數或任何其他以其內部記憶體格式儲存的資料結構。要儲存這些資料類型，必須將它們轉換為其字元等價格式。
某些檔案只能使用字元資料類型。最值得注意的是鍵盤、監視器和印表機的檔案串流（某些物件導向語言如 C++ 中的輸入/輸出物件）。這就是為什麼我們需要特殊函數來格式化從這些設備輸入或輸出的資料。

### 13.6.2 二進位檔 (Binary files)
**二進位檔**是以電腦內部格式儲存的資料集合。在這個定義中，資料可以是整數（包括表示為無符號整數的其他資料類型，如圖像、音訊或視訊）、浮點數或任何其他結構化資料（檔案除外）。
與文字檔不同，二進位檔包含的資料只有在被程式正確解釋時才有意義。如果資料是文字的，則使用一個位元組來表示一個字元。但是如果資料是數值的，則兩個或多個位元組被視為一個資料項目。
`},g={en:`
# Chapter 14: Databases

In this chapter we discuss databases and database management systems (DBMS). We present the three-level architecture for a DBMS, focusing on the **relational database** model, with examples of its operation. We also discuss a language (Standard Query Language) that operates on relational databases. We briefly touch on the design of the databases, and finally mention other database models.

## Objectives
After studying this chapter, the student should be able to:
- Define a database and a database management system (DBMS) and describe the components of a DBMS.
- Describe the architecture of a DBMS based on the ANSI/SPARC definition.
- Define the three traditional database models: hierarchical, networking, and relational.
- Describe the relational model and relations.
- Understand operations on a relational database based on commands available in SQL.
- Describe the steps in database design.
- Define ERM and E-R diagrams and explain the entities and relationships in this model.
- Define the hierarchical levels of normalization and understand the rationale for normalizing the relations.
- List database types other than the relational model.

## 14.1 INTRODUCTION
Data storage traditionally used individual, unrelated files, sometimes called **flat-files**. In the past, each application program in an organization used its own file. In a university, for example, each department might have its own set of files: the record office kept a file about the student information and their grades, the financial aid office kept its own file about students that needed financial aid to continue their education, the scheduling office kept the name of the professors and the courses they were teaching, the payroll department kept its own file about the whole staff (including professors), and so on. Today, however, all of these flat-files can be combined in a single entity, the database for the whole university.

### 14.1.1 Definition
Although it is difficult to give a universally agreed definition of a database, we use the following common definition:
**Definition: A database is a collection of related, logically coherent, data used by the application programs in an organization.**

### 14.1.2 Advantages of databases
Comparing the flat-file system, we can mention several advantages of a database system.

**Less redundancy**
In a flat-file system there is a lot of redundancy. For example, in the flat-file system for a university, the names of professors and students are stored in more than one file.

**Inconsistency avoidance**
If the same piece of information is stored in more than one place, then any changes in the data need to occur in all places that data is stored. For example, if a female student marries and accepts the last name of her husband, the last name of the student needs to be changed in all files that hold information about the student. Lack of care may create inconsistency in the data.

**Efficiency**
A database is usually more efficient that a flat-file system, because a piece of information is stored in fewer locations.

**Data integrity**
In a database system it is easier to maintain data integrity (see Chapter 16) because a piece of data is stored in fewer locations.

**Confidentiality**
It is easier to maintain the confidentiality of the information if the storage of data is centralized in one location.

### 14.1.3 Database management systems
A **database management system (DBMS)** defines, creates, and maintains a database. The DBMS also allows controlled access to data in the database. A DBMS is a combination of five components: hardware, software, data, users, and procedures.

**Hardware**
The hardware is the physical computer system that allows access to data. For example, the terminals, hard disk, main computer, and workstations are considered part of the hardware in a DBMS.

**Software**
The software is the actual program that allows users to access, maintain, and update data. In addition, the software controls which user can access which parts of the data in the database.

**Data**
The data in a database is stored physically on the storage devices. In a database, data is a separate entity from the software that accesses it. This separation allows the organization to change the software without having to change the physical data or the way in which it is stored. If an organization decides to use a DBMS, then all the information needed by the organization should be kept together as one entity, to be accessible by the software in the DBMS.

**Users**
The term users in a DBMS has a broad meaning. We can divide users into two categories: end users and application programs.
- **End users**: End users are those humans who can access the database directly to get information. There are two types of end users: **database administrators (DBAs)** and normal users. Database administrators have the maximum level of privileges and can control other users and their access to the DBMS, grant some of their privileges to somebody else, but retain the ability to revoke them at any time. A normal user, on the other hand, can only use part of the database and has limited access.
- **Application programs**: The other users of data in a database are **application programs**. Applications need to access and process data. For example, a payroll application program needs to access part of the data in a database to create paychecks at the end of the month.

**Procedures**
The last component of a DBMS is a set of procedures or rules that should be clearly defined and followed by the users of the database.

## 14.2 DATABASE ARCHITECTURE
The American National Standards Institute/Standards Planning and Requirements Committee (ANSI/SPARC) has established a three-level architecture for a DBMS: internal, conceptual, and external.

### 14.2.1 Internal level
The **internal level** determines where data is actually stored on the storage devices. This level deals with low-level access methods and how bytes are transferred to and from storage devices. In other words, the internal level interacts directly with the hardware.

### 14.2.2 Conceptual level
The **conceptual level** defines the logical view of the data. The data model is defined on this level, and the main functions of the DBMS, such as queries, are also on this level. The DBMS changes the internal view of data to the external view that users need to see. The conceptual level is an intermediary and frees users from dealing with the internal level.

### 14.2.3 External level
The **external level** interacts directly with the user (end users or application programs). It changes the data coming from the conceptual level to a format and view that is familiar to the users.

## 14.3 DATABASE MODELS
A **database model** defines the logical design of data. The model also describes the relationships between different parts of the data. In the history of database design, three models have been in use: the hierarchical model, the network model, and the relational model.

### 14.3.1 Hierarchical database model
In the **hierarchical model**, data is organized as an inverted tree. Each entity has only one parent but can have several children. At the top of the hierarchy, there is one entity, which is called the *root*. As the hierarchical model is obsolete, no further discussion of this model is necessary.

### 14.3.2 Network database model
In the **network model**, the entities are organized in a graph, in which some entities can be accessed through several paths. There is no hierarchy. This model is also obsolete and needs no further discussion.

### 14.3.3 Relational database model
In the **relational model**, data is organized in two-dimensional tables called **relations**. There is no hierarchical or network structure imposed on the data. The tables or *relations* are, however, related to each other.
The relational model is one of the common models in use today, and we devote most of this chapter to it. In the last section, we briefly discuss the other two common models that are derived from the relational model: the distributed model and the object-oriented model.

## 14.4 THE RELATIONAL DATABASE MODEL
In the **relational database management system (RDBMS)**, the data is represented as a set of relations.

### 14.4.1 Relation
A **relation**, in appearance, is a two-dimensional table. The RDBMS organizes the data so that its external view is a set of relations or tables. This does not mean that data are stored as tables: the physical storage of the data is independent of the way in which the data is logically organized.
A relation in an RDBMS has the following features:
- **Name**. Each relation in a relational database should have a name that is unique among other relations.
- **Attributes**. Each column in a relation is called an **attribute**. The attributes are the column headings in the table. Each attribute gives meaning to the data stored under it. Each column in the table must have a name that is unique in the scope of the relation. The total number of attributes for a relation is called the **degree** of the relation. Note that the attribute names are not stored in the database: the conceptual level uses the attributes to give meaning to each column.
- **Tuples**. Each row in a relation is called a **tuple**. A tuple defines a collection of attribute values. The total number of rows in a relation is called the **cardinality** of the relation. Note that the cardinality of a relation changes when tuples are added or deleted. This makes the database dynamic.

### 14.4.2 Operations on relations
In a relational database we can define several operations to create new relations based on existing ones. We define nine operations in this section: *insert*, *delete*, *update*, *select*, *project*, *join*, *union*, *intersection*, and *difference*. Instead of discussing these operations in the abstract, we describe each operation as defined in the database query language SQL (Structured Query Language).

**Structured Query Language**
**Structured Query Language (SQL)** is the language standardized by the American National Standards Institute (ANSI) and the **International Organization for Standardization (ISO)** for use on relational databases. It is a declarative rather than procedural language, which means that users declare what they want without having to write a step-by-step procedure. The SQL language was first implemented by the Oracle Corporation in 1979, with various versions of SQL being released since then.

**Insert**
The **insert operation** is a **unary operation**—that is, it is applied to a single relation. The operation inserts a new tuple into the relation. The insert operation uses the following format:
\`\`\`sql
insert into RELATION-NAME values (..., ..., ...)
\`\`\`
The *values* clause defines all the attribute values for the corresponding tuple to be inserted. String values are enclosed in quotation marks, numeric values are not.

**Delete**
The **delete operation** is also a unary operation. The operation deletes a tuple defined by a criterion from the relation. The delete operation uses the following format:
\`\`\`sql
delete from RELATION-NAME where criteria
\`\`\`
The criteria for deletion are defined in the *where* clause.

**Update**
The **update operation** is also a unary operation that is applied to a single relation. The operation changes the value of some attributes of a tuple. The update operation uses the following format:
\`\`\`sql
update RELATION-NAME
set attribute1 = value1, attribute2 = value2, ...
where criteria
\`\`\`
The attribute to be changed is defined in the *set* clause and the criteria for updating in the *where* clause.

**Select**
The **select operation** is a unary operation—that is, is applied to a single relation—and creates another relation. The tuples (rows) in the resulting relation are a subset of the tuples in the original relation. The select operation uses some criteria to select some of the tuples from the original relation. The select operation uses the following format:
\`\`\`sql
select *
from RELATION-NAME
where criteria
\`\`\`
The asterisk signifies that all attributes are chosen.

**Project**
The **project operation** is also a unary operation, and creates another relation. The attributes (columns) in the resulting relation are a subset of the attributes in the original relation. The project operation creates a relation in which each tuple has fewer attributes. The number of tuples (rows) in this operation remains the same. The project operation uses the following format:
\`\`\`sql
select attribute-list
from RELATION-NAME
\`\`\`
The names of the columns for the new relation are explicitly listed.

**Join**
The **join operation** is a **binary operation**—it takes two relations and combines them based on common attributes. The join operation uses the following format:
\`\`\`sql
select attribute-list
from RELATION1, RELATION2
where criteria
\`\`\`
The attribute list is the combination of attributes from the two input relations: criteria explicitly define the attributes used as common attributes. The join operation is complex and has many variations.

**Union**
The **union operation** is also a binary operation, taking two relations and creating a new relation. However, there is a restriction on the two relations: they must have the same attributes. The union operation, as defined in set theory, creates a new relation in which each tuple is either in the first relation, in the second, or in both. The union operation uses the following format:
\`\`\`sql
select *
from RELATION1
union
select *
from RELATION2
\`\`\`
Again, asterisks signify that all attributes are selected.

**Intersection**
The **intersection operation** is also a binary operation, taking two relations and creating a new relation. Like the union operation, the two relations must have the same attributes. The intersection operation, as defined in set theory, creates a new relation in which each tuple is a member in both relations. The intersection operation uses the following format:
\`\`\`sql
select *
from RELATION1
intersection
select *
from RELATION2
\`\`\`

**Difference**
The **difference operation** is also a binary operation. It is applied to two relations with the same attributes. The tuples in the resulting relation are those that are in the first relation but not the second. The difference operation uses the following format:
\`\`\`sql
select *
from RELATION1
minus
select *
from RELATION2
\`\`\`

**Combination of statements**
The SQL language allows us to combine the foregoing statements to extract more complex information from a database.

## 14.5 DATABASE DESIGN
The design of any database is a lengthy and involved task that can only be done through a step-by-step process. The first step normally involves a lot of interviewing of potential users of the database, for example in a university, to collect the information needed to be stored and the access requirements of each department. The second step is to build an **entity–relation model (ERM)** that defines the entities for which some information must be maintained, the attributes of these entities, and the relationship between these entities.

The next step in design is based on the type of database to be used. In a relational database, the next step is to build relations based on the ERM and normalize the relations. In this introductory course, we just give some idea about ERMs and normalization.

### 14.5.1 Entity–relation model (ERM)
In this step, the database designer creates an **entity–relationship (E-R) diagram** to show the entities for which information needs to be stored and the relationship between those entities. E-R diagrams uses several geometric shapes, but we use only a few of them here:
- **Rectangles** represent entity sets.
- **Ellipses** represent attributes.
- **Diamonds** represent relationship sets.
- **Lines** link attributes to entity sets and link entity sets to relationship sets.

The relationships, which are shown by diamonds, can be one-to-one, one-to-many, many-to-one, and many-to-many.

### 14.5.2 From E-R diagrams to relations
After the E-R diagram has been finalized, relations (tables) in the relational database can be created.

**Relations for entity sets**
For each entity set in the E-R diagram, we create a relation (table) in which there are *n* columns related to the *n* attributes defined for that set.

**Relations for relationship sets**
For each relationship set in the E-R diagram, we create a relation (table). This relation has one column for the key of each entity set involved in this relationship and also one column for each attribute of the relationship itself if the relationship has attributes.

### 14.5.3 Normalization
**Normalization** is the process by which a given set of relations are transformed to a new set of relations with a more solid structure. Normalization is needed to allow any relation in the database to be represented, to allow a languages like SQL to use powerful retrieval operations composed of atomic operations, to remove anomalies in insertion, deletion, and updating, and reduce the need for restructuring the database as new data type are added.

The normalization process defines a set of hierarchical **normal forms (NFs)**. Several normal forms have been proposed, including 1NF, 2NF, 3NF, BCNF (Boyce–Codd Normal Form), 4NF, PJNF (Projection/Joint Normal Form), 5NF, and so on. The discussion of these normal forms (except 1NF) involves the discussion of functional dependencies, a theoretical discipline, which is beyond the scope of this book. However, one important point that we need to know is that these normal forms form a hierarchical structure. In other words, if the relations in a database are in 3NF, it should have been first in 2NF.

**First normal form (1NF)**
When we transform entities or relationships into tabular relations, there may be some relations in which there are more values in the intersection of a row or column. A relation that is not in the first normal form may suffers from many problems. These two relations can be normalized by repeating the rows in which this problem exists.

**Second normal form (2NF)**
In each relation we need to have a key (called a *primary key*) on which all other attributes (column values) needs to depend. However, it may happen that when relations are established based on the E-R diagram, we may have some composite keys (a combination of two or more keys). In this case, a relation is in second normal form if every non-key attribute depends on the whole composite key.
If some attributes depend on part of the composite key, the relation is not in second normal form. We can apply the 2NF process and divide the relation into two, both in the second normal form.

**Other normal forms**
Other normal forms use more complicated dependencies among attributes. We leave these dependencies to books dedicated to the discussion of database topics.

## 14.6 OTHER DATABASE MODELS
The relational database is not the only database model in use today. Two other common models are *distributed databases* and *object-oriented databases*. We briefly discuss these here.

### 14.6.1 Distributed databases
The **distributed database** model is not a new model, but is based on the relational model. However, the data is stored on several computers that communicate through the Internet or a private wide area network. Each computer (or site) maintains either part of the database or the whole database. In other words, data is either fragmented, with each fragment stored at one site, or data is replicated at each site.

**Fragmented distributed databases**
In a **fragmented distributed database**, data is localized—locally used data is stored at the corresponding site. However, this does not mean that a site cannot access data stored at another site, access is mostly local, but occasionally global. Although each site has complete control over its local data, there is global control through the Internet or a wide area network.
For example, a pharmaceutical company may have multiple sites in many countries. Each site has a database with information about its own employees, but a central personnel department could have control of all the databases.

**Replicated distributed databases**
In a **replicated distributed database**, each site holds an exact replica of another site. Any modification to data stored in one site is repeated exactly at every site. The reason for having such a database is security. If the system at one site fails, users at the site can access data at another site.

### 14.6.2 Object-oriented databases
The relational database has a specific view of data that is based on the nature of the database’s tuples and attributes. The smallest unit of data in a relational database is the intersection of a tuple and an attribute. However, some applications need to look at data in other forms, for example to see data as a structure (see Chapter 11), such as a record composed of fields.
An **object-oriented database** tries to keep the advantages of the relational model and at the same time allows applications to access structured data. In an object-oriented database, objects and their relations are defined. In addition, each object can have attributes that can be expressed as fields.
For example, in an organization, one could define object types for employee, department, and customer. The employee class could define the attributes of an employee object (first name, last name, social security number, salary, and so on) and how they can be accessed. The department object could define the attributes of the department and how they can be accessed. In addition, the database could create a relation between an employee object and a department object to denote that the employee works in that department.

**XML**
The query language normally used for objected-oriented databases is **XML (Extensible Markup Language)**. XML was originally designed to add markup information to text documents, but it also has found its application as a query language in databases. XML can represent data with nested structure.

## 14.7 END-CHAPTER MATERIALS

### 14.7.1 Recommended reading
For more details about subjects discussed in this chapter, the following books are recommended:
- Alagic, S. *Relational Database Technology*, New York: Springer, 1986
- Dietrich, S. *Understanding Relational Database Query Language*, Upper Saddle River, NJ: Prentice-Hall, 2001
- Elmasri, R. and Navathe, S. *Fundamentals of Database Systems*, Reading, MA: Addison-Wesley, 2006
- Mannino, M. *Database Application Development and Design*, New York: McGraw-Hill, 2001
- Ramakrishnan, R. and Gehrke, J. *Database Management Systems*, New York: McGraw-Hill, 2003
- Silberschatz, A., Korth, H. and Sudarshan, S. *Databases: System Concepts*, New York: McGraw-Hill, 2005

### 14.7.2 Key Terms
- application programs
- attribute
- binary operation
- cardinality
- conceptual level
- database
- database management system (DBMS)
- database model
- delete operation
- difference operation
- distributed database
- End users
- Entity-Relation Model (E-R)
- Entity–Relationship (E-R) diagram
- external level
- flat-files
- fragmented distributed database
- hierarchical model
- insert operation
- internal level
- International Organization for Standardization (ISO)
- intersection operation
- join operation
- name
- network model
- normal form (NF)
- normalization
- object-oriented database
- project operation
- relation
- relational database management system (RDBMS)
- relational model
- replicated distributed database
- select operation
- Structured Query Language (SQL)
- tuple
- unary operation
- union operation
- update operation
- users

### 14.7.3 Summary
- A database is a collection of data that is logically, but not necessarily physically, coherent—its various parts can be physically separated. A database management system (DBMS) defines, creates, and maintains a database.
- The American National Standards Institute/Standards Planning and Requirements Committee (ANSI/SPARC) has established a three-level architecture for a DBMS: internal, conceptual, and external. The internal level determines where data is actually stored on storage devices. The conceptual level defines the logical view of the data. The external level interacts directly with the user.
- Traditionally, three types of database model were defined: hierarchical, network, and relational. Only the last, relational model, has survived.
- In the relational model, data is organized in two-dimensional tables called relations. A relation has the following features: name, attributes, and tuples.
- In a relational database we can define several operations to create new relations based on existing ones. We mentioned nine operations in the context of the database query language SQL (Structured Query Language): insert, delete, update, select, project, join, union, intersection, and difference.
- The design of a database, for example for an organization, is often a lengthy task that can only be done through a step-by-step process. The first step often involves interviewing potential users of the database to collect the information that needs to be stored. The second step is to build an Entity-Relation Model (ERM) that defines the entities for which information must be maintained. The next step is to build relations based on the ERM.
- Normalization is the process by which a given set of relations are transformed to a new set of relations with a more solid structure. Normalization is required to allow any relation in the database to be represented, to allow a query language such as SQL to use powerful retrieval operations composed of atomic operations, to remove anomalies in insertion, deletion, and updating, and to reduce the need for restructuring the database as new data types are to be added.
- The relational database is not the only model of database in use today. The other two common models are distributed databases and object-oriented databases.

## 14.8 PRACTICE SET

### 14.8.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 14.8.2 Review questions
1. What are the five necessary components of a DBMS?
2. What are the three database models? Which is the most popular today?
3. What is a relation in a relational database?
4. In a relation, what is an attribute? What is a tuple?
5. List some unary operations in relational databases.
6. List some binary operations in relational databases.
7. What is SQL? What is XML? Which one is a query language for relational databases? Which one is a query language for the objected-oriented language?

### 14.8.3 Problems
1. You have relations A, B, and C as shown in Figure 14.21. Show the resulting relation if you apply the following SQL statements:
   \`\`\`sql
   select *
   from A
   where A2 = 16
   \`\`\`
2. You have relations A, B, and C as shown in Figure 14.21. Show the resulting relation if you apply the following SQL statements:
   \`\`\`sql
   select A1 A2
   from A
   where A2 = 16
   \`\`\`
3. You have relations A, B, and C as shown in Figure 14.21. Show the resulting relation if you apply the following SQL statements:
   \`\`\`sql
   select A3
   from A
   \`\`\`
4. You have relations A, B, and C as shown in Figure 14.21. Show the resulting relation if you apply the following SQL statements:
   \`\`\`sql
   select B1
   from B
   where B2 = 216
   \`\`\`
5. You have relations A, B, and C as shown in Figure 14.21. Show the resulting relation if you apply the following SQL statements:
   \`\`\`sql
   update C
   set C1 = 37
   where C1 = 31
   \`\`\`
6. Using the model in Figure 14.5 in section 14.3.3, show the SQL statement that creates a new relation containing only the course number and the number of units for each course.
7. Using the model in Figure 14.5, show the SQL statement that creates a new relation containing only the student ID and student name.
8. Using the model in Figure 14.5, show the SQL statement that creates a new relation containing only the professor’s name.
9. Using the model in Figure 14.5, show the SQL statement that creates a new relation containing only the department name.
10. Using the model in Figure 14.5, show the SQL statement that creates a new relation containing the courses taken by the student with ID 2010.
11. Using the model in Figure 14.5, show the SQL statement that creates a new relation containing the courses taught by Professor Blake.
12. Using the model in Figure 14.5, show the SQL statement that creates a new relation containing only courses that have three units.
13. Using the model in Figure 14.5, show the SQL statement that creates a new relation containing only the name of students taking course CIS015.
14. Using the model in Figure 14.5, show the SQL statement that creates a new relation containing the department number of the Computer Science Department.
15. Is the following relation in first normal form (1NF)? If not, change the table to make it pass 1NF criteria.
    A | B | C | D
    ---|---|---|---
    1 | 70 | 65 | 14
    2 | 25, 32, 71 | 24 | 12, 18
    3 | 32 | 6, 11 | 18
16. Create an E-R diagram for a public library. Show the outline of the relations that can be created from that diagram.
17. Create an E-R diagram for a real estate company, then show the outline of the relations that can be created from that diagram.
18. Create an E-R diagram for three entities FLIGHT, AIRCRAFT, and PILOT in an airline, then show the outlines of the relations in this company.
19. Use references or the Internet to find some information about third normal form (3NF). What kind of functional dependency is involved in this normal form?
20. Use references or the Internet and find some information about Boyce–Codd Normal Form (BCNF). What kind of functional dependency is involved in this normal form?
`,zh:`
# 第十四章：資料庫

在本章中，我們將討論資料庫和資料庫管理系統 (DBMS)。我們介紹 DBMS 的三層架構，重點放在**關聯式資料庫**模型，並舉例說明其運作。我們也將討論一種在關聯式資料庫上運作的語言（結構化查詢語言）。我們簡要觸及資料庫的設計，最後提到其他資料庫模型。

## 學習目標
學完本章後，學生應能：
- 定義資料庫和資料庫管理系統 (DBMS) 並描述 DBMS 的組件。
- 根據 ANSI/SPARC 定義描述 DBMS 的架構。
- 定義三種傳統的資料庫模型：階層式、網路式和關聯式。
- 描述關聯式模型和關聯。
- 基於 SQL 中的可用命令理解關聯式資料庫的操作。
- 描述資料庫設計的步驟。
- 定義 ERM 和 E-R 圖並解釋此模型中的實體和關係。
- 定義正規化的階層級別並理解正規化關聯的理由。
- 列出關聯式模型以外的資料庫類型。

## 14.1 簡介
資料儲存傳統上使用獨立的、不相關的檔案，有時稱為**扁平檔案**。過去，組織中的每個應用程式都使用自己的檔案。例如，在大學中，每個系所可能有自己的一套檔案：註冊處保存關於學生資訊及其成績的檔案，財政援助辦公室保存關於需要財政援助以繼續學業的學生的檔案，排課辦公室保存教授姓名及其教授課程的檔案，薪資部門保存關於全體員工（包括教授）的檔案，依此類推。然而，今天，所有這些扁平檔案都可以合併在一個單一實體中，即整所大學的資料庫。

### 14.1.1 定義
雖然很難給出一個普遍認同的資料庫定義，但我們使用以下常見定義：
**定義：資料庫是組織中應用程式使用的相關、邏輯上一致的資料集合。**

### 14.1.2 資料庫的優點
與扁平檔案系統相比，我們可以提到資料庫系統的幾個優點。

**較少冗餘**
在扁平檔案系統中有大量的冗餘。例如，在大學的扁平檔案系統中，教授和學生的名字儲存在多個檔案中。

**避免不一致**
如果同一條資訊儲存在多個地方，那麼資料的任何更改都需要在儲存該資料的所有地方進行。例如，如果一名女學生結婚並接受丈夫的姓氏，則需要在所有保存該學生資訊的檔案中更改該學生的姓氏。缺乏照料可能會導致資料不一致。

**效率**
資料庫通常比扁平檔案系統更有效率，因為一條資訊儲存在更少的位置。

**資料完整性**
在資料庫系統中，更容易維護資料完整性（見第 16 章），因為一條資料儲存在更少的位置。

**機密性**
如果資料儲存集中在一個位置，則更容易維護資訊的機密性。

### 14.1.3 資料庫管理系統
**資料庫管理系統 (DBMS)** 定義、創建和維護資料庫。DBMS 還允許受控地存取資料庫中的資料。DBMS 是五個組件的組合：硬體、軟體、資料、使用者和程序。

**硬體**
硬體是允許存取資料的實體電腦系統。例如，終端機、硬碟、主電腦和工作站被視為 DBMS 中硬體的一部分。

**軟體**
軟體是允許使用者存取、維護和更新資料的實際程式。此外，軟體控制哪些使用者可以存取資料庫中的哪些部分資料。

**資料**
資料庫中的資料物理儲存在儲存設備上。在資料庫中，資料是與存取它的軟體分離的實體。這種分離允許組織在不必更改物理資料或其儲存方式的情況下更改軟體。如果組織決定使用 DBMS，則組織所需的所有資訊應作為一個實體保存在一起，以便 DBMS 中的軟體可以存取。

**使用者**
DBMS 中的使用者一詞具有廣泛的含義。我們可以將使用者分為兩類：終端使用者和應用程式。
- **終端使用者**：終端使用者是那些可以直接存取資料庫以獲取資訊的人。有兩種類型的終端使用者：**資料庫管理員 (DBA)** 和普通使用者。資料庫管理員擁有最高級別的特權，可以控制其他使用者及其對 DBMS 的存取，將部分特權授予他人，但保留隨時撤銷特權的能力。另一方面，普通使用者只能使用資料庫的一部分且存取權限有限。
- **應用程式**：資料庫中資料的其他使用者是**應用程式**。應用程式需要存取和處理資料。例如，薪資應用程式需要存取資料庫中的部分資料以在月底製作薪資支票。

**程序**
DBMS 的最後一個組件是一組應由資料庫使用者明確定義並遵循的程序或規則。

## 14.2 資料庫架構
美國國家標準協會/標準規劃與需求委員會 (ANSI/SPARC) 為 DBMS 建立了三層架構：內部、概念和外部。

### 14.2.1 內部層級
**內部層級**決定資料實際儲存在儲存設備上的位置。此層級處理低階存取方法以及位元組如何在儲存設備之間傳輸。換句話說，內部層級直接與硬體互動。

### 14.2.2 概念層級
**概念層級**定義資料的邏輯視圖。資料模型在此層級定義，DBMS 的主要功能（如查詢）也在此層級。DBMS 將資料的內部視圖更改為使用者需要看到的外部視圖。概念層級是一個中介，使用戶免於處理內部層級。

### 14.2.3 外部層級
**外部層級**直接與使用者（終端使用者或應用程式）互動。它將來自概念層級的資料更改為使用者熟悉的格式和視圖。

## 14.3 資料庫模型
**資料庫模型**定義資料的邏輯設計。該模型還描述了資料不同部分之間的關係。在資料庫設計的歷史中，一直使用三種模型：階層式模型、網路式模型和關聯式模型。

### 14.3.1 階層式資料庫模型
在**階層式模型**中，資料組織成倒置的樹狀結構。每個實體只有一個父節點，但可以有多個子節點。在階層的頂部，有一個實體，稱為*根*。由於階層式模型已過時，無需進一步討論此模型。

### 14.3.2 網路式資料庫模型
在**網路式模型**中，實體組織在圖形中，其中某些實體可以透過多條路徑存取。沒有階層結構。此模型也已過時，無需進一步討論。

### 14.3.3 關聯式資料庫模型
在**關聯式模型**中，資料組織在稱為**關聯**的二維表格中。沒有強加於資料的階層或網路結構。然而，表格或*關聯*彼此相關。
關聯式模型是當今使用的常見模型之一，我們將本章的大部分內容用於討論它。在最後一節中，我們簡要討論從關聯式模型衍生的其他兩種常見模型：分散式模型和物件導向模型。

## 14.4 關聯式資料庫模型
在**關聯式資料庫管理系統 (RDBMS)** 中，資料表示為一組關聯。

### 14.4.1 關聯 (Relation)
**關聯**在外觀上是一個二維表格。RDBMS 組織資料，使其外部視圖是一組關聯或表格。這並不意味著資料儲存為表格：資料的物理儲存獨立於資料的邏輯組織方式。
RDBMS 中的關聯具有以下特徵：
- **名稱**。關聯式資料庫中的每個關聯都應具有在其他關聯中唯一的名稱。
- **屬性 (Attribute)**。關聯中的每一列稱為一個**屬性**。屬性是表格中的列標題。每個屬性賦予其下儲存的資料意義。表格中的每一列必須具有在關聯範圍內唯一的名稱。關聯的屬性總數稱為關聯的**度 (degree)**。請注意，屬性名稱不儲存在資料庫中：概念層級使用屬性賦予每一列意義。
- **元組 (Tuple)**。關聯中的每一行稱為一個**元組**。元組定義了一組屬性值。關聯中的總行數稱為關聯的**基數 (cardinality)**。請注意，當添加或刪除元組時，關聯的基數會發生變化。這使得資料庫是動態的。

### 14.4.2 關聯上的操作
在關聯式資料庫中，我們可以定義多種操作以基於現有關聯創建新關聯。我們在本節中定義九種操作：*插入*、*刪除*、*更新*、*選擇*、*投影*、*連接*、*聯集*、*交集*和*差集*。我們不抽象地討論這些操作，而是描述資料庫查詢語言 SQL (結構化查詢語言) 中定義的每個操作。

**結構化查詢語言**
**結構化查詢語言 (SQL)** 是由美國國家標準協會 (ANSI) 和**國際標準化組織 (ISO)** 標準化的用於關聯式資料庫的語言。它是一種宣告式而非程序式語言，這意味著使用者宣告他們想要什麼，而無需編寫逐步程序。SQL 語言最早由 Oracle 公司於 1979 年實作，此後發布了各種版本的 SQL。

**插入 (Insert)**
**插入操作**是一個**一元操作**——也就是說，它應用於單個關聯。該操作將新元組插入關聯中。插入操作使用以下格式：
\`\`\`sql
insert into RELATION-NAME values (..., ..., ...)
\`\`\`
*values* 子句定義要插入的相應元組的所有屬性值。字串值括在引號中，數值則不括。

**刪除 (Delete)**
**刪除操作**也是一個一元操作。該操作從關聯中刪除由標準定義的元組。刪除操作使用以下格式：
\`\`\`sql
delete from RELATION-NAME where criteria
\`\`\`
刪除的標準在 *where* 子句中定義。

**更新 (Update)**
**更新操作**也是應用於單個關聯的一元操作。該操作更改元組某些屬性的值。更新操作使用以下格式：
\`\`\`sql
update RELATION-NAME
set attribute1 = value1, attribute2 = value2, ...
where criteria
\`\`\`
要更改的屬性在 *set* 子句中定義，更新的標準在 *where* 子句中定義。

**選擇 (Select)**
**選擇操作**是一個一元操作——也就是說，應用於單個關聯——並創建另一個關聯。結果關聯中的元組（行）是原始關聯中元組的子集。選擇操作使用一些標準從原始關聯中選擇部分元組。選擇操作使用以下格式：
\`\`\`sql
select *
from RELATION-NAME
where criteria
\`\`\`
星號表示選擇所有屬性。

**投影 (Project)**
**投影操作**也是一個一元操作，並創建另一個關聯。結果關聯中的屬性（列）是原始關聯中屬性的子集。投影操作創建一個每個元組屬性較少的關聯。此操作中的元組（行）數量保持不變。投影操作使用以下格式：
\`\`\`sql
select attribute-list
from RELATION-NAME
\`\`\`
新關聯的列名被明確列出。

**連接 (Join)**
**連接操作**是一個**二元操作**——它獲取兩個關聯並基於共同屬性將它們組合起來。連接操作使用以下格式：
\`\`\`sql
select attribute-list
from RELATION1, RELATION2
where criteria
\`\`\`
屬性列表是來自兩個輸入關聯的屬性組合：標準明確定義用作共同屬性的屬性。連接操作很複雜，有許多變體。

**聯集 (Union)**
**聯集操作**也是一個二元操作，獲取兩個關聯並創建一個新關聯。然而，這兩個關聯有一個限制：它們必須具有相同的屬性。集合論中定義的聯集操作創建一個新關聯，其中的每個元組要麼在第一個關聯中，要麼在第二個關聯中，或者兩者都在。聯集操作使用以下格式：
\`\`\`sql
select *
from RELATION1
union
select *
from RELATION2
\`\`\`
同樣，星號表示選擇所有屬性。

**交集 (Intersection)**
**交集操作**也是一個二元操作，獲取兩個關聯並創建一個新關聯。像聯集操作一樣，這兩個關聯必須具有相同的屬性。集合論中定義的交集操作創建一個新關聯，其中的每個元組都是兩個關聯的成員。交集操作使用以下格式：
\`\`\`sql
select *
from RELATION1
intersection
select *
from RELATION2
\`\`\`

**差集 (Difference)**
**差集操作**也是一個二元操作。它應用於具有相同屬性的兩個關聯。結果關聯中的元組是那些在第一個關聯中但不在第二個關聯中的元組。差集操作使用以下格式：
\`\`\`sql
select *
from RELATION1
minus
select *
from RELATION2
\`\`\`

**語句組合**
SQL 語言允許我們組合上述語句以從資料庫中提取更複雜的資訊。

## 14.5 資料庫設計
任何資料庫的設計都是一項漫長而複雜的任務，只能透過逐步過程完成。第一步通常涉及大量採訪資料庫的潛在使用者，例如在大學中，以收集需要儲存的資訊和每個部門的存取需求。第二步是建立一個**實體關係模型 (ERM)**，定義必須為其維護某些資訊的實體、這些實體的屬性以及這些實體之間的關係。

設計的下一步基於要使用的資料庫類型。在關聯式資料庫中，下一步是基於 ERM 建立關聯並對關聯進行正規化。在這個入門課程中，我們只給出一些關於 ERM 和正規化的概念。

### 14.5.1 實體關係模型 (ERM)
在此步驟中，資料庫設計師創建一個**實體關係 (E-R) 圖**，以顯示需要儲存資訊的實體以及這些實體之間的關係。E-R 圖使用幾種幾何形狀，但我們這裡只使用其中幾種：
- **矩形**代表實體集。
- **橢圓**代表屬性。
- **菱形**代表關係集。
- **線條**將屬性連結到實體集，並將實體集連結到關係集。

由菱形顯示的關係可以是一對一、一對多、多對一和多對多。

### 14.5.2 從 E-R 圖到關聯
E-R 圖定稿後，即可創建關聯式資料庫中的關聯（表格）。

**實體集的關聯**
對於 E-R 圖中的每個實體集，我們創建一個關聯（表格），其中有 *n* 列與為該集定義的 *n* 個屬性相關。

**關係集的關聯**
對於 E-R 圖中的每個關係集，我們創建一個關聯（表格）。此關聯對於參與此關係的每個實體集的鍵都有一列，如果關係有屬性，則對於關係本身的每個屬性也有一列。

### 14.5.3 正規化 (Normalization)
**正規化**是將一組給定的關聯轉換為一組結構更穩固的新關聯的過程。正規化是為了允許資料庫中的任何關聯都能被表示，允許像 SQL 這樣的語言使用由原子操作組成的強大檢索操作，消除插入、刪除和更新中的異常，並減少隨著新資料類型添加而重組資料庫的需求。

正規化過程定義了一組階層式**正規形式 (NF)**。已經提出了幾種正規形式，包括 1NF、2NF、3NF、BCNF (Boyce-Codd 正規形式)、4NF、PJNF (投影/連接正規形式)、5NF 等等。對這些正規形式（除 1NF 外）的討論涉及函數依賴的討論，這是一個理論學科，超出了本書的範圍。然而，我們需要知道的一個重要點是，這些正規形式形成了一個階層結構。換句話說，如果資料庫中的關聯是 3NF，它應該首先是 2NF。

**第一正規形式 (1NF)**
當我們將實體或關係轉換為表格關聯時，可能會有一些關聯在列或行的交叉處有多個值。不符合第一正規形式的關聯可能會遇到許多問題。這兩個關聯可以透過重複存在此問題的行來正規化。

**第二正規形式 (2NF)**
在每個關聯中，我們需要有一個鍵（稱為*主鍵*），所有其他屬性（列值）都依賴於它。然而，當基於 E-R 圖建立關聯時，可能會發生我們有一些複合鍵（兩個或多個鍵的組合）的情況。在這種情況下，如果每個非鍵屬性都依賴於整個複合鍵，則關聯處於第二正規形式。
如果某些屬性依賴於複合鍵的一部分，則該關聯不是第二正規形式。我們可以應用 2NF 過程並將關聯分為兩個，兩者都處於第二正規形式。

**其他正規形式**
其他正規形式使用屬性之間更複雜的依賴關係。我們將這些依賴關係留給專門討論資料庫主題的書籍。

## 14.6 其他資料庫模型
關聯式資料庫並非當今使用的唯一資料庫模型。另外兩個常見的模型是*分散式資料庫*和*物件導向資料庫*。我們在此簡要討論這些。

### 14.6.1 分散式資料庫
**分散式資料庫**模型不是新模型，而是基於關聯式模型。然而，資料儲存在多台透過網際網路或專用廣域網路通訊的電腦上。每台電腦（或站點）維護部分資料庫或整個資料庫。換句話說，資料要麼被分割，每個片段儲存在一個站點，要麼在每個站點複製。

**分割式分散式資料庫**
在**分割式分散式資料庫**中，資料是本地化的——本地使用的資料儲存在相應的站點。然而，這並不意味著一個站點不能存取儲存在另一個站點的資料，存取主要是本地的，但偶爾是全域的。雖然每個站點對其本地資料有完全控制權，但透過網際網路或廣域網路進行全域控制。
例如，一家製藥公司可能在許多國家擁有多個站點。每個站點都有一個包含其自己員工資訊的資料庫，但中央人事部門可以控制所有資料庫。

**複製式分散式資料庫**
在**複製式分散式資料庫**中，每個站點都持有另一個站點的精確複本。對儲存在一個站點的資料的任何修改都會在每個站點精確重複。擁有這種資料庫的原因是安全性。如果一個站點的系統發生故障，該站點的使用者可以存取另一個站點的資料。

### 14.6.2 物件導向資料庫
關聯式資料庫具有基於資料庫元組和屬性性質的特定資料視圖。關聯式資料庫中的最小資料單位是元組和屬性的交叉點。然而，某些應用程式需要以其他形式查看資料，例如將資料視為結構（見第 11 章），如由欄位組成的記錄。
**物件導向資料庫**試圖保留關聯式模型的優點，同時允許應用程式存取結構化資料。在物件導向資料庫中，定義了物件及其關係。此外，每個物件可以具有可以表示為欄位的屬性。
例如，在組織中，可以為員工、部門和客戶定義物件類型。員工類別可以定義員工物件的屬性（名字、姓氏、社會安全號碼、薪水等）以及如何存取它們。部門物件可以定義部門的屬性以及如何存取它們。此外，資料庫可以在員工物件和部門物件之間建立關係，以表示該員工在該部門工作。

**XML**
通常用於物件導向資料庫的查詢語言是 **XML (可擴展標記語言)**。XML 最初設計用於向文字文件添加標記資訊，但它也發現了其作為資料庫查詢語言的應用。XML 可以表示具有巢狀結構的資料。

## 14.7 章末材料

### 14.7.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Alagic, S. *Relational Database Technology*, New York: Springer, 1986
- Dietrich, S. *Understanding Relational Database Query Language*, Upper Saddle River, NJ: Prentice-Hall, 2001
- Elmasri, R. and Navathe, S. *Fundamentals of Database Systems*, Reading, MA: Addison-Wesley, 2006
- Mannino, M. *Database Application Development and Design*, New York: McGraw-Hill, 2001
- Ramakrishnan, R. and Gehrke, J. *Database Management Systems*, New York: McGraw-Hill, 2003
- Silberschatz, A., Korth, H. and Sudarshan, S. *Databases: System Concepts*, New York: McGraw-Hill, 2005

### 14.7.2 關鍵詞
- 應用程式 (application programs)
- 屬性 (attribute)
- 二元操作 (binary operation)
- 基數 (cardinality)
- 概念層級 (conceptual level)
- 資料庫 (database)
- 資料庫管理系統 (database management system, DBMS)
- 資料庫模型 (database model)
- 刪除操作 (delete operation)
- 差集操作 (difference operation)
- 分散式資料庫 (distributed database)
- 終端使用者 (End users)
- 實體關係模型 (Entity-Relation Model, E-R)
- 實體關係圖 (Entity–Relationship (E-R) diagram)
- 外部層級 (external level)
- 扁平檔案 (flat-files)
- 分割式分散式資料庫 (fragmented distributed database)
- 階層式模型 (hierarchical model)
- 插入操作 (insert operation)
- 內部層級 (internal level)
- 國際標準化組織 (International Organization for Standardization, ISO)
- 交集操作 (intersection operation)
- 連接操作 (join operation)
- 名稱 (name)
- 網路式模型 (network model)
- 正規形式 (normal form, NF)
- 正規化 (normalization)
- 物件導向資料庫 (object-oriented database)
- 投影操作 (project operation)
- 關聯 (relation)
- 關聯式資料庫管理系統 (relational database management system, RDBMS)
- 關聯式模型 (relational model)
- 複製式分散式資料庫 (replicated distributed database)
- 選擇操作 (select operation)
- 結構化查詢語言 (Structured Query Language, SQL)
- 元組 (tuple)
- 一元操作 (unary operation)
- 聯集操作 (union operation)
- 更新操作 (update operation)
- 使用者 (users)

### 14.7.3 摘要
- 資料庫是邏輯上但不一定物理上一致的資料集合——其各個部分可以在物理上分開。資料庫管理系統 (DBMS) 定義、創建和維護資料庫。
- 美國國家標準協會/標準規劃與需求委員會 (ANSI/SPARC) 為 DBMS 建立了三層架構：內部、概念和外部。內部層級決定資料實際儲存在儲存設備上的位置。概念層級定義資料的邏輯視圖。外部層級直接與使用者互動。
- 傳統上，定義了三種資料庫模型：階層式、網路式和關聯式。只有最後一種，關聯式模型，倖存下來。
- 在關聯式模型中，資料組織在稱為關聯的二維表格中。關聯具有以下特徵：名稱、屬性和元組。
- 在關聯式資料庫中，我們可以定義多種操作以基於現有關聯創建新關聯。我們在資料庫查詢語言 SQL (結構化查詢語言) 的背景下提到了九種操作：插入、刪除、更新、選擇、投影、連接、聯集、交集和差集。
- 資料庫的設計，例如為組織設計，通常是一項漫長的任務，只能透過逐步過程完成。第一步通常涉及採訪資料庫的潛在使用者以收集需要儲存的資訊。第二步是建立一個實體關係模型 (ERM)，定義必須為其維護資訊的實體。下一步是基於 ERM 建立關聯。
- 正規化是將一組給定的關聯轉換為一組結構更穩固的新關聯的過程。正規化是為了允許資料庫中的任何關聯都能被表示，允許像 SQL 這樣的查詢語言使用由原子操作組成的強大檢索操作，消除插入、刪除和更新中的異常，並減少隨著新資料類型添加而重組資料庫的需求。
- 關聯式資料庫並非當今使用的唯一資料庫模型。另外兩個常見的模型是分散式資料庫和物件導向資料庫。

## 14.8 練習題

### 14.8.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 14.8.2 複習問題
1. DBMS 的五個必要組件是什麼？
2. 三種資料庫模型是什麼？哪一種在今天最流行？
3. 關聯式資料庫中的關聯是什麼？
4. 在關聯中，屬性是什麼？元組是什麼？
5. 列出關聯式資料庫中的一些一元操作。
6. 列出關聯式資料庫中的一些二元操作。
7. 什麼是 SQL？什麼是 XML？哪一個是關聯式資料庫的查詢語言？哪一個是物件導向語言的查詢語言？

### 14.8.3 問題
1. 你有如圖 14.21 所示的關聯 A、B 和 C。顯示如果應用以下 SQL 語句會產生的結果關聯：
   \`\`\`sql
   select *
   from A
   where A2 = 16
   \`\`\`
2. 你有如圖 14.21 所示的關聯 A、B 和 C。顯示如果應用以下 SQL 語句會產生的結果關聯：
   \`\`\`sql
   select A1 A2
   from A
   where A2 = 16
   \`\`\`
3. 你有如圖 14.21 所示的關聯 A、B 和 C。顯示如果應用以下 SQL 語句會產生的結果關聯：
   \`\`\`sql
   select A3
   from A
   \`\`\`
4. 你有如圖 14.21 所示的關聯 A、B 和 C。顯示如果應用以下 SQL 語句會產生的結果關聯：
   \`\`\`sql
   select B1
   from B
   where B2 = 216
   \`\`\`
5. 你有如圖 14.21 所示的關聯 A、B 和 C。顯示如果應用以下 SQL 語句會產生的結果關聯：
   \`\`\`sql
   update C
   set C1 = 37
   where C1 = 31
   \`\`\`
6. 使用 14.3.3 節圖 14.5 中的模型，顯示創建一個僅包含課程編號和每門課程學分數的新關聯的 SQL 語句。
7. 使用圖 14.5 中的模型，顯示創建一個僅包含學生 ID 和學生姓名的新關聯的 SQL 語句。
8. 使用圖 14.5 中的模型，顯示創建一個僅包含教授姓名的新關聯的 SQL 語句。
9. 使用圖 14.5 中的模型，顯示創建一個僅包含系所名稱的新關聯的 SQL 語句。
10. 使用圖 14.5 中的模型，顯示創建一個包含 ID 為 2010 的學生所修課程的新關聯的 SQL 語句。
11. 使用圖 14.5 中的模型，顯示創建一個包含 Blake 教授所教課程的新關聯的 SQL 語句。
12. 使用圖 14.5 中的模型，顯示創建一個僅包含三個學分課程的新關聯的 SQL 語句。
13. 使用圖 14.5 中的模型，顯示創建一個僅包含修習課程 CIS015 的學生姓名的新關聯的 SQL 語句。
14. 使用圖 14.5 中的模型，顯示創建一個包含電腦科學系系所編號的新關聯的 SQL 語句。
15. 以下關聯是否處於第一正規形式 (1NF)？如果不是，更改表格使其通過 1NF 標準。
    A | B | C | D
    ---|---|---|---
    1 | 70 | 65 | 14
    2 | 25, 32, 71 | 24 | 12, 18
    3 | 32 | 6, 11 | 18
16. 為公共圖書館創建 E-R 圖。顯示可以從該圖創建的關聯大綱。
17. 為房地產公司創建 E-R 圖，然後顯示可以從該圖創建的關聯大綱。
18. 為航空公司中的三個實體 FLIGHT、AIRCRAFT 和 PILOT 創建 E-R 圖，然後顯示該公司中關聯的大綱。
19. 使用參考資料或網際網路查找有關第三正規形式 (3NF) 的一些資訊。此正規形式涉及哪種函數依賴？
20. 使用參考資料或網際網路查找有關 Boyce-Codd 正規形式 (BCNF) 的一些資訊。此正規形式涉及哪種函數依賴？
`},f={en:`
# Chapter 15: Data Compression

In recent years technology has changed the way we transmit and store data. For example, fiber-optic cable allows us to transmit data much faster, and DVDs allow us to store huge amounts of data on a physically small medium. However, as in other aspects of life, the rate of demand from the public is ever increasing. Today, we want to download more and more data in a shorter and shorter amount of time. We also want to store more and more data in a smaller space.

Compressing data can reduce the amount of data to be sent or stored by partially eliminating inherent redundancy. Redundancy is created when we produce data. Through data compression, we make transmission and storage more efficient, and at the same time, we preserve the integrity of the data.

## Objectives
After studying this chapter, the student should be able to:
- Distinguish between lossless and lossy compression.
- Describe run-length encoding and how it achieves compression.
- Describe Huffman coding and how it achieves compression.
- Describe Lempel Ziv encoding and the role of the dictionary in encoding and decoding.
- Describe the main idea behind the JPEG standard for compressing still images.
- Describe the main idea behind the MPEG standard for compressing video and its relation to JPEG.
- Describe the main idea behind the MP3 standard for compressing audio.

## 15.1 INTRODUCTION
Data compression implies sending or storing a smaller number of bits. Although many methods are used for this purpose, in general these methods can be divided into two broad categories: lossless and lossy methods.

We first discuss lossless compression methods, as they are simpler and easier to understand. We then present lossy compression methods.

## 15.2 LOSSLESS COMPRESSION METHODS
In **lossless data compression**, the integrity of the data is preserved. The original data and the data after compression and decompression are exactly the same because, in these methods, the compression and decompression algorithms are exact inverses of each other: no part of the data is lost in the process. Redundant data is removed in compression and added during decompression.

Lossless compression methods are normally used when we cannot afford to lose any data. For example, we must not lose data when we compress a text file or an application program.

We discuss three lossless compression methods in this section: *run-length encoding*, *Huffman coding*, and the *Lempel Ziv algorithm*.

### 15.2.1 Run-length encoding
**Run-length encoding** is probably the simplest method of compression. It can be used to compress data made of any combination of symbols. It does not need to know the frequency of occurrence of symbols (as is necessary for Huffman coding) and can be very efficient if data is represented as 0s and 1s.

The general idea behind this method is to replace consecutive repeating occurrences of a symbol by one occurrence of the symbol followed by the number of occurrences. For example, \`AAAAAAAA\` can be replaced by \`A08\`. Note that we use a fixed number of digits (two) to represent the count.

The method can be even more efficient if the data uses only two symbols (for example 0 and 1) in its bit pattern and one symbol is more frequent than the other. For example, let’s say we have an image represented by mostly 0s and some 1s. In this case, we can reduce the number of bits by sending (or storing) the number of 0s occurring between two 1s.

We have represented the counts as a 4-bit binary number (unsigned integer). In an actual situation, we would find an optimal number of bits to avoid introducing extra redundancy.

Note that, given a 4-bit binary compression, if there are more than fifteen 0s, they are broken into two or more groups. For example, a sequence of twenty-five 0s is encoded as \`1111 1010\`. Now the question is how the decoding algorithm knows that this consists of twenty-five 0s and not fifteen 0s, then a 1, and then ten 0s. The answer is that if the first count is \`1111\`, the receiver knows the next 4-bit pattern is a continuation of 0s. Now another question is raised: what if there are exactly fifteen 0s between two 1s? In this case, the pattern is \`1111\` followed by \`0000\`.

### 15.2.2 Huffman coding
**Huffman coding** assigns shorter codes to symbols that occur more frequently and longer codes to those that occur less frequently. For example, imagine we have a text file that uses only five characters (A, B, C, D, E). We chose only five characters to make the discussion simpler, but the procedure is equally valid for a smaller or greater number of characters.

Before we can assign bit patterns to each character, we assign each character a weight based on its frequency of use. Once the weight of each character is established, we build a tree based on those values. The process for building this tree follows three basic steps:
1.  Put the entire character set in a row. Each character is now a node at the lowest level of the tree.
2.  Find the two nodes with the smallest weights and join them to form a third node, resulting in a simple two-level tree. The weight of the new node is the combined weights of the original two nodes. This node, one level up from the leaves, is eligible for combination with other nodes. Remember that the sum of the weights of the two nodes chosen must be smaller than the combination of any other possible choices.
3.  Repeat step 2 until all of the nodes, on every level, are combined into a single tree.

Once the tree is complete, use it to assign codes to each character. First, assign a bit value to each branch. Starting from the root (top node), assign 0 to the left branch and 1 to the right branch and repeat this pattern at each node.

A character’s code is found by starting at the root and following the branches that lead to that character. The code itself is the bit value of each branch on the path, taken in sequence.

**Encoding**
Let us see how to encode text using the code for our five characters.
Two points are worth mentioning. First, notice that there is a sense of compression even in this small and unrealistic code. If we want to send the text without using Huffman coding, we need to assign a 3-bit code to each character. You would have sent 30 bits, whereas with Huffman coding, we send only 22 bits.
Second, notice that we have not used any delimiters between the bits that encode each character. We write the codes one after another. The beauty of Huffman coding is that no code is the prefix of another code. There is therefore no ambiguity in encoding, so the decoding algorithm can decode the received data without ambiguity.

**Decoding**
The recipient has a very easy job in decoding the data that it receives. When the recipient receives the first bits, it does not have to wait for the next bit to make a decision—it knows that these bits encode a specific letter if the bits match a code in the tree. This is why Huffman code is called an instantaneous code—the decoder can unambiguously decode the bits instantaneously, using the minimum number of bits.

### 15.2.3 Lempel Ziv encoding
**Lempel Ziv (LZ) encoding**, named after its inventors (Abraham Lempel and Jacob Ziv), is an example of a category of algorithms called **dictionary-based encoding**. The idea is to create a dictionary (a table) of strings used during the communication session. If both the sender and the receiver have a copy of the dictionary, then previously encountered strings can be substituted by their index in the dictionary to reduce the amount of information transmitted.

Although the idea appears simple, several difficulties surface in the implementation. First, how can a dictionary be created for each session? It cannot be universal, due to its length. Second, how can the recipient acquire the dictionary created by the sender—if we send the dictionary, we are sending extra data, which defeats the whole purpose of compression?

The Lempel Ziv (LZ) algorithm is a practical algorithm that uses the idea of adaptive dictionary-based encoding. The algorithm has gone through several versions (LZ77, LZ78). We introduce the basic idea of this algorithm with an example.

**Compression**
In this phase there are two concurrent events: building an indexed dictionary and compressing a string of symbols. The algorithm extracts the smallest substring that cannot be found in the dictionary from the remaining uncompressed string. It then stores a copy of this substring in the dictionary as a new entry and assigns it an index value. Compression occurs when the substring, except for the last character, is replaced with the index found in the dictionary. The process then inserts the index and the last character of the substring into the compressed string. For example, if the substring is \`ABBB\`, we search for \`ABB\` in the dictionary. If we find that the index for \`ABB\` is 4, the compressed substring is therefore \`4B\`.

**Decompression**
Decompression is the inverse of the compression process. The process extracts the substrings from the compressed string and tries to replace the indexes with the corresponding entry in the dictionary, which is empty at first and built up gradually. The idea is that when an index is received, there is already an entry in the dictionary corresponding to that index.

## 15.3 LOSSY COMPRESSION METHODS
Loss of information is not acceptable in a text file or a program file. It is, however, acceptable in an image, video, or audio file. The reason is that our eyes and ears cannot distinguish subtle changes. In such cases, we can use a **lossy data compression** method. These methods are cheaper—they take less time and space when it comes to sending millions of bits per second for images and video.

Several methods have been developed using lossy compression techniques. **JPEG (Joint Photographic Experts Group)** encoding is used to compress pictures and graphics, **MPEG (Moving Picture Experts Group)** encoding is used to compress video, and **MP3 (MPEG audio layer 3)** for audio compression.

### 15.3.1 Image compression—JPEG encoding
An image can be represented by a two-dimensional array (table) of picture elements (pixels). For example, 640 × 480 = 307,200 pixels. If the picture is grayscale, each pixel can be represented by an 8-bit integer, giving 256 levels of gray. If the picture is color, each pixel can be represented by 24 bits (3 × 8 bits), with each 8 bits representing one of the colors in the RBG color system.

In JPEG, a grayscale picture is divided into blocks of 8 × 8 pixel blocks. The purpose of dividing the picture into blocks is to decrease the number of calculations.
The whole idea of JPEG is to change the picture into a linear (vector) set of numbers that reveals the redundancies. The redundancies (lack of changes) can then be removed using one of the lossless compression methods we studied previously.

**Discrete cosine transform (DCT)**
In this step, each block of 64 pixels goes through a transformation called the **discrete cosine transform (DCT)**. The transformation changes the 64 values so that the relative relationships between pixels are kept but the redundancies are revealed. The value of $T(0,0)$ is the average of the other values. This is called the **DC value**. The rest of the values, called **AC values**, in $T(m, n)$ represent changes in the pixel values.

**Quantization**
After the T table is created, the values are quantized to reduce the number of bits needed for encoding. **Quantization** divides the number of bits by a constant and then drops the fraction. This reduces the required number of bits even more. Note that the only phase in the process that is not reversible is the quantizing phase. You lose some information here that is not recoverable. The only reason that JPEG is a lossy compression method is because of the quantization phase.

**Compression**
After quantization the values are read from the table, and redundant 0s are removed. However, to cluster the 0s together, the process reads the table diagonally in a zigzag fashion rather than row by row or column by column. The reason is that if the picture does not have fine changes, the bottom right corner of the T table is all 0s. JPEG usually uses run-length encoding at the compression phase to compress the bit pattern resulting from the zigzag linearization.

### 15.3.2 Video compression—MPEG encoding
The **Moving Picture Experts Group (MPEG)** method is used to compress video. In principle, a motion picture is a rapid sequence of a set of frames in which each frame is a picture. In other words, a frame is a spatial combination of pixels, and a video is a temporal combination of frames that are sent one after another. Compressing video, then, means spatially compressing each frame and temporally compressing a set of frames.

**Spatial compression**
The **spatial compression** of each frame is done with JPEG, or a modification of it. Each frame is a picture that can be independently compressed.

**Temporal compression**
In **temporal compression**, redundant frames are removed. When we watch television, for example, we receive 30 frames per second. However, most of the consecutive frames are almost the same.
To temporally compress data, the MPEG method first divides frames into three categories: I-frames, P-frames, and B-frames.
- **I-frames**: An **intracoded frame (I-frame)** is an independent frame that is not related to any other frame. They are present at regular intervals. An I-frame must appear periodically due to some sudden change in the frame that the previous and following frames cannot show.
- **P-frames**: A **predicted frame (P-frame)** is related to the preceding I-frame or P-frame. In other words, each P-frame contains only the changes from the preceding frame. P-frames carry much less information than other frame types and carry even fewer bits after compression.
- **B-frames**: A **bidirectional frame (B-frame)** is relative to the preceding and following I-frame or P-frame. In other words, each B-frame is relative to the past and the future. Note that a B-frame is never related to another B-frame.

### 15.3.3 Audio compression
Audio compression can be used for speech or music. Two categories of techniques are used for audio compression: predictive encoding and perceptual encoding.

**Predictive encoding**
In **predictive encoding**, the differences between samples are encoded instead of encoding all the sampled values. This type of compression is normally used for speech. Several standards have been defined such as GSM.

**Perceptual encoding: MP3**
The most common compression technique used to create CD-quality audio is based on the **perceptual encoding** technique. This type of audio needs at least 1.411 Mbps, which cannot be sent over the Internet without compression. **MP3 (MPEG audio layer 3)**, a part of the MPEG standard, uses this technique.

Perceptual encoding is based on the science of psychoacoustics, which is the study of how people perceive sound. The idea is based on flaws in our auditory system: some sounds can mask other sounds. Masking can happen in both frequency and time. In **frequency masking**, a loud sound in one frequency range can partially or totally mask a softer sound in another frequency range. In **temporal masking**, a loud sound can reduce the sensitivity of our hearing for a short time even after the sound has stopped.

MP3 uses these two phenomena, frequency and temporal masking, to compress audio signals. The technique analyzes and divides the audio spectrum into several groups. Zero bits are allocated to frequency ranges that are totally masked, a small number of bits are allocated to frequency ranges that are partially masked, and a larger number of bits are allocated to frequency ranges that are not masked.

## 15.4 END-CHAPTER MATERIALS
### 15.4.2 Key terms
- AC value
- bidirectional frame (B-frame)
- data compression
- DC value
- dictionary-based encoding
- discrete cosine transform (DCT)
- frequency masking
- Huffman coding
- intracoded frame (I-frame)
- Joint Photographic Experts Group (JPEG)
- Lempel Ziv (LZ) encoding
- Lempel Ziv Welch (LZW) encoding
- lossless data compression
- lossy data compression
- Moving Picture Experts Group (MPEG)
- MPEG audio layer 3 (MP3)
- perceptual encoding
- predicted frame (P-frame)
- predictive encoding
- run-length encoding
- spatial compression
- temporal compression
- temporal masking

### 15.4.3 Summary
- Data compression methods are either lossless (all information is recoverable) or lossy (some information is lost).
- In lossless compression methods, the received data is an exact replica of the sent data. Three lossless compression methods are run-length encoding, Huffman coding, and Lempel Ziv (LZ) encoding.
- In run-length encoding, repeated occurrences of a symbol are replaced by a symbol and the number of occurrences of the symbol.
- In Huffman coding, the code length is a function of symbol frequency: more frequent symbols have shorter codes than less frequent symbols.
- In LZ encoding, repeated strings or words are stored in memory locations. An index to the memory location replaces the string or word. LZ encoding requires a dictionary and an algorithm at both sender and receiver.
- In lossy compression methods, the received data need not be an exact replica of the sent data. Three lossy compression methods were discussed in this chapter: JPEG, MPEG, and MP3.
- JPEG (Joint Photographic Experts Group) compression is a method of compressing pictures and graphics. The JPEG process involves blocking, the discrete cosine transform, quantization, and lossless compression.
- MPEG (Moving Pictures Experts Group) compression is a method of compressing video. MPEG involves both spatial compression and temporal compression. The former is similar to JPEG, while the latter removes redundant frames.
- MP3 (MPEG audio layer 3) is a part of the MPEG standard. MP3 uses perceptual encoding techniques to compress CD-quality audio.
`,zh:`
# 第十五章：資料壓縮

近年來，技術改變了我們傳輸和儲存資料的方式。例如，光纖電纜允許我們以更快的速度傳輸資料，而 DVD 允許我們在物理上很小的媒體上儲存大量資料。然而，正如生活的其他方面一樣，大眾的需求率不斷增加。今天，我們希望在越來越短的時間內下載越來越多的資料。我們也希望在更小的空間中儲存越來越多的資料。

壓縮資料可以透過部分消除固有的冗餘來減少要發送或儲存的資料量。當我們產生資料時就會產生冗餘。透過資料壓縮，我們使傳輸和儲存更有效率，同時我們也保留了資料的完整性。

## 學習目標
學完本章後，學生應能：
- 區分無損壓縮和失真壓縮。
- 描述連長編碼 (run-length encoding) 及其如何實現壓縮。
- 描述霍夫曼編碼 (Huffman coding) 及其如何實現壓縮。
- 描述 Lempel Ziv 編碼以及字典在編碼和解碼中的作用。
- 描述用於壓縮靜態圖像的 JPEG 標準背後的主要思想。
- 描述用於壓縮視訊的 MPEG 標準背後的主要思想及其與 JPEG 的關係。
- 描述用於壓縮音訊的 MP3 標準背後的主要思想。

## 15.1 簡介
資料壓縮意味著發送或儲存較少數量的位元。雖然有許多方法用於此目的，但一般來說這些方法可以分為兩大類：無損方法和失真方法。

我們先討論無損壓縮方法，因為它們較簡單且容易理解。然後我們介紹失真壓縮方法。

## 15.2 無損壓縮方法
在**無損資料壓縮**中，資料的完整性得到保留。原始資料與壓縮和解壓縮後的資料完全相同，因為在這些方法中，壓縮和解壓縮演算法互為逆運算：過程中沒有任何資料丟失。冗餘資料在壓縮中被移除，在解壓縮時被添加回來。

無損壓縮方法通常用於我們不能承受丟失任何資料的情況。例如，當我們壓縮文字檔案或應用程式時，我們絕不能丟失資料。

我們在本節討論三種無損壓縮方法：*連長編碼*、*霍夫曼編碼*和 *Lempel Ziv 演算法*。

### 15.2.1 連長編碼 (Run-length encoding)
**連長編碼**可能是最簡單的壓縮方法。它可以用來壓縮由任何符號組合組成的資料。它不需要知道符號出現的頻率（這對於霍夫曼編碼是必要的），如果資料表示為 0 和 1，它可以非常有效率。

這種方法背後的一般思想是用一次符號的出現加上出現的次數來替換連續重複出現的符號。例如，\`AAAAAAAA\` 可以替換為 \`A08\`。請注意，我們使用固定數量的位數（兩位）來表示計數。

如果資料在其位元模式中僅使用兩個符號（例如 0 和 1），並且一個符號比另一個更頻繁，則該方法可以更有效率。例如，假設我們有一個主要由 0 和一些 1 表示的圖像。在這種情況下，我們可以透過發送（或儲存）兩個 1 之間出現的 0 的數量來減少位元數。

我們將計數表示為 4 位元二進位數字（無符號整數）。在實際情況下，我們會找到最佳的位元數以避免引入額外的冗餘。

請注意，給定 4 位元二進位壓縮，如果有超過十五個 0，它們會被分成兩組或多組。例如，二十五個 0 的序列被編碼為 \`1111 1010\`。現在的問題是解碼演算法如何知道這包含二十五個 0 而不是十五個 0，然後是一個 1，然後是十個 0。答案是如果第一個計數是 \`1111\`，接收者知道下一個 4 位元模式是 0 的延續。現在提出了另一個問題：如果兩個 1 之間正好有十五個 0 怎麼辦？在這種情況下，模式是 \`1111\` 後跟 \`0000\`。

### 15.2.2 霍夫曼編碼 (Huffman coding)
**霍夫曼編碼**為出現頻率較高的符號分配較短的代碼，為出現頻率較低的符號分配較長的代碼。例如，想像我們有一個只使用五個字元 (A, B, C, D, E) 的文字檔案。我們只選擇五個字元是為了使討論更簡單，但該程序對於較少或較多數量的字元同樣有效。

在我們為每個字元分配位元模式之前，我們先根據其使用頻率為每個字元分配一個權重。一旦確定了每個字元的權重，我們就根據這些值構建一棵樹。構建這棵樹的過程遵循三個基本步驟：
1.  將整個字元集排成一行。每個字元現在是樹的最低層級的一個節點。
2.  找出權重最小的兩個節點並將它們連接起來形成第三個節點，產生一個簡單的兩層樹。新節點的權重是原始兩個節點權重的總和。這個節點，位於葉子上一層，有資格與其他節點組合。請記住，所選兩個節點的權重總和必須小於任何其他可能選擇的組合。
3.  重複步驟 2，直到所有層級的所有節點組合成一棵單獨的樹。

一旦樹完成，就用它來為每個字元分配代碼。首先，為每個分支分配一個位元值。從根（頂部節點）開始，將 0 分配給左分支，將 1 分配給右分支，並在每個節點重複此模式。

字元的代碼是透過從根開始並跟隨通向該字元的分支找到的。代碼本身是路徑上每個分支的位元值，按順序排列。

**編碼**
讓我們看看如何使用我們五個字元的代碼來編碼文字。
有兩點值得一提。首先，請注意，即使在這個小型且不切實際的代碼中，也有一種壓縮感。如果我們想不使用霍夫曼編碼發送文字，我們需要為每個字元分配一個 3 位元的代碼。你會發送 30 個位元，而使用霍夫曼編碼，我們只發送 22 個位元。
其次，請注意我們沒有在編碼每個字元的位元之間使用任何分隔符。我們一個接一個地寫代碼。霍夫曼編碼的美妙之處在於沒有代碼是另一個代碼的前綴。因此，在編碼中沒有歧義，所以解碼演算法可以無歧義地解碼接收到的資料。

**解碼**
接收者在解碼接收到的資料時工作非常輕鬆。當接收者接收到第一組位元時，它不必等待下一個位元來做決定——如果位元與樹中的代碼匹配，它就知道這些位元編碼了一個特定的字母。這就是為什麼霍夫曼編碼被稱為即時碼——解碼器可以使用最少的位元數即時且無歧義地解碼位元。

### 15.2.3 Lempel Ziv 編碼
**Lempel Ziv (LZ) 編碼**，以其發明者（Abraham Lempel 和 Jacob Ziv）命名，是稱為**基於字典的編碼**的一類演算法的例子。其想法是創建一個通訊會話期間使用的字串字典（表）。如果發送者和接收者都有字典的副本，那麼先前遇到的字串可以用它們在字典中的索引替換，以減少傳輸的資訊量。

雖然這個想法看起來很簡單，但在實作中會出現一些困難。首先，如何為每個會話創建一個字典？由於其長度，它不可能是通用的。其次，接收者如何獲取發送者創建的字典——如果我們發送字典，我們就在發送額外的資料，這違背了壓縮的初衷？

Lempel Ziv (LZ) 演算法是一個實用的演算法，它使用自適應基於字典的編碼思想。該演算法經歷了幾個版本 (LZ77, LZ78)。我們通過一個例子介紹該演算法的基本思想。

**壓縮**
在這個階段有兩個並發事件：建立索引字典和壓縮符號字串。演算法從剩餘的未壓縮字串中提取在字典中找不到的最小子字串。然後它將此子字串的副本儲存在字典中作為新條目並分配一個索引值。當子字串（除了最後一個字元）被字典中找到的索引替換時，就會發生壓縮。該過程隨後將索引和子字串的最後一個字元插入壓縮字串中。例如，如果子字串是 \`ABBB\`，我們在字典中搜尋 \`ABB\`。如果我們發現 \`ABB\` 的索引是 4，那麼壓縮後的子字串就是 \`4B\`。

**解壓縮**
解壓縮是壓縮過程的逆過程。該過程從壓縮字串中提取子字串，並嘗試用字典中的相應條目替換索引，字典起初是空的，並逐漸建立起來。其想法是，當接收到索引時，字典中已經有對應於該索引的條目。

## 15.3 失真壓縮方法
資訊的丟失在文字檔案或程式檔案中是不可接受的。然而，在圖像、視訊或音訊檔案中是可以接受的。原因是我們的眼睛和耳朵無法區分細微的變化。在這種情況下，我們可以使用**失真資料壓縮**方法。這些方法更便宜——在每秒發送數百萬位元的圖像和視訊時，它們佔用的時間和空間更少。

已經使用失真壓縮技術開發了幾種方法。**JPEG (聯合圖像專家小組)** 編碼用於壓縮圖片和圖形，**MPEG (動態影像專家小組)** 編碼用於壓縮視訊，以及 **MP3 (MPEG 音訊層 3)** 用於音訊壓縮。

### 15.3.1 圖像壓縮—JPEG 編碼
圖像可以由圖片元素（像素）的二維陣列（表）表示。例如，640 × 480 = 307,200 像素。如果圖片是灰階的，每個像素可以用一個 8 位元整數表示，給出 256 個灰度級別。如果圖片是彩色的，每個像素可以用 24 位元（3 × 8 位元）表示，每 8 位元代表 RGB 顏色系統中的一種顏色。

在 JPEG 中，灰階圖片被分成 8 × 8 像素的區塊。將圖片分成區塊的目的是減少計算量。
JPEG 的整個想法是將圖片變成一組顯示冗餘的線性（向量）數字。冗餘（缺乏變化）隨後可以使用我們先前研究過的無損壓縮方法之一去除。

**離散餘弦變換 (DCT)**
在此步驟中，每個 64 像素的區塊都要經過稱為**離散餘弦變換 (DCT)** 的轉換。轉換改變了 64 個值，使得像素之間的相對關係得以保留，但揭示了冗餘。$T(0,0)$ 的值是其他值的平均值。這稱為 **DC 值**。$T(m, n)$ 中的其餘值稱為 **AC 值**，代表像素值的變化。

**量化**
在 T 表創建後，對值進行量化以減少編碼所需的位元數。**量化**將位元數除以一個常數，然後捨去小數部分。這進一步減少了所需的位元數。請注意，過程中唯一不可逆的階段是量化階段。你在這裡丟失了一些無法恢復的資訊。JPEG 是失真壓縮方法的唯一原因是因為量化階段。

**壓縮**
量化後，從表中讀取值，並移除冗餘的 0。然而，為了將 0 聚集在一起，該過程以 Z 字形對角線讀取表，而不是逐行或逐列讀取。原因是如果圖片沒有細微的變化，T 表的右下角全是 0。JPEG 通常在壓縮階段使用連長編碼來壓縮 Z 字形線性化產生的位元模式。

### 15.3.2 視訊壓縮—MPEG 編碼
**動態影像專家小組 (MPEG)** 方法用於壓縮視訊。原則上，動態圖片是一組影格的快速序列，其中每個影格都是一張圖片。換句話說，影格是像素的空間組合，而視訊是依次發送的影格的時間組合。因此，壓縮視訊意味著在空間上壓縮每個影格，並在時間上壓縮一組影格。

**空間壓縮**
每個影格的**空間壓縮**是使用 JPEG 或其修改版本完成的。每個影格都是一張可以獨立壓縮的圖片。

**時間壓縮**
在**時間壓縮**中，冗餘影格被移除。例如，當我們看電視時，我們每秒接收 30 個影格。然而，大多數連續的影格幾乎相同。
為了在時間上壓縮資料，MPEG 方法首先將影格分為三類：I-frames、P-frames 和 B-frames。
- **I-frames**：**幀內編碼影格 (I-frame)** 是一個與任何其他影格無關的獨立影格。它們定期出現。由於前一個和後一個影格無法顯示的某些突然變化，I-frame 必須週期性地出現。
- **P-frames**：**預測影格 (P-frame)** 與前面的 I-frame 或 P-frame 有關。換句話說，每個 P-frame 僅包含來自前一個影格的變化。P-frame 攜帶的資訊比其他影格類型少得多，並且在壓縮後攜帶的位元更少。
- **B-frames**：**雙向影格 (B-frame)** 與前面和後面的 I-frame 或 P-frame 有關。換句話說，每個 B-frame 與過去和未來都有關。請注意，B-frame 永遠不與另一個 B-frame 相關。

### 15.3.3 音訊壓縮
音訊壓縮可用於語音或音樂。兩類技術用於音訊壓縮：預測編碼和感知編碼。

**預測編碼**
在**預測編碼**中，對樣本之間的差異進行編碼，而不是對所有採樣值進行編碼。這種類型的壓縮通常用於語音。已經定義了幾個標準，如 GSM。

**感知編碼：MP3**
用於創建 CD 品質音訊的最常見壓縮技術是基於**感知編碼**技術。這種類型的音訊至少需要 1.411 Mbps，如果不壓縮就無法透過網際網路發送。**MP3 (MPEG 音訊層 3)** 是 MPEG 標準的一部分，使用了這種技術。

感知編碼基於心理聲學，即研究人們如何感知聲音的學科。這個想法基於我們聽覺系統的缺陷：有些聲音可以掩蓋其他聲音。掩蔽可以發生在頻率和時間上。在**頻率掩蔽**中，一個頻率範圍內的響亮聲音可以部分或完全掩蓋另一個頻率範圍內的較柔和聲音。在**時間掩蔽**中，響亮的聲音即使在聲音停止後也能在短時間內降低我們聽覺的靈敏度。

MP3 使用這兩種現象，頻率和時間掩蔽，來壓縮音訊信號。該技術分析並將音訊頻譜分為幾組。零位元分配給完全被掩蓋的頻率範圍，少量位元分配給部分被掩蓋的頻率範圍，較多位元分配給未被掩蓋的頻率範圍。

## 15.4 章末材料
### 15.4.2 關鍵詞
- AC 值
- 雙向影格 (B-frame)
- 資料壓縮
- DC 值
- 基於字典的編碼
- 離散餘弦變換 (DCT)
- 頻率掩蔽
- 霍夫曼編碼
- 幀內編碼影格 (I-frame)
- 聯合圖像專家小組 (JPEG)
- Lempel Ziv (LZ) 編碼
- Lempel Ziv Welch (LZW) 編碼
- 無損資料壓縮
- 失真資料壓縮
- 動態影像專家小組 (MPEG)
- MPEG 音訊層 3 (MP3)
- 感知編碼
- 預測影格 (P-frame)
- 預測編碼
- 連長編碼
- 空間壓縮
- 時間壓縮
- 時間掩蔽

### 15.4.3 摘要
- 資料壓縮方法要麼是無損的（所有資訊都可恢復），要麼是失真的（丟失一些資訊）。
- 在無損壓縮方法中，接收到的資料是發送資料的精確複本。三種無損壓縮方法是連長編碼、霍夫曼編碼和 Lempel Ziv (LZ) 編碼。
- 在連長編碼中，重複出現的符號被符號和符號出現的次數所取代。
- 在霍夫曼編碼中，代碼長度是符號頻率的函數：較頻繁的符號比較不頻繁的符號具有更短的代碼。
- 在 LZ 編碼中，重複的字串或單詞儲存在記憶體位置中。記憶體位置的索引替換字串或單詞。LZ 編碼要求發送者和接收者都有字典和演算法。
- 在失真壓縮方法中，接收到的資料不必是發送資料的精確複本。本章討論了三種失真壓縮方法：JPEG、MPEG 和 MP3。
- JPEG (聯合圖像專家小組) 壓縮是一種壓縮圖片和圖形的方法。JPEG 過程涉及分塊、離散餘弦變換、量化和無損壓縮。
- MPEG (動態影像專家小組) 壓縮是一種壓縮視訊的方法。MPEG 涉及空間壓縮和時間壓縮。前者類似於 JPEG，而後者移除了冗餘影格。
- MP3 (MPEG 音訊層 3) 是 MPEG 標準的一部分。MP3 使用感知編碼技術來壓縮 CD 品質的音訊。
`},b={en:`
# Chapter 16: Security

The topic of security is very broad and involves some specific areas of mathematics such as number theory. In this chapter, we try to give a very simple introduction to this topic to prepare the background for more study.

## Objectives
After studying this chapter, the student should be able to: 
- Define security goals: confidentiality, integrity, and availability.
- Show how confidentiality can be achieved using symmetric-key and asymmetric-key cipher.
- Discuss other aspects of security: message integrity, message authentication, digital signature, entity authentication, and key management.
- Discuss the use of firewalls to protect a system from harmful messages. 

## 16.1 INTRODUCTION
We are living in the information age. We need to keep information about every aspect of our lives. In other words, information is an asset that has a value like any other asset. As an asset, information needs to be secured from attacks. To be secure, information needs to be hidden from unauthorized access (**confidentiality**), protected from unauthorized change (**integrity**), and available to an authorized entity when it is needed (**availability**).

During the last three decades, computer networks have created a revolution in the use of information. Information is now distributed. Authorized people can send and retrieve information from a distance using computer networks. Although the three above-mentioned requirements—confidentiality, integrity, and availability—have not changed, they now have some new dimensions. Not only should information be confidential when it is stored; there should also be a way to maintain its confidentiality when it is transmitted from one computer to another.

In this section, we first discuss the three major goals of information security. We then see how attacks can threaten these three goals. We then discuss the security services in relation to these security goals. Finally, we define two techniques to implement the security goals and prevent attacks.

### 16.1.1 Security goals
Let us first discuss the three security goals: confidentiality, integrity, and availability.

**Confidentiality**
**Confidentiality** is probably the most common aspect of information security. We need to protect our confidential information. An organization needs to guard against those malicious actions that endanger the confidentiality of its information. Confidentiality not only applies to the storage of information, it also applies to the transmission of information. When we send a piece of information to be stored in a remote computer or when we retrieve a piece of information from a remote computer, we need to conceal it during transmission.

**Integrity**
Information needs to be changed constantly. In a bank, when a customer deposits or withdraws money, the balance of their account needs to be changed. **Integrity** means that changes need to be done only by authorized entities and through authorized mechanisms. Integrity violation is not necessarily the result of a malicious act; an interruption in the system, such as a power surge, may also create unwanted changes in some information.

**Availability**
The third component of information security is **availability**. The information created and stored by an organization needs to be available to authorized entities. Information is useless if it is not available. Information needs to be constantly changed, which means it must be accessible to authorized entities. The unavailability of information is just as harmful for an organization as the lack of confidentiality or integrity. Imagine what would happen to a bank if the customers could not access their accounts for transactions.

### 16.1.2 Attacks
Our three goals of security—confidentiality, integrity, and availability—can be threatened by **security attacks**. Although the literature uses different approaches to categorizing the attacks, we divide them into three groups related to the security goals.

**Attacks threatening confidentiality**
In general, two types of attacks threaten the confidentiality of information: snooping and traffic analysis.

**Snooping**
**Snooping** refers to unauthorized access to or interception of data. For example, a file transferred through the Internet may contain confidential information. An unauthorized entity may intercept the transmission and use the contents for their own benefit. To prevent snooping, the data can be made nonintelligible to the intercepter by using encipherment techniques discussed later.

**Traffic analysis**
Although encipherment of data may make it nonintelligible for the intercepter, they can obtain some other type of information by monitoring online traffic. For example, they can find the electronic address (such as the email address) of the sender or the receiver. They can collect pairs of requests and responses to help them guess the nature of the transaction.

**Attacks threatening integrity**
The integrity of data can be threatened by several kinds of attacks: modification, masquerading, replaying, and repudiation.

**Modification**
After intercepting or accessing information, the attacker modifies the information to make it beneficial to them. For example, a customer sends a message to a bank to initiate some transaction. The attacker intercepts the message and changes the type of transaction to benefit them. Note that sometimes the attacker simply deletes or delays the message to harm the system or to benefit from it.

**Masquerading**
**Masquerading**, or **spoofing**, happens when the attacker impersonates somebody else. For example, an attacker might steal the bank card and PIN of a bank customer and pretend that they are that customer. Sometimes the attacker pretends instead to be the receiver entity. For example, a user tries to contact a bank, but another site pretends that it is the bank and obtains some information from the user.

**Replaying**
**Replaying** is another attack. The attacker obtains a copy of a message sent by a user and later tries to replay it. For example, a person sends a request to their bank to ask for payment to the attacker, who has done a job for them. The attacker intercepts the message and sends it again to receive another payment from the bank.

**Repudiation**
This type of attack is different from others because it is performed by one of the two parties in the communication: the sender or the receiver. The sender of the message might later deny that they have sent the message; the receiver of the message might later deny that they have received the message. An example of denial by the sender would be a bank customer asking their bank to send some money to a third party but later denying that they have made such a request. An example of denial by the receiver could occur when a person buys a product from a manufacturer and pays for it electronically, but the manufacturer later denies having received the payment and asks to be paid.

**Attacks threatening availability**
We mention only one attack threatening availability: denial of service.

**Denial of service**
**Denial of service (DoS)** is a very common attack. It may slow down or totally interrupt the service of a system. The attacker can use several strategies to achieve this. They might send so many bogus requests to a server that the server crashes because of the heavy load. The attacker might intercept and delete a server’s response to a client, making the client believe that the server is not responding. The attacker may also intercept requests from the clients, causing the clients to send requests many times and overload the system.

### 16.1.3 Services and techniques
ITU-T defines some security services to achieve security goals and prevent attacks. Each of these services is designed to prevent one or more attacks while maintaining security goals. The actual implementation of security goals needs some techniques.
Two techniques are prevalent today: one is very general (cryptography) and one is specific (steganography).

**Cryptography**
Some security services can be implemented using cryptography. **Cryptography**, a word with Greek origins, means ‘secret writing’. However, we use the term to refer to the science and art of transforming messages to make them secure and immune to attacks. Although in the past cryptography referred only to the **encryption** and **decryption** of messages using **secret keys**, today it is defined as involving three distinct mechanisms: symmetric-key encipherment, asymmetric-key encipherment, and hashing. We will discuss all these mechanisms later in the chapter.

**Steganography**
Although this chapter and the next are based on cryptography as a technique for implementing security mechanisms, another technique that was used for secret communication in the past is being revived at the present time: steganography. The word **steganography**, with origins in Greek, means ‘covered writing’, in contrast to cryptography, which means ‘secret writing’. *Cryptography* means concealing the contents of a message by enciphering; *steganography* means concealing the message itself by covering it with something else. We leave the discussion of steganography to those books dedicated to this topic.

## 16.2 CONFIDENTIALITY
We now look at the first goal of security, confidentiality. Confidentiality can be achieved using ciphers. Ciphers can be divided into two broad categories: symmetric-key and asymmetric-key.

### 16.2.1 Symmetric-key ciphers
A **symmetric-key cipher** uses the same key for both encryption and decryption, and the key can be used for bidirectional communication, which is why it is called symmetric.

**Symmetric-key ciphers are also called secret-key ciphers.**

The original message from Alice to Bob is called **plaintext**; the message that is sent through the channel is called **ciphertext**. To create the ciphertext from the plaintext, Alice uses an **encryption algorithm** and a *shared secret key*.
To create the plaintext from ciphertext, Bob uses a **decryption algorithm** and the same secret key. We refer to encryption and decryption algorithms as **ciphers**. A **key** is a set of values (numbers) that the cipher, as an algorithm, operates on.

Note that the symmetric-key encipherment uses a single key (the key itself may be a set of values) for both encryption and decryption. In addition, the encryption and decryption algorithms are inverses of each other.

**Encryption**: $C = E_k(P)$        **Decryption**: $P = D_k(C)$

Encryption can be thought of as locking the message in a box; decryption can be thought of as unlocking the box. In symmetric-key encipherment, the same key locks and unlocks.

The symmetric-key ciphers can be divided into traditional ciphers and modern ciphers. Traditional ciphers are simple, character-oriented ciphers that are not secured based on today’s standard. Modern ciphers, on the other hand, are complex, bit-oriented ciphers that are more secure. We briefly discuss the traditional ciphers to pave the way for discussing more complex modern ciphers.

**Traditional symmetric-key ciphers**
Traditional ciphers belong to the past. However, we briefly discuss them here because they can be thought of as the components of the modern ciphers. To be more exact, we can divide traditional ciphers into substitution ciphers and transposition ciphers.

**Substitution ciphers**
A **substitution cipher** replaces one symbol with another. If the symbols in the plaintext are alphabetic characters, we replace one character with another. For example, we can replace letter A with letter D and letter T with letter Z. If the symbols are digits (0 to 9), we can replace 3 with 7 and 2 with 6.
Substitution ciphers can be categorized as either monoalphabetic ciphers or polyalphabetic ciphers.

**Monoalphabetic ciphers**
In a **monoalphabetic cipher**, a character (or a symbol) in the plaintext is always changed to the same character (or symbol) in the ciphertext regardless of its position in the text. For example, if the algorithm says that letter A in the plaintext is changed to letter D, every letter A is changed to letter D. In other words, the relationship between letters in the plaintext and the ciphertext is one-to-one.
The simplest monoalphabetic cipher is the **additive cipher** (or **shift cipher**). Assume that the plaintext consists of lowercase letters (a to z), and that the ciphertext consists of uppercase letters (A to Z). To be able to apply mathematical operations on the plaintext and ciphertext, we assign numerical values to each letter (lower- or uppercase).
The encryption algorithm adds the key to the plaintext character; the decryption algorithm subtracts the key from the ciphertext character. All operations are done in modulo 26.
Historically, additive ciphers are called shift ciphers because the encryption algorithm can be interpreted as ‘shift key characters down’ and the encryption algorithm can be interpreted as ‘shift key characters up’. Julius Caesar used an additive cipher, with a key of 3, to communicate with his officers. For this reason, additive ciphers are sometimes referred to as the **Caesar cipher**.

**Polyalphabetic ciphers**
In a **polyalphabetic cipher**, each occurrence of a character may have a different substitute. The relationship between a character in the plaintext to a character in the ciphertext is one-to-many. For example, ‘a’ could be enciphered as ‘D’ at the beginning of the text, but as ‘N’ in the middle. Polyalphabetic ciphers have the advantage of hiding the letter frequency of the underlying language. Eve cannot use single-letter frequency statistics to break the ciphertext.
To create a polyalphabetic cipher, we need to make each ciphertext character dependent on both the corresponding plaintext character and the position of the plaintext character in the message.

**Transposition ciphers**
A **transposition cipher** does not substitute one symbol for another; instead it changes the location of the symbols. A symbol in the first position of the plaintext may appear in the tenth position of the ciphertext. A symbol in the eighth position in the plaintext may appear in the first position of the ciphertext. In other words, a transposition cipher reorders (transposes) the symbols.

**Stream and block ciphers**
The literature divides the symmetric ciphers into two broad categories: stream ciphers and block ciphers.

**Stream cipher**
In a **stream cipher**, encryption and decryption are done one symbol (such as a character or a bit) at a time. We have a plaintext stream, a ciphertext stream, and a key stream.

**Block ciphers**
In a **block cipher**, a group of plaintext symbols of size $m$ ($m > 1$) are encrypted together, creating a group of ciphertext of the same size. Based on the definition, in a block cipher, a single key is used to encrypt the whole block even if the key is made of multiple values. In a block cipher, a ciphertext block depends on the whole plaintext block.

**Modern symmetric-key ciphers**
The traditional symmetric-key ciphers that we have studied so far are character-oriented ciphers. With the advent of the computer, we need bit-oriented ciphers. This is because the information to be encrypted is not just text; it can also consist of numbers, graphics, audio, and video data. It is convenient to convert these types of data into a stream of bits, to encrypt the stream, and then to send the encrypted stream.

**Modern block ciphers**
A symmetric-key *modern block cipher* encrypts an $n$-bit block of plaintext or decrypts an $n$-bit block of ciphertext. The encryption or decryption algorithm uses a $k$-bit key. The decryption algorithm must be the inverse of the encryption algorithm, and both operations must use the same secret key so that Bob can retrieve the message sent by Alice.

**Modern stream ciphers**
In addition to modern block ciphers, we can also use modern stream ciphers. In a modern stream cipher, encryption and decryption are done $r$ bits at a time. Stream ciphers are faster than block ciphers. The hardware implementation of a stream cipher is also easier. When we need to encrypt binary streams and transmit them at a constant rate, a stream cipher is the better choice to use.
The simplest and the most secure type of synchronous stream cipher is called the **one-time pad**, which was invented and patented by Gilbert Vernam. A one-time pad cipher uses a key stream that is randomly chosen for each encipherment. The encryption and decryption algorithms each use a single exclusive-OR operation. The one-time pad is an ideal cipher. It is perfect. There is no way that an adversary can guess the key or the plaintext and ciphertext statistics. However, there is an issue here. How can the sender and the receiver share a one-time pad key each time they want to communicate?

### 16.2.2 Asymmetric-key ciphers
In previous sections we discussed symmetric-key ciphers. In this section, we start the discussion of **asymmetric-key ciphers**. Symmetric- and asymmetric-key ciphers will exist in parallel and continue to serve the community. We actually believe that they are complements of each other; the advantages of one can compensate for the disadvantages of the other.

The conceptual differences between the two systems are based on how these systems keep a secret. In symmetric-key cryptography, the secret must be shared between two persons. In asymmetric-key cryptography, the secret is personal (unshared); each person creates and keeps his or her own secret.

**Symmetric-key cryptography is based on sharing secrecy; asymmetric-key cryptography is based on personal secrecy.**

There are some other aspects of security besides encipherment that need asymmetric-key cryptography. These include authentication and digital signatures. Whenever an application is based on a personal secret, we need to use asymmetric-key cryptography.

Whereas symmetric-key cryptography is based on substitution and permutation of symbols (characters or bits), asymmetric-key cryptography is based on applying mathematical functions to numbers. In asymmetric-key cryptography, the plaintext and ciphertext are numbers; encryption and decryption are mathematical functions that are applied to numbers to create other numbers.

**In symmetric-key cryptography, symbols are permuted or substituted; in asymmetric-key cryptography, numbers are manipulated.**

Asymmetric-key cryptography uses two separate keys: one private and one public. If encryption and decryption are thought of as locking and unlocking padlocks with keys, then the padlock that is locked with a public key can be unlocked only with the corresponding private key.

**Asymmetric-key ciphers are sometimes called public-key ciphers.**

**General idea**
The burden of providing security is mostly on the shoulders of the receiver (Bob, in this case). Bob needs to create two keys: one private and one public. Bob is responsible for distributing the public key to the community.
Second, asymmetric-key cryptography means that Bob and Alice cannot use the same set of keys for two-way communication. Each entity in the community should create its own private and public keys.
Third, asymmetric-key cryptography means that Bob needs only one private key to receive all correspondence from anyone in the community, but Alice needs $n$ public keys to communicate with $n$ entities in the community, one public key for each entity. In other words, Alice needs a ring of public keys.

**Plaintext/ciphertext**
Unlike in symmetric-key cryptography, plaintext and ciphertext in asymmetric-key cryptography are treated as integers. The message must be encoded as an integer (or a set of integers) before encryption; the integer (or the set of integers) must be decoded into the message after decryption. Asymmetric-key cryptography is normally used to encrypt or decrypt small pieces of information, such as the cipher key for a symmetric-key cryptography.

**Asymmetric-key cryptography is normally used to encrypt or decrypt small pieces of information.**

**RSA cryptosystem**
Although there are several asymmetric-key cryptosystems, one of the common public-key algorithms is the **RSA cryptosystem**, named for its inventors (Rivest, Shamir, and Adleman). RSA uses two exponents, $e$ and $d$, where $e$ is public and $d$ is private. Suppose $P$ is the plaintext and $C$ is the ciphertext. Alice uses $C = P^e \\pmod n$ to create ciphertext $C$ from plaintext $P$; Bob uses $P = C^d \\pmod n$ to retrieve the plaintext sent by Alice. The modulus $n$, a very large number, is created during the key generation process.

Bob chooses two large numbers, $p$ and $q$, and calculates $n = p \\times q$ and $\\phi = (p - 1) \\times (q - 1)$. Bob then selects $e$ and $d$ such that $(e \\times d) \\pmod \\phi = 1$. Bob advertises $e$ and $n$ to the community as the public key; Bob keeps $d$ as the private key. Anyone, including Alice, can encrypt a message and send the ciphertext to Bob, using $C = P^e \\pmod n$; only Bob can decrypt the message, using $P = C^d \\pmod n$. An intruder such as Eve cannot decrypt the message if $p$ and $q$ are very large numbers (she does not know $d$).

Although RSA can be used to encrypt and decrypt actual messages, it is very slow if the message is long. RSA, therefore, is useful for short messages. In particular, we will see that RSA is used in digital signatures and other cryptosystems that often need to encrypt a small message without having access to a symmetric key.

## 16.3 OTHER ASPECTS OF SECURITY
The cryptography systems that we have studied so far provide confidentiality. However, in modern communication, we need to take care of other aspects of security, such as integrity, message and entity authentication, non-repudiation, and key management. We briefly discuss these issues in this section.

### 16.3.1 Message integrity
There are occasions where we may not even need secrecy but instead must have integrity: the message should remain unchanged.

**Message and message digest**
One way to preserve the integrity of a document is through the use of a **fingerprint**. The electronic equivalent of the document and fingerprint pair is the message and digest pair. To preserve the integrity of a message, the message is passed through an algorithm called a **cryptographic hash function**. The function creates a compressed image of the message, called a **digest**, that can be used like a fingerprint. To check the integrity of a message or document, Bob runs the cryptographic hash function again and compares the new digest with the previous one. If both are the same, Bob is sure that the original message has not been changed.

**The message digest needs to be safe from change.**

**Hash functions**
A cryptographic hash function takes a message of arbitrary length and creates a message digest of fixed length. All cryptographic hash functions need to create a fixed-size digest out of a variable-size message. Creating such a function is best accomplished using iteration. Instead of using a hash function with variable-size input, a function with fixed-size input is created and is used a necessary number of times. The fixed-size input function is referred to as a compression function. It compresses an $n$-bit string to create an $m$-bit string where $n$ is normally greater than $m$. The scheme is referred to as an *iterated cryptographic hash function*.
Several hash algorithms were designed by Ron Rivest. These are referred to as **MD2**, **MD4**, and **MD5**, where MD stands for **message digest**. The last version, MD5, is a strengthened version of MD4 that divides the message into blocks of 512 bits and creates a 128-bit digest. It turns out, however, that a message digest of size 128 bits is too small to resist attack.
In response to the insecurity of MD hash algorithms, the Secure Hash Algorithm was invented. The **Secure Hash Algorithm (SHA)** is a standard that was developed by the National Institute of Standards and Technology (NIST). SHA has gone through several versions.

### 16.3.2 Message authentication
A digest can be used to check the integrity of a message—that the message has not been changed. To ensure the integrity of the message and the data origin authentication—that Alice is the originator of the message, not somebody else—we need to include a secret shared by Alice and Bob (that Eve does not possess) in the process; we need to create a **message authentication code (MAC)**.

Alice uses a hash function to create a MAC from the concatenation of the key and the message, $h(K + M)$. She sends the message and the MAC to Bob over the insecure channel. Bob separates the message from the MAC. He then makes a new MAC from the concatenation of the message and the secret key. Bob then compares the newly created MAC with the one received. If the two MACs match, the message is authentic and has not been modified by an adversary.

**A MAC provides message integrity and message authentication using a combination of a hash function and a secret key.**

### 16.3.3 Digital signature
Another way to provide message integrity and message authentication (and some more security services, as we will see shortly) is a digital signature. A MAC uses a secret key to protect the digest; a digital signature uses a pair of private–public keys.

**A digital signature uses a pair of private–public keys.**

When Alice sends a message to Bob, Bob needs to check the authenticity of the sender; he needs to be sure that the message comes from Alice and not Eve. Bob can ask Alice to sign the message electronically. In other words, an electronic signature can prove the authenticity of Alice as the sender of the message. We refer to this type of signature as a **digital signature**.

**Comparison**
- **Inclusion**: A conventional signature is included in the document; it is part of the document. But when we sign a document digitally, we send the signature as a separate document.
- **Verification method**: For a conventional signature, when the recipient receives a document, they compare the signature on the document with the signature on file. For a digital signature, the recipient receives the message and the signature. The recipient needs to apply a verification technique to the combination of the message and the signature to verify the authenticity.
- **Relationship**: For a conventional signature, there is normally a one-to-many relationship between a signature and documents. For a digital signature, there is a one-to-one relationship between a signature and a message. Each message has its own signature.
- **Duplicity**: Another difference between the two types of signatures is a quality called *duplicity*. With a conventional signature, a copy of the signed document can be distinguished from the original one on file. With a digital signature, there is no such distinction unless there is a factor of time (such as a timestamp) on the document.

**Process**
The sender uses a **signing algorithm** to sign the message. The message and the signature are sent to the receiver. The receiver receives the message and the signature and applies the **verifying algorithm** to the combination. If the result is true, the message is accepted; otherwise, it is rejected.

In a digital signature, the signer uses her **private key**, applied to a signing algorithm, to sign the document. The verifier, on the other hand, uses the **public key** of the signer, applied to the verifying algorithm, to verify the document.

**A digital signature needs a public-key system. The signer signs with her private key; the verifier verifies with the signer’s public key.**

**A cryptosystem uses the private and public keys of the receiver; a digital signature uses the private and public keys of the sender.**

**Signing the digest**
Asymmetric-key cryptosystems are very inefficient when dealing with long messages. In a digital signature system, the messages are normally long, but we have to use asymmetric-key schemes. The solution is to sign a digest of the message, which is much shorter than the message. A carefully selected message digest has a one-to-one relationship with the message. The sender can sign the message digest and the receiver can verify the message digest. The effect is the same.

**Services**
- **Message authentication**: A secure digital signature scheme can provide message authentication (also referred to as data-origin authentication). Bob can verify that the message is sent by Alice because Alice’s public key is used in verification. Alice’s public key cannot verify the signature signed by Eve’s private key.
- **Message integrity**: The integrity of the message is preserved if we sign the message or the digest of the message because we cannot get the same digest if any part of the message is changed.
- **Nonrepudiation**: If Alice signs a message and then denies it, Bob can prove that Alice actually signed it. One solution is a trusted third party. People can create an established trusted party among themselves.

**Confidentiality**
A digital signature does not provide confidential communication. If confidentiality is required, the message and the signature must be encrypted using either a symmetric-key or an asymmetric-key cipher.

### 16.3.4 Entity authentication
**Entity authentication** is a technique designed to let one party verify the identity of another party. An **entity** can be a person, a process, a client, or a server. The entity whose identity needs to be proven is called the **claimant**; the party that tries to verify the identity of the claimant is called the **verifier**.

**Entity versus message authentication**
1.  Message authentication (or data-origin authentication) might not happen in real time; entity authentication does. In the former, Alice sends a message to Bob. When Bob authenticates the message, Alice may or may not be present in the communication process. On the other hand, when Alice requests entity authentication, there is no real message communication involved until Alice is authenticated by Bob. Alice needs to be online and to take part in the process.
2.  Message authentication simply authenticates one message; the process needs to be repeated for each new message. Entity authentication authenticates the claimant for the entire duration of a session.

**Verification categories**
In entity authentication, the claimant must identify him- or herself to the verifier. This can be done with one of three kinds of witnesses: something known, something possessed, or something inherent.
- **Something known**: This is a secret known only by the claimant that can be checked by the verifier. Examples are a password, a PIN, a secret key, and a private key.
- **Something possessed**: This is something that can prove the claimant’s identity. Examples are a passport, a driver’s license, an identification card, a credit card, and a smart card.
- **Something inherent**: This is an inherent characteristic of the claimant. Examples are conventional signatures, fingerprints, voice, facial characteristics, retinal pattern, and handwriting.

**Passwords**
The simplest and oldest method of entity authentication is the use of a **password**, which is something that the claimant *knows*. A password is used when a user needs to access a system’s resources (login). Each user has a user identification that is public, and a password that is private. Passwords, however, are very prone to attack.

**Challenge–response**
In password authentication, the claimant proves her identity by demonstrating that she knows a secret, the password. However, because the claimant sends this secret, it is susceptible to interception by the adversary. In **challenge–response authentication**, the claimant proves that she *knows* a secret without sending it to the verifier. In other words, the claimant does not send the secret to the verifier; the verifier either has it or finds it.

**In challenge–response authentication, the claimant proves that she knows a secret without sending it to the verifier.**

The **challenge** is a time-varying value such as a random number or a timestamp that is sent by the verifier. The claimant applies a function to the challenge and sends the result, called a **response**, to the verifier. The response shows that the claimant knows the secret.

**Using a symmetric-key cipher**
Several approaches to challenge–response authentication use **symmetric-key encryption**. The secret here is the shared secret key, known by both the claimant and the verifier. The function is the encrypting algorithm applied on the challenge.

**Using an asymmetric-key cipher**
Instead of a symmetric-key cipher, we can use an asymmetric-key cipher for entity authentication. Here the secret must be the private key of the claimant. The claimant must show that she owns the private key related to the public key that is available to everyone.

**Using digital signatures**
Entity authentication can also be achieved using a digital signature. When a digital signature is used for entity authentication, the claimant uses her private key for signing.

### 16.3.5 Key management
We discussed symmetric-key and asymmetric-key cryptography in the previous sections. However, we have not yet discussed how secret keys in symmetric-key cryptography, and public keys in asymmetric-key cryptography, are distributed and maintained. This section touches on these two issues.

**Symmetric-key distribution**
Symmetric-key cryptography is more efficient than asymmetric-key cryptography for enciphering large messages. Symmetric-key cryptography, however, needs a shared secret key between two parties.
If Alice needs to exchange confidential messages with $N$ people, she needs $N$ different keys. What if $N$ people need to communicate with each other? A total of $N(N - 1)/2$ keys are needed. This is normally referred to as the $N^2$ problem because the number of required keys for $N$ entities is close to $N^2$.
The number of keys is not the only problem; the distribution of keys is another. Using the Internet is definitely not a secure method.

**Key distribution center: KDC**
A practical solution is the use of a trusted third party, referred to as a **key-distribution center (KDC)**. To reduce the number of keys, each person establishes a shared secret key with the KDC. A secret key is established between the KDC and each member. Now the question is how Alice can send a confidential message to Bob.
1.  Alice sends a request to the KDC stating that she needs a session (temporary) secret key between herself and Bob.
2.  The KDC informs Bob about Alice’s request.
3.  If Bob agrees, a session key is created between the two.
The secret key between Alice and Bob that is established with the KDC is used to authenticate Alice and Bob to the KDC and to prevent Eve from impersonating either of them.

**Session keys**
A KDC creates a secret key for each member. This secret key can be used only between the member and the KDC, not between two members. If Alice needs to communicate secretly with Bob, she needs a secret key between herself and Bob. A KDC can create a **session key** between Alice and Bob, using their keys with the center. The keys of Alice and Bob are used to authenticate Alice and Bob to the center and to each other before the session key is established. After communication is terminated, the session key is no longer useful.

**A session symmetric key between two parties is used only once.**

**Public-key distribution**
In asymmetric-key cryptography, people do not need to know a symmetric shared key. If Alice wants to send a message to Bob, she only needs to know Bob’s public key, which is open to the public and available to everyone. In public-key cryptography, everyone shields a private key and advertises a public key.

**In public-key cryptography, everyone has access to everyone’s public key; public keys are available to the public.**

**Public announcement**
The naive approach is to announce public keys publicly. Bob can put his public key on his website or announce it in a local or national newspaper. This approach, however, is not secure; it is subject to forgery. For example, Eve could make such a public announcement. Eve can fool Alice into sending her a message that is intended for Bob.

**Certification authority**
The common approach to distributing public keys is to create **public-key certificates**. Bob wants two things; he wants people to know his public key, and he wants no one to accept a forged public key as his. Bob can go to a **certification authority (CA)**, a federal or state organization that binds a public key to an entity and issues a certificate.
The CA itself has a well-known public key that cannot be forged. The CA checks Bob’s identification. It then asks for Bob’s public key and writes it on the certificate. To prevent the certificate itself from being forged, the CA signs the certificate with its private key. Now Bob can upload the signed certificate. Anyone who wants Bob’s public key downloads the signed certificate and uses the authority’s public key to extract Bob’s public key.

**X.509**
Although the use of a CA has solved the problem of public-key fraud, it has created a **side effect**. Each certificate may have a different format. Anything that needs to be used universally must have a universal format. To remove this side effect, the ITU has designed **X.509**, a recommendation that has been accepted by the Internet with some changes. X.509 is a way to describe the certificate in a structured way. It uses a well-known protocol called ASN.1 that defines fields familiar to computer programmers.

## 16.4 FIREWALLS
All previous security measures cannot prevent Eve from sending a harmful message to a system. To control access to a system we need firewalls. A **firewall** is a device (usually a router or a computer) installed between the internal network of an organization and the rest of the Internet. It is designed to forward some packets and filter (not forward) others.

For example, a firewall may filter all incoming packets destined for a specific host or a specific server such as HTTP. A firewall can be used to deny access to a specific host or a specific service in the organization. A firewall is usually classified as a *packet-filter firewall* or a *proxy-based firewall*.

### 16.4.1 Packet-filter firewall
A firewall can be used as a packet filter. It can forward or block packets based on the information in the network-layer and transport-layer headers: source and destination IP addresses, source and destination **port addresses**, and type of protocol (TCP or UDP). A **packet-filter firewall** is a router that uses a filtering table to decide which packets must be discarded (not forwarded).

### 16.4.2 Proxy firewall
The packet-filter firewall is based on the information available in the network-layer and transport-layer headers (IP and TCP/UDP). However, sometimes we need to filter a message based on the information available in the message itself (at the application layer). As an example, assume that an organization wants to implement the following policies regarding its web pages: only those Internet users who have previously established business relations with the company can have access; access to other users must be blocked. In this case, a packet-filter firewall is not feasible because it cannot distinguish between different packets arriving at TCP port 80 (HTTP). Testing must be done at the application level (using URLs).

One solution is to install a proxy computer (sometimes called an **application gateway**), which stands between the customer computer and the corporation computer. When the user client process sends a message, the application gateway runs a server process to receive the request. The server opens the packet at the application level and finds out if the request is legitimate. If it is, the server acts as a client process and sends the message to the real server in the corporation. If it is not, the message is dropped and an error message is sent to the external user. In this way, the requests of the external users are filtered based on the contents at the application layer.

## 16.5 END-CHAPTER MATERIALS
### 16.5.2 Key terms
- additive cipher
- application gateway
- asymmetric-key cipher
- autokey cipher
- availability
- block cipher
- caesar cipher
- certification authority (CA)
- challenge–response authentication
- cipher
- ciphertext
- confidentiality
- cryptographic hash function
- cryptography
- decryption
- decryption algorithm
- denial of service (DoS)
- digest
- digital signature
- encryption
- encryption algorithm
- firewall
- hashed MAC (HMAC)
- integrity
- key
- key-distribution center (KDC)
- masquerading
- message authentication code (MAC)
- message digest (MD)
- monoalphabetic cipher
- one-time pad
- packet-filter firewall
- plaintext
- polyalphabetic cipher
- port address
- private key
- proxy firewall
- public key
- public-key certificate
- replaying
- RSA cryptosystem
- secret key
- Secure Hash Algorithm (SHA)
- security attack
- security goal
- shift cipher
- side effect
- snooping
- spoofing
- steganography
- stream cipher
- substitution cipher
- symmetric-key cipher
- symmetric-key encryption
- ticket
- traffic analysis
- transposition cipher
- verifying algorithm
- X.509

### 16.5.3 Summary
- Data compression methods are either lossless (all information is recoverable) or lossy (some information is lost).
- In lossless compression methods, the received data is an exact replica of the sent data. Three lossless compression methods are run-length encoding, Huffman coding, and Lempel Ziv (LZ) encoding.
- In run-length encoding, repeated occurrences of a symbol are replaced by a symbol and the number of occurrences of the symbol.
- In Huffman coding, the code length is a function of symbol frequency: more frequent symbols have shorter codes than less frequent symbols.
- In LZ encoding, repeated strings or words are stored in memory locations. An index to the memory location replaces the string or word. LZ encoding requires a dictionary and an algorithm at both sender and receiver.
- In lossy compression methods, the received data need not be an exact replica of the sent data. Three lossy compression methods were discussed in this chapter: JPEG, MPEG, and MP3.
- JPEG (Joint Photographic Experts Group) compression is a method of compressing pictures and graphics. The JPEG process involves blocking, the discrete cosine transform, quantization, and lossless compression.
- MPEG (Moving Pictures Experts Group) compression is a method of compressing video. MPEG involves both spatial compression and temporal compression. The former is similar to JPEG, while the latter removes redundant frames.
- MP3 (MPEG audio layer 3) is a part of the MPEG standard. MP3 uses perceptual encoding techniques to compress CD-quality audio.
`,zh:`
# 第十六章：安全性

安全性的主題非常廣泛，涉及一些特定的數學領域，如數論。在本章中，我們試圖對此主題做一個非常簡單的介紹，為更深入的學習做準備。

## 學習目標
學完本章後，學生應能：
- 定義安全性目標：機密性、完整性和可用性。
- 展示如何使用對稱金鑰和非對稱金鑰加密法實現機密性。
- 討論安全性的其他方面：訊息完整性、訊息驗證、數位簽章、實體驗證和金鑰管理。
- 討論如何使用防火牆保護系統免受有害訊息的侵害。

## 16.1 簡介
我們生活在資訊時代。我們需要保存關於生活各個方面的資訊。換句話說，資訊是一種像任何其他資產一樣有價值的資產。作為一種資產，資訊需要免受攻擊。為了安全，資訊需要隱藏以防止未經授權的存取（**機密性**），保護以免受未經授權的更改（**完整性**），並在需要時對授權實體可用（**可用性**）。

在過去的三十年中，電腦網路在資訊的使用上創造了一場革命。資訊現在是分散式的。授權人員可以使用電腦網路從遠處發送和檢索資訊。雖然上述三個要求——機密性、完整性和可用性——沒有改變，但它們現在有了一些新的維度。資訊不僅在儲存時應該保密；還應該有一種方法在從一台電腦傳輸到另一台電腦時保持其機密性。

在本節中，我們首先討論資訊安全的三個主要目標。然後我們看看攻擊如何威脅這三個目標。接著我們討論與這些安全目標相關的安全服務。最後，我們定義兩種技術來實現安全目標並防止攻擊。

### 16.1.1 安全性目標
讓我們先討論三個安全性目標：機密性、完整性和可用性。

**機密性 (Confidentiality)**
**機密性**可能是資訊安全中最常見的方面。我們需要保護我們的機密資訊。組織需要防範那些危及資訊機密性的惡意行為。機密性不僅適用於資訊的儲存，也適用於資訊的傳輸。當我們發送一條資訊以儲存在遠端電腦中，或當我們從遠端電腦檢索一條資訊時，我們需要在傳輸過程中將其隱藏。

**完整性 (Integrity)**
資訊需要不斷更改。在銀行中，當客戶存款或取款時，他們的帳戶餘額需要更改。**完整性**意味著更改只能由授權實體並通過授權機制完成。完整性違規不一定是惡意行為的結果；系統中的中斷，例如電湧，也可能在某些資訊中產生不必要的更改。

**可用性 (Availability)**
資訊安全的第三個組成部分是**可用性**。組織創建和儲存的資訊需要對授權實體可用。如果資訊不可用，它就是無用的。資訊需要不斷更改，這意味著它必須可供授權實體存取。資訊的不可用性對組織的危害與缺乏機密性或完整性一樣大。想像一下，如果客戶無法存取他們的帳戶進行交易，銀行會發生什麼事。

### 16.1.2 攻擊
我們的三個安全性目標——機密性、完整性和可用性——可能會受到**安全性攻擊**的威脅。雖然文獻使用不同的方法對攻擊進行分類，但我們將它們分為與安全性目標相關的三組。

**威脅機密性的攻擊**
一般來說，有兩種類型的攻擊威脅資訊的機密性：窺探和流量分析。

**窺探 (Snooping)**
**窺探**是指未經授權存取或攔截資料。例如，透過網際網路傳輸的檔案可能包含機密資訊。未經授權的實體可能會攔截傳輸並將內容用於自己的利益。為了防止窺探，可以使用稍後討論的加密技術使攔截者無法理解資料。

**流量分析 (Traffic analysis)**
雖然資料加密可能會使攔截者無法理解資料，但他們可以透過監控線上流量來獲取其他類型的資訊。例如，他們可以找到發送者或接收者的電子位址（如電子郵件地址）。他們可以收集請求和回應對，以幫助他們猜測交易的性質。

**威脅完整性的攻擊**
資料的完整性可能會受到幾種攻擊的威脅：修改、偽裝、重放和否認。

**修改 (Modification)**
在攔截或存取資訊後，攻擊者會修改資訊以使其對自己有利。例如，客戶向銀行發送訊息以啟動某些交易。攻擊者攔截訊息並更改交易類型以使自己受益。請注意，有時攻擊者只是刪除或延遲訊息以損害系統或從中受益。

**偽裝 (Masquerading)**
**偽裝**或**欺騙 (spoofing)** 發生在攻擊者冒充他人時。例如，攻擊者可能會竊取銀行客戶的銀行卡和 PIN 碼，並假裝自己是該客戶。有時攻擊者假裝是接收實體。例如，使用者試圖聯繫銀行，但另一個網站假裝是銀行並從使用者那裡獲取一些資訊。

**重放 (Replaying)**
**重放**是另一種攻擊。攻擊者獲取使用者發送的訊息副本，稍後嘗試重放它。例如，一個人向銀行發送請求，要求向為其完成工作的攻擊者付款。攻擊者攔截訊息並再次發送以從銀行獲得另一筆付款。

**否認 (Repudiation)**
這種類型的攻擊與其他攻擊不同，因為它是由通訊中的兩方之一執行的：發送者或接收者。訊息的發送者稍後可能會否認他們發送了該訊息；訊息的接收者稍後可能會否認他們收到了該訊息。發送者否認的一個例子是銀行客戶要求銀行向第三方匯款，但後來否認他們提出了這樣的請求。接收者否認的一個例子可能發生在一個人從製造商那裡購買產品並以電子方式付款，但製造商後來否認收到付款並要求付款。

**威脅可用性的攻擊**
我們只提到一種威脅可用性的攻擊：阻斷服務。

**阻斷服務 (Denial of service)**
**阻斷服務 (DoS)** 是一種非常常見的攻擊。它可能會減慢或完全中斷系統的服務。攻擊者可以使用幾種策略來實現這一目標。他們可能會向伺服器發送大量虛假請求，導致伺服器因負載過重而崩潰。攻擊者可能會攔截並刪除伺服器對客戶端的回應，使客戶端認為伺服器沒有回應。攻擊者也可能攔截來自客戶端的請求，導致客戶端多次發送請求並使系統過載。

### 16.1.3 服務與技術
ITU-T 定義了一些安全性服務來實現安全性目標並防止攻擊。這些服務中的每一項都旨在防止一種或多種攻擊，同時維護安全性目標。安全性目標的實際實作需要一些技術。
今天流行兩種技術：一種是非常通用的（密碼學），一種是特定的（隱寫術）。

**密碼學 (Cryptography)**
一些安全性服務可以使用密碼學來實現。**密碼學**一詞源於希臘語，意思是「秘密寫作」。然而，我們使用該術語來指代轉換訊息使其安全並免受攻擊的科學與藝術。雖然在過去，密碼學僅指使用**秘密金鑰**對訊息進行**加密**和**解密**，但今天它被定義為涉及三種不同的機制：對稱金鑰加密、非對稱金鑰加密和雜湊。我們將在本章稍後討論所有這些機制。

**隱寫術 (Steganography)**
雖然本章和下一章是基於密碼學作為實作安全機制的技術，但在過去用於秘密通訊的另一種技術目前正在復興：隱寫術。**隱寫術**一詞源於希臘語，意思是「覆蓋寫作」，與意為「秘密寫作」的密碼學形成對比。*密碼學*意味著透過加密來隱藏訊息的內容；*隱寫術*意味著透過用其他東西覆蓋訊息來隱藏訊息本身。我們將隱寫術的討論留給專門討論此主題的書籍。

## 16.2 機密性
我們現在來看安全性的第一個目標，機密性。可以使用加密法實現機密性。加密法可以分為兩大類：對稱金鑰和非對稱金鑰。

### 16.2.1 對稱金鑰加密法
**對稱金鑰加密法**使用相同的金鑰進行加密和解密，並且該金鑰可用於雙向通訊，這就是為什麼它被稱為對稱的原因。

**對稱金鑰加密法也稱為秘密金鑰加密法。**

從 Alice 到 Bob 的原始訊息稱為**明文**；透過通道發送的訊息稱為**密文**。為了從明文創建密文，Alice 使用**加密演算法**和*共享秘密金鑰*。
為了從密文創建明文，Bob 使用**解密演算法**和相同的秘密金鑰。我們將加密和解密演算法稱為**加密法 (ciphers)**。**金鑰**是一組值（數字），加密法作為演算法對其進行操作。

請注意，對稱金鑰加密使用單個金鑰（金鑰本身可能是一組值）進行加密和解密。此外，加密和解密演算法互為逆運算。

**加密**: $C = E_k(P)$        **解密**: $P = D_k(C)$

加密可以被認為是將訊息鎖在盒子裡；解密可以被認為是解鎖盒子。在對稱金鑰加密中，同一把鑰匙用於鎖定和解鎖。

對稱金鑰加密法可以分為傳統加密法和現代加密法。傳統加密法是簡單的、面向字元的加密法，基於今天的標準並不安全。另一方面，現代加密法是複雜的、面向位元的加密法，更加安全。我們簡要討論傳統加密法，為討論更複雜的現代加密法鋪路。

**傳統對稱金鑰加密法**
傳統加密法屬於過去。然而，我們在這裡簡要討論它們，因為它們可以被認為是現代加密法的組成部分。更確切地說，我們可以將傳統加密法分為替換加密法和換位加密法。

**替換加密法 (Substitution ciphers)**
**替換加密法**用一個符號替換另一個符號。如果明文中的符號是字母字元，我們用另一個字元替換一個字元。例如，我們可以用字母 D 替換字母 A，用字母 Z 替換字母 T。如果符號是數字（0 到 9），我們可以用 7 替換 3，用 6 替換 2。
替換加密法可以歸類為單字母加密法或多字母加密法。

**單字母加密法 (Monoalphabetic ciphers)**
在**單字母加密法**中，明文中的一個字元（或符號）總是變更為密文中的同一個字元（或符號），無論其在文本中的位置如何。例如，如果演算法說明文中的字母 A 變更為字母 D，那麼每個字母 A 都會變更為字母 D。換句話說，明文和密文中的字母之間的關係是一對一的。
最簡單的單字母加密法是**加法加密法**（或**移位加密法**）。假設明文由小寫字母（a 到 z）組成，密文由大寫字母（A 到 Z）組成。為了能夠對明文和密文應用數學運算，我們為每個字母（小寫或大寫）分配數值。
加密演算法將金鑰加到明文字元上；解密演算法從密文字元中減去金鑰。所有操作都在模 26 中完成。
歷史上，加法加密法被稱為移位加密法，因為加密演算法可以解釋為「將金鑰字元向下移位」，加密演算法可以解釋為「將金鑰字元向上移位」。朱利葉斯·凱撒使用加法加密法，金鑰為 3，與他的軍官通訊。因此，加法加密法有時被稱為**凱撒密碼**。

**多字母加密法 (Polyalphabetic ciphers)**
在**多字母加密法**中，每個出現的字元可能有不同的替換。明文字元與密文字元的關係是一對多的。例如，'a' 在文本開頭可能被加密為 'D'，但在中間可能被加密為 'N'。多字母加密法的優點是隱藏了底層語言的字母頻率。Eve 無法使用單字母頻率統計來破解密文。
為了創建多字母加密法，我們需要使每個密文字元同時依賴於相應的明文字元和明文字元在訊息中的位置。

**換位加密法 (Transposition ciphers)**
**換位加密法**不替換一個符號為另一個符號；相反，它改變符號的位置。明文第一個位置的符號可能出現在密文的第十個位置。明文第八個位置的符號可能出現在密文的第一個位置。換句話說，換位加密法重新排序（換位）符號。

**串流和區塊加密法**
文獻將對稱加密法分為兩大類：串流加密法和區塊加密法。

**串流加密法 (Stream cipher)**
在**串流加密法**中，加密和解密是一次一個符號（如字元或位元）進行的。我們有明文串流、密文串流和金鑰串流。

**區塊加密法 (Block ciphers)**
在**區塊加密法**中，大小為 $m$ ($m > 1$) 的一組明文符號被一起加密，創建相同大小的一組密文。根據定義，在區塊加密法中，單個金鑰用於加密整個區塊，即使金鑰由多個值組成。在區塊加密法中，密文區塊取決於整個明文區塊。

**現代對稱金鑰加密法**
我們到目前為止學習的傳統對稱金鑰加密法是面向字元的加密法。隨著電腦的出現，我們需要面向位元的加密法。這是因為要加密的資訊不僅僅是文字；它還可以由數字、圖形、音訊和視訊資料組成。將這些類型的資料轉換為位元流，加密該流，然後發送加密流是很方便的。

**現代區塊加密法**
對稱金鑰*現代區塊加密法*加密 $n$ 位元明文區塊或解密 $n$ 位元密文區塊。加密或解密演算法使用 $k$ 位元金鑰。解密演算法必須是加密演算法的逆運算，並且兩個操作必須使用相同的秘密金鑰，以便 Bob 可以檢索 Alice 發送的訊息。

**現代串流加密法**
除了現代區塊加密法，我們還可以使用現代串流加密法。在現代串流加密法中，加密和解密是一次 $r$ 位元進行的。串流加密法比區塊加密法快。串流加密法的硬體實作也更容易。當我們需要加密二進位串流並以恆定速率傳輸它們時，串流加密法是更好的選擇。
最簡單和最安全的同步串流加密法類型稱為**一次性密碼本 (one-time pad)**，由 Gilbert Vernam 發明並獲得專利。一次性密碼本加密法使用為每次加密隨機選擇的金鑰流。加密和解密演算法各使用單個互斥或 (XOR) 運算。一次性密碼本是一種理想的加密法。它是完美的。對手無法猜測金鑰或明文和密文的統計數據。然而，這裡有一個問題。發送者和接收者如何能在每次想要通訊時分享一個一次性密碼本金鑰？

### 16.2.2 非對稱金鑰加密法
在前幾節中，我們討論了對稱金鑰加密法。在本節中，我們開始討論**非對稱金鑰加密法**。對稱和非對稱金鑰加密法將並行存在並繼續服務社群。我們實際上認為它們是互補的；一種的優點可以彌補另一種的缺點。

這兩個系統之間的概念差異在於這些系統如何保守秘密。在對稱金鑰密碼學中，秘密必須在兩個人之間共享。在非對稱金鑰密碼學中，秘密是個人的（不共享）；每個人創建並保存自己的秘密。

**對稱金鑰密碼學基於共享秘密；非對稱金鑰密碼學基於個人秘密。**

除了加密之外，還有其他一些安全性方面需要非對稱金鑰密碼學。這些包括驗證和數位簽章。每當應用程式基於個人秘密時，我們就需要使用非對稱金鑰密碼學。

雖然對稱金鑰密碼學基於符號（字元或位元）的替換和排列，但非對稱金鑰密碼學基於對數字應用數學函數。在非對稱金鑰密碼學中，明文和密文是數字；加密和解密是應用於數字以創建其他數字的數學函數。

**在對稱金鑰密碼學中，符號被排列或替換；在非對稱金鑰密碼學中，數字被操作。**

非對稱金鑰密碼學使用兩個獨立的金鑰：一個私鑰和一個公鑰。如果將加密和解密視為用鑰匙鎖定和解鎖掛鎖，那麼用公鑰鎖定的掛鎖只能用相應的私鑰解鎖。

**非對稱金鑰加密法有時稱為公開金鑰加密法。**

**基本概念**
提供安全性的負擔主要在接收者（在本例中為 Bob）肩上。Bob 需要創建兩個金鑰：一個私鑰和一個公鑰。Bob 負責將公鑰分發給社群。
其次，非對稱金鑰密碼學意味著 Bob 和 Alice 不能使用同一組金鑰進行雙向通訊。社群中的每個實體都應創建自己的私鑰和公鑰。
第三，非對稱金鑰密碼學意味著 Bob 只需要一個私鑰來接收來自社群中任何人的所有信件，但 Alice 需要 $n$ 個公鑰與社群中的 $n$ 個實體通訊，每個實體一個公鑰。換句話說，Alice 需要一串公鑰。

**明文/密文**
與對稱金鑰密碼學不同，非對稱金鑰密碼學中的明文和密文被視為整數。訊息在加密前必須編碼為整數（或一組整數）；整數（或一組整數）在解密後必須解碼為訊息。非對稱金鑰密碼學通常用於加密或解密小塊資訊，例如對稱金鑰密碼學的密碼金鑰。

**非對稱金鑰密碼學通常用於加密或解密小塊資訊。**

**RSA 密碼系統**
雖然有幾種非對稱金鑰密碼系統，但常見的公開金鑰演算法之一是 **RSA 密碼系統**，以其發明者（Rivest、Shamir 和 Adleman）命名。RSA 使用兩個指數，$e$ 和 $d$，其中 $e$ 是公開的，$d$ 是私有的。假設 $P$ 是明文，$C$ 是密文。Alice 使用 $C = P^e \\pmod n$ 從明文 $P$ 創建密文 $C$；Bob 使用 $P = C^d \\pmod n$ 檢索 Alice 發送的明文。模數 $n$ 是一個非常大的數字，在金鑰生成過程中創建。

Bob 選擇兩個大數 $p$ 和 $q$，並計算 $n = p \\times q$ 和 $\\phi = (p - 1) \\times (q - 1)$。然後 Bob 選擇 $e$ 和 $d$，使得 $(e \\times d) \\pmod \\phi = 1$。Bob 向社群公佈 $e$ 和 $n$ 作為公鑰；Bob 保留 $d$ 作為私鑰。任何人，包括 Alice，都可以加密訊息並將密文發送給 Bob，使用 $C = P^e \\pmod n$；只有 Bob 可以解密訊息，使用 $P = C^d \\pmod n$。入侵者如 Eve 如果 $p$ 和 $q$ 是非常大的數字，則無法解密訊息（她不知道 $d$）。

雖然 RSA 可用於加密和解密實際訊息，但如果訊息很長，它會非常慢。因此，RSA 適用於短訊息。特別是，我們將看到 RSA 用於數位簽章和其他經常需要加密小訊息而無需存取對稱金鑰的密碼系統。

## 16.3 安全性的其他方面
我們到目前為止學習的密碼學系統提供了機密性。然而，在現代通訊中，我們需要關注安全性的其他方面，如完整性、訊息和實體驗證、不可否認性和金鑰管理。我們在本節簡要討論這些問題。

### 16.3.1 訊息完整性
有些場合我們甚至可能不需要保密，但必須有完整性：訊息應保持不變。

**訊息與訊息摘要**
保持文件完整性的一種方法是使用**指紋**。文件和指紋對的電子等價物是訊息和摘要對。為了保持訊息的完整性，訊息通過稱為**密碼雜湊函數**的演算法。該函數創建訊息的壓縮影像，稱為**摘要**，可以像指紋一樣使用。為了檢查訊息或文件的完整性，Bob 再次運行密碼雜湊函數，並將新摘要與前一個摘要進行比較。如果兩者相同，Bob 確信原始訊息未被更改。

**訊息摘要需要防止更改。**

**雜湊函數**
密碼雜湊函數獲取任意長度的訊息並創建固定長度的訊息摘要。所有密碼雜湊函數都需要從可變大小的訊息中創建固定大小的摘要。創建這樣的函數最好使用迭代來完成。不是使用具有可變大小輸入的雜湊函數，而是創建一個具有固定大小輸入的函數，並使用必要的次數。固定大小輸入函數稱為壓縮函數。它壓縮 $n$ 位元字串以創建 $m$ 位元字串，其中 $n$ 通常大於 $m$。該方案稱為*迭代密碼雜湊函數*。
Ron Rivest 設計了幾種雜湊演算法。這些被稱為 **MD2**、**MD4** 和 **MD5**，其中 MD 代表**訊息摘要**。最後一個版本 MD5 是 MD4 的增強版本，它將訊息分為 512 位元的區塊並創建 128 位元的摘要。然而，事實證明，128 位元的訊息摘要太小，無法抵禦攻擊。
為了應對 MD 雜湊演算法的不安全性，發明了安全雜湊演算法。**安全雜湊演算法 (SHA)** 是由美國國家標準技術研究所 (NIST) 開發的標準。SHA 已經歷了幾個版本。

### 16.3.2 訊息驗證
摘要可用於檢查訊息的完整性——訊息未被更改。為了確保訊息的完整性和資料來源驗證——Alice 是訊息的發起者，而不是其他人——我們需要在過程中包含 Alice 和 Bob 共享的秘密（Eve 不擁有）；我們需要創建一個**訊息驗證碼 (MAC)**。

Alice 使用雜湊函數從金鑰和訊息的串聯 $h(K + M)$ 中創建 MAC。她透過不安全的通道將訊息和 MAC 發送給 Bob。Bob 將訊息與 MAC 分開。然後他從訊息和秘密金鑰的串聯中創建一個新的 MAC。然後 Bob 將新創建的 MAC 與接收到的 MAC 進行比較。如果兩個 MAC 匹配，則訊息是真實的，並且未被對手修改。

**MAC 使用雜湊函數和秘密金鑰的組合提供訊息完整性和訊息驗證。**

### 16.3.3 數位簽章
提供訊息完整性和訊息驗證（以及我們稍後將看到的一些更多安全性服務）的另一種方法是數位簽章。MAC 使用秘密金鑰保護摘要；數位簽章使用一對私鑰-公鑰。

**數位簽章使用一對私鑰-公鑰。**

當 Alice 發送訊息給 Bob 時，Bob 需要檢查發送者的真實性；他需要確定訊息來自 Alice 而不是 Eve。Bob 可以要求 Alice 以電子方式簽署訊息。換句話說，電子簽章可以證明 Alice 作為訊息發送者的真實性。我們將這種類型的簽章稱為**數位簽章**。

**比較**
- **包含**：傳統簽章包含在文件中；它是文件的一部分。但是當我們以數位方式簽署文件時，我們會將簽章作為單獨的文件發送。
- **驗證方法**：對於傳統簽章，當接收者收到文件時，他們會將文件上的簽章與檔案中的簽章進行比較。對於數位簽章，接收者收到訊息和簽章。接收者需要對訊息和簽章的組合應用驗證技術來驗證真實性。
- **關係**：對於傳統簽章，簽章和文件之間通常是一對多的關係。對於數位簽章，簽章和訊息之間是一對一的關係。每條訊息都有自己的簽章。
- **複製性**：兩種類型簽章之間的另一個區別是一種稱為*複製性*的品質。對於傳統簽章，簽署文件的副本可以與檔案中的原始文件區分開來。對於數位簽章，除非文件上有時間因素（如時間戳），否則沒有這種區別。

**過程**
發送者使用**簽署演算法**簽署訊息。訊息和簽章發送給接收者。接收者接收訊息和簽章，並將**驗證演算法**應用於組合。如果結果為真，則接受訊息；否則，拒絕訊息。

在數位簽章中，簽署者使用她的**私鑰**，應用於簽署演算法，來簽署文件。另一方面，驗證者使用簽署者的**公鑰**，應用於驗證演算法，來驗證文件。

**數位簽章需要公開金鑰系統。簽署者用她的私鑰簽署；驗證者用簽署者的公鑰驗證。**

**密碼系統使用接收者的私鑰和公鑰；數位簽章使用發送者的私鑰和公鑰。**

**簽署摘要**
非對稱金鑰密碼系統在處理長訊息時效率很低。在數位簽章系統中，訊息通常很長，但我們必須使用非對稱金鑰方案。解決方案是簽署訊息的摘要，它比訊息短得多。精心選擇的訊息摘要與訊息具有一對一的關係。發送者可以簽署訊息摘要，接收者可以驗證訊息摘要。效果是一樣的。

**服務**
- **訊息驗證**：安全的數位簽章方案可以提供訊息驗證（也稱為資料來源驗證）。Bob 可以驗證訊息是由 Alice 發送的，因為驗證中使用了 Alice 的公鑰。Alice 的公鑰無法驗證由 Eve 的私鑰簽署的簽章。
- **訊息完整性**：如果我們簽署訊息或訊息摘要，則訊息的完整性得以保留，因為如果訊息的任何部分發生更改，我們無法獲得相同的摘要。
- **不可否認性**：如果 Alice 簽署了一條訊息然後否認它，Bob 可以證明 Alice 確實簽署了它。一種解決方案是受信任的第三方。人們可以在他們之間建立一個受信任的第三方。

**機密性**
數位簽章不提供機密通訊。如果需要機密性，訊息和簽章必須使用對稱金鑰或非對稱金鑰加密法進行加密。

### 16.3.4 實體驗證
**實體驗證**是一種旨在讓一方驗證另一方身份的技術。**實體**可以是人、行程、客戶端或伺服器。需要證明其身份的實體稱為**索賠人**；試圖驗證索賠人身份的一方稱為**驗證者**。

**實體與訊息驗證**
1.  訊息驗證（或資料來源驗證）可能不會即時發生；實體驗證會。在前一種情況下，Alice 發送訊息給 Bob。當 Bob 驗證訊息時，Alice 可能在也可能不在通訊過程中。另一方面，當 Alice 請求實體驗證時，在 Alice 被 Bob 驗證之前不涉及真正的訊息通訊。Alice 需要在線並參與該過程。
2.  訊息驗證只是驗證一條訊息；對於每條新訊息都需要重複該過程。實體驗證在整個會話期間驗證索賠人。

**驗證類別**
在實體驗證中，索賠人必須向驗證者表明自己的身份。這可以透過三種證人之一來完成：知道的東西、擁有的東西或固有的東西。
- **知道的東西**：這是只有索賠人知道的秘密，可以由驗證者檢查。例子有密碼、PIN、秘密金鑰和私鑰。
- **擁有的東西**：這是可以證明索賠人身份的東西。例子有護照、駕駛執照、身份證、信用卡和智慧卡。
- **固有的東西**：這是索賠人的固有特徵。例子有傳統簽名、指紋、聲音、面部特徵、視網膜模式和筆跡。

**密碼**
最簡單和最古老的實體驗證方法是使用**密碼**，這是索賠人*知道*的東西。當使用者需要存取系統資源（登入）時使用密碼。每個使用者都有一個公開的使用者標識和一個私有的密碼。然而，密碼很容易受到攻擊。

**挑戰–回應**
在密碼驗證中，索賠人透過證明她知道一個秘密（密碼）來證明她的身份。然而，因為索賠人發送了這個秘密，它很容易被對手攔截。在**挑戰–回應驗證**中，索賠人證明她*知道*一個秘密，而不將其發送給驗證者。換句話說，索賠人不向驗證者發送秘密；驗證者要麼有它，要麼能找到它。

**在挑戰–回應驗證中，索賠人證明她知道一個秘密，而不將其發送給驗證者。**

**挑戰**是一個隨時間變化的值，如隨機數或時間戳，由驗證者發送。索賠人對挑戰應用一個函數並將結果（稱為**回應**）發送給驗證者。回應顯示索賠人知道秘密。

**使用對稱金鑰加密法**
幾種挑戰–回應驗證方法使用**對稱金鑰加密**。這裡的秘密是共享秘密金鑰，由索賠人和驗證者都知道。函數是應用於挑戰的加密演算法。

**使用非對稱金鑰加密法**
代替對稱金鑰加密法，我們可以使用非對稱金鑰加密法進行實體驗證。這裡的秘密必須是索賠人的私鑰。索賠人必須證明她擁有與每個人都可用的公鑰相關的私鑰。

**使用數位簽章**
實體驗證也可以使用數位簽章來實現。當數位簽章用於實體驗證時，索賠人使用她的私鑰進行簽署。

### 16.3.5 金鑰管理
我們在前幾節中討論了對稱金鑰和非對稱金鑰密碼學。然而，我們尚未討論對稱金鑰密碼學中的秘密金鑰和非對稱金鑰密碼學中的公鑰是如何分發和維護的。本節觸及這兩個問題。

**對稱金鑰分發**
對稱金鑰密碼學在加密長訊息方面比非對稱金鑰密碼學更有效率。然而，對稱金鑰密碼學需要雙方之間有共享的秘密金鑰。
如果 Alice 需要與 $N$ 個人交換機密訊息，她需要 $N$ 個不同的金鑰。如果 $N$ 個人需要相互通訊怎麼辦？總共需要 $N(N - 1)/2$ 個金鑰。這通常被稱為 $N^2$ 問題，因為 $N$ 個實體所需的金鑰數量接近 $N^2$。
金鑰數量不是唯一的問題；金鑰的分發是另一個問題。使用網際網路絕對不是一種安全的方法。

**金鑰分發中心：KDC**
一個實際的解決方案是使用受信任的第三方，稱為**金鑰分發中心 (KDC)**。為了減少金鑰數量，每個人都與 KDC 建立一個共享秘密金鑰。在 KDC 和每個成員之間建立秘密金鑰。現在的問題是 Alice 如何向 Bob 發送機密訊息。
1.  Alice 向 KDC 發送請求，說明她需要一個她和 Bob 之間的會話（臨時）秘密金鑰。
2.  KDC 通知 Bob 關於 Alice 的請求。
3.  如果 Bob 同意，則在兩者之間創建一個會話金鑰。
與 KDC 建立的 Alice 和 Bob 之間的秘密金鑰用於向 KDC 驗證 Alice 和 Bob，並防止 Eve 冒充他們中的任何一個。

**會話金鑰**
KDC 為每個成員創建一個秘密金鑰。此秘密金鑰只能在成員和 KDC 之間使用，不能在兩個成員之間使用。如果 Alice 需要與 Bob 秘密通訊，她需要一個她和 Bob 之間的秘密金鑰。KDC 可以使用 Alice 和 Bob 與中心的金鑰創建一個 Alice 和 Bob 之間的**會話金鑰**。Alice 和 Bob 的金鑰用於在建立會話金鑰之前向中心和彼此驗證 Alice 和 Bob。通訊終止後，會話金鑰不再有用。

**兩方之間的會話對稱金鑰僅使用一次。**

**公開金鑰分發**
在非對稱金鑰密碼學中，人們不需要知道對稱共享金鑰。如果 Alice 想要發送訊息給 Bob，她只需要知道 Bob 的公鑰，該公鑰對公眾開放且每個人都可用。在公開金鑰密碼學中，每個人都保護私鑰並公佈公鑰。

**在公開金鑰密碼學中，每個人都可以存取每個人的公鑰；公鑰對公眾可用。**

**公開公告**
天真的方法是公開宣佈公鑰。Bob 可以將他的公鑰放在他的網站上，或在當地或國家報紙上宣佈。然而，這種方法並不安全；它容易被偽造。例如，Eve 可以發布這樣的公開公告。Eve 可以愚弄 Alice 向她發送打算給 Bob 的訊息。

**憑證頒發機構**
分發公鑰的常見方法是創建**公鑰憑證**。Bob 想要兩件事；他希望人們知道他的公鑰，並且他不希望任何人接受偽造的公鑰作為他的。Bob 可以去**憑證頒發機構 (CA)**，這是一個將公鑰綁定到實體並頒發憑證的聯邦或州組織。
CA 本身有一個無法偽造的知名公鑰。CA 檢查 Bob 的身份。然後它要求 Bob 的公鑰並將其寫在憑證上。為了防止憑證本身被偽造，CA 用其私鑰簽署憑證。現在 Bob 可以上傳簽署的憑證。任何想要 Bob 公鑰的人都可以下載簽署的憑證，並使用頒發機構的公鑰提取 Bob 的公鑰。

**X.509**
雖然使用 CA 解決了公鑰欺詐的問題，但它產生了一個**副作用**。每個憑證可能有不同的格式。任何需要普遍使用的東西都必須有通用格式。為了消除這種副作用，ITU 設計了 **X.509**，這是一個已被網際網路接受並進行了一些更改的建議。X.509 是一種以結構化方式描述憑證的方法。它使用一個稱為 ASN.1 的知名協定，定義了電腦程式設計師熟悉的欄位。

## 16.4 防火牆
所有先前的安全措施都無法防止 Eve 向系統發送有害訊息。為了控制對系統的存取，我們需要防火牆。**防火牆**是安裝在組織內部網路和網際網路其餘部分之間的設備（通常是路由器或電腦）。它旨在轉發某些封包並過濾（不轉發）其他封包。

例如，防火牆可能會過濾所有發往特定主機或特定伺服器（如 HTTP）的傳入封包。防火牆可用於拒絕對組織中特定主機或特定服務的存取。防火牆通常分為*封包過濾防火牆*或*基於代理的防火牆*。

### 16.4.1 封包過濾防火牆
防火牆可以用作封包過濾器。它可以根據網路層和傳輸層標頭中的資訊轉發或阻止封包：來源和目的 IP 位址、來源和目的**埠位址**以及協定類型（TCP 或 UDP）。**封包過濾防火牆**是一個使用過濾表來決定必須丟棄（不轉發）哪些封包的路由器。

### 16.4.2 代理防火牆
封包過濾防火牆基於網路層和傳輸層標頭（IP 和 TCP/UDP）中可用的資訊。然而，有時我們需要根據訊息本身（在應用層）可用的資訊來過濾訊息。例如，假設一個組織想要實施關於其網頁的以下政策：只有那些以前與公司建立業務關係的網際網路使用者才能存取；必須阻止其他使用者的存取。在這種情況下，封包過濾防火牆是不可行的，因為它無法區分到達 TCP 埠 80 (HTTP) 的不同封包。測試必須在應用層級（使用 URL）完成。

一種解決方案是安裝一台代理電腦（有時稱為**應用閘道器**），它位於客戶電腦和公司電腦之間。當使用者客戶端行程發送訊息時，應用閘道器運行伺服器行程來接收請求。伺服器在應用層打開封包並查明請求是否合法。如果是，伺服器充當客戶端行程並將訊息發送到公司的真實伺服器。如果不是，訊息將被丟棄，並向外部使用者發送錯誤訊息。透過這種方式，外部使用者的請求會根據應用層的內容進行過濾。

## 16.5 章末材料
### 16.5.2 關鍵詞
- 加法加密法
- 應用閘道器
- 非對稱金鑰加密法
- 自動金鑰加密法
- 可用性
- 區塊加密法
- 凱撒密碼
- 憑證頒發機構 (CA)
- 挑戰–回應驗證
- 加密法
- 密文
- 機密性
- 密碼雜湊函數
- 密碼學
- 解密
- 解密演算法
- 阻斷服務 (DoS)
- 摘要
- 數位簽章
- 加密
- 加密演算法
- 防火牆
- 雜湊 MAC (HMAC)
- 完整性
- 金鑰
- 金鑰分發中心 (KDC)
- 偽裝
- 訊息驗證碼 (MAC)
- 訊息摘要 (MD)
- 單字母加密法
- 一次性密碼本
- 封包過濾防火牆
- 明文
- 多字母加密法
- 埠位址
- 私鑰
- 代理防火牆
- 公鑰
- 公鑰憑證
- 重放
- RSA 密碼系統
- 秘密金鑰
- 安全雜湊演算法 (SHA)
- 安全性攻擊
- 安全性目標
- 移位加密法
- 副作用
- 窺探
- 欺騙
- 隱寫術
- 串流加密法
- 替換加密法
- 對稱金鑰加密法
- 對稱金鑰加密
- 票據
- 流量分析
- 換位加密法
- 驗證演算法
- X.509

### 16.5.3 摘要
- 資料壓縮方法要麼是無損的（所有資訊都可恢復），要麼是失真的（丟失一些資訊）。
- 在無損壓縮方法中，接收到的資料是發送資料的精確複本。三種無損壓縮方法是連長編碼、霍夫曼編碼和 Lempel Ziv (LZ) 編碼。
- 在連長編碼中，重複出現的符號被符號和符號出現的次數所取代。
- 在霍夫曼編碼中，代碼長度是符號頻率的函數：較頻繁的符號比較不頻繁的符號具有更短的代碼。
- 在 LZ 編碼中，重複的字串或單詞儲存在記憶體位置中。記憶體位置的索引替換字串或單詞。LZ 編碼要求發送者和接收者都有字典和演算法。
- 在失真壓縮方法中，接收到的資料不必是發送資料的精確複本。本章討論了三種失真壓縮方法：JPEG、MPEG 和 MP3。
- JPEG (聯合圖像專家小組) 壓縮是一種壓縮圖片和圖形的方法。JPEG 過程涉及分塊、離散餘弦變換、量化和無損壓縮。
- MPEG (動態影像專家小組) 壓縮是一種壓縮視訊的方法。MPEG 涉及空間壓縮和時間壓縮。前者類似於 JPEG，而後者移除了冗餘影格。
- MP3 (MPEG 音訊層 3) 是 MPEG 標準的一部分。MP3 使用感知編碼技術來壓縮 CD 品質的音訊。
`},y={en:`
# Chapter 17: Theory of Computation

In Chapters 1 through 16, we considered a computer as a problem-solving machine. In this chapter, we answer some questions such as: which problems can be solved by a computer? Is one language superior to another? Before running a program, can it be determined whether the program will halt (terminate) or run forever? How long does it take to solve a problem using a particular language? To answer these questions, we turn to a discipline called the theory of computation.

## Objectives
After studying this chapter, the student should be able to:
- Describe a programming language we call Simple Language and define its basic statements.
- Write macros in Simple Language using the combination of simple statements.
- Describe the components of a Turing machine as a computation model.
- Show how simple statements in Simple Language can be simulated using a Turing machine.
- Understand the Church–Turing thesis and its implication.
- Define the Gödel number and its application.
- Understand the concept of the halting problem and how it can be proved that this problem is unsolvable.
- Distinguish between solvable and unsolvable problems.
- Distinguish between polynomial and nonpolynomial solvable problems.

## 17.1 SIMPLE LANGUAGE
We can define a computer language with only three statements: the **increment statement**, the **decrement statement**, and the **loop statement** (Figure 17.1). In this language, the only data type we use is nonnegative integers. There is no need for any other data type, because the goal of the chapter is merely to demonstrate some ideas in computation theory. The language uses only a few symbols such as '{' and '}'.

### 17.1.1 Increment statement
The increment statement adds 1 to a variable. The format is shown in Algorithm 17.1.

**Algorithm 17.1 The increment statement**
\`\`\`text
incr (X)
\`\`\`

### 17.1.2 Decrement statement
The decrement statement subtracts 1 from a variable. The format is shown in Algorithm 17.2.

**Algorithm 17.2 The decrement statement**
\`\`\`text
decr (X)
\`\`\`

### 17.1.3 Loop statement
The loop statement repeats an action (or a series of actions) while the value of the variable is not 0. The format is shown in Algorithm 17.3.

**Algorithm 17.3 The loop statement**
\`\`\`text
while (X)
{
  decr (X)
  Body of the loop
}
\`\`\`

### 17.1.4 The power of the simple language
It can be shown that this simple programming language with only three statements is as powerful—although not necessarily as efficient—as any sophisticated language in use today, such as C. To do so, we show how we can simulate several statements found in some popular languages.

**Macros in Simple Language**
We call each simulation a **macro** and use it in other simulations without the need to repeat code. A *macro* (short for *macroinstruction*) is an instruction in a high-level language that is equivalent to a specific set of one or more ordinary instructions in the same language.

**First macro: X ← 0**
Algorithm 17.4 shows how to use the statements in Simple Language to assign 0 to a variable X. It is sometimes called *clearing* a variable.

**Algorithm 17.4 Macro X ← 0**
\`\`\`text
while (X)
{
  decr (X)
}
\`\`\`

**Second macro: X ← n**
Algorithm 17.5 shows how to use the statements in Simple Language to assign a positive integer $n$ to a variable X. First clear the variable X, then increment X $n$ times.

**Algorithm 17.5 Macro X ← n**
\`\`\`text
X ← 0
incr (X)
incr (X)
...
incr (X)
// The statement incr (X) is repeated n times.
\`\`\`

**Third macro: Y ← X**
Algorithm 17.6 simulates the macro Y ← X in Simple Language. Note that we can use an extra line of code to restore the value of X.

**Algorithm 17.6 Macro Y ← X**
\`\`\`text
Y ← 0
while (X)
{
  decr (X)
  incr (Y)
}
\`\`\`

**Fourth macro: Y ← Y + X**
Algorithm 17.7 simulates the macro Y ← Y + X in Simple Language. Again, we can use more code lines to restore the value of X to its original value.

**Algorithm 17.7 Macro Y ← Y + X**
\`\`\`text
while (X)
{
  decr (X)
  incr (Y)
}
\`\`\`

**Fifth macro: Y ← Y × X**
Algorithm 17.8 simulates the macro Y ← Y × X in Simple Language. We can use the addition macro because integer multiplication can be simulated by repeated addition. Note that we need to preserve the value of X in a temporary variable, because in each addition we need the original value of X to be added to Y.

**Algorithm 17.8 Macro Y ← Y × X**
\`\`\`text
TEMP ← Y
Y ← 0
while (X)
{
  decr (X)
  Y ← Y + TEMP
}
\`\`\`

**Sixth macro: Y ← Y^X**
Algorithm 17.9 simulates the macro Y ← Y^X in Simple Language. We do this using the multiplication macro because integer exponentiation can be simulated by repeated multiplication.

**Algorithm 17.9 Macro Y ← Y^X**
\`\`\`text
TEMP ← Y
Y ← 1
while (X)
{
  decr (X)
  Y ← Y × TEMP
}
\`\`\`

**Seventh macro: if X then A**
Algorithm 17.10 simulates the seventh macro in Simple Language. This macro simulates the decision-making (*if*) statement of modern languages. In this macro, the variable X has only one of the two values 0 or 1. If the value of X is not 0, A (an action or a series of actions) is executed in the loop. However, the loop is executed only once because, after the first iteration, the value of X becomes 0 and we come out of the loop. If the value of X is originally 0, the loop is skipped.

**Algorithm 17.10 Macro if X then A**
\`\`\`text
while (X)
{
  decr (X)
  A
}
\`\`\`

**Other macros**
It is obvious that we need more macros to make Simple Language compatible with contemporary languages. Creating other macros is possible, although not trivial.

**Input and output**
In this simple language the statement *read X* can be simulated using (X ← n). We also simulate the output by assuming that the last variable used in a program holds what should be printed. Remember that this is not a practical language, it is merely designed to prove some theorems in computer science.

## 17.2 THE TURING MACHINE
The **Turing machine** was introduced in 1936 by Alan M. Turing to solve computable problems, and is the foundation of modern computers. In this section we introduce a very simplified version of the machine to show how it works.

### 17.2.1 Turing machine components
A Turing machine is made of three components: a tape, a controller, and a read/write head (Figure 17.2).

**Tape**
Although modern computers use a random-access storage device with finite capacity, we assume that the Turing machine’s memory is infinite. The tape, at any one time, holds a sequence of characters from the set of characters accepted by the machine. For our purpose, we assume that the machine can accept only two symbols: a blank (**b**) and digit **1**. Figure 17.3 shows an example of data on a tape in this machine.

The left-hand blank defines the beginning of the nonnegative integers stored on the tape. The integer is represented by a string of 1s, and the right-hand blank defines the end of the integer. The rest of the tape contains blank characters. If more than one integer are stored on the tape, they are separated by at least one blank character.
We also assume that the tape processes only positive integer data represented in unary arithmetic. In this arithmetic, a positive integer is made up only of 1s. For example, the integer 4 is represented as 1111 (four 1s) and the integer 7 is represented as 1111111 (seven 1s). The absence of 1s represents 0.

**Read/write head**
The **read/write head** at any moment points to one symbol on the tape. We call this symbol the *current* symbol. The read/write head reads and writes one symbol at a time from the tape. After reading and writing, it moves to the left or to the right. Reading, writing, and moving are all done under instructions from the controller.

**Controller**
The **controller** is the theoretical counterpart of the central processing unit (CPU) in modern computers. It is a **finite state automaton**, a machine that has a predetermined finite number of states and moves from one state to another based on the input. At any moment, it can be in one of these states.
Figure 17.4 shows the transition state diagram for a simple controller as a finite state automaton. In this figure, the automaton has only three states (A, B, and C), although a controller normally has many states. The diagram shows the change of state as a function of the character read. The expression on each line, *x/y/L*, *x/y/R*, and *x/y/N*, shows that if the controller has read the symbol *x*, it writes the symbol *y* (overwrites *x*), and the read/write head moves to the left (L), right (R), or does not move (N). Note that since the symbols on the tape can be only a blank or the digit 1, there should be two paths out of each state: one if the blank symbol is read and one if the digit 1 is read. The beginning of the line (called the *transition line*) shows the current state and the end of the line (arrow head) shows the next state.

We can create a transition table (Table 17.1) in which each row relates to one state. The table will have five columns: current state, the symbol that is read, the symbol to write, the direction of movement of the head, and the next symbol. Since the machine can only go through a finite number of states, we can create an instruction set like the one we create for the Simple Computer in Chapter 5.

**Table 17.1 Transition table**
| Current State | Read | Write | Move | New State |
| :--- | :--- | :--- | :--- | :--- |
| A | b | b | R | A |
| A | 1 | 1 | R | B |
| B | b | 1 | R | B |
| B | 1 | b | N | C |
| C | b | b | L | A |
| C | 1 | 1 | L | B |

The instructions put together the value of five columns in each row. For this elementary machine, we have only six instructions:
1. (A, b, b, R, A)
2. (A, 1, 1, R, B)
3. (B, b, 1, R, B)
4. (B, 1, b, N, C)
5. (C, b, b, L, A)
6. (C, 1, 1, L, B)

For example, the first instruction says that if the machine is in state A and has read the symbol b, it overwrites the symbol with a new b, moves to the next symbol to the right, and the machine transitions to state A—that is, remains in the same state.

> **Example 17.1**
> A Turing machine has only two states and the following four instructions:
> 1. (A, b, b, L, A)
> 2. (A, 1, 1, R, B)
> 3. (B, b, b, L, A)
> 4. (B, 1, b, R, A)
> If the machine starts with the configuration shown in Figure 17.5 (Controller state A, pointing to first 1 in sequence 'b 1 1 1 1 b'), what is the configuration of the machine after executing one of the above instructions? Note that the machine can only execute one of the instructions, the one that matches the current state and the current symbol.
>
> **Solution**
> The machine is in state A and the current symbol is 1, which means that only the second instruction, (A, 1, 1, R, B) can be executed. The new configuration is also shown in Figure 17.5. Note that the state of the controller has been changed to B and the read/write head has moved one symbol to the right.

### 17.2.2 Simulating Simple Language
We can now write programs that implement the statements of Simple Language. Note that these statements can be written in many different ways: we have chosen the simplest or most convenient for our educational purpose, but they are not necessarily the best ones.

**Increment statement**
Figure 17.6 shows the Turing machine for the **incr (X)** statement. The controller has four states, S1 through S4. State S1 is the starting state, state S2 is the moving-right state, state S3 is the moving-left state, and state S4 is the halting state. If the machine reaches the halting state, it stops: there is no instruction that starts with this state.

Figure 17.6 also shows the program for the incr (X) statement. It has only five instructions. The process starts from the blank symbol at the left of X (data to be incremented), moves right over all 1s until it reaches the blank symbol at the right of X. It changes this blank to 1. It then moves left over all 1s until it reaches the blank at the left again. At this point it halts. Note that we have also written the program to move the read/write head back to the blank symbol to the left of X, which is necessary if more operations are to be performed on X.

> **Example 17.2**
> Show how the Turing machine can increment X when X = 2.
>
> **Solution**
> Figure 17.7 shows the solution. The value of X (11 in the unary system) is stored between the two blank symbols. It takes seven steps for the machine to increment X and return the read/write head to its original position. Steps 1 to 4 move the read/write head to the end of X. Steps 5 to 7 change the blank at the end and move the read/write head back to where it was before.

**Decrement statement**
We implement the **decr (X)** statement using the minimum number of instructions. The reason is that we need to use this statement in the next statement, the *while* loop, which will also be used to implement all macros. Figure 17.8 shows the Turing machine for this statement. The controller has three states, S1, S2, and S3. Statement S1 is the starting state. State S2 is the checking statement, which checks to see if the current symbol is 1 or b. If it is b, the statement goes to the halting state: if the next symbol is 1, the second statement changes it to b and goes to the halting state. Figure 17.8 also shows the program for this statement.

> **Example 17.3**
> Show how the Turing machine can decrement X when X = 2.
>
> **Solution**
> Figure 17.9 shows the situation. The machine starts at the blank to the left of the data and changes the next symbol to blank if it is 1. The read/write head stops over the blank character to the left of the resulting data. This is the same arrangement as with the increment statement. Note that we could have moved the read/write head to the end of the data and deleted the last 1 instead of the first one, but that program would be much longer than our version. Since we need this statement in every loop statement, we have used the shorter version to save the number of instructions. We use the short version of this statement in the *while* loop statement that we develop next.

**Loop statement**
To simulate the loop, we assume that X and the data to be processed by the body of the loop are stored on the tape separated by a single blank symbol. Figure 17.10 shows the table, the program, and the state transition diagram for a general loop statement.

The three states S1, S2, and S3 control the loops by determining X and exiting the loop if X = 0. Compare these three statements to the three statements used in the decrement statement in Figure 17.8. The state MR moves the read/write head over the blank symbol that defines the start of the data at the beginning of processing data in each iteration, the state ML moves the read/write head over the blank symbol defining the start of the X at the end of processing in each iteration. The state BS (*body start*) defines the beginning state of the body of the loop, while the state BH (*body halt*) defines the halting state for the body of the loop. The body of the loop may have several states between these two states.

Figure 17.10 also shows the repetitive nature of the statement. The state diagram itself is a loop that is repeated as long as the value of X is not zero. When the value of X becomes 0, the loop stops and state S3, the halting state, is reached.

> **Example 17.4**
> Let us show a very simple example. Suppose we want to simulate the fourth macro, Y ← Y + X (page 454). As we discussed before, this macro can be simulated using the while statement in Simple Language:
> \`\`\`text
> while (X)
> {
>   decr (X)
>   incr (Y)
> }
> \`\`\`
> To make the procedure shorter, we assume that X = 2 and Y = 3, so the result is Y = 5. Figure 17.11 shows the state of the tape before and after applying the macro. Note that in this program we erase the value of X to make the process shorter, but the original value of X can be preserved if we allow other symbols on the tape.
> Since X = 2, the program goes through two iterations. At the end of the first iteration, the value of X = 1 and the value of Y = 4. At the end of the second iteration, the value of X = 0 and the value of Y = 5.

### 17.2.3 The Church–Turing thesis
We have shown that a Turing machine can simulate the three basic statements in Simple Language. This means that the Turing machine can also simulate all the macros we defined for Simple Language. Can the Turing machine therefore solve any problem that can be solved by a computer? The answer to this question can be found in the Church–Turing thesis.

**The Church–Turing Thesis**
**If an algorithm exists to do a symbol manipulation task, then a Turing machine exists to do that task.**

Based on this claim, any symbol-manipulation task that can be done by writing an algorithm to do so can also be done by a Turing machine. Note that this is only a *thesis*, not a *theorem*. A theorem can be proved mathematically, a thesis cannot. Although this thesis probably can never be proved, there are strong arguments in its favor. First, no algorithms have been found that cannot be simulated using a Turing machine. Second, it has been proven that all computing models that have been mathematically proved are equivalent to the Turing machine model.

## 17.3 GÖDEL NUMBERS
In theoretical computer science, an unsigned number is assigned to every program that can be written in a specific language. This is usually referred to as the **Gödel number**, named after the Austrian mathematician Kurt Gödel.

This assignment has many advantages. First, programs can be used as a single data item as input to other programs. Second, programs can be referred to by just their integer representations. Third, the numbering can be used to prove that some problems cannot be solved by a computer, by showing that the total number of problems in the world is much larger than the total number of programs that can ever be written.

Different methods have been devised for numbering programs. We use a very simple transformation to number programs written in our Simple Language. Simple Language uses only fifteen symbols (Table 17.2).

**Table 17.2 Code for symbols used in Simple Language**
| Symbol | Hex code | Symbol | Hex code |
| :--- | :--- | :--- | :--- |
| 1 | 1 | 9 | 9 |
| 2 | 2 | incr | A |
| 3 | 3 | decr | B |
| 4 | 4 | while | C |
| 5 | 5 | { | D |
| 6 | 6 | } | E |
| 7 | 7 | X | F |
| 8 | 8 | | |

Note that in this language we use only X, X1, X2, …, X9 as variables. To encode these variables, we handle Xn as two symbols X and n (X3 is X and 3). If we have a macro with other variables, they need to be changed to Xn.

### 17.3.1 Representing a program
Using the table, we can represent any program written in Simple Language by a unique positive integer by following these steps:
1.  Replace each symbol with the corresponding hexadecimal code from the table.
2.  Interpret the resulting hexadecimal number as an unsigned integer.

> **Example 17.5**
> What is the Gödel number for the program \`incr X\`?
>
> **Solution**
> Replace each symbol by its hexadecimal code.
> \`incr X\` → (AF)16 → 175
> So this program can be represented by the number 175.

### 17.3.2 Interpreting a number
To show that the numbering system is unique, use the following steps to interpret a Gödel number:
1.  Convert the number to hexadecimal.
2.  Interpret each **hexadecimal digit** as a symbol using Table 17.2 (ignore a 0).

Note that while any program written in Simple Language can be represented by a number, not every number can be interpreted as a valid program. After conversion, if the symbols do not follow the syntax of the language, the number is not a valid program.

> **Example 17.6**
> Interpret 3058 as a program.
>
> **Solution**
> Change the number to hexadecimal and replace each digit with the corresponding symbol:
> 3058 → (BF2)16 → decr X 2 → decr (X2)
> This means that the equivalent code in Simple Language is \`decr (X2)\`. Note that in Simple Language, each program includes input and output. This means that the combination of a program and its inputs defines the Gödel number.

## 17.4 THE HALTING PROBLEM
Almost every program written in a programming language involves some form of repetition—loops or recursive functions. A repetition construct may never terminate (halt): that is, a program can run forever if it has an infinite loop. For example, the following program in Simple Language never terminates:
\`\`\`text
X → 1
while (X)
{
}
\`\`\`

A classical programming question is:
**Can we write a program that tests whether or not any program, represented by its Gödel number, will terminate?**

The existence of this program would save programmers a lot of time. Running a program without knowing if it halts or not is a tedious job. Unfortunately, it has now been proven that such a program cannot exist—much to the disappointment of programmers!

### 17.4.1 The halting problem is not solvable
Instead of saying that the testing program does not exist and can never exist, the computer scientist says ‘The **halting problem** is not solvable’.

**Proof**
Let us give an informal proof about the nonexistence of this testing program. Our method, called *proof by contradiction*, is often used in mathematics: we assume that the program does exist, then show that its existence creates a contradiction—therefore, it cannot exist. We use three steps to show the proof in this approach.

**Step 1**
In this step, we assume that a program, called Test, exists. It can accept any program such as $P$, represented by its Gödel number, as input, and outputs either 1 or 0. If $P$ terminates, the output of Test is 1: if $P$ does not terminate, the output of Test is 0 (see Figure 17.12).

**Step 2**
In this step, we create another program called Strange that is made of two parts: a copy of Test at the beginning and an empty loop—a loop with an empty body—at the end. The loop uses X as the testing variable, which is actually the output of the Test program. This program also uses $P$ as the input. We call this program Strange for the following reason: if $P$ terminates, the first part of Strange, which is a copy of Test, outputs 1. This 1 is input to the loop. The loop does not terminate—it’s an infinite loop—and consequently Strange does not terminate. If $P$ does not terminate, the first part of Strange, which is a copy of Test, outputs 0. This 0 is input to the loop, so the loop does terminate—it’s now a finite loop, the loop never iterates—and consequently, Strange does terminate. In other words, we have these strange situations:
- If $P$ terminates, Strange does not terminate.
- If $P$ does not terminate, Strange terminates.

**Step 3**
Having written the program Strange, we test it with itself (its Gödel number) as input. This is legitimate because we did not put any restrictions on $P$.
If we assume that Test exists, we have the following contradictions:
- Strange does not terminate if Strange terminates.
- Strange terminates if Strange does not terminate.
This proves that the Test program cannot exist and that we should stop looking for it, so…
**The halting problem is unsolvable.**

The unsolvability of the halting program has proved that many other programs are also unsolvable, because if they are solvable, then the halting problem is solvable—which it is not.

## 17.5 THE COMPLEXITY OF PROBLEMS
Now that we have shown that at least one problem is unsolvable by a computer, we’ll touch on this important issue a bit more. In computer science, we can say that, in general, problems can be divided into two categories: **solvable problems** and **unsolvable problems**. The solvable problems can themselves be divided into two categories: **polynomial** and **nonpolynomial** problems (Figure 17.15).

### 17.5.1 Unsolvable problems
There are an infinite number of problems that cannot be solved by a computer: one is the halting problem. One method to prove that a problem is not solvable is to show that if that problem is solvable, the halting problem is solvable too. In other words, prove that the solvability of a problem results in the solvability of the halting problem.

### 17.5.2 Solvable problems
There are many problems that can be solved by a computer. However, we often want to know how *long* it takes for the computer to solve that problem. In other words, how complex is the program?
The complexity of a program can be measured in several different ways, such as its run time, the memory it needs, and so on. One approach is the program’s run time—how long does the program take to run?

**Complexity of solvable problems**
One way to measure the complexity of a solvable problem is to find the number of operations executed by the computer when it runs the program. In this way, the complexity measure is independent of the speed of the computer that runs the program. This measure of complexity can depend on the number of inputs. For example, if a program is processing a list, such as sorting it, the complexity depends on the number of elements in the list.

**Big-O notation**
With the speed of computers today, we are not as concerned with exact numbers as with general orders of magnitude. For example, if the analysis of two programs shows that one executes 15 operations (or a set of operations) while the other executes 25, they are both so fast that we can’t see the difference. On the other hand, if the numbers are 15 versus 1500, we should be concerned.
This simplification of efficiency is known as **big-O notation**. We present the idea of this notation without delving into its formal definition and calculation. In big-O notation, the number of operations—or a set of related operations—is given as a function of the number of inputs. The notation O(n) means a program does $n$ operations for $n$ inputs, while the notation O($n^2$) means a program does $n^2$ operations for $n$ inputs.

> **Example 17.7**
> Imagine we have written three different programs to solve the same problem. The first one has a complexity of O($\\log_{10} n$), the second O($n$), and the third O($n^2$). Assuming 1 million inputs, how long does it take to execute each of these programs on a computer that executes one instruction in one microsecond, that is, one million instructions per second?
>
> **Solution**
> The following shows the analysis:
> *   1st program: $n = 1000000$, O($\\log_{10} n$) → 6. Time → 6 µs
> *   2nd program: $n = 1000000$, O($n$) → 1000000. Time → 1 sec
> *   3rd program: $n = 1000000$, O($n^2$) → $10^{12}$. Time → 277 hours

**Polynomial problems**
If a program has a complexity of O(log $n$), O($n$), O($n^2$), O($n^3$), O($n^4$), or O($n^k$), where $k$ is a constant, it is called **polynomial**. With the speed of computers today, we can get solutions to **polynomial problems** with a reasonable number of inputs, for example 1000 to 1 million.

**Non polynomial problems**
If a program has a complexity that is greater than a polynomial—for example, O($10^n$) or O($n!$)—it can be solved if the number of inputs is very small, such as fewer than 100. If the number of inputs is large, one could sit in front of the computer for months to see the result of a **nonpolynomial problem**. But who knows? At the rate at which the speed of computers is increasing, we may be able to get a result for this type of problem in less time.

## 17.6 END-CHAPTER MATERIALS
### 17.6.1 Recommended reading
For more details about the subjects discussed in this chapter, the following books are recommended:
- Hennie, F. *Introduction to Computability*, Reading, MA: Addison-Wesley, 1977
- Hofstadter, D. *Gödel, Escher, Bach: An Eternal Golden Braid*, St. Paul, MN: Vintage, 1980
- Hopcroft, J., Motwani, R. and Ullman, J. *Introduction to Automata Theory, Languages, and Computation*, Reading, MA: Addison-Wesley, 2006
- Kfoury, A., Moll, R. and Michael, A. *A Programming Approach to Computability*, New York: Springer, 1982
- Minsky, M. *Computation: Finite and Infinite Machines*, Engelwood Cliffs, NJ: Prentice-Hall, 1967
- Sipser, M. *Introduction to the Theory of Computation*, Boston, MA: Course Technology, 2005

### 17.6.2 Key terms
- big-O notation
- Church–Turing thesis
- controller
- decrement statement
- finite state automaton
- Gödel number
- halting problem
- hexadecimal digit
- increment statement
- loop statement
- macro
- nonpolynomial problem
- polynomial problem
- read/write head
- solvable problem
- Turing machine
- unsolvable problem

### 17.6.3 Summary
- We can define a computer language with only three statements: the increment statement, the decrement statement, and the loop statement. The increment statement adds 1 to a variable, the decrement statement subtracts 1 from a variable, and the loop statement repeats an action or a series of actions while the value of a variable is not 0.
- It can be shown that this simple programming language can simulate several statements found in some popular languages. We call each simulation a macro and use it in other simulations without the need to repeat code.
- The Turing machine was designed to solve computable problems. It is the foundation of modern computers. A Turing machine is made of three components: a tape, a controller, and a read/write head.
- Based on the Church–Turing thesis, if an algorithm to do a symbol manipulation task exists, then a Turing machine to do that task also exists.
- In theoretical computer science, an unsigned number is assigned to every program that can be written in a specific language. This is usually referred to as the Gödel number.
- A classical programming question is whether a program that can determine if another program halts can be constructed. Unfortunately, it has now been proved that this program cannot exist: the halting problem is not solvable.
- In computer science, problems can be divided into two categories: solvable problems and unsolvable problems. The solvable problems can themselves be divided into two categories: polynomial and non polynomial problems.

## 17.7 PRACTICE SET
### 17.7.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 17.7.2 Review questions
1. Name and describe the functions of the three basic statements that are the foundation of other statements in Simple Language.
2. Show how assigning the value of one variable to another uses the three basic statements.
3. What is the relationship between the Turing machine and our Simple Language?
4. What are the components of the Turing machine and what is the function of each component?
5. Describe one way to delimit the data on a Turing machine’s tape.
6. When a read/write head in a Turing machine finishes reading and writing a symbol, what are its next options?
7. How is a transition state diagram related to a Turing machine controller?
8. How is a transition state diagram related to a transition table? Do they have the same information? Which has more information?
9. What is a Gödel number? How do we use a Gödel number to prove that the halting problem is not solvable?
10. Compare and contrast the complexity of a polynomial solvable problem and a non polynomial solvable problem.

### 17.7.3 Problems
1. Rewrite Algorithm 17.6 (Y ← X) so that it preserves the value of X.
2. Rewrite Algorithm 17.7 so that it calculates Z ← Y + X while preserving the values of X and Y.
3. Rewrite Algorithm 17.8 so that it calculates Z ← Y × X while preserving the values of X and Y.
4. Rewrite Algorithm 17.9 so that it calculates Z ← Y^X while preserving the values of X and Y.
5. Simulate the following macro using the previously defined statements or macros in Simple Language: Y ← Y - X.
6. Simulate the following macro using the previously defined statements or macros in the Language (X can be only 0 or 1):
   \`\`\`text
   if (X) then
   {
     A1
   }
   else
   {
     A2
   }
   \`\`\`
7. Given a Turing machine with a single instruction (A, 1, b, R, B) and the tape configuration:
   ... b 1 1 1 b ...
   (pointing to first 1)
   show the final configuration of the tape.
8. Given a Turing machine with a single instruction (A, b, b, R, B) and the tape configuration:
   ... b 1 1 1 b ...
   (pointing to first b)
   show the final configuration of the tape.
9. Given a Turing machine with five instructions (A, b, b, R, B), (B, 1, #, R, B), (B, b, b, L, C), (C, #, 1, L, C), (C, b, b, R, B) and the tape configuration:
   ... b 1 1 1 b ...
   (pointing to first b)
   show the final configuration of the tape.
10. Show the state diagram of a Turing machine that increments a nonnegative integer represented in the binary system. For example, if the contents of the tape is $(101)_2$, it will be changed to $(110)_2$.
11. Show that the simulation of incr (X) in the Turing machine, as defined in this chapter, gives the correct answer when X = 0.
12. Show that the simulation of decr (X) in the Turing machine, as defined in this chapter, gives the correct answer when X = 0.
13. Show how the simulation of a loop statement in the Turing machine, as defined in this chapter, can be changed to preserve the original value of X if we allow another symbol such as # to be used by the machine.
14. Give the transition states and the program for the Turing machine that simulates the macro X ← 0.
15. Give the transition states and the program for the Turing machine that simulates the macro Y ← X.
16. A Turing machine uses a single 1 to represent the integer 0. Show how the integer n can be represented in this machine.
17. What is the Gödel number for the macro X1 ← 0?
18. What is the Gödel number for the macro X2 ← 2?
19. What is the Gödel number for the macro X3 ← X1 + X2?
`,zh:`
# 第十七章：計算理論

在第 1 章到第 16 章中，我們將電腦視為一種解決問題的機器。在本章中，我們將回答一些問題，例如：哪些問題可以由電腦解決？一種語言是否優於另一種語言？在運行程式之前，能否確定程式是會停止（終止）還是永遠運行？使用特定語言解決問題需要多長時間？為了回答這些問題，我們轉向一個稱為計算理論的學科。

## 學習目標
學完本章後，學生應能：
- 描述我們稱為「簡單語言」的程式語言並定義其基本陳述式。
- 使用簡單陳述式的組合在簡單語言中編寫巨集。
- 描述圖靈機作為計算模型的組件。
- 展示如何使用圖靈機模擬簡單語言中的簡單陳述式。
- 理解邱奇-圖靈論題及其意涵。
- 定義哥德爾數及其應用。
- 理解停機問題的概念以及如何證明該問題是不可解的。
- 區分可解和不可解問題。
- 區分多項式和非多項式可解問題。

## 17.1 簡單語言
我們可以定義一種只有三個陳述式的電腦語言：**遞增陳述式**、**遞減陳述式**和**迴圈陳述式**（圖 17.1）。在這種語言中，我們使用的唯一資料類型是非負整數。不需要任何其他資料類型，因為本章的目的僅僅是演示計算理論中的一些想法。該語言僅使用少數符號，如 '{' 和 '}'。

### 17.1.1 遞增陳述式
遞增陳述式將變數加 1。格式如演算法 17.1 所示。

**演算法 17.1 遞增陳述式**
\`\`\`text
incr (X)
\`\`\`

### 17.1.2 遞減陳述式
遞減陳述式從變數中減去 1。格式如演算法 17.2 所示。

**演算法 17.2 遞減陳述式**
\`\`\`text
decr (X)
\`\`\`

### 17.1.3 迴圈陳述式
當變數的值不為 0 時，迴圈陳述式重複一個動作（或一系列動作）。格式如演算法 17.3 所示。

**演算法 17.3 迴圈陳述式**
\`\`\`text
while (X)
{
  decr (X)
  Body of the loop
}
\`\`\`

### 17.1.4 簡單語言的威力
可以證明，這種只有三個陳述式的簡單程式語言與當今使用的任何複雜語言（如 C）一樣強大——儘管不一定那麼有效率。為此，我們展示如何模擬一些流行語言中的陳述式。

**簡單語言中的巨集**
我們稱每個模擬為**巨集**，並在其他模擬中使用它，而無需重複代碼。*巨集*（*巨集指令*的縮寫）是高階語言中的一條指令，相當於同一語言中一組特定的一個或多個普通指令。

**第一個巨集：X ← 0**
演算法 17.4 顯示如何使用簡單語言中的陳述式將 0 賦值給變數 X。這有時稱為*清除*變數。

**演算法 17.4 巨集 X ← 0**
\`\`\`text
while (X)
{
  decr (X)
}
\`\`\`

**第二個巨集：X ← n**
演算法 17.5 顯示如何使用簡單語言中的陳述式將正整數 $n$ 賦值給變數 X。首先清除變數 X，然後將 X 遞增 $n$ 次。

**演算法 17.5 巨集 X ← n**
\`\`\`text
X ← 0
incr (X)
incr (X)
...
incr (X)
// 陳述式 incr (X) 重複 n 次。
\`\`\`

**第三個巨集：Y ← X**
演算法 17.6 模擬簡單語言中的巨集 Y ← X。請注意，我們可以使用額外的代碼行將 X 的值恢復為其原始值。

**演算法 17.6 巨集 Y ← X**
\`\`\`text
Y ← 0
while (X)
{
  decr (X)
  incr (Y)
}
\`\`\`

**第四個巨集：Y ← Y + X**
演算法 17.7 模擬簡單語言中的巨集 Y ← Y + X。同樣，我們可以使用更多的代碼行將 X 的值恢復為其原始值。

**演算法 17.7 巨集 Y ← Y + X**
\`\`\`text
while (X)
{
  decr (X)
  incr (Y)
}
\`\`\`

**第五個巨集：Y ← Y × X**
演算法 17.8 模擬簡單語言中的巨集 Y ← Y × X。我們可以使用加法巨集，因為整數乘法可以透過重複加法來模擬。請注意，我們需要在臨時變數中保留 X 的值，因為在每次加法中，我們都需要將 X 的原始值加到 Y 上。

**演算法 17.8 巨集 Y ← Y × X**
\`\`\`text
TEMP ← Y
Y ← 0
while (X)
{
  decr (X)
  Y ← Y + TEMP
}
\`\`\`

**第六個巨集：Y ← Y^X**
演算法 17.9 模擬簡單語言中的巨集 Y ← Y^X。我們使用乘法巨集來執行此操作，因為整數求冪可以透過重複乘法來模擬。

**演算法 17.9 巨集 Y ← Y^X**
\`\`\`text
TEMP ← Y
Y ← 1
while (X)
{
  decr (X)
  Y ← Y × TEMP
}
\`\`\`

**第七個巨集：if X then A**
演算法 17.10 模擬簡單語言中的第七個巨集。此巨集模擬現代語言中的決策（*if*）陳述式。在此巨集中，變數 X 只有兩個值 0 或 1 之一。如果 X 的值不為 0，則在迴圈中執行 A（一個動作或一系列動作）。然而，迴圈只執行一次，因為在第一次迭代後，X 的值變為 0，我們跳出迴圈。如果 X 的值最初為 0，則跳過迴圈。

**演算法 17.10 巨集 if X then A**
\`\`\`text
while (X)
{
  decr (X)
  A
}
\`\`\`

**其他巨集**
顯然，我們需要更多的巨集來使簡單語言與當代語言相容。創建其他巨集是可能的，儘管並非微不足道。

**輸入和輸出**
在這種簡單語言中，陳述式 *read X* 可以使用 (X ← n) 來模擬。我們還透過假設程式中使用的最後一個變數保存應該列印的內容來模擬輸出。請記住，這不是一種實用的語言，它僅僅是為了證明電腦科學中的一些定理而設計的。

## 17.2 圖靈機
**圖靈機**由艾倫·圖靈於 1936 年提出，用於解決可計算問題，是現代電腦的基礎。在本節中，我們介紹機器的非常簡化版本以展示其工作原理。

### 17.2.1 圖靈機組件
圖靈機由三個組件組成：一條紙帶、一個控制器和一個讀寫頭（圖 17.2）。

**紙帶 (Tape)**
雖然現代電腦使用容量有限的隨機存取儲存設備，但我們假設圖靈機的記憶體是無限的。紙帶在任何時候都保存來自機器接受的字元集的字元序列。就我們的目的而言，我們假設機器只能接受兩個符號：空白 (**b**) 和數字 **1**。圖 17.3 顯示了該機器紙帶上的資料範例。

左側空白定義了儲存在紙帶上的非負整數的開始。整數由一串 1 表示，右側空白定義了整數的結束。紙帶的其餘部分包含空白字元。如果紙帶上儲存了多個整數，則它們至少由一個空白字元分隔。
我們還假設紙帶僅處理以一元運算表示的正整數資料。在這種運算中，正整數僅由 1 組成。例如，整數 4 表示為 1111（四個 1），整數 7 表示為 1111111（七個 1）。沒有 1 代表 0。

**讀寫頭 (Read/write head)**
**讀寫頭**在任何時刻都指向紙帶上的一個符號。我們稱此符號為*當前*符號。讀寫頭一次從紙帶讀取和寫入一個符號。讀寫後，它向左或向右移動。讀取、寫入和移動都是在控制器的指令下完成的。

**控制器 (Controller)**
**控制器**是現代電腦中中央處理單元 (CPU) 的理論對應物。它是一個**有限狀態自動機**，一種具有預定有限數量狀態並根據輸入從一個狀態移動到另一個狀態的機器。在任何時刻，它可以處於這些狀態之一。
圖 17.4 顯示了作為有限狀態自動機的簡單控制器的轉換狀態圖。在此圖中，自動機只有三個狀態（A、B 和 C），儘管控制器通常有許多狀態。該圖顯示了狀態隨讀取字元的變化。每條線上的表達式 *x/y/L*、*x/y/R* 和 *x/y/N* 顯示如果控制器讀取了符號 *x*，它寫入符號 *y*（覆蓋 *x*），並且讀寫頭向左移動 (L)、向右移動 (R) 或不移動 (N)。請注意，由於紙帶上的符號只能是空白或數字 1，因此每個狀態應該有兩條路徑：一條是讀取空白符號，另一條是讀取數字 1。線的開頭（稱為*轉換線*）顯示當前狀態，線的末端（箭頭）顯示下一個狀態。

我們可以創建一個轉換表（表 17.1），其中每一行與一個狀態相關。該表將有五列：當前狀態、讀取的符號、寫入的符號、頭的移動方向和下一個符號。由於機器只能經過有限數量的狀態，我們可以像第 5 章中為簡單電腦創建的那樣創建一個指令集。

**表 17.1 轉換表**
| 當前狀態 | 讀取 | 寫入 | 移動 | 新狀態 |
| :--- | :--- | :--- | :--- | :--- |
| A | b | b | R | A |
| A | 1 | 1 | R | B |
| B | b | 1 | R | B |
| B | 1 | b | N | C |
| C | b | b | L | A |
| C | 1 | 1 | L | B |

指令將每行中五列的值放在一起。對於這台基本機器，我們只有六條指令：
1. (A, b, b, R, A)
2. (A, 1, 1, R, B)
3. (B, b, 1, R, B)
4. (B, 1, b, N, C)
5. (C, b, b, L, A)
6. (C, 1, 1, L, B)

例如，第一條指令說如果機器處於狀態 A 並且讀取了符號 b，它會用新的 b 覆蓋該符號，移動到右邊的下一個符號，並且機器轉換到狀態 A——也就是說，保持在同一狀態。

> **範例 17.1**
> 一台圖靈機只有兩個狀態和以下四條指令：
> 1. (A, b, b, L, A)
> 2. (A, 1, 1, R, B)
> 3. (B, b, b, L, A)
> 4. (B, 1, b, R, A)
> 如果機器從圖 17.5 所示的配置開始（控制器狀態 A，指向序列 'b 1 1 1 1 b' 中的第一個 1），執行上述指令之一後機器的配置是什麼？請注意，機器只能執行其中一條指令，即與當前狀態和當前符號匹配的指令。
>
> **解答**
> 機器處於狀態 A 且當前符號為 1，這意味著只能執行第二條指令 (A, 1, 1, R, B)。新配置也顯示在圖 17.5 中。請注意，控制器的狀態已更改為 B，讀寫頭向右移動了一個符號。

### 17.2.2 模擬簡單語言
我們現在可以編寫實作簡單語言陳述式的程式。請注意，這些陳述式可以用許多不同的方式編寫：我們選擇了最簡單或最方便的方式用於教育目的，但它們不一定是最好的。

**遞增陳述式**
圖 17.6 顯示了 **incr (X)** 陳述式的圖靈機。控制器有四個狀態，S1 到 S4。狀態 S1 是開始狀態，狀態 S2 是向右移動狀態，狀態 S3 是向左移動狀態，狀態 S4 是停機狀態。如果機器到達停機狀態，它就會停止：沒有以此狀態開始的指令。

圖 17.6 還顯示了 incr (X) 陳述式的程式。它只有五條指令。該過程從 X 左側的空白符號開始（要遞增的資料），向右移動越過所有 1，直到到達 X 右側的空白符號。它將此空白更改為 1。然後它向左移動越過所有 1，直到再次到達左側的空白。此時它停止。請注意，我們還編寫了程式將讀寫頭移回 X 左側的空白符號，如果要在 X 上執行更多操作，這是必要的。

> **範例 17.2**
> 展示當 X = 2 時圖靈機如何遞增 X。
>
> **解答**
> 圖 17.7 顯示了解決方案。X 的值（一元系統中的 11）儲存在兩個空白符號之間。機器需要七個步驟來遞增 X 並將讀寫頭返回其原始位置。步驟 1 到 4 將讀寫頭移動到 X 的末尾。步驟 5 到 7 更改末尾的空白並將讀寫頭移回之前的位置。

**遞減陳述式**
我們使用最少數量的指令實作 **decr (X)** 陳述式。原因是我們需要在下一個陳述式，*while* 迴圈中使用此陳述式，這也將用於實作所有巨集。圖 17.8 顯示了此陳述式的圖靈機。控制器有三個狀態，S1、S2 和 S3。陳述式 S1 是開始狀態。狀態 S2 是檢查陳述式，它檢查當前符號是 1 還是 b。如果是 b，則陳述式進入停機狀態：如果下一個符號是 1，則第二個陳述式將其更改為 b 並進入停機狀態。圖 17.8 還顯示了此陳述式的程式。

> **範例 17.3**
> 展示當 X = 2 時圖靈機如何遞減 X。
>
> **解答**
> 圖 17.9 顯示了這種情況。機器從資料左側的空白開始，如果是 1 則將下一個符號更改為空白。讀寫頭停在結果資料左側的空白字元上方。這與遞增陳述式的安排相同。請注意，我們可以將讀寫頭移動到資料末尾並刪除最後一個 1 而不是第一個，但該程式會比我們的版本長得多。由於我們在每個迴圈陳述式中都需要此陳述式，因此我們使用了較短的版本來節省指令數量。我們在接下來開發的 *while* 迴圈陳述式中使用此陳述式的簡短版本。

**迴圈陳述式**
為了模擬迴圈，我們假設 X 和要由迴圈主體處理的資料儲存在紙帶上，由單個空白符號分隔。圖 17.10 顯示了一般迴圈陳述式的表、程式和狀態轉換圖。

三個狀態 S1、S2 和 S3 透過確定 X 並在 X = 0 時退出迴圈來控制迴圈。將這三個陳述式與圖 17.8 遞減陳述式中使用的三個陳述式進行比較。狀態 MR 在每次迭代處理資料開始時將讀寫頭移動到定義資料開始的空白符號上方，狀態 ML 在每次迭代處理結束時將讀寫頭移動到定義 X 開始的空白符號上方。狀態 BS（*主體開始*）定義迴圈主體的開始狀態，而狀態 BH（*主體停止*）定義迴圈主體的停機狀態。迴圈主體在這兩個狀態之間可能有幾個狀態。

圖 17.10 還顯示了陳述式的重複性質。狀態圖本身是一個迴圈，只要 X 的值不為零就會重複。當 X 的值變為 0 時，迴圈停止並到達狀態 S3，即停機狀態。

> **範例 17.4**
> 讓我們展示一個非常簡單的例子。假設我們想要模擬第四個巨集 Y ← Y + X（第 454 頁）。正如我們之前討論的，這個巨集可以使用簡單語言中的 while 陳述式來模擬：
> \`\`\`text
> while (X)
> {
>   decr (X)
>   incr (Y)
> }
> \`\`\`
> 為了使過程更短，我們假設 X = 2 且 Y = 3，因此結果是 Y = 5。圖 17.11 顯示了應用巨集前後紙帶的狀態。請注意，在這個程式中，我們刪除 X 的值以使過程更短，但如果我們允許紙帶上有其他符號，則可以保留 X 的原始值。
> 由於 X = 2，程式經過兩次迭代。在第一次迭代結束時，X = 1 且 Y = 4。在第二次迭代結束時，X = 0 且 Y = 5。

### 17.2.3 邱奇-圖靈論題
我們已經證明圖靈機可以模擬簡單語言中的三個基本陳述式。這意味著圖靈機也可以模擬我們為簡單語言定義的所有巨集。那麼圖靈機是否可以解決電腦可以解決的任何問題呢？這個問題的答案可以在邱奇-圖靈論題中找到。

**邱奇-圖靈論題**
**如果存在一個演算法來執行符號操作任務，那麼就存在一台圖靈機來執行該任務。**

基於這一主張，任何可以透過編寫演算法來完成的符號操作任務也可以由圖靈機完成。請注意，這只是一個*論題*，而不是一個*定理*。定理可以用數學證明，論題則不能。雖然這個論題可能永遠無法被證明，但有強有力的論據支持它。首先，還沒有發現不能使用圖靈機模擬的演算法。其次，已經證明所有已被數學證明的計算模型都等同於圖靈機模型。

## 17.3 哥德爾數
在理論電腦科學中，對於可以用特定語言編寫的每個程式，都會分配一個無符號數。這通常被稱為**哥德爾數**，以奧地利數學家庫爾特·哥德爾命名。

這種分配有許多優點。首先，程式可以作為單個資料項目作為其他程式的輸入。其次，程式可以僅透過其整數表示來引用。第三，編號可以用來證明某些問題無法由電腦解決，方法是證明世界上的問題總數遠大於可以編寫的程式總數。

已經設計了不同的方法來為程式編號。我們使用一種非常簡單的轉換來為用我們的簡單語言編寫的程式編號。簡單語言僅使用十五個符號（表 17.2）。

**表 17.2 簡單語言中使用的符號代碼**
| 符號 | 十六進位代碼 | 符號 | 十六進位代碼 |
| :--- | :--- | :--- | :--- |
| 1 | 1 | 9 | 9 |
| 2 | 2 | incr | A |
| 3 | 3 | decr | B |
| 4 | 4 | while | C |
| 5 | 5 | { | D |
| 6 | 6 | } | E |
| 7 | 7 | X | F |
| 8 | 8 | | |

請注意，在這種語言中，我們僅使用 X, X1, X2, …, X9 作為變數。為了編碼這些變數，我們將 Xn 處理為兩個符號 X 和 n（X3 是 X 和 3）。如果我們有一個帶有其他變數的巨集，它們需要更改為 Xn。

### 17.3.1 表示程式
使用該表，我們可以透過以下步驟將任何用簡單語言編寫的程式表示為唯一的正整數：
1.  用表中的相應十六進位代碼替換每個符號。
2.  將結果十六進位數字解釋為無符號整數。

> **範例 17.5**
> 程式 \`incr X\` 的哥德爾數是多少？
>
> **解答**
> 用其十六進位代碼替換每個符號。
> \`incr X\` → (AF)16 → 175
> 所以這個程式可以用數字 175 表示。

### 17.3.2 解釋數字
為了證明編號系統是唯一的，使用以下步驟解釋哥德爾數：
1.  將數字轉換為十六進位。
2.  使用表 17.2 將每個**十六進位數字**解釋為一個符號（忽略 0）。

請注意，雖然任何用簡單語言編寫的程式都可以用一個數字表示，但並非每個數字都可以解釋為有效程式。轉換後，如果符號不遵循語言的語法，則該數字不是有效程式。

> **範例 17.6**
> 將 3058 解釋為一個程式。
>
> **解答**
> 將數字更改為十六進位並用相應的符號替換每個數字：
> 3058 → (BF2)16 → decr X 2 → decr (X2)
> 這意味著簡單語言中的等效代碼是 \`decr (X2)\`。請注意，在簡單語言中，每個程式都包括輸入和輸出。這意味著程式及其輸入的組合定義了哥德爾數。

## 17.4 停機問題
幾乎每個用程式語言編寫的程式都涉及某種形式的重複——迴圈或遞迴函數。重複建構可能永遠不會終止（停止）：也就是說，如果程式有無限迴圈，它可以永遠運行。例如，以下簡單語言中的程式永遠不會終止：
\`\`\`text
X → 1
while (X)
{
}
\`\`\`

一個經典的程式設計問題是：
**我們能否編寫一個程式來測試任何程式（由其哥德爾數表示）是否會終止？**

這個程式的存在將為程式設計師節省大量時間。在不知道程式是否停止的情況下運行程式是一項乏味的工作。不幸的是，現在已經證明這樣的程式不可能存在——這讓程式設計師非常失望！

### 17.4.1 停機問題是不可解的
電腦科學家不說測試程式不存在且永遠不可能存在，而是說「**停機問題**是不可解的」。

**證明**
讓我們給出關於此測試程式不存在的非正式證明。我們的方法稱為*反證法*，常用於數學：我們假設程式確實存在，然後證明其存在會產生矛盾——因此，它不可能存在。我們使用三個步驟來展示這種方法的證明。

**步驟 1**
在此步驟中，我們假設存在一個名為 Test 的程式。它可以接受任何程式（如 $P$，由其哥德爾數表示）作為輸入，並輸出 1 或 0。如果 $P$ 終止，Test 的輸出為 1：如果 $P$ 不終止，Test 的輸出為 0（見圖 17.12）。

**步驟 2**
在此步驟中，我們創建另一個名為 Strange 的程式，它由兩部分組成：開頭是 Test 的副本，末尾是一個空迴圈——一個主體為空的迴圈。該迴圈使用 X 作為測試變數，這實際上是 Test 程式的輸出。此程式也使用 $P$ 作為輸入。我們稱此程式為 Strange，原因如下：如果 $P$ 終止，Strange 的第一部分（Test 的副本）輸出 1。這個 1 輸入到迴圈中。迴圈不終止——它是一個無限迴圈——因此 Strange 不終止。如果 $P$ 不終止，Strange 的第一部分（Test 的副本）輸出 0。這個 0 輸入到迴圈中，所以迴圈確實終止——它現在是一個有限迴圈，迴圈從不迭代——因此，Strange 終止。換句話說，我們有這些奇怪的情況：
- 如果 $P$ 終止，Strange 不終止。
- 如果 $P$ 不終止，Strange 終止。

**步驟 3**
編寫了程式 Strange 後，我們用它自己（它的哥德爾數）作為輸入來測試它。這是合法的，因為我們沒有對 $P$ 施加任何限制。
如果我們假設 Test 存在，我們有以下矛盾：
- 如果 Strange 終止，Strange 不終止。
- 如果 Strange 不終止，Strange 終止。
這證明 Test 程式不可能存在，我們應該停止尋找它，所以……
**停機問題是不可解的。**

停機程式的不可解性證明了許多其他程式也是不可解的，因為如果它們是可解的，那麼停機問題就是可解的——而事實並非如此。

## 17.5 問題的複雜度
現在我們已經證明至少有一個問題是電腦無法解決的，我們將稍微多談談這個重要問題。在電腦科學中，我們可以說，一般而言，問題可以分為兩類：**可解問題**和**不可解問題**。可解問題本身可以分為兩類：**多項式**和**非多項式**問題（圖 17.15）。

### 17.5.1 不可解問題
有無限多個問題是電腦無法解決的：其中之一是停機問題。證明一個問題不可解的一種方法是證明如果該問題可解，那麼停機問題也可解。換句話說，證明問題的可解性導致停機問題的可解性。

### 17.5.2 可解問題
有許多問題可以由電腦解決。然而，我們經常想知道電腦解決該問題需要多*長*時間。換句話說，程式有多複雜？
程式的複雜度可以用幾種不同的方式來衡量，例如其運行時間、所需的記憶體等等。一種方法是程式的運行時間——程式運行需要多長時間？

**可解問題的複雜度**
衡量可解問題複雜度的一種方法是找出電腦運行程式時執行的操作數量。透過這種方式，複雜度度量與運行程式的電腦速度無關。這種複雜度度量可能取決於輸入的數量。例如，如果程式正在處理列表（例如對其進行排序），則複雜度取決於列表中的元素數量。

**大 O 符號**
以當今電腦的速度，我們不關心確切的數字，而關心一般的數量級。例如，如果對兩個程式的分析顯示一個執行 15 次操作（或一組操作），而另一個執行 25 次，它們都太快了，我們看不出區別。另一方面，如果數字是 15 對 1500，我們就應該關注了。
這種效率的簡化稱為**大 O 符號**。我們在不深入探討其正式定義和計算的情況下介紹這種符號的概念。在大 O 符號中，操作的數量——或一組相關的操作——以輸入數量的函數給出。符號 O(n) 意味著程式對 $n$ 個輸入執行 $n$ 次操作，而符號 O($n^2$) 意味著程式對 $n$ 個輸入執行 $n^2$ 次操作。

> **範例 17.7**
> 想像我們編寫了三個不同的程式來解決同一個問題。第一個的複雜度為 O($\\log_{10} n$)，第二個為 O($n$)，第三個為 O($n^2$)。假設有 100 萬個輸入，在一台執行一條指令需一微秒（即每秒一百萬條指令）的電腦上執行每個程式需要多長時間？
>
> **解答**
> 分析如下：
> *   第 1 個程式：$n = 1000000$，O($\\log_{10} n$) → 6。時間 → 6 µs
> *   第 2 個程式：$n = 1000000$，O($n$) → 1000000。時間 → 1 秒
> *   第 3 個程式：$n = 1000000$，O($n^2$) → $10^{12}$。時間 → 277 小時

**多項式問題**
如果程式的複雜度為 O(log $n$)、O($n$)、O($n^2$)、O($n^3$)、O($n^4$) 或 O($n^k$)，其中 $k$ 是常數，則稱為**多項式**。以當今電腦的速度，我們可以在合理的輸入數量下（例如 1000 到 100 萬）獲得**多項式問題**的解決方案。

**非多項式問題**
如果程式的複雜度大於多項式——例如 O($10^n$) 或 O($n!$)——只有當輸入數量非常小（例如少於 100）時才能解決。如果輸入數量很大，一個人可能會坐在電腦前幾個月才能看到**非多項式問題**的結果。但也許誰知道呢？按照電腦速度增長的速度，我們也許能夠在更短的時間內獲得這類問題的結果。

## 17.6 章末材料
### 17.6.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Hennie, F. *Introduction to Computability*, Reading, MA: Addison-Wesley, 1977
- Hofstadter, D. *Gödel, Escher, Bach: An Eternal Golden Braid*, St. Paul, MN: Vintage, 1980
- Hopcroft, J., Motwani, R. and Ullman, J. *Introduction to Automata Theory, Languages, and Computation*, Reading, MA: Addison-Wesley, 2006
- Kfoury, A., Moll, R. and Michael, A. *A Programming Approach to Computability*, New York: Springer, 1982
- Minsky, M. *Computation: Finite and Infinite Machines*, Engelwood Cliffs, NJ: Prentice-Hall, 1967
- Sipser, M. *Introduction to the Theory of Computation*, Boston, MA: Course Technology, 2005

### 17.6.2 關鍵詞
- 大 O 符號 (big-O notation)
- 邱奇-圖靈論題 (Church–Turing thesis)
- 控制器 (controller)
- 遞減陳述式 (decrement statement)
- 有限狀態自動機 (finite state automaton)
- 哥德爾數 (Gödel number)
- 停機問題 (halting problem)
- 十六進位數字 (hexadecimal digit)
- 遞增陳述式 (increment statement)
- 迴圈陳述式 (loop statement)
- 巨集 (macro)
- 非多項式問題 (nonpolynomial problem)
- 多項式問題 (polynomial problem)
- 讀寫頭 (read/write head)
- 可解問題 (solvable problem)
- 圖靈機 (Turing machine)
- 不可解問題 (unsolvable problem)

### 17.6.3 摘要
- 我們可以定義一種只有三個陳述式的電腦語言：遞增陳述式、遞減陳述式和迴圈陳述式。遞增陳述式將變數加 1，遞減陳述式從變數中減去 1，迴圈陳述式在變數值不為 0 時重複一個動作或一系列動作。
- 可以證明，這種簡單的程式語言可以模擬一些流行語言中的幾個陳述式。我們稱每個模擬為巨集，並在其他模擬中使用它，而無需重複代碼。
- 圖靈機旨在解決可計算問題。它是現代電腦的基礎。圖靈機由三個組件組成：一條紙帶、一個控制器和一個讀寫頭。
- 根據邱奇-圖靈論題，如果存在執行符號操作任務的演算法，那麼也存在執行該任務的圖靈機。
- 在理論電腦科學中，對於可以用特定語言編寫的每個程式，都會分配一個無符號數。這通常被稱為哥德爾數。
- 一個經典的程式設計問題是是否可以構建一個程式來確定另一個程式是否停止。不幸的是，現在已經證明這個程式不可能存在：停機問題是不可解的。
- 在電腦科學中，問題可以分為兩類：可解問題和不可解問題。可解問題本身可以分為兩類：多項式和非多項式問題。

## 17.7 練習題
### 17.7.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 17.7.2 複習問題
1. 命名並描述三個基本陳述式的功能，這三個陳述式是簡單語言中其他陳述式的基礎。
2. 展示將一個變數的值賦給另一個變數如何使用這三個基本陳述式。
3. 圖靈機與我們的簡單語言有什麼關係？
4. 圖靈機的組件是什麼？每個組件的功能是什麼？
5. 描述一種劃分圖靈機紙帶上資料的方法。
6. 當圖靈機中的讀寫頭完成讀寫符號後，它的下一個選項是什麼？
7. 轉換狀態圖與圖靈機控制器有何關係？
8. 轉換狀態圖與轉換表有何關係？它們有相同的資訊嗎？哪個資訊更多？
9. 什麼是哥德爾數？我們如何使用哥德爾數來證明停機問題是不可解的？
10. 比較和對比多項式可解問題和非多項式可解問題的複雜度。

### 17.7.3 問題
1. 重寫演算法 17.6 (Y ← X)，使其保留 X 的值。
2. 重寫演算法 17.7，使其計算 Z ← Y + X，同時保留 X 和 Y 的值。
3. 重寫演算法 17.8，使其計算 Z ← Y × X，同時保留 X 和 Y 的值。
4. 重寫演算法 17.9，使其計算 Z ← Y^X，同時保留 X 和 Y 的值。
5. 使用先前在簡單語言中定義的陳述式或巨集模擬以下巨集：Y ← Y - X。
6. 使用語言中先前定義的陳述式或巨集模擬以下巨集（X 只能是 0 或 1）：
   \`\`\`text
   if (X) then
   {
     A1
   }
   else
   {
     A2
   }
   \`\`\`
7. 給定一台具有單條指令 (A, 1, b, R, B) 和紙帶配置的圖靈機：
   ... b 1 1 1 b ...
   (指向第一個 1)
   顯示紙帶的最終配置。
8. 給定一台具有單條指令 (A, b, b, R, B) 和紙帶配置的圖靈機：
   ... b 1 1 1 b ...
   (指向第一個 b)
   顯示紙帶的最終配置。
9. 給定一台具有五條指令 (A, b, b, R, B), (B, 1, #, R, B), (B, b, b, L, C), (C, #, 1, L, C), (C, b, b, R, B) 和紙帶配置的圖靈機：
   ... b 1 1 1 b ...
   (指向第一個 b)
   顯示紙帶的最終配置。
10. 顯示遞增以二進位系統表示的非負整數的圖靈機的狀態圖。例如，如果紙帶的內容是 $(101)_2$，它將更改為 $(110)_2$。
11. 證明本章定義的圖靈機中 incr (X) 的模擬在 X = 0 時給出正確答案。
12. 證明本章定義的圖靈機中 decr (X) 的模擬在 X = 0 時給出正確答案。
13. 說明如果我們允許機器使用另一個符號（如 #），如何更改本章定義的圖靈機中迴圈陳述式的模擬以保留 X 的原始值。
14. 給出模擬巨集 X ← 0 的圖靈機的轉換狀態和程式。
15. 給出模擬巨集 Y ← X 的圖靈機的轉換狀態和程式。
16. 一台圖靈機使用單個 1 來表示整數 0。展示整數 n 如何在這台機器中表示。
17. 巨集 X1 ← 0 的哥德爾數是多少？
18. 巨集 X2 ← 2 的哥德爾數是多少？
19. 巨集 X3 ← X1 + X2 的哥德爾數是多少？
`},w={en:`
# Chapter 18: Artificial Intelligence

In this chapter of the book, we offer an introduction to **artificial intelligence (AI)**. The first section is a brief history and an attempt to define artificial intelligence. **Knowledge representation**, a broad and well-developed area in AI, is discussed in the next section. We then introduce **expert systems**, systems that can replace human expertise when it is needed but not available. We then discuss how artificial intelligence can be used to simulate the normal (mundane) behavior of human beings in two areas: **image processing** and **language analysis**. We then show how expert systems and mundane systems can solve problems using different searching method. Finally, we discuss how **neural networks** can simulate the process of learning in an intelligent agent.

## Objectives
After studying this chapter, the student should be able to:
- Define and give a brief history of artificial intelligence.
- Describe how knowledge is represented in an intelligent agent.
- Show how expert systems can be used when a human expert is not available.
- Show how an artificial agent can be used to simulate mundane tasks performed by human beings.
- Show how expert systems and mundane systems can use different search techniques to solve problems.
- Show how the learning process in humans can be simulated, to some extent, using neural networks that create the electronic version of a neuron called a perceptron.

## 18.1 INTRODUCTION
In this section we first try to define the term **artificial intelligence (AI)** informally and give a brief history of it. We also define an **intelligent agent** and its two broad categories. Finally, we mention two programming languages that are commonly used in artificial intelligence.

### 18.1.1 What is artificial intelligence?
Although there is no universally agreed definition of artificial intelligence, we accept the following definition that matches the topics covered in this chapter:

**Artificial intelligence is the study of programmed systems that can simulate, to some extent, human activities such as perceiving, thinking, learning, and acting.**

### 18.1.2 A brief history of artificial intelligence
Although artificial intelligence as an independent field of study is relatively new, it has some roots in the past. We can say that it started 2400 years ago when the Greek philosopher Aristotle invented the concept of logical reasoning. The effort to finalize the language of logic continued with Leibniz and Newton. George Boole developed Boolean algebra in the nineteenth century (Appendix E) that laid the foundation of computer circuits. However, the main idea of a thinking machine came from Alan Turing, who proposed the Turing test. The term ‘artificial intelligence’ was first coined by John McCarthy in 1956.

### 18.1.3 The Turing test
In 1950, Alan Turing proposed the **Turing Test**, which provides a definition of *intelligence* in a machine. The test simply compares the intelligent behavior of a human being with that of a computer. An interrogator asks a set of questions that are forwarded to both a computer and a human being. The interrogator receives two sets of responses, but does not know which set comes from the human and which set from the computer. After careful examination of the two sets, if the interrogator cannot definitely tell which set has come from the computer and which from the human, the computer has passed the Turing test for intelligent behavior.

### 18.1.4 Intelligent agents
An **intelligent agent** is a system that perceives its environment, learns from it, and interacts with it intelligently. Intelligent agents can be divided into two broad categories: *software agents* and *physical agents*.

**Software agents**
A **software agent** is a set of programs that are designed to do particular tasks. For example, some intelligent systems can be used to organize electronic mail (email). This type of agent can check the contents of received emails and classify them into different categories (junk, less important, important, very important, and so on). Another example of software agents is a search engine used to search the World Wide Web and find sites that can provide information about a requested subject.

**Physical agents**
A **physical agent (robot)** is a programmable system that can be used to perform a variety of tasks. Simple robots can be used in manufacturing to do routine jobs such as assembling, welding, or painting. Some organizations use mobile robots that do delivery jobs such as distributing mail or correspondence to different rooms. There are mobile robots that are used underwater for prospecting for oil.
A humanoid robot is an autonomous mobile robot that is supposed to behave like a human. Although humanoid robots are prevalent in science fiction, there is still a lot of work to do before such robots will be able to interact properly with their surroundings and learn from events that occur there.

### 18.1.5 Programming languages
Although some all-purpose languages such as C, C++, and Java are used to create intelligent software, two languages are specifically designed for AI: LISP and PROLOG.

**LISP**
**LISP (LISt Programming)** was invented by John McCarthy in 1958. As the name implies, LISP is a programming language that manipulates lists. LISP treats data as well as programs as lists, which means that a LISP program can change itself. This feature matches the idea of an intelligent agent that can learn from its environment and improve its behavior.
However, one drawback of LISP is its sluggishness. It is slow if the list to be handled is long. Another drawback is the complexity of its syntax.

**PROLOG**
**PROLOG (PROgramming in LOGic)** is a language that can build a database of facts and a knowledge base of rules. A program in PROLOG can use logical reasoning to answer questions that can be inferred from the knowledge base. However, PROLOG is not a very efficient programming language. Some complex problems can be more efficiently solved using other languages, such as C, C++, or Java.

## 18.2 KNOWLEDGE REPRESENTATION
If an artificial agent is supposed to solve some problems related to the real world, it needs to be able to represent knowledge somehow. Facts are represented as data structures that can be manipulated by programs stored inside the computer. In this section, we describe four common methods for representing knowledge: *semantic networks*, *frames*, *predicate logic*, and *rule-based systems*.

### 18.2.1 Semantic networks
**Semantic networks** were developed in the early 1960s by Richard H. Richens. A semantic network uses directed graphs to represent knowledge. A directed graph, as discussed in Chapter 12, is made of vertices (nodes) and edges (arcs). Semantic networks use vertices to represent concepts, and edges (denoted by arrows) to represent the relation between two concepts (Figure 18.1).

**Concepts**
To develop an exact definition of a concept, experts have related the definition of concepts to the theory of sets. A concept, therefore, can be thought of as a set or a subset. For example, *animal* defines the set of all animals, *horse* defines the set of all horses and is a subset of the set *animal*. An object is a member (instance) of a set. Concepts are shown by vertices.

**Relations**
In a semantic network, relations are shown by edges. An edge can define a *subclass* relation—the edge is directed from the subclass to its superclass. An edge can also define an *instance* relation—the edge is directed from the instance to the set to which it belongs. An edge can also define an *attribute* of an object (color, size, ...). Finally, an edge can define a property of an object, such as possessing another object. One of the most important relations that can be well defined in a semantic network is *inheritance*. An inheritance relation defines the fact that all the attributes of a class are present in an inherited class. This can be used to infer new knowledge from the knowledge represented by the graph.

### 18.2.2 Frames
**Frames** are closely related to semantic networks. In semantic networks, a graph is used to represent knowledge: in frames, data structures (records) are used to represent the same knowledge. One advantage of frames over semantic networks is that programs can handle frames more easily than semantic networks. Figure 18.2 shows how the semantic network shown in Figure 18.1 can be implemented using frames.

**Objects**
A node in a semantic network becomes an object in a set of frames, so an object can define a class, a subclass, or an instance of a class. In Figure 18.2 *reptile*, *mammal*, *dog*, *Roxy*, and *Ringo* are objects.

**Slots**
Edges in semantic networks are translated into **slots**—fields in the data structure. The name of the slot defines the type of the relationship and the value of the slot completes the relationship. In Figure 18.2, for example, *animal* is a slot in the *reptile* object.

### 18.2.3 Predicate logic
The most common knowledge representation is **predicate logic**. Predicate logic can be used to represent complex facts. It is a well-defined language developed via a long history of theoretical logic. Although this section defines predicate logic, we first introduce **propositional logic**, a simpler language. We then discuss predicate logic, which employs propositional logic.

**Propositional logic**
Propositional logic is a language made up from a set of sentences that can be used to carry out logical reasoning about the world.

**Operators**
Propositional logic uses five operators, as shown below:
¬ (not), ∨ (or), ∧ (and), → (if ... then), ↔ (if and only if)

The first operator is unary—the operator takes only one sentence: the other four operators are binary—they take two sentences. The logical value (*true* or *false*) of each sentence depends on the logical value of the atomic sentences (sentences with no operators) of which the complex sentence is made. Figure 18.3 shows the truth table for each logical operator in propositional logic. Truth tables were introduced in Chapter 4 and explained in Appendix E.

**Sentence**
A sentence in this language is defined recursively as shown below:
1.  An uppercase letter, such as A, B, S, or T, that represents a statement in a natural languages, is a sentence.
2.  Any of the two constant values (*true* and *false*) is a sentence.
3.  If P is a sentence, then ¬P is a sentence.
4.  If P and Q are sentences, then P ∨ Q, P ∧ Q, P → Q, and P ↔ Q are sentences.

> **Example 18.1**
> The following are sentences in propositional language:
> a. Today is Sunday (S).
> b. It is raining (R).
> c. Today is Sunday or Monday (S ∨ M).
> d. It is not raining (¬R)
> e. If a dog is a mammal then a cat is a mammal (D → C)

**Deduction**
In AI we need to create new facts from the existing facts. In propositional logic, the process is called **deduction**. Given two presumably true sentences, we can deduce a new true sentence. The first two sentences are called *premisses*: the deduced sentence is called the *conclusion*. The whole is called an *argument*. For example:
*   Premiss 1: Either he is at home or at the office
*   Premiss 2: He is not at home
*   Conclusion: Therefore, he is at the office

If we use H for ‘he is at home’, O for ‘he is at office’, and the symbol |- for the ‘therefore’, then we can show the above argument as:
{H ∨ O, ¬H} |- O

The question is how we can prove if a deductive argument is *valid*. A valid deductive argument is an argument whose conclusions follow necessarily from its premisses. In other words, in a valid deductive argument, it is impossible for the conclusion to be false while its premisses all are true.
One way to do this is to create a truth table for the premisses and the conclusion. A conclusion is invalid if we can find a *counterexample* case: a case in which both premisses are true, but the conclusion is false.

**An argument is valid if no counterexample can be found.**

> **Example 18.2**
> The validity of the argument {H ∨ O, ¬H} |- O can be proved using a truth table. The row where H is False and O is True makes both premisses true and the conclusion true. There is no row where premisses are true and conclusion is false.

> **Example 18.3**
> The argument {R → C, C} |- R is not valid because a counterexample can be found. (R: She is rich, C: She has a car). Premiss 1: If she is rich, she has a car. Premiss 2: She has a car. Conclusion: Therefore, she is rich.
> Counterexample: She has a car (True), but she is not rich (False). Premiss 1 (F → T is T) is True, Premiss 2 is True, but Conclusion is False.

**Predicate logic**
In propositional logic, a symbol that represents a sentence is atomic: it cannot be broken up to find information about its components. For example, consider the sentences:
P1: ‘Linda is Mary’s mother’
P2: ‘Mary is Anne’s mother’
We can combine these two sentences in many ways to create other sentences, but we cannot extract any relation between Linda and Anne. For example, we cannot infer from the above two sentences that Linda is the grandmother of Anne. To do so, we need predicate logic: the logic that defines the relation between the parts in a proposition.

In predicate logic, a sentence is divided into a predicate and arguments. For example, each of the following propositions can be written as predicates with two arguments:
P1: ‘Linda is Mary’s mother’ becomes **mother (Linda, Mary)**
P2: ‘Mary is Anne’s mother’ becomes **mother (Mary, Anne)**

The relationship of motherhood in each of the above sentences is defined by the predicate *mother*. If the object *Mary* in both sentences refers to the same person, we can infer a new relation between Linda and Anne: **grandmother (Linda, Anne)**. This is the whole purpose of predicate logic.

**Sentence**
A sentence in predicate language is defined as follows:
1.  A predicate with n arguments such as *predicate_name (argument1, ..., argumentn)* is a sentence. The *predicate_name* relates arguments to each other. Each argument can be:
    a. A constant, such as *human*, *animal*, *John*, *Mary*.
    b. A variable, such as *x*, *y*, and *z*.
    c. A function such as *mother (Anne)*. Note that a function is a predicate that is used as an argument: a function returns an object that can takes the place of an argument.
2.  Any of the two constant values (*true* and *false*) is a sentence.
3.  If P is a sentence, then ¬P is a sentence.
4.  If P and Q are sentences, then P ∨ Q, P ∧ Q, P → Q, and P ↔ Q are sentences.

> **Example 18.4**
> 1. The sentence ‘John works for Ann’s sister’ can be written as: **works [John, sister (Ann)]**
> 2. The sentence ‘John’s father loves Ann’s sister’ can be written as: **loves [father (John), sister (Ann)]**

**Quantifiers**
Predicate logic allows us to use **quantifiers**. Two quantifiers are common in predicate logic: ∀ and ∃.
1.  The first, **∀**, which is read as ‘for all’, is called the **universal quantifier**: it states that something is true for every object that its variable represents.
2.  The second, **∃**, which is read as ‘there exists’, is called the **existential quantifier**: it states that something is true for one or more objects that its variable represents.

> **Example 18.5**
> 1. 'All men are mortals': ∀x [man (x) → mortal (x)]
> 2. 'Frogs are green': ∀x [frog (x) → green (x)]
> 3. 'Some flowers are red': ∃x [flower (x) ∧ red(x)]
> 4. 'John has a book': ∃x [book (x) ∧ has (John, x)]
> 5. 'No frog is yellow': ∀x[frog (x) → ¬yellow (x)] or ¬∃x [frog (x) ∧ yellow (x)]

**Deduction**
In predicate logic, if there is no quantifier, the verification of an argument is the same as that which we discussed in propositional logic. However, the verification becomes more complicated if there are quantifiers.
Premiss 1: All men are mortals.
Premiss 2: Socrates is a man.
Conclusion: Therefore, Socrates is mortal.
Verification: ∀x [man (x) → mortal (x)] , man (Socrates) |- mortal (Socrates)

**Beyond predicate logic**
There have been further developments in logic to include the need of logical reasoning. Some examples of these include high-order logic, default logic, modal logic, and temporal logic.
- **High-order logic**: Extends the scope of quantifiers to predicates themselves (e.g., ∀P).
- **Modal logic**: Includes expressions like ‘could’, ‘should’, ‘may’, ‘might’, ‘ought’.
- **Temporal logic**: Extends predicate logic with temporal operators such as ‘from now on’.
- **Default logic**: Assumes default conclusions unless there is evidence to the contrary (e.g., birds fly).

### 18.2.4 Rule-based systems
A **rule-based system** represents knowledge using a set of rules that can be used to deduce new facts from known facts. The rules express what is true if specific conditions are met. A rule-based database is a set of if... then... statements in the form
**If A then B** or **A → B**
in which A is called the *antecedent* and B is called the *consequent*. Note that in a rule-based system, each rule is handled independently without any connection to other rules.

**Components**
A rule-based system is made up of three components: an **interpreter** (or **inference engine**), a **knowledge base**, and a **fact database**, as shown in Figure 18.4.

**Knowledge base**
The knowledge base component in a rule-based system is a database (repository) of rules. It contains a set of pre-established rules that can be used to draw conclusions from the given facts.

**Database of facts**
The database of facts contains a set of conditions that are used by the rules in the knowledge base.

**Interpreter**
The interpreter (inference engine) is a processor or controller—a program, for example—that combines rules and facts. Interpreters are of two types: **forward chaining** and **backward chaining**.

**Forward chaining**
**Forward chaining** is the process in which an interpreter uses a set of rules and a set of facts to perform an action. The action can be just adding a new fact to the base of facts, or issuing some commands. The interpreter interprets and executes rules until no more rules can be interpreted.
If there is any conflict in which two different rules can be applied to one fact or one rule can be applied to two facts, the system needs to call a conflict resolution procedure.

**Backward chaining**
Forward chaining is not very efficient if the system tries to prove a conclusion. All facts must be checked by all rules to come up with the given conclusion. In this case, it may be more efficient if **backward chaining** is used. The process starts with the conclusion (goal). If the goal is already in the fact database, the process stops and the conclusion is proved. If the goal is not in the fact database, the system finds the rule that has the goal in its conclusion. However, instead of firing that rule, backward chaining is now applied to each fact in the rule (recursion).

## 18.3 EXPERT SYSTEMS
**Expert systems** use the knowledge representation languages discussed in the previous section to perform tasks that normally need human expertise. They can be used in situations in which that expertise is in short supply, expensive, or unavailable when required. For example, in medicine, an expert system can narrow down a set of symptoms to a likely subset of causes, a task normally carried out by a doctor.

### 18.3.1 Extracting knowledge
An expert system is built on predefined knowledge about its field of expertise. The first step in building an expert system is therefore to extract the knowledge from a human expert. This extracted knowledge becomes the knowledge base.
Extracting knowledge from an expert is normally a difficult task because the knowledge is often heuristic (based on probability rather than certainty) and intuitive. The knowledge-extraction process is normally done by a *knowledge engineer*.

### 18.3.2 Extracting facts
To be able to infer new facts or perform actions, a fact database is needed in addition to the knowledge base. The fact database in an expert system is case-based, in which facts collected or measured are entered into the system to be used by the inference engine.

### 18.3.3 Architecture
Figure 18.7 shows the general idea behind the architecture of an expert system. An expert system can have up to seven components: user, user interface, inference engine, knowledge base, fact database, explanation system, and knowledge base editor.
The **inference engine** is the heart of an expert system. Four of the seven components—user interface, inference engine, explanation system, and knowledge base editor—can be made once and used for many applications, as they are not dependent on the particular knowledge base or fact database. These components form an **expert system shell**.

- **User interface**: Allows the user to interact with the system.
- **Inference engine**: Uses the knowledge base and fact database to infer the action.
- **Knowledge base**: Collection of rules based on expert interviews.
- **Fact database**: Case-based data entered by the user.
- **Explanation system**: Explains the rationale behind the decision made.
- **Knowledge base editor**: Used to update the knowledge base.

## 18.4 PERCEPTION
One of the goals in artificial intelligence is to create a machine that behaves like an ordinary human. **Perception** is understanding what is received through the senses—sight, hearing, touch, smell, taste. An intelligent agent should be able to perceive if it needs to act like a human being. AI has been particularly involved in two types of perception, sight and hearing.

### 18.4.1 Image processing
**Image processing** or **computer vision** is an area of AI that deals with the perception of objects through the artificial eyes of an agent, such as a camera. An image processor takes a two-dimensional image from the outside world and tries to create a description of the three-dimensional objects present in the scene. The processor uses a database containing the characteristics of objects for comparison.

**Edge detection**
The first stage in image processing is **edge detection**: finding where the edges in the image are. Edges can define the boundaries between an object and its background. Edges show discontinuity in surface, depth, or illumination. The edges can be detected by finding adjacent pixels with a large difference in intensity.

**Segmentation**
**Segmentation** is the next stage in image analysis. Segmentation divides the image into homogeneous segments or areas. A homogeneous area is an area in which the intensity of pixels varies smoothly. Segmentation finds the boundaries between different areas inside the object. Several methods exist, such as *thresholding*, *splitting*, and *merging*.

**Finding depth**
The next step is to find the depth of the object or objects in the image. Depth finding can help the intelligent agent to gauge how far the object is from it.
- **Stereo vision**: Uses two eyes or two cameras. If the object is very close, the two images are different; if far away, they are almost the same.
- **Motion**: Creates several images when one or more objects are moving. The relative position of a moving object with respect to other objects gives a clue to distance.

**Finding orientation**
Orientation of the object in the scene can be found using two techniques: *shading* and *texture*.
- **Shading**: The amount of light reflected from a surface depends on the orientation of the surface relative to the light source.
- **Texture**: A regularly repeated pattern can help in finding the orientation or curvature.

**Object recognition**
The last step is **object recognition**. To recognize an object, the agent needs to have a model of the object in memory for comparison. One solution is to assume that objects are compound objects made of a set of simple **primitive geometric shapes** (block, cylinder, cone, etc.). When an agent ‘sees’ an object, it tries to decompose the object into a combination of the primitives.

### 18.4.2 Language understanding
One of the inherent capabilities of a human being is to understand—that is, interpret—the audio signals that they perceive. A machine that can understand **natural language** can be very useful. We can divide the task into four consecutive steps: speech recognition, syntactic analysis, semantic analysis, and pragmatic analysis.

**Speech recognition**
The first step is **speech recognition**. The speech signal (analog) is analyzed and the sequence of words it contains are extracted. The signal needs to be divided into different sounds, sometimes called *phonemes*.

**Syntactic analysis**
The **syntactic analysis** step is used to define how words are to be grouped in a sentence.
- **Grammar**: The first tool to correctly analyze a sentence is a well-defined grammar.
- **Parser**: A machine that determines if a sentence is grammatically (syntactically) correct does not need to check all possible choices before rejecting a sentence as an invalid one. This is done by a **parser**, which creates a **parse tree** based on the grammar rules.

**Semantic analysis**
The **semantic analysis** extracts the meaning of a sentence after it has been syntactically analyzed. This analysis creates a representation of the objects involved in the sentence, their relations, and their attributes.

**Pragmatic analysis**
**Pragmatic analysis** is needed to further clarify the purpose of the sentence and to remove ambiguities.
- **Purpose**: Determine if the sentence is a request, an inquiry, etc.
- **Removing ambiguity**: Resolving ambiguities where a word has multiple functions or meanings, or where a syntactically correct sentence is nonsense.

## 18.5 SEARCHING
One of the techniques for solving problems in artificial intelligence is **searching**. Searching can be described as solving a problem using a set of **states** (a situation). A search procedure starts from an **initial state**, goes through **intermediate states** until finally reaching a **target state**. The set of all states used by a searching process is referred to as the **search space**.
Example: The 8-puzzle.

### 18.5.1 Search methods
There are two general search methods: *brute-force* and *heuristic*. The brute-force method is itself either *breadth-first* or *depth-first*.

**Brute-force search**
We use **brute-force search** if we do not have any prior knowledge about the search.
- **Breadth-first search**: We start from the root of the tree and examine all the nodes at each level before we move to the next level. This guarantees finding a solution if one exists and finding the shortest path, but is inefficient.
- **Depth-first search**: We start from the root and do a forward search until we hit the goal or a dead-end. If we hit a dead-end, we **backtrack** to the nearest branch and do a forward search again.

**Heuristic search**
Using **heuristic search**, we assign a quantitative value called a **heuristic value (h value)** to each node. This quantitative value shows the relative closeness of the node to the goal state. For example, in the 8-puzzle, the heuristic value could be the minimum number of movements a tile must make to reach its goal position. We start with the state with the smaller *h* value (closer to the goal) and continue this way.

## 18.6 NEURAL NETWORKS
If an intelligent agent is supposed to behave like a human being, it may need to learn. Most methods use **inductive learning** or **learning by example**. This means that a large set of problems and their solutions are given to the machine from which to learn. **Neural networks** try to simulate the learning process of the human brain using a network of neurons.

### 18.6.1 Biological neurons
The human brain has billions of processing units, called **neurons**. A neuron is made of three parts: **soma**, **axon**, and **dendrites**. The dendrites act as input devices; the axon acts as an output device. The **synapse** is the connecting point. A neuron can be in one of two states: *excited* (fires an output) or *inhibited*.

### 18.6.2 Perceptrons
A **perceptron** is an artificial neuron similar to a single biological neuron. It takes a set of weighted inputs, sums the inputs, and compares the result with a **threshold** value. If the result is above the threshold value, the perceptron fires (output 1), otherwise, it does not (output 0).
$S = (x_1 \\cdot w_1 + x_2 \\cdot w_2 + ...)$
If $S > T$, then $y = 1$; else $y = 0$.
A perceptron can be trained by adjusting weights based on correct or incorrect outputs from known examples.

### 18.6.3 Multilayer networks
Several layers of perceptrons can be combined to create **multilayer neural networks**. The output from each layer becomes the input to the next layer. The first layer is the **input layer**, the middle layers are called **hidden layers**, and the last layer is the **output layer**.

### 18.6.4 Applications
Neural networks can be used when enough pre-established inputs and outputs exist to train the network. Applications include **optical character recognition (OCR)** and credit assignment (establishing credit ratings).

## 18.7 END-CHAPTER MATERIALS
### 18.7.1 Recommended reading
- Cawsey, A. *The Essence of Artificial Intelligence*, Upper Saddle River, NJ: Prentice-Hall, 1998
- Luger, G. *Artificial Intelligence: Structures and Strategies for Complex Problem Solving*, Reading, MA: Addison-Wesley, 2004
- Winston, P. *Artificial Intelligence*, Reading, MA: Addison-Wesley, 1993
- Coppin, B. *Artificial Intelligence Illuminated*, Sudbury, MA: Jones and Bartlett, 2004
- Russel, S. and Norvig, P. *Artificial Intelligence: A Modern Approach*, Upper Saddle River, NJ: Prentice-Hall, 2003
- Dean, T. *Artificial Intelligence: Theory and Practice*, Redwood City, Reading, MA: Addison-Wesley, 2002

### 18.7.2 Key terms
- artificial intelligence
- axon
- brute-force search
- breadth-first search
- depth-first search
- expert system
- frame
- heuristic search
- image processing
- intelligent agent
- LISP
- neural network
- neuron
- perceptron
- physical agent
- pragmatic analysis
- predicate logic
- PROLOG
- search space
- segmentation
- semantic analysis
- semantic network
- software agent
- soma
- speech recognition
- synapse
- syntactic analysis
- temporal logic
- thresholding
- Turing test

### 18.7.3 Summary
- Artificial intelligence is the study of programmed systems that can simulate human activities such as perceiving, thinking, learning, and acting. The Turing Test compares the intelligent behavior of a human being with that of a computer.
- An intelligent agent is a system that perceives its environment, learns from it, and interacts with it. Agents can be software agents or physical agents (robots).
- Knowledge representation methods include semantic networks, frames, predicate logic, and rule-based systems. Semantic networks use graphs; frames use data structures. Predicate logic uses logical reasoning. Rule-based systems use rules to deduce new facts.
- Expert systems perform tasks that normally need human expertise. They extract knowledge from experts and use an inference engine to make decisions.
- Perception involves understanding sensory inputs. Image processing deals with visual perception (edge detection, segmentation, depth finding, object recognition). Language understanding involves speech recognition, syntactic analysis, semantic analysis, and pragmatic analysis.
- Searching is a technique for solving problems by moving through states in a search space. Brute-force search (breadth-first, depth-first) explores systematically. Heuristic search uses rules of thumb to find solutions faster.
- Neural networks simulate the learning process of the human brain using artificial neurons called perceptrons, often arranged in multilayer networks. They learn by example (inductive learning).

## 18.8 PRACTICE SET
### 18.8.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 18.8.2 Review questions
1. Describe the Turing test. Do you think this test can be used to define an intelligent system accurately?
2. Define an intelligent systems and list two broad categories of agents.
3. Compare and contrast LISP and PROLOG when they are used in artificial intelligence.
4. Describe the need for knowledge representation and list four different methods discussed in this chapter.
5. Compare and contrast predicate logic and propositional logic.
6. Compare and contrast frames and semantic networks.
7. Define a rule-base system and compare it with semantic networks.
8. Compare and contrast expert systems and mundane systems.
9. List different steps in image processing.
10. List different steps in language processing.
11. Define a neural network and how it can simulate the learning process in human beings.
12. Define a perceptron.

### 18.8.3 Problems
1. Draw a semantic network to show the relations between the following: medical doctor, family practitioner, gynecologist, intern, engineer, accountant, Dr. Pascal who is a French family practitioner.
2. Represent the semantic network of Problem P18-1 as a set of frames.
3. Using the symbol R for the sentence ‘It is raining’ and the symbol S for the sentence ‘It is sunny’, write each of the following English sentences in propositional logic:
   a. It is not raining.
   b. It is not sunny.
   c. It is neither raining nor sunny.
   d. It is raining and sunny.
   e. If it is sunny, then it is not raining.
   f. If it is raining, then it is not sunny.
   g. It is sunny if and only if it is not raining.
   h. It is not true that if it is not raining, it is sunny.
4. If the symbols C, W, and H mean ‘it is cold’, ‘it is warm’, and ‘it is hot’, write the English statements corresponding to the following statements in propositional logic:
   a. ¬H
   b. W ∨ H
   c. W ∧ H
   d. W ∧ (¬ H)
   e. ¬ (W ∧ H)
   f. W → H
   g. (¬ C) → W
   h. ¬ (W → H)
   i. H → (¬ W)
   j. ((¬C) ∧ H) ∨ (C ∨ (¬H))
5. Using the symbols Wh, Re, Gr, and Fl for the predicates ‘is white’, ‘is red’, ‘is green’, and ‘is a flower’ respectively, write the following sentences in predicate logic:
   a. Some flowers are white.
   b. Some flowers are not red.
   c. Not all flowers are red.
   d. Some flowers are either red or white.
   e. There is not a green flower.
   f. No flowers are green.
   g. Some flowers are not white.
6. Using the symbols Has, Loves, Dog, and Cat for the predicates ‘has’, ‘loves’, ‘is a dog’, and ‘is a cat’ respectively, write the following sentences in predicate logic:
   a. John has a cat.
   b. John loves all cats.
   c. John loves Anne.
   d. Anne loves some dogs.
   e. Not everything John loves is a cat.
   f. Anne does not like some cats.
   g. If John loves a cat, Anne loves it.
   h. John loves a cat if and only if Anne loves it.
7. Using the symbols Expensive, Cheap, Buys, and Sells for the predicates ‘is expensive’, ‘is cheap’, ‘buys’, and ‘sells’ respectively, write the following sentences in predicate logic:
   a. Everything is expensive.
   b. Everything is cheap.
   c. Bob buys everything that is cheap.
   d. John sells something expensive.
   e. Not everything is expensive.
   f. Not everything is cheap.
   g. If something is cheap, then it is not expensive.
8. Using the symbols Identical for the predicate ‘is identical to’, write the following sentences in predicate logic. Note that the predicate ‘equal’ needs two arguments:
   a. John is not Anne.
   b. John exists.
   c. Anne does not exist.
   d. Something exists.
   e. Nothing exists.
   f. There are at least two things.
9. Use a truth table to find whether the following argument is valid: {P → Q, P} |- Q
10. Use a truth table to find whether the following argument is valid: {P ∨ Q, P} |- Q
11. Use a truth table to find whether the following argument is valid: {P ∧ Q, P} |- Q
12. Use a truth table to find whether the following argument is valid: {P → Q, Q → R} |- (P → R)
13. Draw a neural network that can simulate an OR gate.
14. Draw a neural network that can simulate an AND gate.
15. The initial and goal states of an 8-puzzle are shown in Figure 18.25. Draw the heuristic search tree for solving the puzzle.
16. Show the breadth-first search for the tree diagram shown in Figure 18.26.
17. Show the depth-first search for the tree diagram of Problem P18-16.
18. Draw the tree diagram for the maze shown in Figure 18.27.
19. Draw the tree and show a breadth-first search for Problem P18-18.
20. Draw the tree and show a depth-first search for Problem P18-18.
`,zh:`
# 第十八章：人工智慧

在本書的這一章中，我們介紹**人工智慧 (AI)**。第一節是簡短的歷史並嘗試定義人工智慧。**知識表示**是 AI 中一個廣泛且發展完善的領域，將在下一節討論。然後我們介紹**專家系統**，即在需要但無法獲得人類專業知識時可以替代人類專業知識的系統。接著我們討論如何使用人工智慧來模擬人類在兩個領域的正常（平凡）行為：**影像處理**和**語言分析**。然後我們展示專家系統和平凡系統如何使用不同的搜尋方法來解決問題。最後，我們討論**神經網路**如何模擬智慧代理中的學習過程。

## 學習目標
學完本章後，學生應能：
- 定義並簡述人工智慧的歷史。
- 描述知識如何在智慧代理中表示。
- 展示當無法獲得人類專家時如何使用專家系統。
- 展示如何使用人工代理來模擬人類執行的平凡任務。
- 展示專家系統和平凡系統如何使用不同的搜尋技術來解決問題。
- 展示如何使用創建神經元電子版本（稱為感知器）的神經網路在一定程度上模擬人類的學習過程。

## 18.1 簡介
在本節中，我們首先嘗試非正式地定義**人工智慧 (AI)** 一詞並簡述其歷史。我們還定義了**智慧代理**及其兩大類。最後，我們提到兩種常用於人工智慧的程式語言。

### 18.1.1 什麼是人工智慧？
雖然對於人工智慧沒有普遍認同的定義，但我們接受以下符合本章涵蓋主題的定義：

**人工智慧是研究能夠在一定程度上模擬人類活動（如感知、思考、學習和行動）的程式化系統的學科。**

### 18.1.2 人工智慧簡史
雖然人工智慧作為一個獨立的研究領域相對較新，但它在過去有一些根源。我們可以說它始於 2400 年前，當時希臘哲學家亞里斯多德發明了邏輯推理的概念。完善邏輯語言的努力在萊布尼茲和牛頓那裡繼續進行。喬治·布爾在 19 世紀發展了布林代數（附錄 E），為電腦電路奠定了基礎。然而，思維機器的主要想法來自艾倫·圖靈，他提出了圖靈測試。「人工智慧」一詞最早由約翰·麥卡錫在 1956 年創造。

### 18.1.3 圖靈測試
1950 年，艾倫·圖靈提出了**圖靈測試**，提供了機器*智慧*的定義。該測試簡單地比較人類和電腦的智慧行為。審問者提出一組問題，轉發給電腦和人類。審問者收到兩組回應，但不知道哪一組來自人類，哪一組來自電腦。經過仔細檢查這兩組回應後，如果審問者無法確定哪一組來自電腦，哪一組來自人類，則電腦通過了智慧行為的圖靈測試。

### 18.1.4 智慧代理
**智慧代理**是一個感知其環境、從中學習並與之進行智慧互動的系統。智慧代理可分為兩大類：*軟體代理*和*實體代理*。

**軟體代理**
**軟體代理**是一組設計用於執行特定任務的程式。例如，一些智慧系統可用於組織電子郵件。這種類型的代理可以檢查收到電子郵件的內容並將其分類為不同類別（垃圾郵件、次要、重要、非常重要等等）。軟體代理的另一個例子是用於搜尋全球資訊網並查找可以提供有關請求主題資訊的網站的搜尋引擎。

**實體代理**
**實體代理 (機器人)** 是一個可程式化的系統，可用於執行各種任務。簡單的機器人可用於製造業，執行組裝、焊接或噴漆等常規工作。一些組織使用移動機器人執行遞送工作，例如將郵件或信件分發到不同房間。還有用於水下勘探石油的移動機器人。
人形機器人是一種自主移動機器人，被認為像人類一樣行為。雖然人形機器人在科幻小說中很普遍，但在這些機器人能夠正確地與周圍環境互動並從發生的事件中學習之前，還有很多工作要做。

### 18.1.5 程式語言
雖然一些通用語言如 C、C++ 和 Java 用於創建智慧軟體，但有兩種語言專門為 AI 設計：LISP 和 PROLOG。

**LISP**
**LISP (LISt Programming，列表程式設計)** 由約翰·麥卡錫於 1958 年發明。顧名思義，LISP 是一種操作列表的程式語言。LISP 將資料和程式都視為列表，這意味著 LISP 程式可以更改自身。此功能符合智慧代理可以從其環境中學習並改善其行為的想法。
然而，LISP 的一個缺點是遲緩。如果要處理的列表很長，速度會很慢。另一個缺點是其語法的複雜性。

**PROLOG**
**PROLOG (PROgramming in LOGic，邏輯程式設計)** 是一種可以建立事實資料庫和規則知識庫的語言。PROLOG 程式可以使用邏輯推理來回答可以從知識庫推斷出的問題。然而，PROLOG 不是一種非常有效率的程式語言。一些複雜問題可以使用其他語言（如 C、C++ 或 Java）更有效率地解決。

## 18.2 知識表示
如果人工代理要解決一些與現實世界相關的問題，它需要以某種方式表示知識。事實表示為可以在電腦內部由程式操作的資料結構。在本節中，我們描述四種常見的知識表示方法：*語意網路*、*框架*、*謂詞邏輯*和*規則型系統*。

### 18.2.1 語意網路
**語意網路**由 Richard H. Richens 於 1960 年代初開發。語意網路使用有向圖來表示知識。如第 12 章所述，有向圖由頂點（節點）和邊（弧）組成。語意網路使用頂點表示概念，使用邊（由箭頭表示）表示兩個概念之間的關係（圖 18.1）。

**概念**
為了對概念進行精確定義，專家將概念的定義與集合論聯繫起來。因此，概念可以被認為是一個集合或子集。例如，*動物*定義了所有動物的集合，*馬*定義了所有馬的集合，並且是集合*動物*的子集。物件是集合的成員（實例）。概念由頂點顯示。

**關係**
在語意網路中，關係由邊顯示。邊可以定義*子類別*關係——邊從子類別指向其超類別。邊也可以定義*實例*關係——邊從實例指向它所屬的集合。邊還可以定義物件的*屬性*（顏色、大小...）。最後，邊可以定義物件的屬性，例如擁有另一個物件。在語意網路中可以很好定義的最重要關係之一是*繼承*。繼承關係定義了類別的所有屬性都存在於繼承類別中的事實。這可用於從圖形表示的知識中推斷新知識。

### 18.2.2 框架
**框架**與語意網路密切相關。在語意網路中，圖形用於表示知識：在框架中，資料結構（記錄）用於表示相同的知識。框架相對於語意網路的一個優點是程式可以比語意網路更容易地處理框架。圖 18.2 顯示了如何使用框架實作圖 18.1 中顯示的語意網路。

**物件**
語意網路中的節點成為一組框架中的物件，因此物件可以定義類別、子類別或類別的實例。在圖 18.2 中，*爬行動物*、*哺乳動物*、*狗*、*Roxy* 和 *Ringo* 是物件。

**槽 (Slots)**
語意網路中的邊被轉換為**槽**——資料結構中的欄位。槽的名稱定義關係的類型，槽的值完成關係。例如，在圖 18.2 中，*動物*是*爬行動物*物件中的一個槽。

### 18.2.3 謂詞邏輯
最常見的知識表示是**謂詞邏輯**。謂詞邏輯可用於表示複雜事實。它是一種透過長期的理論邏輯歷史發展而來的定義明確的語言。雖然本節定義謂詞邏輯，但我們先介紹**命題邏輯**，一種更簡單的語言。然後我們討論謂詞邏輯，它採用命題邏輯。

**命題邏輯**
命題邏輯是由一組句子組成的語言，可用於對世界進行邏輯推理。

**運算子**
命題邏輯使用五個運算子，如下所示：
¬ (非), ∨ (或), ∧ (且), → (如果...則), ↔ (若且唯若)

第一個運算子是一元的——運算子只接受一個句子：其他四個運算子是二元的——它們接受兩個句子。每個句子的邏輯值（*真*或*假*）取決於組成複雜句子的原子句子（沒有運算子的句子）的邏輯值。圖 18.3 顯示了命題邏輯中每個邏輯運算子的真值表。真值表在第 4 章介紹並在附錄 E 中解釋。

**句子**
這種語言中的句子遞迴定義如下：
1.  代表自然語言陳述的大寫字母，如 A、B、S 或 T，是一個句子。
2.  兩個常數值（*真*和*假*）中的任何一個都是一個句子。
3.  如果 P 是一個句子，那麼 ¬P 是一個句子。
4.  如果 P 和 Q 是句子，那麼 P ∨ Q, P ∧ Q, P → Q, 和 P ↔ Q 是句子。

> **範例 18.1**
> 以下是命題語言中的句子：
> a. 今天是星期日 (S)。
> b. 正在下雨 (R)。
> c. 今天是星期日或星期一 (S ∨ M)。
> d. 沒有下雨 (¬R)
> e. 如果狗是哺乳動物，那麼貓是哺乳動物 (D → C)

**推論**
在 AI 中，我們需要從現有事實中創建新事實。在命題邏輯中，這個過程稱為**推論**。給定兩個假定為真的句子，我們可以推導出一個新的真句子。前兩個句子稱為*前提*：推導出的句子稱為*結論*。整體稱為*論證*。例如：
*   前提 1：他在家或在辦公室
*   前提 2：他不在家
*   結論：因此，他在辦公室

如果我們用 H 代表「他在家」，O 代表「他在辦公室」，符號 |- 代表「因此」，那麼我們可以將上述論證表示為：
{H ∨ O, ¬H} |- O

問題是我們如何證明演繹論證是*有效*的。有效的演繹論證是指其結論必然源自其前提的論證。換句話說，在有效的演繹論證中，前提全為真而結論為假是不可能的。
一種方法是為前提和結論創建真值表。如果我們可以找到一個*反例*情況：即兩個前提都為真但結論為假的情況，則結論無效。

**如果找不到反例，則論證有效。**

> **範例 18.2**
> 論證 {H ∨ O, ¬H} |- O 的有效性可以使用真值表證明。當 H 為假且 O 為真時，兩個前提都為真，結論也為真。沒有前提為真而結論為假的情況。

> **範例 18.3**
> 論證 {R → C, C} |- R 無效，因為可以找到反例。（R：她很富有，C：她有車）。前提 1：如果她很富有，她就有車。前提 2：她有車。結論：因此，她很富有。
> 反例：她有車（真），但她不富有（假）。前提 1（F → T 為 T）為真，前提 2 為真，但結論為假。

**謂詞邏輯**
在命題邏輯中，表示句子的符號是原子的：它不能被分解以查找有關其組件的資訊。例如，考慮句子：
P1：「Linda 是 Mary 的母親」
P2：「Mary 是 Anne 的母親」
我們可以以多種方式組合這兩個句子來創建其他句子，但我們無法提取 Linda 和 Anne 之間的任何關係。例如，我們無法從上述兩個句子推斷出 Linda 是 Anne 的祖母。為此，我們需要謂詞邏輯：定義命題中各部分之間關係的邏輯。

在謂詞邏輯中，句子分為謂詞和引數。例如，以下每個命題都可以寫成帶有兩個引數的謂詞：
P1：「Linda 是 Mary 的母親」變為 **mother (Linda, Mary)**
P2：「Mary 是 Anne 的母親」變為 **mother (Mary, Anne)**

上述每個句子中的母性關係由謂詞 *mother* 定義。如果兩個句子中的物件 *Mary* 指的是同一個人，我們可以推斷出 Linda 和 Anne 之間的新關係：**grandmother (Linda, Anne)**。這就是謂詞邏輯的全部目的。

**句子**
謂詞語言中的句子定義如下：
1.  帶有 n 個引數的謂詞，如 *predicate_name (argument1, ..., argumentn)* 是一個句子。*predicate_name* 將引數相互關聯。每個引數可以是：
    a. 常數，如 *human*、*animal*、*John*、*Mary*。
    b. 變數，如 *x*、*y* 和 *z*。
    c. 函數，如 *mother (Anne)*。請注意，函數是用作引數的謂詞：函數回傳一個可以代替引數的物件。
2.  兩個常數值（*真*和*假*）中的任何一個都是一個句子。
3.  如果 P 是一個句子，那麼 ¬P 是一個句子。
4.  如果 P 和 Q 是句子，那麼 P ∨ Q, P ∧ Q, P → Q, 和 P ↔ Q 是句子。

> **範例 18.4**
> 1. 句子「John 為 Ann 的姐姐工作」可以寫成：**works [John, sister (Ann)]**
> 2. 句子「John 的父親愛 Ann 的姐姐」可以寫成：**loves [father (John), sister (Ann)]**

**量詞**
謂詞邏輯允許我們使用**量詞**。謂詞邏輯中常見兩個量詞：∀ 和 ∃。
1.  第一個，**∀**，讀作「對於所有」，稱為**全稱量詞**：它聲明對於其變數所代表的每個物件，某事都是真的。
2.  第二個，**∃**，讀作「存在」，稱為**存在量詞**：它聲明對於其變數所代表的一個或多個物件，某事是真的。

> **範例 18.5**
> 1. 「所有人都會死」：∀x [man (x) → mortal (x)]
> 2. 「青蛙是綠色的」：∀x [frog (x) → green (x)]
> 3. 「有些花是紅色的」：∃x [flower (x) ∧ red(x)]
> 4. 「John 有一本書」：∃x [book (x) ∧ has (John, x)]
> 5. 「沒有青蛙是黃色的」：∀x[frog (x) → ¬yellow (x)] 或 ¬∃x [frog (x) ∧ yellow (x)]

**推論**
在謂詞邏輯中，如果沒有量詞，論證的驗證與我們在命題邏輯中討論的相同。然而，如果有量詞，驗證會變得更加複雜。
前提 1：所有人都會死。
前提 2：蘇格拉底是人。
結論：因此，蘇格拉底會死。
驗證：∀x [man (x) → mortal (x)] , man (Socrates) |- mortal (Socrates)

**超越謂詞邏輯**
邏輯已有進一步發展以包含邏輯推理的需求。其中一些例子包括高階邏輯、預設邏輯、模態邏輯和時序邏輯。
- **高階邏輯**：將量詞的範圍擴展到謂詞本身（例如 ∀P）。
- **模態邏輯**：包括諸如「可以」、「應該」、「可能」、「或許」、「應當」等表達式。
- **時序邏輯**：用諸如「從現在開始」之類的時序運算子擴展謂詞邏輯。
- **預設邏輯**：假設預設結論，除非有相反的證據（例如，鳥會飛）。

### 18.2.4 規則型系統
**規則型系統**使用一組規則來表示知識，這些規則可用於從已知事實推斷出新事實。規則表達了如果滿足特定條件什麼是真的。規則型資料庫是一組如果...則...陳述式，形式為
**如果 A 則 B** 或 **A → B**
其中 A 稱為*前件*，B 稱為*後件*。請注意，在規則型系統中，每個規則都是獨立處理的，與其他規則沒有任何連接。

**組件**
規則型系統由三個組件組成：**直譯器**（或**推論引擎**）、**知識庫**和**事實資料庫**，如圖 18.4 所示。

**知識庫**
規則型系統中的知識庫組件是規則的資料庫（儲存庫）。它包含一組預先建立的規則，可用於從給定事實得出結論。

**事實資料庫**
事實資料庫包含一組條件，由知識庫中的規則使用。

**直譯器**
直譯器（推論引擎）是一個處理器或控制器——例如程式——結合規則和事實。直譯器有兩種類型：**前向鏈接**和**後向鏈接**。

**前向鏈接**
**前向鏈接**是直譯器使用一組規則和一組事實來執行動作的過程。動作可以只是向事實庫添加新事實，或發出一些命令。直譯器解釋並執行規則，直到沒有更多規則可以解釋。
如果存在衝突，即兩個不同的規則可以應用於一個事實，或一個規則可以應用於兩個事實，系統需要呼叫衝突解決程序。

**後向鏈接**
如果系統試圖證明一個結論，前向鏈接效率不高。必須檢查所有事實的所有規則才能得出給定的結論。在這種情況下，如果使用**後向鏈接**可能會更有效率。過程從結論（目標）開始。如果目標已經在事實資料庫中，過程停止，結論被證明。如果目標不在事實資料庫中，系統找到在其結論中具有目標的規則。然而，後向鏈接現在應用於規則中的每個事實（遞迴），而不是觸發該規則。

## 18.3 專家系統
**專家系統**使用上一節討論的知識表示語言來執行通常需要人類專業知識的任務。它們可用於專業知識短缺、昂貴或在需要時無法獲得的情況。例如，在醫學中，專家系統可以將一組症狀縮小到可能的病因集，這通常是由醫生執行的任務。

### 18.3.1 提取知識
專家系統建立在其專業領域的預定義知識之上。因此，建立專家系統的第一步是從人類專家那裡提取知識。這個提取的知識成為知識庫。
從專家那裡提取知識通常是一項困難的任務，因為知識通常是啟發式的（基於機率而非確定性）和直覺的。知識提取過程通常由*知識工程師*完成。

### 18.3.2 提取事實
為了能夠推斷新事實或執行動作，除了知識庫外還需要事實資料庫。專家系統中的事實資料庫是基於案例的，其中收集或測量的事實被輸入系統供推論引擎使用。

### 18.3.3 架構
圖 18.7 顯示了專家系統架構背後的一般想法。專家系統最多可以有七個組件：使用者、使用者介面、推論引擎、知識庫、事實資料庫、解釋系統和知識庫編輯器。
**推論引擎**是專家系統的心臟。七個組件中的四個——使用者介面、推論引擎、解釋系統和知識庫編輯器——可以製作一次並用於許多應用程式，因為它們不依賴於特定的知識庫或事實資料庫。這些組件構成了**專家系統外殼**。

- **使用者介面**：允許使用者與系統互動。
- **推論引擎**：使用知識庫和事實資料庫來推斷動作。
- **知識庫**：基於專家訪談的規則集合。
- **事實資料庫**：使用者輸入的基於案例的資料。
- **解釋系統**：解釋決策背後的理由。
- **知識庫編輯器**：用於更新知識庫。

## 18.4 感知
人工智慧的目標之一是創造一台行為像普通人的機器。**感知**是理解透過感官（視覺、聽覺、觸覺、嗅覺、味覺）接收到的內容。智慧代理應該能夠感知它是否需要像人類一樣行動。AI 特別涉及兩種類型的感知，視覺和聽覺。

### 18.4.1 影像處理
**影像處理**或**電腦視覺**是 AI 的一個領域，處理透過代理的人造眼睛（如相機）對物體的感知。影像處理器從外部世界獲取二維影像，並試圖創建場景中存在的三維物體的描述。處理器使用包含物體特徵的資料庫進行比較。

**邊緣偵測**
影像處理的第一階段是**邊緣偵測**：找出影像中的邊緣在哪裡。邊緣可以定義物體與其背景之間的邊界。邊緣顯示表面、深度或照明的不連續性。可以透過尋找強度差異大的相鄰像素來偵測邊緣。

**分割**
**分割**是影像分析的下一個階段。分割將影像劃分為同質的區段或區域。同質區域是像素強度平滑變化的區域。分割找出物體內部不同區域之間的邊界。存在幾種方法，如*閾值化*、*分裂*和*合併*。

**尋找深度**
下一步是找出影像中物體的深度。深度尋找可以幫助智慧代理判斷物體離它有多遠。
- **立體視覺**：使用兩隻眼睛或兩台相機。如果物體很近，兩個影像不同；如果很遠，它們幾乎相同。
- **運動**：當一個或多個物體移動時創建多個影像。移動物體相對於其他物體的相對位置提供了距離的線索。

**尋找方向**
可以使用兩種技術找出場景中物體的方向：*陰影*和*紋理*。
- **陰影**：從表面反射的光量取決於表面相對於光源的方向。
- **紋理**：有規律重複的圖案可以幫助找出方向或曲率。

**物體辨識**
最後一步是**物體辨識**。為了辨識物體，代理需要在記憶體中有物體的模型進行比較。一種解決方案是假設物體是由一組簡單的**原始幾何形狀**（塊、圓柱體、圓錐體等）組成的複合體。當代理「看到」一個物體時，它試圖將物體分解為原始形狀的組合。

### 18.4.2 語言理解
人類固有的能力之一是理解——即解釋——他們感知到的音訊信號。能夠理解**自然語言**的機器非常有用。我們可以將任務分為四個連續步驟：語音辨識、句法分析、語意分析和語用分析。

**語音辨識**
第一步是**語音辨識**。分析語音信號（類比）並提取其中包含的單詞序列。信號需要被分成不同的聲音，有時稱為*音素*。

**句法分析**
**句法分析**步驟用於定義單詞如何在句子中分組。
- **文法**：正確分析句子的第一個工具是定義明確的文法。
- **解析器**：決定句子在文法（句法）上是否正確的機器不需要在拒絕句子為無效之前檢查所有可能的選擇。這是由**解析器**完成的，它根據文法規則創建**解析樹**。

**語意分析**
**語意分析**在句子經過句法分析後提取其含義。此分析創建了句子中涉及的物件、它們的關係及其屬性的表示。

**語用分析**
需要**語用分析**來進一步闡明句子的目的並消除歧義。
- **目的**：確定句子是請求、詢問等。
- **消除歧義**：解決單詞具有多種功能或含義，或句法正確的句子是無意義的情況下的歧義。

## 18.5 搜尋
人工智慧中解決問題的技術之一是**搜尋**。搜尋可以描述為使用一組**狀態**（一種情況）來解決問題。搜尋程序從**初始狀態**開始，經過**中間狀態**，直到最終達到**目標狀態**。搜尋過程使用的所有狀態的集合稱為**搜尋空間**。
範例：八數位推盤。

### 18.5.1 搜尋方法
有兩種一般的搜尋方法：*暴力*和*啟發式*。暴力方法本身又是*廣度優先*或*深度優先*。

**暴力搜尋**
如果我們對搜尋沒有任何先驗知識，我們使用**暴力搜尋**。
- **廣度優先搜尋**：我們從樹的根開始，檢查每一層的所有節點，然後再移動到下一層。這保證在解存在時找到解並找到最短路徑，但效率低。
- **深度優先搜尋**：我們從根開始，進行前向搜尋，直到達到目標或死胡同。如果我們遇到死胡同，我們**回溯**到最近的分支並再次進行前向搜尋。

**啟發式搜尋**
使用**啟發式搜尋**，我們為每個節點分配一個稱為**啟發式值 (h 值)** 的定量值。此定量值顯示節點與目標狀態的相對接近程度。例如，在八數位推盤中，啟發式值可以是方塊到達其目標位置所需的最小移動次數。我們從 *h* 值較小（更接近目標）的狀態開始，並以這種方式繼續。

## 18.6 神經網路
如果智慧代理要像人類一樣行為，它可能需要學習。大多數方法使用**歸納學習**或**範例學習**。這意味著給機器一大組問題及其解決方案以供學習。**神經網路**試圖使用神經元網路模擬人腦的學習過程。

### 18.6.1 生物神經元
人腦有數十億個處理單元，稱為**神經元**。神經元由三部分組成：**細胞體**、**軸突**和**樹突**。樹突充當輸入設備；軸突充當輸出設備。**突觸**是連接點。神經元可以處於兩種狀態之一：*興奮*（發射輸出）或*抑制*。

### 18.6.2 感知器
**感知器**是類似於單個生物神經元的人工神經元。它獲取一組加權輸入，對輸入求和，並將結果與**閾值**進行比較。如果結果高於閾值，感知器發射（輸出 1），否則不發射（輸出 0）。
$S = (x_1 \\cdot w_1 + x_2 \\cdot w_2 + ...)$
如果 $S > T$，則 $y = 1$；否則 $y = 0$。
可以透過根據已知範例的正確或錯誤輸出調整權重來訓練感知器。

### 18.6.3 多層網路
可以組合幾層感知器來創建**多層神經網路**。每層的輸出成為下一層的輸入。第一層是**輸入層**，中間層稱為**隱藏層**，最後一層是**輸出層**。

### 18.6.4 應用
當存在足夠的預先建立的輸入和輸出以訓練網路時，可以使用神經網路。應用包括**光學字元辨識 (OCR)** 和信用評估（建立信用評級）。

## 18.7 章末材料
### 18.7.1 推薦閱讀
- Cawsey, A. *The Essence of Artificial Intelligence*, Upper Saddle River, NJ: Prentice-Hall, 1998
- Luger, G. *Artificial Intelligence: Structures and Strategies for Complex Problem Solving*, Reading, MA: Addison-Wesley, 2004
- Winston, P. *Artificial Intelligence*, Reading, MA: Addison-Wesley, 1993
- Coppin, B. *Artificial Intelligence Illuminated*, Sudbury, MA: Jones and Bartlett, 2004
- Russel, S. and Norvig, P. *Artificial Intelligence: A Modern Approach*, Upper Saddle River, NJ: Prentice-Hall, 2003
- Dean, T. *Artificial Intelligence: Theory and Practice*, Redwood City, Reading, MA: Addison-Wesley, 2002

### 18.7.2 關鍵詞
- 人工智慧
- 軸突
- 暴力搜尋
- 廣度優先搜尋
- 深度優先搜尋
- 專家系統
- 框架
- 啟發式搜尋
- 影像處理
- 智慧代理
- LISP
- 神經網路
- 神經元
- 感知器
- 實體代理
- 語用分析
- 謂詞邏輯
- PROLOG
- 搜尋空間
- 分割
- 語意分析
- 語意網路
- 軟體代理
- 細胞體
- 語音辨識
- 突觸
- 句法分析
- 時序邏輯
- 閾值化
- 圖靈測試

### 18.7.3 摘要
- 人工智慧是研究能夠模擬人類活動（如感知、思考、學習和行動）的程式化系統的學科。圖靈測試比較人類和電腦的智慧行為。
- 智慧代理是一個感知其環境、從中學習並與之互動的系統。代理可以是軟體代理或實體代理（機器人）。
- 知識表示方法包括語意網路、框架、謂詞邏輯和規則型系統。語意網路使用圖形；框架使用資料結構。謂詞邏輯使用邏輯推理。規則型系統使用規則來推斷新事實。
- 專家系統執行通常需要人類專業知識的任務。它們從專家那裡提取知識並使用推論引擎做出決策。
- 感知涉及理解感官輸入。影像處理處理視覺感知（邊緣偵測、分割、深度尋找、物體辨識）。語言理解涉及語音辨識、句法分析、語意分析和語用分析。
- 搜尋是一種透過在搜尋空間中的狀態之間移動來解決問題的技術。暴力搜尋（廣度優先、深度優先）系統地探索。啟發式搜尋使用經驗法則更快地找到解決方案。
- 神經網路使用稱為感知器的人工神經元（通常排列在多層網路中）來模擬人腦的學習過程。它們透過範例學習（歸納學習）。

## 18.8 練習題
### 18.8.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 18.8.2 複習問題
1. 描述圖靈測試。您認為此測試可用於準確定義智慧系統嗎？
2. 定義智慧系統並列出兩大類代理。
3. 比較 LISP 和 PROLOG 在人工智慧中的使用。
4. 描述知識表示的需求並列出本章討論的四種不同方法。
5. 比較和對比謂詞邏輯和命題邏輯。
6. 比較和對比框架和語意網路。
7. 定義規則型系統並將其與語意網路進行比較。
8. 比較和對比專家系統和平凡系統。
9. 列出影像處理的不同步驟。
10. 列出語言處理的不同步驟。
11. 定義神經網路以及它如何模擬人類的學習過程。
12. 定義感知器。

### 18.8.3 問題
1. 畫一個語意網路來顯示以下之間的關係：醫生、家庭醫生、婦科醫生、實習生、工程師、會計師、Pascal 博士（一位法國家庭醫生）。
2. 將問題 P18-1 的語意網路表示為一組框架。
3. 使用符號 R 代表句子「正在下雨」，符號 S 代表句子「陽光普照」，用命題邏輯寫出以下每個英語句子：
   a. 沒有下雨。
   b. 沒有陽光普照。
   c. 既沒下雨也沒陽光普照。
   d. 正在下雨且陽光普照。
   e. 如果陽光普照，就沒有下雨。
   f. 如果正在下雨，就沒有陽光普照。
   g. 若且唯若沒有下雨時，陽光普照。
   h. 如果沒有下雨就是陽光普照，這不是真的。
4. 如果符號 C、W 和 H 分別表示「很冷」、「很溫暖」和「很熱」，寫出對應於以下命題邏輯陳述式的英語陳述：
   a. ¬H
   b. W ∨ H
   c. W ∧ H
   d. W ∧ (¬ H)
   e. ¬ (W ∧ H)
   f. W → H
   g. (¬ C) → W
   h. ¬ (W → H)
   i. H → (¬ W)
   j. ((¬C) ∧ H) ∨ (C ∨ (¬H))
5. 分別使用符號 Wh、Re、Gr 和 Fl 代表謂詞「是白色的」、「是紅色的」、「是綠色的」和「是一朵花」，用謂詞邏輯寫出以下句子：
   a. 有些花是白色的。
   b. 有些花不是紅色的。
   c. 並非所有花都是紅色的。
   d. 有些花是紅色或白色的。
   e. 沒有綠色的花。
   f. 沒有花是綠色的。
   g. 有些花不是白色的。
6. 分別使用符號 Has、Loves、Dog 和 Cat 代表謂詞「有」、「愛」、「是狗」和「是貓」，用謂詞邏輯寫出以下句子：
   a. John 有一隻貓。
   b. John 愛所有的貓。
   c. John 愛 Anne。
   d. Anne 愛一些狗。
   e. John 愛的不是所有東西都是貓。
   f. Anne 不喜歡一些貓。
   g. 如果 John 愛一隻貓，Anne 也愛它。
   h. 若且唯若 Anne 愛一隻貓時，John 才愛它。
7. 分別使用符號 Expensive、Cheap、Buys 和 Sells 代表謂詞「是昂貴的」、「是便宜的」、「買」和「賣」，用謂詞邏輯寫出以下句子：
   a. 所有東西都很貴。
   b. 所有東西都很便宜。
   c. Bob 買所有便宜的東西。
   d. John 賣一些昂貴的東西。
   e. 並非所有東西都很貴。
   f. 並非所有東西都很便宜。
   g. 如果某樣東西便宜，它就不貴。
8. 使用符號 Identical 代表謂詞「等同於」，用謂詞邏輯寫出以下句子。請注意，謂詞「equal」需要兩個引數：
   a. John 不是 Anne。
   b. John 存在。
   c. Anne 不存在。
   d. 某物存在。
   e. 沒有東西存在。
   f. 至少有兩樣東西。
9. 使用真值表找出以下論證是否有效：{P → Q, P} |- Q
10. 使用真值表找出以下論證是否有效：{P ∨ Q, P} |- Q
11. 使用真值表找出以下論證是否有效：{P ∧ Q, P} |- Q
12. 使用真值表找出以下論證是否有效：{P → Q, Q → R} |- (P → R)
13. 畫一個可以模擬 OR 閘的神經網路。
14. 畫一個可以模擬 AND 閘的神經網路。
15. 8 數位推盤的初始狀態和目標狀態如圖 18.25 所示。畫出解決該難題的啟發式搜尋樹。
16. 顯示圖 18.26 所示樹狀圖的廣度優先搜尋。
17. 顯示問題 P18-16 樹狀圖的深度優先搜尋。
18. 畫出圖 18.27 所示迷宮的樹狀圖。
19. 畫出樹狀圖並顯示問題 P18-18 的廣度優先搜尋。
20. 畫出樹狀圖並顯示問題 P18-18 的深度優先搜尋。
`},v={en:`
# Chapter 19: Introduction to Social Media

In this chapter, we briefly touch on **social media** as one of the applications of computer science. Our goal is not to show how to use social media; many students know and use social media in their daily lives. Our goal is primarily to show the concepts behind social media and how these websites are designed for this purpose. We will discuss only two, **Facebook** and **Twitter**, each as an example of a particular social media type.

## Objectives
After studying this chapter, the student should be able to:
- Define the *friendship* relationship in Facebook.
- Define the two-way relationship between friends in Facebook.
- Understand the communication channels in Facebook.
- Know how to become a member and how to terminate membership in Facebook.
- Know how to log in and log out of Facebook.
- Know how to find friends in Facebook.
- Know how to communicate with friends in Facebook.
- Define the *following* relationship in Twitter.
- Define the one-way relationship between members and followers in Twitter.
- Understand the communication channels in Twitter.
- Know how to become a member and how to terminate membership in Twitter.
- Know how to log in and log out of Twitter.
- Know how to follow other members in Twitter.
- Know how to communicate with followers in Twitter.

## 19.1 INTRODUCTION
In the last century, when computer science started as a discipline, we could never have imagined that it would become a part of our daily life in such a short period of time. One of the areas in which computer science has helped all citizens is with the advent of *social media*. Today most people around the world are, to a greater or lesser extent, involved with one or more types of social media, which can be considered a computer science application. Social media is in fact the result of using several computer science disciplines including operating systems, computer programming, computer networks, and databases.

Social media platforms are websites on a large scale, designed to let people exchange their ideas, opinions and experiences. Some are designed primary for exchanging messages or pictures; some are designed to let job seekers find employers, and employers find employees.

A discussion of all types of social media would take a book by itself. In this chapter, therefore, we look at only two of them: Facebook and Twitter. We have chosen these two because the concepts behind Facebook or Twitter are duplicated, more or less, in several other sites.

## 19.2 FACEBOOK
Facebook is a **social media** that allows families and friends around the world to keep in touch with each other and share thoughts, pictures, comments, and so on.

**Facebook allows members to share thoughts, pictures and comments.**

### 19.2.1 General idea
Before explaining how to use Facebook, let us consider the general ideas behind it.

**Friendship**
In Facebook, sharing is done only between **friends**. **Friendship** is a one-to-one reciprocal relationship. If John is a friend of Lucie, Lucie is also a friend of John. However, the relationship does not propagate; if John is a friend of Lucie and Lucie is a friend of Ann, it does not necessarily mean that John is a friend of Ann. To be so, John or Ann needs to request friendship from the other.

**In Facebook, a friend of a friend is not necessarily a friend.**

Although there are billions of members in Facebook, we will assume for the purposes of this discussion that it has only eight members (Ml to M8), as shown in Figure 19.1.

Now assume that the following requests for friendship are made and are all accepted by the other members:
1. Ml requests friendship from M2.
2. M2 requests friendship from M5.
3. M3 requests friendship from M2.
4. M4 requests friendship from M7.
5. M6 requests friendship from M3.
6. M7 requests friendship from M6.
7. M8 requests friendship from M2.

Figure 19.2 shows the friendship relationships between the eight members. Note that Facebook holds the information about each member, but adds a link between two friends after the friendship has been requested and approved.

**Communication**
Although friendship between members is a two-way relationship, we can think of communication as a one-way (one-to-many) relationship: one member posts something, and all their friends can see it, as shown in Figure 19.3:
a. What is posted by Ml can be seen by M2.
b. What is posted by M2 can be seen by Ml, M3, M5, and M8.
c. What is posted by M3 can be seen by M2 and M6.
d. What is posted by M4 can be seen by M7.
e. What is posted by M5 can be seen M2.
f. What is posted by M6 can be seen by M3 and M7.
g. What is posted by M7 can be seen by M4 and M6.
h. What is posted by M8 can be seen by M2.

### 19.2.2 Web pages
Facebook uses several pages, but the two used most often are the home page and the general page. Let us show these two pages before explaining how to use them.

**Home page**
The **home page** is used only for sign-up (enrolling) and log-in (accessing) Facebook. The general format is shown in Figure 19.4.

**User page**
The **user page** is the main page you will use on Facebook. The page is fairly complex, but the general format is shown in Figure 19.5. Note that your page always has a toolbar as the first row. It has three columns, but the two columns on the left can be scrolled to show more options.

### 19.2.3 Membership
You need to be a member of Facebook to use it. To become a member, you need to sign up. To terminate your membership, you need to sign out or deactivate your account.

**Sign up**
To become a member of Facebook (which is free), you need to go to the Facebook home page (www.facebook.com) as shown in Figure 19.4. You can then use the following steps to sign up.
1. Ignore the *log-in* section (first row) and go to the *sign-up* section.
2. Enter your first and last name in the corresponding boxes.
3. Enter your email or mobile number in the corresponding box.
4. Re-enter your email or mobile number in the corresponding box.
5. Select your data of birth (Month, Day, Year).
6. Check your gender button.
7. Click on the sign-up button.

**Sign out (deactivation)**
To permanently deactivate your account in Facebook, go to your home page (Figure 19.5) and do the following:
1. Click the down arrow on the far right of the tool bar.
2. In the submenu that appears, click on *Settings*.
3. Click on *Security*.
4. Choose *Deactivate your account* and follow the steps to confirm it.

### 19.2.4 Accessing services of Facebook
Even if you have signed up as a member, whenever you want to use Facebook, you need to *log in*. When you do not want to use it for a while, you can *log out*.

**Log in**
To log in into your account, go to the Facebook home page at www.facebook.com (Figure 19.5). In the first row, type your email or mobile number, type your password, and click on the log-in button. You will see your page, which means you can now use Facebook.

**Log out**
Whenever you are not using your Facebook page for a while, you can log out. On the toolbar of user page (your page) (Figure 19.5) click on the down arrow to see the menu. Then click on the log-out button.

### 19.2.5 Friends
As described above, the whole idea of using Facebook is to keep in touch with *friends*. If you post something on the Facebook site, you need to have friends to see it. If you want to see what another member posts, you have to be one of her friends. In other words, you need to find friends and let other members find you as a friend before you can start to communicate through Facebook.

**Finding friends**
There are several ways of finding friends in Facebook.

**Accept Facebook recommendation**
You can accept a Facebook recommendation, based on the information you provided during sign-up. To accept a recommendation, go to the toolbar of your page (Figure 19.5) and click on the *find friend* button, which displays a list of people whom you may know. The list is divided into several categories (eg people you may know, mutual friends, people from your home town, current city, high school, college or university, employer etc) that you can scroll through to choose from. In each category, you can select people with whom you want to be friends and click the *add friend* button in front of their name.

**Follow email contacts**
You can **follow** people who regularly contact you by email. On your home page toolbar (Figure 19.5) click on the *friend* icon (two faces next to *find friend* button). Facebook displays a page with different email icons. Choose the appropriate one and type your email and password to see a list of individuals who communicate with you by email. If you want someone on this list to be your Facebook friend, click on the *add friend* button.

**Find people you know**
At the left side of your home page toolbar (Figure 19.5) type the member name and click on the search icon. Facebook shows the list of members with that name. If you find someone you know, click on the name to see their profile page. If you want that person to be your Facebook friend, click on the *add friend* button.

**Accept friendship from other members**
Other members may want to add you as their friends. In this case, you may accept or decline friendship when you receive the request. On the toolbar, click on the *friend request* button. You will see the profile for every member who has sent you a request to be your friend. You can click the *confirm* or *decline* button in front of the member name to accept or reject the invitation.

**Unfriend a friend**
You can remove any member from your friends list at any time. To do so, click on your profile picture on your home page toolbar (Figure 19.5). Click the *friends* button under your name to see the list of your friends. Scroll down until you see the name of a member that you want to unfriend. Then click on the *unfriend* button.

### 19.2.6 Exchanging information
The whole purpose of Facebook is to allow friends to exchange news (texts, photos, videos etc). To receive your friends’ posts, go to your *news feed* where they will appear. To send news to your friends, you need to *update your status*. We will briefly show these two activities.

**Reading news**
To see what news your friends have posted, go the toolbar (Figure 19.5) and click on the *home* button. You will see all the new posts made by your friends. Each post includes the name of your friend, the date it was posted, and the contents. They may also contain links to web pages. Posted photos will also appear there, but you may want to make them larger by clicking on them. If there are videos in the posts, a thumbnail appears in the body of the news feed with the *play* arrow; click it to play the video.

**Commenting on posted updates**
At the top of each item of posted news (called an update), there is a *like* button that you can click on to show that you like the post.

**Sharing posted updates**
Click the *share* button underneath the original post to see a new window. Enter any comments you want to make about the post in the new window and then click the *share* button in the new window. In this way, you can post what you have received to your own friends.

**Posting news**
Facebook allows you to post news (called updates) for your friends. This can be a long message (up to 60000 characters), a link to a web page, a photo, or a video.

**Posting news**
To post **news**, go to the toolbar (Figure 19.5) and click on the *home* button to see the posting window. The *update status* will be selected by default. Click on the *what’s on your mind* button and type your news. Then click the *post* button to post the news for your friends.

**Posting photos or videos**
In the posting window (see Posting News paragraph), click on the *add photos/video* button and then select the right-hand button to post your photos or videos.

**Tagging**
If you want to mention a friend in your post, you can *tag* that friend. To do so, you need to click on the *tag* button (picture of a head) and then select the name of the friend from the list.

**Limiting who can see your post**
Generally, when you post something on Facebook, all Facebook members can see it. You can restrict this just to your friends or even just to yourself. In the *status update* window (see Posting News paragraph), click the button *public* to let anyone see the post, click the *friends* button so that only your friends see the post, or click the *only me* button so that no one except you sees the post.

## 19.3 TWITTER
**Twitter** is a social network that allows members to post a short message, called a **tweet**, of a maximum 140 characters, for their followers to see.

**Twitter allows members to post a tweet for their followers.**

### 19.3.1 General idea
Before showing how to use Twitter, let us discuss the general idea behind this social media site.

**Member–followers relationship**
In Twitter, the relationship is between members and their followers; a one-to-many relationship. A group of Twitter members follow the member they like; the followed member may not even know who their followers are. This is similar to the relationship between a celebrity and her followers: the followers are interested in what the celebrity does, but the celebrity probably does not know who these followers are.

Let us assume that we have eight members registered on the Twitter site as shown in Figure 19.6. Now assume some members decide to follow other members as shown below:
1. M1 follows M2 and M5.
2. M2 follows M3.
3. M3 follows M4 and M5.
4. M4 follows M3 and M8.
5. M5 follows M2 and M6.
6. M6 follows M8.
7. M7 follows M3.
8. M8 follows M7.

Figure 19.7 shows the new one-way relationships (follower–followed).

**Communication**
In Twitter, it is also easier to think of communication as a one-to-many relationship. A member posts a tweet for her followers. Figure 19.8 shows this scenario.
a. M1 has no followers. This means that what is posted by M1 can be seen by no one.
b. M2 has M1 and M5 as followers. This means that what is posted by M2 can be seen by M1 and M5.
c. M3 has M2, M4, and M7 as followers. This means that what is posted by M3 can be seen by M2, M4, and M7.
d. M4 has M3 as a follower. This means that what is posted by M4 can be seen by M3.
e. M5 has M1 and M3 as followers. This means that what is posted by M5 can be seen by M1 and M3.
f. M6 only has M5 as a follower. This means that what is posted by M6 can be seen only by M5.
g. M7 has no followers. This means that what is posted by M7 can be seen by no one.
h. M8 has M4 and M6 as follower. This means what is posted by M8 can be seen by M4 and M6.

### 19.3.2 Pages
The Twitter website has several pages, but the two used primarily are the *web page* and the *home page*. Other pages can be reached from one of these two pages. Let us describe these two pages before explaining how to use them.

**Web page**
The **web page** is used for joining Twitter for the first time or when you want to log into your account (Figure 19.9)

**Home page**
The **home page** is used when you have already have an account with Twitter and you want to use it. The general format of this page is shown in Figure 19.10.

### 19.3.3 Membership
As with any social media, you need to sign up to become a member (Figure 19.9). If you want to deactivate your account you need to sign out (Figure 19.10).

**Sign up**
To become a member of Twitter, go to www.twitter.com to find the Twitter web page, as shown in Figure 19.9. Then click on the *sign-up* button to see the sign-up window as shown in Figure 19.11.
In the sign-up window give your full name, your phone number or email, and your password. Now click the *sign-up* button to join as a member.

**Sign out (deactivation)**
To permanently deactivate your account in Twitter, go to the Twitter home page (Figure 19.10) and do the following:
1. Click the *profile* and *settings* icons.
2. When the new window opens, click on the *settings* and *privacy* buttons.
3. When the new window opens, click on the *deactivate my account* button.

### 19.3.4 Accessing services of Twitter
Even if you are a member, whenever you want to use Twitter, you need to *log in*. When you do not want to use it for a while, you can *log out*.

**Log in**
When you are a member, you can log in to your account from any computer or smartphone. On the Twitter web page (Figure 19.9), click on the *log-in* button to see the log-in window as shown in Figure 19.12.
In the log-in window, give your full name, your phone number or email, and your password. Now click the *log-in* button. You can now use Twitter.

**Log out**
To log out of your account in Twitter, go to the Twitter home page (Figure 19.10) and do the following:
1. Click the *profile* and *settings* icons.
2. When the new window opens, click on the *log-out* button.

### 19.3.5 Following and being followed
The whole idea of Twitter is to enable members and their followers to communicate. Members can receive tweets if they follow other members. If members have followers, they can send useful tweets which will be received by their followers.

**You need to follow other members**
If you want to receive tweets from certain members, you need to let Twitter know that you want to **follow** them. There is no need to get permission from the member you want to follow (unless they explicitly ask Twitter to block you as one of their followers). If you enter the names of the members you want to follow, Twitter creates a list of them in your profile and every time any of these members sends a tweet, you will get a copy. The question is: how do you tell Twitter who you want to follow? There are several ways to do this.

**Accept Twitter recommendation**
You can accept Twitter’s recommendation (based on your past activity and interests). To do this, go to the bottom left section of the Twitter home page, the *who to follow* window, as shown in Figure 19.13 and click the *view-all* button to see Twitter’s recommendations. To learn more about any of these members, click on the @name. To follow a member, click the *follow* button.

**Follow email contacts**
You can follow people who regularly contact you by email. On the *who to follow* page (Figure 19.13) click on the *find friends* button (at the bottom of the right-hand column). A list of email providers appears on the next window, from which you can choose those friends who communicate with you via those email providers.

**Search for specific people or organizations**
On the *who to follow* section (Figure 19.13) click the *view all* button. When the new window opens, enter either the actual name or the Twitter name of the person or organization you are looking for. Now click the *search* button. If an individual or organization with that name is a Twitter member, you can choose to follow them.

**Stop following a member**
You may for some reason want to stop receiving tweets from a member. To do so, you must unfollow them. Go to the Twitter home page, click on the *following* link. Move the mouse over the *follow* button for that member and change it to *unfollow* button.

**Other members following you**
If you want your tweets to be read, you need to have followers to receive them. However, you cannot choose your followers; they have to find you and decide to follow you. They do not need to get your approval to follow you, but if you wish to, you can inform Twitter that you want to block a specific follower.

### 19.3.6 Sending tweets
Although you do not know all your followers personally—they have selected you, you have not selected them—and cannot communicate with them directly, Twitter has a list of your followers. To send a tweet to your followers, just post it on your Twitter page and the site will send it to all your followers.

**Compose a new tweet**
The first thing you need to know is how to compose a new tweet. This can be done as follows (see Figure 19.14).
1. Click the *tweet* button on any Twitter web page to see the *compose new tweet* panel.
2. In the *compose new tweet* panel, type your message.
3. Click the *tweet* button at the bottom of the page to post your tweet.
4. Twitter takes your tweet and adds your profile, including your name, at the top of the tweet.
5. Twitter then sends a copy to all your followers.

**Referring to other people’s tweets**
In any tweets you send, you can also refer to the tweets of other users. This can be done in two ways: by using **ampersands** and/or by using **hashtags**.

**Using ampersands**
When you are sending a tweet to your followers, if you want to refer to the tweets of another user, you can insert the name of that user preceded by an ampersand (@). Any of your followers can click on the name to see tweets posted by that user.

**Using hashtags**
Sometimes you want to refer to a set of tweets that contain a specific word or phrase originating from different senders. In this case you can use a hashtag (#) in front of the word. The word becomes a keyword representing a particular topic or issue, and any click on the word displays all recent tweets that contain that word.

### 19.3.7 Receiving tweets
After you identify and designate those members that you want to follow, any tweet posted by any one of them comes to your Twitter home page (also called your Twitter feed). To get to your home page, click on the *home* icon at the top-left of the Twitter toolbar (Figure 19.10) which enlarges the *what’s happening* section. After reading any tweet, you can:
1. click on the arrow to compose a tweet in response to the sender of the tweet.
2. click on the double arrow to **retweet** the received tweet to their own followers.
3. click on the star to show that they like the tweet.

## 19.4 END-CHAPTER MATERIALS
### 19.4.1 Recommended reading
For more details about the subjects discussed in this chapter, the following book is recommended:
Russel Matthew A. *Mining the Social Web*, Sebastopol, CA: O’Reilly, 2014

### 19.4.2 Key terms
- Facebook
- follow
- following
- friend
- friendship
- hashtag
- home page
- news
- sign out
- social media
- tweet
- Twitter
- user page
- web page

### 19.4.3 Summary
- Facebook allows families and friends around the world to keep in touch with each other.
- In Facebook, each member needs to find friends to communicate with, but a friend of a friend is not a friend.
- Communication in Facebook is one-to-many. What is posted by one member can be seen by all their friends.
- To become a member of Facebook, one needs to sign up. To terminate membership, one needs to sign out.
- To use Facebook, a member needs to log in; to stop using Facebook for a while, a member needs to log out.
- Twitter allows a member to post a tweet (small message) for their followers to read.
- In Twitter, each member needs to find other members to follow.
- Communication in Twitter is one-to-many. Everything posted by one member can be seen by all their followers.
- To become a member of Twitter, one needs to sign up. To terminate membership, one needs to sign out.
- To use Twitter, a member needs to log in; to stop using Twitter for a while, a member needs to log out.
- A member needs to follow other members to receive tweets from them.

## 19.5 PRACTICE SET
### 19.5.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 19.5.2 True/false questions
Categorize the following statements as true or false.
T19-1. In Facebook, members post something for their followers.
T19-2. In Facebook, sharing is done between friends.
T19-3. In Facebook, a friend of a friend is a friend.
T19-4. Friendship in Facebook is a one-way relationship.
T19-5. Communication in Facebook is one-way.
T19-6. To sign up in Facebook you need to be on the user page.
T19-7. There is only one way to find friends in Facebook.
T19-8. In Facebook, what is posted by one member can be seen by all their friends.
T19-9. In Twitter communication takes place between a member and his/her friends.
T19-10. To become a member of Twitter, you need to log in.
T19-11. To discontinue membership in Twitter, you need to sign out.
T19-12. Before using Twitter, you need to look for followers.
T19-13. In Twitter, a post (message) can contain thousands of characters.
T19-14. To refer to another person named in your tweet, you need to use an ampersand.
T19-15. To refer to a word in all tweets, you need to use a hashtag.

### 19.5.3 Review questions
Q19-1. What is the difference between Facebook and Twitter when we consider the relationship between members?
Q19-2. What is the difference between Facebook and Twitter when we are thinking about the size of messages exchanged?
Q19-3. In Twitter, explain why a follower cannot send a message to the member that he/she follows.
Q19-4. In Facebook, if x and y are friends and z is only a friend of x but not a friend of y, can x send a message to z? Can z send a message to x?
Q19-5. In Twitter, if x is a follower of y and y is a follower of z, can x see a tweet sent by z?

### 19.5.4 Problems
P19-1. In Figure 19.2, assume that M2 and M5 terminate their friendships. Redraw Figure 19.3 for the new situation.
P19-2. In Figure 19.2, assume that M3 and M8 become friends. Redraw Figure 19.3 for the new situation.
P19-3. In Figure 19.7, assume that M2 decided to follow M6. Redraw Figure 19.7 using the new situation.
P19-4. In Figure 19.7, assume that M4 follows M7 and M7 follows M3. Redraw Figure 19.7 using the new situation.
`,zh:`
# 第十九章：社群媒體簡介

在本章中，我們簡要探討**社群媒體**作為電腦科學的應用之一。我們的目標不是展示如何使用社群媒體；許多學生在日常生活中已經知道並使用社群媒體。我們的主要目標是展示社群媒體背後的概念以及這些網站是如何為此目的設計的。我們將只討論 **Facebook** 和 **Twitter** 這兩個平台，分別作為特定社群媒體類型的範例。

## 學習目標
學完本章後，學生應能：
- 定義 Facebook 中的*朋友*關係。
- 定義 Facebook 中朋友之間的雙向關係。
- 理解 Facebook 中的溝通管道。
- 了解如何成為 Facebook 會員以及如何終止會員資格。
- 了解如何登入和登出 Facebook。
- 了解如何在 Facebook 中尋找朋友。
- 了解如何在 Facebook 中與朋友溝通。
- 定義 Twitter 中的*追蹤*關係。
- 定義 Twitter 中成員與追蹤者之間的單向關係。
- 理解 Twitter 中的溝通管道。
- 了解如何成為 Twitter 會員以及如何終止會員資格。
- 了解如何登入和登出 Twitter。
- 了解如何在 Twitter 中追蹤其他成員。
- 了解如何在 Twitter 中與追蹤者溝通。

## 19.1 簡介
在上個世紀，當電腦科學作為一門學科開始時，我們永遠無法想像它會在如此短的時間內成為我們日常生活的一部分。電腦科學幫助所有公民的領域之一是*社群媒體*的出現。今天，世界上大多數人在某種程度上都參與了一種或多種社群媒體，這可以被視為一種電腦科學應用。社群媒體實際上是使用多種電腦科學學科的結果，包括作業系統、電腦程式設計、電腦網路和資料庫。

社群媒體平台是大型網站，旨在讓使用者交流思想、意見和經驗。有些主要設計用於交換訊息或圖片；有些旨在讓求職者尋找雇主，以及雇主尋找員工。

討論所有類型的社群媒體本身就需要一本書。因此，在本章中，我們只探討其中兩種：Facebook 和 Twitter。我們選擇這兩個是因為 Facebook 或 Twitter 背後的概念或多或少在其他幾個網站中都有重複。

## 19.2 FACEBOOK
Facebook 是一個**社群媒體**，讓世界各地的家人和朋友能夠保持聯繫，分享想法、圖片、評論等。

**Facebook 允許成員分享想法、圖片和評論。**

### 19.2.1 基本概念
在解釋如何使用 Facebook 之前，讓我們考慮其背後的一般概念。

**朋友關係**
在 Facebook 中，分享僅在**朋友**之間進行。**朋友關係**是一對一的互惠關係。如果 John 是 Lucie 的朋友，Lucie 也是 John 的朋友。然而，這種關係不會傳播；如果 John 是 Lucie 的朋友，而 Lucie 是 Ann 的朋友，這並不一定意味著 John 是 Ann 的朋友。要成為朋友，John 或 Ann 需要向對方請求建立朋友關係。

**在 Facebook 中，朋友的朋友不一定是朋友。**

雖然 Facebook 有數十億成員，但為了討論方便，我們假設它只有八名成員（M1 到 M8），如圖 19.1 所示。

現在假設發出了以下朋友關係請求並全部被其他成員接受：
1. M1 請求與 M2 建立朋友關係。
2. M2 請求與 M5 建立朋友關係。
3. M3 請求與 M2 建立朋友關係。
4. M4 請求與 M7 建立朋友關係。
5. M6 請求與 M3 建立朋友關係。
6. M7 請求與 M6 建立朋友關係。
7. M8 請求與 M2 建立朋友關係。

圖 19.2 顯示了這八名成員之間的朋友關係。請注意，Facebook 保存了每位成員的資訊，但在請求並批准朋友關係後，會在兩位朋友之間添加連結。

**溝通**
雖然成員之間的朋友關係是雙向的，但我們可以將溝通視為一對多（單向發送，多方接收）的關係：一個成員發布某些內容，他們所有的朋友都能看到，如圖 19.3 所示：
a. M1 發布的內容可以被 M2 看到。
b. M2 發布的內容可以被 M1、M3、M5 和 M8 看到。
c. M3 發布的內容可以被 M2 和 M6 看到。
d. M4 發布的內容可以被 M7 看到。
e. M5 發布的內容可以被 M2 看到。
f. M6 發布的內容可以被 M3 和 M7 看到。
g. M7 發布的內容可以被 M4 和 M6 看到。
h. M8 發布的內容可以被 M2 看到。

### 19.2.2 網頁
Facebook 使用多個頁面，但最常使用的兩個是首頁和一般頁面。在解釋如何使用它們之前，讓我們展示這兩個頁面。

**首頁 (Home page)**
**首頁**僅用於註冊（加入）和登入（存取）Facebook。一般格式如圖 19.4 所示。

**使用者頁面 (User page)**
**使用者頁面**是您在 Facebook 上使用的主要頁面。該頁面相當複雜，但一般格式如圖 19.5 所示。請注意，您的頁面始終將工具列作為第一行。它有三列，但左邊的兩列可以滾動以顯示更多選項。

### 19.2.3 會員資格
您需要成為 Facebook 的會員才能使用它。要成為會員，您需要註冊。要終止您的會員資格，您需要登出或停用您的帳戶。

**註冊 (Sign up)**
要成為 Facebook 的會員（免費），您需要前往 Facebook 首頁 (www.facebook.com)，如圖 19.4 所示。然後您可以使用以下步驟進行註冊。
1. 忽略*登入*部分（第一行）並前往*註冊*部分。
2. 在相應的框中輸入您的名字和姓氏。
3. 在相應的框中輸入您的電子郵件或手機號碼。
4. 在相應的框中重新輸入您的電子郵件或手機號碼。
5. 選擇您的出生日期（月、日、年）。
6. 勾選您的性別按鈕。
7. 點擊註冊按鈕。

**登出 (停用)**
要永久停用您在 Facebook 中的帳戶，請前往您的首頁（圖 19.5）並執行以下操作：
1. 點擊工具列最右側的向下箭頭。
2. 在出現的子選單中，點擊*設定*。
3. 點擊*安全性*。
4. 選擇*停用您的帳戶*並按照步驟確認。

### 19.2.4 存取 Facebook 服務
即使您已註冊成為會員，每當您想使用 Facebook 時，您都需要*登入*。當您暫時不想使用時，您可以*登出*。

**登入 (Log in)**
要登入您的帳戶，請前往 Facebook 首頁 www.facebook.com（圖 19.5）。在第一行，輸入您的電子郵件或手機號碼，輸入您的密碼，然後點擊登入按鈕。您將看到您的頁面，這意味著您現在可以使用 Facebook。

**登出 (Log out)**
每當您暫時不使用您的 Facebook 頁面時，您可以登出。在使用者頁面（您的頁面）的工具列上（圖 19.5），點擊向下箭頭以查看選單。然後點擊登出按鈕。

### 19.2.5 朋友
如上所述，使用 Facebook 的整個想法是與*朋友*保持聯繫。如果您在 Facebook 網站上發布某些內容，您需要有朋友才能看到它。如果您想看另一位成員發布的內容，您必須是她的朋友之一。換句話說，在您可以開始透過 Facebook 溝通之前，您需要尋找朋友並讓其他成員找到您作為朋友。

**尋找朋友**
在 Facebook 中有幾種尋找朋友的方法。

**接受 Facebook 推薦**
您可以接受 Facebook 根據您在註冊期間提供的資訊所做的推薦。要接受推薦，請前往您頁面的工具列（圖 19.5）並點擊*尋找朋友*按鈕，這將顯示您可能認識的人的列表。該列表分為幾個類別（例如您可能認識的人、共同朋友、來自您家鄉的人、當前城市、高中、學院或大學、雇主等），您可以滾動瀏覽以進行選擇。在每個類別中，您可以選擇您想成為朋友的人，並點擊他們名字前面的*加為朋友*按鈕。

**追蹤電子郵件聯絡人**
您可以**追蹤**經常透過電子郵件與您聯繫的人。在您的首頁工具列上（圖 19.5），點擊*朋友*圖示（*尋找朋友*按鈕旁邊的兩張臉）。Facebook 顯示一個帶有不同電子郵件圖示的頁面。選擇適當的一個並輸入您的電子郵件和密碼，以查看透過電子郵件與您通訊的個人列表。如果您希望此列表中的某人成為您的 Facebook 朋友，請點擊*加為朋友*按鈕。

**尋找您認識的人**
在您的首頁工具列左側（圖 19.5），輸入成員姓名並點擊搜尋圖示。Facebook 顯示具有該姓名的成員列表。如果您找到您認識的人，點擊姓名以查看其個人資料頁面。如果您希望該人成為您的 Facebook 朋友，請點擊*加為朋友*按鈕。

**接受其他成員的朋友請求**
其他成員可能想加您為朋友。在這種情況下，當您收到請求時，您可以接受或拒絕朋友關係。在工具列上，點擊*朋友請求*按鈕。您將看到向您發送朋友請求的每位成員的個人資料。您可以點擊成員名字前面的*確認*或*刪除*按鈕來接受或拒絕邀請。

**刪除朋友 (Unfriend)**
您可以隨時從您的朋友列表中刪除任何成員。為此，請點擊您首頁工具列上的個人資料圖片（圖 19.5）。點擊您名字下的*朋友*按鈕以查看您的朋友列表。向下滾動直到您看到您想要刪除的朋友的名字。然後點擊*刪除朋友*按鈕。

### 19.2.6 交換資訊
Facebook 的全部目的是允許朋友交換新聞（文字、照片、影片等）。要接收您朋友的貼文，請前往您的*動態消息*，它們將出現在那裡。要向您的朋友發送新聞，您需要*更新您的狀態*。我們將簡要展示這兩項活動。

**閱讀新聞**
要查看您的朋友發布了什麼新聞，請前往工具列（圖 19.5）並點擊*首頁*按鈕。您將看到您的朋友發布的所有新貼文。每個貼文都包括您朋友的名字、發布日期和內容。它們也可能包含指向網頁的連結。發布的照片也會出現在那裡，但您可能想點擊它們以放大查看。如果貼文中有影片，動態消息主體中會出現縮圖和*播放*箭頭；點擊它以播放影片。

**評論發布的動態**
在每條發布的新聞（稱為動態更新）頂部，有一個*讚*按鈕，您可以點擊它以表示您喜歡該貼文。

**分享發布的動態**
點擊原始貼文下方的*分享*按鈕以查看新視窗。在新視窗中輸入您想對貼文發表的任何評論，然後點擊新視窗中的*分享*按鈕。透過這種方式，您可以將收到的內容發布給您自己的朋友。

**發布新聞**
Facebook 允許您為朋友發布新聞（稱為動態更新）。這可以是一條長訊息（最多 60000 個字元）、指向網頁的連結、照片或影片。

**發布新聞**
要發布**新聞**，請前往工具列（圖 19.5）並點擊*首頁*按鈕以查看發布視窗。*更新狀態*將被預設選中。點擊*你在想什麼*按鈕並輸入您的新聞。然後點擊*發布*按鈕為您的朋友發布新聞。

**發布照片或影片**
在發布視窗中（見發布新聞段落），點擊*相片/影片*按鈕，然後選擇右側按鈕以發布您的照片或影片。

**標記 (Tagging)**
如果您想在貼文中提及朋友，您可以*標記*該朋友。為此，您需要點擊*標記*按鈕（頭像圖片），然後從列表中選擇朋友的名字。

**限制誰可以看到您的貼文**
通常，當您在 Facebook 上發布內容時，所有 Facebook 成員都可以看到。您可以將此限制為僅您的朋友甚至僅您自己。在*狀態更新*視窗中（見發布新聞段落），點擊*公開*按鈕讓任何人都能看到貼文，點擊*朋友*按鈕讓只有您的朋友能看到貼文，或點擊*只限本人*按鈕讓除了您之外沒有人能看到貼文。

## 19.3 TWITTER
**Twitter** 是一個社群網路，允許成員發布一則最多 140 個字元的短訊息，稱為**推文 (tweet)**，供他們的追蹤者查看。

**Twitter 允許成員為其追蹤者發布推文。**

### 19.3.1 基本概念
在展示如何使用 Twitter 之前，讓我們討論這個社群媒體網站背後的一般概念。

**成員-追蹤者關係**
在 Twitter 中，關係是成員與其追蹤者之間的關係；這是一對多的關係。一群 Twitter 成員追蹤他們喜歡的成員；被追蹤的成員甚至可能不知道他們的追蹤者是誰。這類似於名人與其追蹤者之間的關係：追蹤者對名人的所作所為感興趣，但名人可能不知道這些追蹤者是誰。

讓我們假設有八名成員在 Twitter 網站上註冊，如圖 19.6 所示。現在假設一些成員決定追蹤其他成員，如下所示：
1. M1 追蹤 M2 和 M5。
2. M2 追蹤 M3。
3. M3 追蹤 M4 和 M5。
4. M4 追蹤 M3 和 M8。
5. M5 追蹤 M2 和 M6。
6. M6 追蹤 M8。
7. M7 追蹤 M3。
8. M8 追蹤 M7。

圖 19.7 顯示了新的單向關係（追蹤者-被追蹤者）。

**溝通**
在 Twitter 中，將溝通視為一對多關係也更容易。成員為其追蹤者發布推文。圖 19.8 顯示了這種情況。
a. M1 沒有追蹤者。這意味著 M1 發布的內容沒人能看到。
b. M2 有 M1 和 M5 作為追蹤者。這意味著 M2 發布的內容可以被 M1 和 M5 看到。
c. M3 有 M2、M4 和 M7 作為追蹤者。這意味著 M3 發布的內容可以被 M2、M4 和 M7 看到。
d. M4 有 M3 作為追蹤者。這意味著 M4 發布的內容可以被 M3 看到。
e. M5 有 M1 和 M3 作為追蹤者。這意味著 M5 發布的內容可以被 M1 和 M3 看到。
f. M6 只有 M5 作為追蹤者。這意味著 M6 發布的內容只能被 M5 看到。
g. M7 沒有追蹤者。這意味著 M7 發布的內容沒人能看到。
h. M8 有 M4 和 M6 作為追蹤者。這意味著 M8 發布的內容可以被 M4 和 M6 看到。

### 19.3.2 頁面
Twitter 網站有幾個頁面，但主要使用的是*網頁*和*首頁*。其他頁面可以從這兩個頁面之一到達。在解釋如何使用它們之前，讓我們描述這兩個頁面。

**網頁 (Web page)**
**網頁**用於首次加入 Twitter 或當您想登入帳戶時（圖 19.9）。

**首頁 (Home page)**
**首頁**用於當您已經擁有 Twitter 帳戶並想使用它時。此頁面的一般格式如圖 19.10 所示。

### 19.3.3 會員資格
與任何社群媒體一樣，您需要註冊才能成為會員（圖 19.9）。如果您想停用帳戶，您需要登出（圖 19.10）。

**註冊 (Sign up)**
要成為 Twitter 的會員，請前往 www.twitter.com 找到 Twitter 網頁，如圖 19.9 所示。然後點擊*註冊*按鈕以查看註冊視窗，如圖 19.11 所示。
在註冊視窗中提供您的全名、電話號碼或電子郵件以及密碼。現在點擊*註冊*按鈕加入成為會員。

**登出 (停用)**
要永久停用您在 Twitter 中的帳戶，請前往 Twitter 首頁（圖 19.10）並執行以下操作：
1. 點擊*個人資料*和*設定*圖示。
2. 當新視窗打開時，點擊*設定*和*隱私*按鈕。
3. 當新視窗打開時，點擊*停用我的帳戶*按鈕。

### 19.3.4 存取 Twitter 服務
即使您是會員，每當您想使用 Twitter 時，您都需要*登入*。當您暫時不想使用時，您可以*登出*。

**登入 (Log in)**
當您是會員時，您可以從任何電腦或智慧型手機登入您的帳戶。在 Twitter 網頁（圖 19.9）上，點擊*登入*按鈕以查看登入視窗，如圖 19.12 所示。
在登入視窗中，提供您的全名、電話號碼或電子郵件以及密碼。現在點擊*登入*按鈕。您現在可以使用 Twitter。

**登出 (Log out)**
要登出您在 Twitter 中的帳戶，請前往 Twitter 首頁（圖 19.10）並執行以下操作：
1. 點擊*個人資料*和*設定*圖示。
2. 當新視窗打開時，點擊*登出*按鈕。

### 19.3.5 追蹤與被追蹤
Twitter 的整個想法是使成員及其追蹤者能夠溝通。成員如果追蹤其他成員，就可以接收推文。如果成員有追蹤者，他們可以發送有用的推文，這些推文將被其追蹤者接收。

**您需要追蹤其他成員**
如果您想接收某些成員的推文，您需要讓 Twitter 知道您想**追蹤**他們。不需要獲得您想追蹤的成員的許可（除非他們明確要求 Twitter 封鎖您作為他們的追蹤者）。如果您輸入您想追蹤的成員姓名，Twitter 會在您的個人資料中創建一個列表，每當這些成員中的任何一位發送推文時，您都會收到一份副本。問題是：您如何告訴 Twitter 您想追蹤誰？有幾種方法可以做到這一點。

**接受 Twitter 推薦**
您可以接受 Twitter 的推薦（基於您過去的活動和興趣）。為此，請前往 Twitter 首頁左下角的*推薦追蹤*視窗，如圖 19.13 所示，並點擊*查看全部*按鈕以查看 Twitter 的推薦。要了解有關這些成員中任何一位的更多資訊，請點擊 @name。要追蹤成員，請點擊*追蹤*按鈕。

**追蹤電子郵件聯絡人**
您可以追蹤經常透過電子郵件與您聯繫的人。在*推薦追蹤*頁面（圖 19.13）上，點擊*尋找朋友*按鈕（在右側欄底部）。下一個視窗會出現電子郵件提供者列表，您可以從中選擇那些透過這些電子郵件提供者與您通訊的朋友。

**搜尋特定人員或組織**
在*推薦追蹤*部分（圖 19.13）點擊*查看全部*按鈕。當新視窗打開時，輸入您正在尋找的人員或組織的實際名稱或 Twitter 名稱。現在點擊*搜尋*按鈕。如果具有該名稱的個人或組織是 Twitter 成員，您可以選擇追蹤他們。

**停止追蹤成員**
由於某種原因，您可能想停止接收來自成員的推文。為此，您必須取消追蹤他們。前往 Twitter 首頁，點擊*正在追蹤*連結。將滑鼠移到該成員的*追蹤中*按鈕上，並將其更改為*取消追蹤*按鈕。

**其他成員追蹤您**
如果您希望您的推文被閱讀，您需要有追蹤者來接收它們。然而，您不能選擇您的追蹤者；他們必須找到您並決定追蹤您。他們不需要獲得您的批准來追蹤您，但如果您希望，您可以通知 Twitter 您想封鎖特定追蹤者。

### 19.3.6 發送推文
雖然您不認識所有的追蹤者——他們選擇了您，您沒有選擇他們——並且無法直接與他們溝通，但 Twitter 有您的追蹤者列表。要向您的追蹤者發送推文，只需將其發布在您的 Twitter 頁面上，網站就會將其發送給您的所有追蹤者。

**撰寫新推文**
您需要知道的第一件事是如何撰寫新推文。這可以按如下方式完成（見圖 19.14）。
1. 點擊任何 Twitter 網頁上的*推文*按鈕以查看*撰寫新推文*面板。
2. 在*撰寫新推文*面板中，輸入您的訊息。
3. 點擊頁面底部的*推文*按鈕發布您的推文。
4. Twitter 獲取您的推文並在推文頂部添加您的個人資料，包括您的姓名。
5. 然後 Twitter 向您的所有追蹤者發送副本。

**提及他人的推文**
在您發送的任何推文中，您也可以提及其他使用者的推文。這可以通過兩種方式完成：使用 **@ 符號 (ampersands)** 和/或使用 **# 符號 (hashtags)**。

**使用 @ 符號**
當您向追蹤者發送推文時，如果您想提及另一位使用者的推文，您可以插入該使用者的名字，並在前面加上 @ 符號 (@)。您的任何追蹤者都可以點擊該名字以查看該使用者發布的推文。

**使用 # 符號 (hashtags)**
有時您想提及包含特定單詞或片語的一組推文，這些推文來自不同的發送者。在這種情況下，您可以在單詞前面使用 # 符號 (#)。該單詞成為代表特定主題或議題的關鍵字，任何對該單詞的點擊都會顯示包含該單詞的所有最近推文。

### 19.3.7 接收推文
在您識別並指定您想追蹤的成員後，他們中任何一位發布的任何推文都會來到您的 Twitter 首頁（也稱為您的 Twitter 動態）。要前往您的首頁，請點擊 Twitter 工具列左上角的*首頁*圖示（圖 19.10），這將放大*正在發生*部分。閱讀任何推文後，您可以：
1. 點擊箭頭撰寫推文以回應推文的發送者。
2. 點擊雙箭頭**轉推 (retweet)** 收到的推文給自己的追蹤者。
3. 點擊星星表示喜歡該推文。

## 19.4 章末材料
### 19.4.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
Russel Matthew A. *Mining the Social Web*, Sebastopol, CA: O’Reilly, 2014

### 19.4.2 關鍵詞
- Facebook
- 追蹤 (follow)
- 正在追蹤 (following)
- 朋友 (friend)
- 朋友關係 (friendship)
- 主題標籤 (hashtag)
- 首頁 (home page)
- 新聞 (news)
- 登出 (sign out)
- 社群媒體 (social media)
- 推文 (tweet)
- Twitter
- 使用者頁面 (user page)
- 網頁 (web page)

### 19.4.3 摘要
- Facebook 允許世界各地的家人和朋友保持聯繫。
- 在 Facebook 中，每個成員都需要尋找朋友進行溝通，但朋友的朋友不是朋友。
- Facebook 中的溝通是一對多的。一個成員發布的內容可以被他們所有的朋友看到。
- 要成為 Facebook 會員，需要註冊。要終止會員資格，需要登出。
- 要使用 Facebook，成員需要登入；要暫時停止使用 Facebook，成員需要登出。
- Twitter 允許成員發布推文（短訊息）供其追蹤者閱讀。
- 在 Twitter 中，每個成員都需要尋找其他成員來追蹤。
- Twitter 中的溝通是一對多的。一個成員發布的所有內容都可以被他們所有的追蹤者看到。
- 要成為 Twitter 會員，需要註冊。要終止會員資格，需要登出。
- 要使用 Twitter，成員需要登入；要暫時停止使用 Twitter，成員需要登出。
- 成員需要追蹤其他成員才能接收他們的推文。

## 19.5 練習題
### 19.5.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 19.5.2 是非題
將以下陳述分類為對或錯。
T19-1. 在 Facebook 中，成員為其追蹤者發布內容。
T19-2. 在 Facebook 中，分享是在朋友之間進行的。
T19-3. 在 Facebook 中，朋友的朋友是朋友。
T19-4. Facebook 中的朋友關係是單向關係。
T19-5. Facebook 中的溝通是單向的。
T19-6. 要在 Facebook 中註冊，您需要在使用者頁面上。
T19-7. 在 Facebook 中只有一種尋找朋友的方法。
T19-8. 在 Facebook 中，一個成員發布的內容可以被他們所有的朋友看到。
T19-9. 在 Twitter 中，溝通發生在成員和他/她的朋友之間。
T19-10. 要成為 Twitter 會員，您需要登入。
T19-11. 要終止 Twitter 會員資格，您需要登出。
T19-12. 在使用 Twitter 之前，您需要尋找追蹤者。
T19-13. 在 Twitter 中，貼文（訊息）可以包含數千個字元。
T19-14. 要提及推文中命名的另一個人，您需要使用 @ 符號。
T19-15. 要引用所有推文中的一個詞，您需要使用 # 符號。

### 19.5.3 複習問題
Q19-1. 當我們考慮成員之間的關係時，Facebook 和 Twitter 有什麼區別？
Q19-2. 當我們考慮交換訊息的大小時，Facebook 和 Twitter 有什麼區別？
Q19-3. 在 Twitter 中，解釋為什麼追蹤者不能向他/她追蹤的成員發送訊息。
Q19-4. 在 Facebook 中，如果 x 和 y 是朋友，而 z 只是 x 的朋友但不是 y 的朋友，x 可以向 z 發送訊息嗎？z 可以向 x 發送訊息嗎？
Q19-5. 在 Twitter 中，如果 x 是 y 的追蹤者，而 y 是 z 的追蹤者，x 可以看到 z 發送的推文嗎？

### 19.5.4 問題
P19-1. 在圖 19.2 中，假設 M2 和 M5 終止了他們的朋友關係。為新情況重畫圖 19.3。
P19-2. 在圖 19.2 中，假設 M3 和 M8 成為朋友。為新情況重畫圖 19.3。
P19-3. 在圖 19.7 中，假設 M2 決定追蹤 M6。使用新情況重畫圖 19.7。
P19-4. 在圖 19.7 中，假設 M4 追蹤 M7 且 M7 追蹤 M3。使用新情況重畫圖 19.7。
`},T={en:`
# Chapter 20: Social and Ethical Issues

In this chapter, we briefly focus on social and ethical issues related to the use of computers and to the Internet as a network of computers.

## Objectives
After studying this chapter, the student should be able to:
- Define three ethical principles related to the use of computers.
- Distinguish between physical and intellectual property and list some types of intellectual property.
- Define privacy as related to the use of computers.
- Give the definition of a computer crime and discuss types of attacks, motivation for attacks, and how to protect against attacks.
- Define hackers and the damage done by them.

## 20.1 ETHICAL PRINCIPLES
One of the ways to evaluate our responsibility towards the rest of the world when using a computer is to base our decisions on **ethics**. Ethics is a very complex subject that would take several books to describe in detail. In this chapter, we discuss only three principles that can be related to our goal, shown in Figure 20.1.

### 20.1.1 Moral rules
The first ethical principle states that when we make an ethical decision, we need to consider if the decision is made in accordance with a universally accepted principle of morality. For example, if we want to illegally access a computer to get some information, we need to ask ourselves if this act is moral. We know that most people in the world do not consider such actions to be moral, which means that we would be ignoring the first principle of ethics if we acted in this way.

**The first principle of ethics says that we should avoid doing anything if it is against universal morality.**

### 20.1.2 Utilization
The second theory of ethics is related to the consequences of the act. An act is ethical if it results in consequences which are useful for society. If a person accesses a bank’s computer and erases customer records, is this act useful for society? Since this action may damage the financial status of the bank’s customer, it is detrimental to society. It does not bring about a good result. It is not ethical.

**The second principle of ethics says that an act is ethical if it brings about a good result.**

### 20.1.3 Social contract
The social contract theory says that an act is ethical when a majority of people in society agrees with it. If someone breaks into somebody else’s house and commits a robbery, does this act receive the approval of a majority of society? Since the answer is negative, this act is not ethical.

**The third principle of ethics says an act is ethical if a majority of people in society agree with it.**

## 20.2 INTELLECTUAL PROPERTY
Most ethical issues in the past were related to physical property. Physical property has been defined and physical property rights have been recognized by society throughout history. If a person has a physical object, such as a computer, the rights to this property are granted to the owner. It has been proved that ignoring physical property rights may affect the three ethical principles discussed above.

Modern societies have gone further and have recognized the right to **intellectual property**. For example, an author should be given the right to benefit from his/her written book. An artist should be given the right to benefit from his/her artwork. However, there are some differences between the two types of property:
1. A physical property cannot be copied; it needs to be manufactured or built. If we need another computer, we need to physically build it. On the other hand, intellectual property can be copied. We can make a copy of a book without rewriting it.
2. Copying intellectual property still leaves the owner with the original. Stealing a computer deprives the owner of its use.
3. The owner of intellectual property is only one person (or a group); many people can have the same physical property.

### 20.2.1 Types of intellectual property
Modern societies have recognized several types of intellectual property: trademarks, trade secrets, patents, and copyright.

**Trademarks**
A **trademark** identifies a company’s product or service. A trademark is an intellectual property right granted by the government for a limited term, but which can be renewed. A trademark is considered intellectual property in that the corresponding product cannot legally be copied by other companies or individuals.

**Trade secrets**
A **trade secret** is the information about a product that is kept secret by the owner. For example, a company can create a product but keep the formula secret. A programmer can create a piece of software, but keep the program code secret. People can use the product or the software, but they do not own the formula or the code. Unlike trademarks, a trade secret does not have to be registered; the owner just has to keep it secret.

**Patents**
A **patent** is a right to a monopoly to use and commercially exploit a piece of intellectual property for a limited period of time. The owner has the right to give or not to give permission to anyone who wishes to use the invention. However, the individual property needs to have certain characteristics such as novelty, usefulness, and the capability of being built.

**Copyright**
A **copyright** is a right to a written or created work. It gives the author the exclusive rights to copy, distribute, and display the work. Copyright arises automatically, and does not need to be applied for or formally registered, but a statement of the creator’s copyright should be mentioned somewhere on the work.

## 20.3 PRIVACY
Today, a large amount of personal information about a citizen is collected by private and public agencies. Although in many cases the collection of this information is necessary, it may also pose some risks. Some of the information collected by government or private companies can be used commercially. In many countries, a citizen’s right to privacy is, directly or indirectly, mentioned in the nation’s constitution. However, there is a conflict between people’s right to privacy and the need to collect information about them. Usually governments create a balance between the two through laws. Some countries have introduced codes of ethics related to the use of computers to collect data, as shown below:
1. Collect only data that are needed.
2. Be sure that the collected data are accurate.
3. Allow individuals to know what data have been collected.
4. Allow individuals to correct the collected data if necessary.
5. Be sure that collected data are used only for the original purpose.
6. Use encryption techniques (discussed in Chapter 16) to accomplish private communication.

## 20.4 COMPUTER CRIMES
For the purposes of this book, we give a simple definition of a computer crime. A computer crime is an illegal act, called an *attack*, involving any of the following:
1. A computer
2. A computer network
3. A computer-related device
4. Software
5. Data stored in a computer
6. Documentation related to the use of computers

### 20.4.1 Types of attacks
Attacks can be divided into two categories: *penetration* and *denial of service*.

**Penetration attack**
Penetration in this case means breaking into a system to get access to the data stored in a computer or in a computer network. Penetration can result in changing data directly or injecting **viruses**, **worms**, and **Trojan horses** to alter the data indirectly.

**Viruses**
Viruses are unwanted programs that are hidden within other programs (host). When the user executes the host program, the virus takes control and replicates itself by attaching itself to other programs. Eventually, the multitude of viruses may stop normal computer operations. Viruses can also be transferred to other machines through the network.

**Worms**
A worm is an independent program which can copy itself and which travels through the network. It is a self-replicating piece of software that can travel from one node to another. It tries to find weaknesses in the system to inflict harm. It can reproduce many copies of itself, thus slowing down access to the Internet or stopping communication altogether.

**Trojan horses**
A Trojan horse is a computer program that does perform a legitimate task, but which also contains code to carry out malicious attacks such as deleting or corrupting files. It can also be used to access user passwords or other secret information.

**Denial of service attack**
The **denial of service** is an attack on a computer connected to the Internet. These attacks reduce the capability of a computer system to function correctly or bring the system down altogether by exhausting its resources.

### 20.4.2 Motives
Attacks are made with many different motivations such as political reasons, a hacker’s personal interpretation of computer ethics, terrorism, espionage, financial gain, or hate.

### 20.4.3 Attack protection
Although attacks cannot be avoided easily, there are some strategies that can be applied to reduce the number or impact of the attacks. We describe three strategies briefly.

**Use physical protection**
The computer can be physically protected to allow physical access only to trusted individuals.

**Use protective software**
Software can be used to protect your data, such as data encryption or the use of strong passwords to access the software.

**Install strong anti-virus software**
Strong anti-virus software can control access to the computer when installing new software or accessing Internet sites.

### 20.4.4 Cost
It is obvious that ordinary citizens usually bear the cost of these computer attacks. When private companies spend money on preventing attacks, consumers using their products pay through increased prices. When government organizations spend money to prevent attacks, citizens pay through increased taxes.

## 20.5 HACKERS
The word **hacker** today has a different meaning than when it was used in the past. Previously, a hacker was a person with a lot of knowledge who could improve a system and increase its capability. Today, a hacker is someone who gains unauthorized access to a computer belonging to someone else in order to copy secret information.

Although some of the infiltrations carried out by hackers can be harmless, most countries impose heavy penalties for both harmless and harmful hacking. In most countries, accessing government computers without authorization is a crime. Moreover, in many countries there is a heavy punishment for hackers who access the computers of private institutions, and the simple act of obtaining information from somebody else’s computer is a crime, whether the information is used or not.

## 20.6 END-CHAPTER MATERIALS
### 20.6.1 Recommended reading
For more details about the subjects discussed in this chapter, the following books are recommended:
- Kizza, J. M. *Ethical and Social Issues in the Information Age*, London: Springer, 2010
- Schneider, M and. Gersting, J. L. *Invitation to Computer Science*, 7th edition, Boston, MA: Cengage Learning, 2016
- Reynold, C. and Tymann, P. *Schaum’s Outline of Principles of Computer Science*, New York: McGraw-Hill, 2008
- Long, L and Long, N. *Computers*, Upper Saddle River, NJ: Prentice-Hall, 1999

### 20.6.2 Key terms
- copyright
- denial of service
- ethical principle
- hackers
- intellectual property
- moral rules
- patent
- penetration attack
- privacy
- social contract
- trademark
- trade secret
- Trojan horse
- utilization
- virus
- worm

### 20.6.3 Summary
- One of the ways to evaluate our responsibility towards the rest of the world when using a computer is to base our decisions on ethics using the three principles of moral rules, utilization, and social contract.
- Ethical issues nowadays deal not only with physical property but also with intellectual property.
- Four different types of intellectual property are trademarks, trade secrets, patents, and copyrights.
- One major ethical issue of our time is respect of privacy.
- Computer crime mostly involves penetration or denial of service attacks on computer systems.
- Computer attacks can be avoided using physical protection, protective software, and anti-virus software.
- The term *hacker* today refers to a person or organization that gains unauthorized access to a computer belonging to someone else to copy secret information.

## 20.7 PRACTICE SET
### 20.7.1 Quizzes
A set of interactive quizzes for this chapter can be found on the book’s website. It is strongly recommended that the student takes the quizzes to check his/her understanding of the materials before continuing with the practice set.

### 20.7.2 Review questions
Q20-1. What are the three principles of ethics discussed in this chapter?
Q20-2. What are some differences between a physical and an intellectual property?
Q20-3. What are some privacy codes of ethics related to using computers?
Q20-4. What is the difference between penetration and denial of service when talking about computer crimes?
Q20-5. What are the three ways a malicious person can penetrate a computer belonging to someone else?

### 20.7.3 Problems
P20-1. Assume you have created a piece of software that can be used by many vendors. Is this intellectual property protected by a copyright or a patent? Explain your answer.
P20-2. You have created a piece of software for which you want to keep the code secret. Do you need to register this intellectual property? Explain your answer.
P20-3. If someone collects data about you without informing you in advance, is this act against your right to privacy? Explain your answer.
P20-4. If someone sends you an email that carries a virus, what type of computer crime is committed here? Explain your answer.
P20-5. If someone renders an institution’s computer system so busy that it cannot do any more work, what type of computer crime is committed? Explain your answer.
P20-6. Explain the difference between a virus and a worm.
P20-7. Explain the difference between a virus and a Trojan horse.
P20-8. Explain the difference between a worm and a Trojan horse.
P20-9. Describe different ways in which you can protect your computer from attacks.
P20-10. Explain the damage that a hacker can inflict on a computer system of a financial institution.
`,zh:`
# 第二十章：社會與倫理議題

在本章中，我們將簡要關注與電腦使用以及作為電腦網路的網際網路相關的社會和倫理議題。

## 學習目標
學完本章後，學生應能：
- 定義與電腦使用相關的三個倫理原則。
- 區分實體財產和智慧財產，並列舉一些智慧財產的類型。
- 定義與電腦使用相關的隱私權。
- 給出電腦犯罪的定義，並討論攻擊類型、攻擊動機以及如何防範攻擊。
- 定義駭客及其造成的損害。

## 20.1 倫理原則
在使用電腦時評估我們對世界其他地方責任的一種方法是基於**倫理**做出決策。倫理是一個非常複雜的主題，需要幾本書才能詳細描述。在本章中，我們僅討論與我們目標相關的三個原則，如圖 20.1 所示。

### 20.1.1 道德規則
第一個倫理原則指出，當我們做出倫理決策時，我們需要考慮該決策是否符合普遍接受的道德原則。例如，如果我們想非法存取電腦以獲取某些資訊，我們需要問自己這種行為是否道德。我們知道世界上大多數人不認為這種行為是道德的，這意味著如果我們以這種方式行事，我們將忽視第一個倫理原則。

**第一個倫理原則說，如果某事違反普世道德，我們應避免去做。**

### 20.1.2 功利主義 (Utilization)
第二個倫理理論與行為的後果有關。如果一項行為導致對社會有用的後果，那麼它就是合乎倫理的。如果一個人存取銀行電腦並刪除客戶記錄，這種行為對社會有用嗎？由於此行為可能會損害銀行客戶的財務狀況，因此對社會有害。它不會帶來好的結果。它不合乎倫理。

**第二個倫理原則說，如果一項行為能帶來好的結果，那麼它就是合乎倫理的。**

### 20.1.3 社會契約
社會契約理論說，如果社會上大多數人同意一項行為，那麼它就是合乎倫理的。如果有人闖入別人的房子並實施搶劫，這種行為會得到社會大多數人的批准嗎？由於答案是否定的，這種行為不合乎倫理。

**第三個倫理原則說，如果社會上大多數人同意一項行為，那麼它就是合乎倫理的。**

## 20.2 智慧財產
過去大多數倫理問題都與實體財產有關。實體財產已被定義，實體財產權在歷史上一直被社會承認。如果一個人擁有實體物件，例如電腦，則該財產的權利授予所有者。事實證明，忽視實體財產權可能會影響上述三個倫理原則。

現代社會已經走得更遠，承認**智慧財產權**。例如，作者應被賦予從其所寫書籍中獲益的權利。藝術家應被賦予從其藝術作品中獲益的權利。然而，兩種類型的財產之間存在一些差異：
1. 實體財產無法複製；它需要製造或建造。如果我們需要另一台電腦，我們需要實際建造它。另一方面，智慧財產可以複製。我們可以在不重寫的情況下複製一本書。
2. 複製智慧財產仍然讓所有者保留原件。偷竊電腦剝奪了所有者的使用權。
3. 智慧財產的所有者只有一個人（或一群人）；許多人可以擁有相同的實體財產。

### 20.2.1 智慧財產的類型
現代社會承認幾種類型的智慧財產：商標、商業機密、專利和版權。

**商標 (Trademarks)**
**商標**識別一家公司的產品或服務。商標是政府授予的有限期限的智慧財產權，但可以續期。商標被視為智慧財產，因為相應的產品不能被其他公司或個人合法複製。

**商業機密 (Trade secrets)**
**商業機密**是由所有者保密的產品資訊。例如，一家公司可以創造一種產品但對配方保密。程式設計師可以創建一個軟體，但對程式代碼保密。人們可以使用產品或軟體，但他們不擁有配方或代碼。與商標不同，商業機密不需要註冊；所有者只需保密即可。

**專利 (Patents)**
**專利**是在有限期間內使用和商業利用一項智慧財產的壟斷權。所有者有權給予或不給予任何希望使用該發明的人許可。然而，個人財產需要具有某些特徵，如新穎性、實用性和可建造性。

**版權 (Copyright)**
**版權**是對書面或創作作品的權利。它賦予作者複製、分發和展示作品的專有權利。版權自動產生，不需要申請或正式註冊，但創作者的版權聲明應在作品某處提及。

## 20.3 隱私權
今天，私人和公共機構收集了大量關於公民的個人資訊。雖然在許多情況下收集這些資訊是必要的，但也可能帶來一些風險。政府或私人公司收集的一些資訊可以用於商業用途。在許多國家，公民的隱私權直接或間接地在國家憲法中提及。然而，人們的隱私權與收集關於他們的資訊的需求之間存在衝突。通常政府透過法律在兩者之間建立平衡。一些國家已引入與使用電腦收集資料相關的道德準則，如下所示：
1. 僅收集需要的資料。
2. 確保收集的資料準確。
3. 允許個人知道已收集了哪些資料。
4. 如有必要，允許個人更正收集的資料。
5. 確保收集的資料僅用於原始目的。
6. 使用加密技術（在第 16 章討論）來實現私人通訊。

## 20.4 電腦犯罪
就本書而言，我們給出電腦犯罪的簡單定義。電腦犯罪是一種非法行為，稱為*攻擊*，涉及以下任何一項：
1. 電腦
2. 電腦網路
3. 電腦相關設備
4. 軟體
5. 儲存在電腦中的資料
6. 與電腦使用相關的文件

### 20.4.1 攻擊類型
攻擊可分為兩類：*滲透*和*阻斷服務*。

**滲透攻擊**
這種情況下的滲透意味著侵入系統以存取儲存在電腦或電腦網路中的資料。滲透可能導致直接更改資料或注入**病毒**、**蠕蟲**和**特洛伊木馬**以間接更改資料。

**病毒 (Viruses)**
病毒是隱藏在其他程式（宿主）中的不需要的程式。當使用者執行宿主程式時，病毒取得控制權並透過將自己附加到其他程式來自我複製。最終，大量的病毒可能會停止正常的電腦運作。病毒也可以透過網路轉移到其他機器。

**蠕蟲 (Worms)**
蠕蟲是一個獨立的程式，它可以自我複製並在網路中傳播。它是一個可以從一個節點傳播到另一個節點的自我複製軟體。它試圖在系統中尋找弱點以造成傷害。它可以複製許多自身的副本，從而減慢網際網路存取速度或完全停止通訊。

**特洛伊木馬 (Trojan horses)**
特洛伊木馬是一個電腦程式，它確實執行合法任務，但也包含執行惡意攻擊的代碼，如刪除或損壞檔案。它也可以用來獲取使用者密碼或其他秘密資訊。

**阻斷服務攻擊**
**阻斷服務**是對連接到網際網路的電腦發動的攻擊。這些攻擊透過耗盡其資源來降低電腦系統正常運作的能力或使系統完全崩潰。

### 20.4.2 動機
攻擊有多種不同的動機，如政治原因、駭客對電腦倫理的個人解釋、恐怖主義、間諜活動、經濟利益或仇恨。

### 20.4.3 攻擊防護
雖然攻擊不容易避免，但可以應用一些策略來減少攻擊的數量或影響。我們簡要描述三種策略。

**使用實體保護**
可以對電腦進行實體保護，只允許受信任的個人進行實體存取。

**使用保護性軟體**
軟體可以用來保護您的資料，例如資料加密或使用強密碼來存取軟體。

**安裝強大的防毒軟體**
強大的防毒軟體可以在安裝新軟體或存取網際網路站點時控制對電腦的存取。

### 20.4.4 成本
顯然，普通公民通常承擔這些電腦攻擊的成本。當私人公司花錢預防攻擊時，使用其產品的消費者透過價格上漲來支付。當政府組織花錢預防攻擊時，公民透過稅收增加來支付。

## 20.5 駭客
**駭客**一詞今日的含義與過去不同。以前，駭客是一個知識淵博的人，可以改進系統並增加其能力。如今，駭客是指未經授權存取他人電腦以複製秘密資訊的人。

雖然駭客進行的一些滲透可能是無害的，但大多數國家對無害和有害的駭客行為都處以重罰。在大多數國家，未經授權存取政府電腦是犯罪行為。此外，在許多國家，對存取私人機構電腦的駭客處以重罰，即使不使用資訊，從他人電腦獲取資訊的簡單行為也是犯罪。

## 20.6 章末材料
### 20.6.1 推薦閱讀
關於本章討論主題的更多詳細資訊，推薦以下書籍：
- Kizza, J. M. *Ethical and Social Issues in the Information Age*, London: Springer, 2010
- Schneider, M and. Gersting, J. L. *Invitation to Computer Science*, 7th edition, Boston, MA: Cengage Learning, 2016
- Reynold, C. and Tymann, P. *Schaum’s Outline of Principles of Computer Science*, New York: McGraw-Hill, 2008
- Long, L and Long, N. *Computers*, Upper Saddle River, NJ: Prentice-Hall, 1999

### 20.6.2 關鍵詞
- 版權 (copyright)
- 阻斷服務 (denial of service)
- 倫理原則 (ethical principle)
- 駭客 (hackers)
- 智慧財產 (intellectual property)
- 道德規則 (moral rules)
- 專利 (patent)
- 滲透攻擊 (penetration attack)
- 隱私權 (privacy)
- 社會契約 (social contract)
- 商標 (trademark)
- 商業機密 (trade secret)
- 特洛伊木馬 (Trojan horse)
- 功利主義 (utilization)
- 病毒 (virus)
- 蠕蟲 (worm)

### 20.6.3 摘要
- 在使用電腦時評估我們對世界其他地方責任的一種方法是使用道德規則、功利主義和社會契約這三個原則，基於倫理做出決策。
- 如今的倫理問題不僅涉及實體財產，還涉及智慧財產。
- 四種不同類型的智慧財產是商標、商業機密、專利和版權。
- 我們這個時代的一個主要倫理問題是尊重隱私。
- 電腦犯罪主要涉及對電腦系統的滲透或阻斷服務攻擊。
- 可以使用實體保護、保護性軟體和防毒軟體來避免電腦攻擊。
- *駭客*一詞今天指的是未經授權存取他人電腦以複製秘密資訊的個人或組織。

## 20.7 練習題
### 20.7.1 測驗
本章的一組互動測驗可以在本書的網站上找到。強烈建議學生在繼續練習題之前參加測驗以檢查他/她對材料的理解。

### 20.7.2 複習問題
Q20-1. 本章討論的三個倫理原則是什麼？
Q20-2. 實體財產和智慧財產之間有哪些區別？
Q20-3. 有哪些與使用電腦相關的隱私道德準則？
Q20-4. 在談論電腦犯罪時，滲透和阻斷服務有什麼區別？
Q20-5. 惡意人員滲透他人電腦的三種方式是什麼？

### 20.7.3 問題
P20-1. 假設您創建了一個可以被許多供應商使用的軟體。此智慧財產受版權還是專利保護？解釋您的答案。
P20-2. 您創建了一個軟體，您希望對其代碼保密。您需要註冊此智慧財產嗎？解釋您的答案。
P20-3. 如果有人在未事先通知您的情況下收集關於您的資料，這種行為是否違反您的隱私權？解釋您的答案。
P20-4. 如果有人向您發送帶有病毒的電子郵件，這是什麼類型的電腦犯罪？解釋您的答案。
P20-5. 如果有人使機構的電腦系統如此繁忙以至於無法做任何更多工作，這是什麼類型的電腦犯罪？解釋您的答案。
P20-6. 解釋病毒和蠕蟲之間的區別。
P20-7. 解釋病毒和特洛伊木馬之間的區別。
P20-8. 解釋蠕蟲和特洛伊木馬之間的區別。
P20-9. 描述您可以保護電腦免受攻擊的不同方法。
P20-10. 解釋駭客可能對金融機構的電腦系統造成的損害。
`},A={en:`
# Appendix A: Unicode

Computers use numbers. They store characters by assigning a number to each one. The original coding system was called ASCII (American Standard Code for Information Interchange) and had 128 characters each stored as a 7-bit number. ASCII can satisfactorily handle lowercase and uppercase letters, digits, punctuation characters, and some control characters. An attempt was made to extend the ASCII character set to eight bits. The new code, which was called Extended ASCII, was never internationally standardized.

To overcome the difficulties inherent in ASCII and Extended ASCII—not enough bits to represent characters and other symbols needed for communication in other languages—the Unicode Consortium, a group of multilingual software manufacturers, created a universal encoding system to provide a comprehensive character set, called **Unicode**.

Unicode was originally a 2-byte character set. Unicode version 5, however, is a 4-byte code and is fully compatible with ASCII and Extended ASCII. The ASCII set, which is now called Basic Latin, is Unicode with the upper 25 bits set to zero. Extended ASCII, which is now called Latin-1, is Unicode with the 24 upper bits set to zero. Figure A.1 shows how the different systems are compatible.

Each character or symbol in Unicode is defined by a 32-bit number. The code can define up to $2^{32}$ (4294967296) characters or symbols. The description here uses hexadecimal digits in the following format, in which each X is a hexadecimal digit:

\`U+XXXXXXXX\`

## A.1 PLANES
Unicode divides the whole code space into planes. The most significant 16 bits define the plane, which means we can have 65536 ($2^{16}$) planes. For plane 0, the most significant 16 bits are 0s, $(0000)_{16}$, in plane 1 the bits are $(0001)_{16}$, in plane 2 they are $(0002)_{16}$, and so on until in the plane 65536, they are $(FFFF)_{16}$. Each plane can define up to 65536 characters or symbols. Figure A.2 shows the structure of Unicode code spaces and its planes.

### A.1.1 Basic multilingual plane (BMP)
The **basic multilingual plane**, plane 0, is designed to be compatible with the previous 16-bit Unicode. The most significant 16 bits in this plane are all zeros. The codes are normally shown as \`U+XXXX\` with the understanding that XXXX defines only the least significant 16 bits. This plane mostly defines character sets in different languages, with the exception of some codes used for control or other special characters (for more information, see the Unicode Web Page).

### A.1.2 Other planes
Unicode had other planes:
*   The **supplementary multilingual plane**, plane $(0001)_{16}$, is designed to provide more code for multilingual characters that are not included in the BMP plane.
*   The **supplementary ideographic plane**, plane $(0002)_{16}$, is designed to provide code for ideographic symbols, any symbol that primarily denotes an idea or meaning in contrast to a sound or pronunciation.
*   The **supplementary special plane**, plane $(000E)_{16}$, is used for special characters not found in the Basic Latin or Basic Latin-1 codes.
*   **Private use planes**, planes $(000F)_{16}$ and $(0010)_{16}$, are reserved for private use.

## A.2 ASCII
Today, ASCII or Basic Latin, is part of Unicode. It occupies the first 128 codes in Unicode (U-00000000 to U-0000007F). Table A.1 contains the hexadecimal codes and symbols. To find the actual code, we prepend $(000000)_{16}$ to the code.

**Table A.1 ASCII**

| Code | Symbol | Code | Symbol | Code | Symbol | Code | Symbol |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| $(00)_{16}$ | Null | $(20)_{16}$ | Space | $(40)_{16}$ | @ | $(60)_{16}$ | \` |
| $(01)_{16}$ | SOH | $(21)_{16}$ | ! | $(41)_{16}$ | A | $(61)_{16}$ | a |
| $(02)_{16}$ | STX | $(22)_{16}$ | “ | $(42)_{16}$ | B | $(62)_{16}$ | b |
| $(03)_{16}$ | ETX | $(23)_{16}$ | # | $(43)_{16}$ | C | $(63)_{16}$ | c |
| $(04)_{16}$ | EOT | $(24)_{16}$ | $ | $(44)_{16}$ | D | $(64)_{16}$ | d |
| $(05)_{16}$ | ENQ | $(25)_{16}$ | % | $(45)_{16}$ | E | $(65)_{16}$ | e |
| $(06)_{16}$ | ACK | $(26)_{16}$ | & | $(46)_{16}$ | F | $(66)_{16}$ | f |
| $(07)_{16}$ | BEL | $(27)_{16}$ | ‘ | $(47)_{16}$ | G | $(67)_{16}$ | g |
| $(08)_{16}$ | BS | $(28)_{16}$ | ( | $(48)_{16}$ | H | $(68)_{16}$ | h |
| $(09)_{16}$ | HT | $(29)_{16}$ | ) | $(49)_{16}$ | I | $(69)_{16}$ | i |
| $(0A)_{16}$ | LF | $(2A)_{16}$ | * | $(4A)_{16}$ | J | $(6A)_{16}$ | j |
| $(0B)_{16}$ | VT | $(2B)_{16}$ | + | $(4B)_{16}$ | K | $(6B)_{16}$ | k |
| $(0C)_{16}$ | FF | $(2C)_{16}$ | , | $(4C)_{16}$ | L | $(6C)_{16}$ | l |
| $(0D)_{16}$ | CR | $(2D)_{16}$ | - | $(4D)_{16}$ | M | $(6D)_{16}$ | m |
| $(0E)_{16}$ | SO | $(2E)_{16}$ | . | $(4E)_{16}$ | N | $(6E)_{16}$ | n |
| $(0F)_{16}$ | SI | $(2F)_{16}$ | / | $(4F)_{16}$ | O | $(6F)_{16}$ | o |
| $(10)_{16}$ | DLE | $(30)_{16}$ | 0 | $(50)_{16}$ | P | $(70)_{16}$ | p |
| $(11)_{16}$ | DC1 | $(31)_{16}$ | 1 | $(51)_{16}$ | Q | $(71)_{16}$ | q |
| $(12)_{16}$ | DC2 | $(32)_{16}$ | 2 | $(52)_{16}$ | R | $(72)_{16}$ | r |
| $(13)_{16}$ | DC3 | $(33)_{16}$ | 3 | $(53)_{16}$ | S | $(73)_{16}$ | s |
| $(14)_{16}$ | DC4 | $(34)_{16}$ | 4 | $(54)_{16}$ | T | $(74)_{16}$ | t |
| $(15)_{16}$ | NAK | $(35)_{16}$ | 5 | $(55)_{16}$ | U | $(75)_{16}$ | u |
| $(16)_{16}$ | SYN | $(36)_{16}$ | 6 | $(56)_{16}$ | V | $(76)_{16}$ | v |
| $(17)_{16}$ | ETB | $(37)_{16}$ | 7 | $(57)_{16}$ | W | $(77)_{16}$ | w |
| $(18)_{16}$ | CAN | $(38)_{16}$ | 8 | $(58)_{16}$ | X | $(78)_{16}$ | x |
| $(19)_{16}$ | EM | $(39)_{16}$ | 9 | $(59)_{16}$ | Y | $(79)_{16}$ | y |
| $(1A)_{16}$ | SUB | $(3A)_{16}$ | : | $(5A)_{16}$ | Z | $(7A)_{16}$ | z |
| $(1B)_{16}$ | ESC | $(3B)_{16}$ | ; | $(5B)_{16}$ | [ | $(7B)_{16}$ | { |
| $(1C)_{16}$ | FS | $(3C)_{16}$ | < | $(5C)_{16}$ | \\ | $(7C)_{16}$ | | |
| $(1D)_{16}$ | GS | $(3D)_{16}$ | = | $(5D)_{16}$ | ] | $(7D)_{16}$ | } |
| $(1E)_{16}$ | RS | $(3E)_{16}$ | > | $(5E)_{16}$ | ^ | $(7E)_{16}$ | ~ |
| $(1F)_{16}$ | US | $(3F)_{16}$ | ? | $(5F)_{16}$ | _ | $(7F)_{16}$ | DEL |

### A.2.1 Some properties of ASCII
ASCII has some interesting properties that we need to briefly mention here:
1.  The first code, $(00)_{16}$, which is non-printable, is the null character. It represents the absence of any character.
2.  The last code, $(7F)_{16}$, is the delete character, which is also non-printable. It is used by some programs to delete the current character.
3.  The space character, $(20)_{16}$, is a printable character. It prints a blank space.
4.  Characters with code $(01)_{16}$ to $(1F)_{16}$ are control characters: they are not printable. Table A.2 shows their functions. Most of these characters were used in data communication in out-of-date protocols.

**Table A.2 Explanation for control characters**
| Symbol | Explanation | Symbol | Explanation |
| :--- | :--- | :--- | :--- |
| SOH | Start of heading | DC1 | Device control 1 |
| STX | Start of text | DC2 | Device control 2 |
| ETX | End of text | DC3 | Device control 3 |
| EOT | End of transmission | DC4 | Device control 4 |
| ENQ | Enquiry | NAK | Negative acknowledgment |
| ACK | Acknowledgment | SYN | Synchronous idle |
| BEL | Ring bell | ETB | End of transmission block |
| BS | Backspace | CAN | Cancel |
| HT | Horizontal tab | EM | End of medium |
| LF | Line feed | SUB | Substitute |
| VT | Vertical tab | ESC | Escape |
| FF | Form feed | FS | File separator |
| CR | Carriage return | GS | Group separator |
| SO | Shift out | RS | Record separator |
| SI | Shift in | US | Unit separator |

5.  The uppercase letters start from $(41)_{16}$. The lowercase letters start from $(61)_{16}$. When numerically compared, uppercase letters are smaller than lowercase ones. This means that when we sort a list based on ASCII values, the uppercase letters show before the lowercase letters.
6.  The uppercase and lowercase letters differ by only one bit in the 7-bit code. For example, character A is $(41)_{16}$ and character a is $(61)_{16}$. The difference is bit 6, which is 0 in uppercase letters and 1 in lowercase letters. If we know the code for one case, we can find the code for the other easily by adding or subtracting, $(20)_{16}$ in hexadecimal or flipping the sixth bit. In other words, the code for character A is $(41)_{16} = (1000001)_2$, but the code for character a is $(61)_{16} = (1100001)_2$: the sixth bit in binary notation is flipped from 0 to 1.
7.  The uppercase letters are not immediately followed by lowercase letters—there are some punctuation characters in between.
8.  Decimal digits (0 to 9) begin at $(30)_{16}$. This means that if we want to change a numeric character to its face value as an integer, we need to subtract $(30)_{16} = 48$ from it. For example, the code for 8 in ASCII is $(38)_{16} = 56$. To find the face value, we need to subtract 48 from this, or $56 - 48 = 8$.
`,zh:`
# 附錄 A：萬國碼 (Unicode)

電腦使用數字。它們透過為每個字元分配一個數字來儲存字元。最初的編碼系統稱為 ASCII（美國資訊交換標準碼），有 128 個字元，每個字元儲存為 7 位元數字。ASCII 可以令人滿意地處理大寫和小寫字母、數字、標點符號和一些控制字元。曾有人試圖將 ASCII 字元集擴展到八位元。新代碼稱為擴展 ASCII (Extended ASCII)，但從未在國際上標準化。

為了克服 ASCII 和擴展 ASCII 固有的困難——沒有足夠的位元來表示其他語言通訊所需的字元和其他符號——Unicode 聯盟（一群多語言軟體製造商）創建了一個通用的編碼系統，以提供全面的字元集，稱為 **Unicode**。

Unicode 最初是一個 2 位元組的字元集。然而，Unicode 第 5 版是一個 4 位元組代碼，並且與 ASCII 和擴展 ASCII 完全相容。ASCII 集（現在稱為基本拉丁文）是高 25 位元設為零的 Unicode。擴展 ASCII（現在稱為 Latin-1）是高 24 位元設為零的 Unicode。圖 A.1 顯示了不同系統如何相容。

Unicode 中的每個字元或符號都由一個 32 位元數字定義。該代碼最多可以定義 $2^{32}$ (4294967296) 個字元或符號。這裡的描述使用以下格式的十六進位數字，其中每個 X 是一個十六進位數字：

\`U+XXXXXXXX\`

## A.1 平面 (PLANES)
Unicode 將整個代碼空間劃分為多個平面。最高有效的 16 位元定義了平面，這意味著我們可以有 65536 ($2^{16}$) 個平面。對於平面 0，最高有效的 16 位元是 0，$(0000)_{16}$，在平面 1 中，位元是 $(0001)_{16}$，在平面 2 中，它們是 $(0002)_{16}$，依此類推，直到在平面 65536 中，它們是 $(FFFF)_{16}$。每個平面最多可以定義 65536 個字元或符號。圖 A.2 顯示了 Unicode 代碼空間及其平面的結構。

### A.1.1 基本多文種平面 (BMP)
**基本多文種平面**，平面 0，旨在與以前的 16 位元 Unicode 相容。此平面中最高有效的 16 位元全為零。代碼通常顯示為 \`U+XXXX\`，其中 XXXX 僅定義最低有效的 16 位元。此平面主要定義不同語言的字元集，除了一些用於控制或其他特殊字元的代碼（有關更多資訊，請參閱 Unicode 網頁）。

### A.1.2 其他平面
Unicode 有其他平面：
*   **輔助多文種平面**，平面 $(0001)_{16}$，旨在為未包含在 BMP 平面中的多語言字元提供更多代碼。
*   **輔助表意文字平面**，平面 $(0002)_{16}$，旨在為表意符號提供代碼，即任何主要表示思想或意義而非聲音或發音的符號。
*   **輔助專用平面**，平面 $(000E)_{16}$，用於未在基本拉丁文或基本拉丁文-1 代碼中找到的特殊字元。
*   **私人使用平面**，平面 $(000F)_{16}$ 和 $(0010)_{16}$，保留供私人使用。

## A.2 ASCII
今天，ASCII 或基本拉丁文是 Unicode 的一部分。它佔據了 Unicode 中的前 128 個代碼（U-00000000 到 U-0000007F）。表 A.1 包含十六進位代碼和符號。要找到實際代碼，我們在代碼前加上 $(000000)_{16}$。

**表 A.1 ASCII**

| 代碼 | 符號 | 代碼 | 符號 | 代碼 | 符號 | 代碼 | 符號 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| $(00)_{16}$ | Null | $(20)_{16}$ | Space | $(40)_{16}$ | @ | $(60)_{16}$ | \` |
| $(01)_{16}$ | SOH | $(21)_{16}$ | ! | $(41)_{16}$ | A | $(61)_{16}$ | a |
| $(02)_{16}$ | STX | $(22)_{16}$ | “ | $(42)_{16}$ | B | $(62)_{16}$ | b |
| $(03)_{16}$ | ETX | $(23)_{16}$ | # | $(43)_{16}$ | C | $(63)_{16}$ | c |
| $(04)_{16}$ | EOT | $(24)_{16}$ | $ | $(44)_{16}$ | D | $(64)_{16}$ | d |
| $(05)_{16}$ | ENQ | $(25)_{16}$ | % | $(45)_{16}$ | E | $(65)_{16}$ | e |
| $(06)_{16}$ | ACK | $(26)_{16}$ | & | $(46)_{16}$ | F | $(66)_{16}$ | f |
| $(07)_{16}$ | BEL | $(27)_{16}$ | ‘ | $(47)_{16}$ | G | $(67)_{16}$ | g |
| $(08)_{16}$ | BS | $(28)_{16}$ | ( | $(48)_{16}$ | H | $(68)_{16}$ | h |
| $(09)_{16}$ | HT | $(29)_{16}$ | ) | $(49)_{16}$ | I | $(69)_{16}$ | i |
| $(0A)_{16}$ | LF | $(2A)_{16}$ | * | $(4A)_{16}$ | J | $(6A)_{16}$ | j |
| $(0B)_{16}$ | VT | $(2B)_{16}$ | + | $(4B)_{16}$ | K | $(6B)_{16}$ | k |
| $(0C)_{16}$ | FF | $(2C)_{16}$ | , | $(4C)_{16}$ | L | $(6C)_{16}$ | l |
| $(0D)_{16}$ | CR | $(2D)_{16}$ | - | $(4D)_{16}$ | M | $(6D)_{16}$ | m |
| $(0E)_{16}$ | SO | $(2E)_{16}$ | . | $(4E)_{16}$ | N | $(6E)_{16}$ | n |
| $(0F)_{16}$ | SI | $(2F)_{16}$ | / | $(4F)_{16}$ | O | $(6F)_{16}$ | o |
| $(10)_{16}$ | DLE | $(30)_{16}$ | 0 | $(50)_{16}$ | P | $(70)_{16}$ | p |
| $(11)_{16}$ | DC1 | $(31)_{16}$ | 1 | $(51)_{16}$ | Q | $(71)_{16}$ | q |
| $(12)_{16}$ | DC2 | $(32)_{16}$ | 2 | $(52)_{16}$ | R | $(72)_{16}$ | r |
| $(13)_{16}$ | DC3 | $(33)_{16}$ | 3 | $(53)_{16}$ | S | $(73)_{16}$ | s |
| $(14)_{16}$ | DC4 | $(34)_{16}$ | 4 | $(54)_{16}$ | T | $(74)_{16}$ | t |
| $(15)_{16}$ | NAK | $(35)_{16}$ | 5 | $(55)_{16}$ | U | $(75)_{16}$ | u |
| $(16)_{16}$ | SYN | $(36)_{16}$ | 6 | $(56)_{16}$ | V | $(76)_{16}$ | v |
| $(17)_{16}$ | ETB | $(37)_{16}$ | 7 | $(57)_{16}$ | W | $(77)_{16}$ | w |
| $(18)_{16}$ | CAN | $(38)_{16}$ | 8 | $(58)_{16}$ | X | $(78)_{16}$ | x |
| $(19)_{16}$ | EM | $(39)_{16}$ | 9 | $(59)_{16}$ | Y | $(79)_{16}$ | y |
| $(1A)_{16}$ | SUB | $(3A)_{16}$ | : | $(5A)_{16}$ | Z | $(7A)_{16}$ | z |
| $(1B)_{16}$ | ESC | $(3B)_{16}$ | ; | $(5B)_{16}$ | [ | $(7B)_{16}$ | { |
| $(1C)_{16}$ | FS | $(3C)_{16}$ | < | $(5C)_{16}$ | \\ | $(7C)_{16}$ | | |
| $(1D)_{16}$ | GS | $(3D)_{16}$ | = | $(5D)_{16}$ | ] | $(7D)_{16}$ | } |
| $(1E)_{16}$ | RS | $(3E)_{16}$ | > | $(5E)_{16}$ | ^ | $(7E)_{16}$ | ~ |
| $(1F)_{16}$ | US | $(3F)_{16}$ | ? | $(5F)_{16}$ | _ | $(7F)_{16}$ | DEL |

### A.2.1 ASCII 的一些特性
ASCII 有一些我們需要在這裡簡要提及的有趣特性：
1.  第一個代碼 $(00)_{16}$ 是不可列印的，是空字元。它代表沒有任何字元。
2.  最後一個代碼 $(7F)_{16}$ 是刪除字元，也是不可列印的。它被一些程式用來刪除當前字元。
3.  空格字元 $(20)_{16}$ 是一個可列印字元。它列印一個空白空間。
4.  代碼為 $(01)_{16}$ 到 $(1F)_{16}$ 的字元是控制字元：它們不可列印。表 A.2 顯示了它們的功能。這些字元中的大多數用於過時協定中的資料通訊。

**表 A.2 控制字元解釋**
| 符號 | 解釋 | 符號 | 解釋 |
| :--- | :--- | :--- | :--- |
| SOH | 標題開始 | DC1 | 設備控制 1 |
| STX | 文本開始 | DC2 | 設備控制 2 |
| ETX | 文本結束 | DC3 | 設備控制 3 |
| EOT | 傳輸結束 | DC4 | 設備控制 4 |
| ENQ | 詢問 | NAK | 否定確認 |
| ACK | 確認 | SYN | 同步閒置 |
| BEL | 響鈴 | ETB | 傳輸區塊結束 |
| BS | 退格 | CAN | 取消 |
| HT | 水平定位 | EM | 媒體結束 |
| LF | 換行 | SUB | 替換 |
| VT | 垂直定位 | ESC | 逸出 |
| FF | 換頁 | FS | 檔案分隔符 |
| CR | 歸位 | GS | 群組分隔符 |
| SO | 移出 | RS | 記錄分隔符 |
| SI | 移入 | US | 單元分隔符 |

5.  大寫字母從 $(41)_{16}$ 開始。小寫字母從 $(61)_{16}$ 開始。在數值比較時，大寫字母小於小寫字母。這意味著當我們根據 ASCII 值對列表進行排序時，大寫字母顯示在小寫字母之前。
6.  大寫和小寫字母在 7 位元代碼中僅相差一個位元。例如，字元 A 是 $(41)_{16}$，字元 a 是 $(61)_{16}$。區別在於第 6 位元，在大寫字母中為 0，在小寫字母中為 1。如果我們知道一種情況的代碼，我們可以透過加上或減去十六進位的 $(20)_{16}$ 或翻轉第六位元來輕鬆找到另一種情況的代碼。換句話說，字元 A 的代碼是 $(41)_{16} = (1000001)_2$，但字元 a 的代碼是 $(61)_{16} = (1100001)_2$：二進位表示法中的第六位元從 0 翻轉為 1。
7.  大寫字母後面不緊跟小寫字母——中間有一些標點符號。
8.  十進位數字（0 到 9）從 $(30)_{16}$ 開始。這意味著如果我們想將數字字元更改為其作為整數的面值，我們需要從中減去 $(30)_{16} = 48$。例如，ASCII 中 8 的代碼是 $(38)_{16} = 56$。要找到面值，我們需要從中減去 48，即 $56 - 48 = 8$。
`},$={en:`
# Appendix B: Unified Modeling Language (UML)

**Unified Modeling Language (UML)** is a graphical language used for analysis and design. Through UML we can specify, visualize, construct, and document software and hardware systems using standard graphical notations. UML provides different levels of abstraction, called **views**, as shown in Figure B.1.

As shown in Figure B.1 the four views are:
1.  The **user view**, which shows the interaction of the user with the system. This view is represented by use-case diagrams.
2.  The **structural view**, which shows the static structure of the system. This view is represented by class diagrams.
3.  The **behavioral view**, which shows how the objects in the system behave. This view is represented by collaboration, sequence, state, and activity diagrams.
4.  The **implementation view**, which shows how the system is implemented. It contains component and deployment diagrams.

## B.1 THE USER VIEW
The user view is a high level view of the whole system. It shows how a system is organized in general. There is only one type of diagram in user views, the use-case diagram.

### B.1.1 Use-case diagrams
A project normally starts with a use-case diagram. A **use-case diagram** gives the user’s view of a system: it shows how the users communicate with the system. Figure B.2 shows an example of a use-case diagram. A use-case diagram uses four main components: **system**, **use cases**, **actors**, and **relationships**. Each component is explained below.

**System**
A system performs a function. We are interested only in a computer system. The computer system in a use-case diagram is shown by a rectangular box with the name of the system outside the box in the top-left corner.

**Use cases**
A system contains many actions represented as use cases. Each use case defines one of the actions that can be taken by the users of a system. A use case in a use-case diagram is shown by a rectangle with rounded corners.

**Actors**
An actor is someone or something that uses the system. Although actors are shown as stick figures, they do not necessarily represent human beings.

**Relationships**
Relationships are associations between actors and use cases. A relationship is shown as a line connecting actors to use cases. An actor can relate to multiple use cases and a use case can be used by multiple actors.

## B.2 THE STRUCTURAL VIEW
The structural view shows the static nature of the system, classes and their relationships. The structural view uses only one type of diagram, class diagrams.

### B.2.1 Class diagrams
A **class diagram** manifests the static structure of a system. It shows the characteristics of the classes and the relationship between them. The symbol for a class is a rectangle with the name of the class written inside. Figure B.3 shows three classes, Person, Fraction, and Elevator, belonging to three different systems—that is, there is no relationship between them.

Class diagrams are extended by adding attributes, types, and methods to the diagram. Relationships between classes are shown with association and generalization diagrams.

**Attributes and types**
A class symbol can include attributes and types in a separate compartment. An attribute is a property of a class and a type is the type of data used to represent that attribute. Figure B.4 shows some attributes of the classes Person and Fraction.

**Methods**
A class can also be extended to include methods. A method is a procedure that can be used by an object (an instance of a class) or applied to an object. In other words, an object is either a doer or a receiver. Figure B.5 shows two classes with attributes and methods. The attributes and methods are listed in separate compartments.

**Association**
An association is a conceptual relation between two classes. An association is shown by a solid line between two classes. If a name is given to the association, it is written next to the line with a solid arrow.
An association can be one-to-one, one-to-many, many-to-one or many-to-many. Figure B.6 shows four classes and some associations between them. It shows that one professor (an object of the Professor class) can teach from one to five courses (1…5). Conversely, in this example, a course can have only one professor. The university (an object of the University class) can have many professors and many students (objects of the Student class), as indicated by the asterisk (*) on the association line. The figure also shows that a student can take many courses.

**Generalization**
Generalization organizes classes based on their similarities and differences. Generalization allows us to define **subclasses** and **superclasses**. A subclass inherits characteristics (attributes and methods) of all its superclasses, but it normally has some characteristics (attributes and methods) of its own. Figure B.7 shows single and multiple inheritance.

## B.3 THE BEHAVIORAL VIEW
A behavioral view looks at the behavior of objects in a system. Depending on the type of the behavior, we can have four different diagrams: collaboration diagrams, state diagrams, sequence diagrams, and activity diagrams.

### B.3.1 Collaboration diagrams
A collaboration diagram is similar to a class diagram. The difference is that the class diagram shows the relationship between classes, whereas a collaboration diagram shows the relationship between objects (instances of classes).
Any object instantiated from the class can also be shown in a rectangle with the name of the object followed by a colon and the name of the class. For an anonymous object, the name of the object is left out. Figure B.8 shows three objects instantiated from the class Person.

**Attributes and values**
An attribute is a property of a class, while a value is a property of an object corresponding to an attribute. An object symbol can include values. Figure B.9 shows some attributes of the classes Person and Fraction with values for attributes within the classes.

**Methods and operations**
Although an object symbol can also include methods and operations, it is not common in a collaboration diagram.

**Links**
A link in a collaboration diagram is an instance of an association in a class diagram. Objects can be related to each other using links. Two stereotype notations can be used for links: local and parameter. The first shows that one object uses another object as a local variable: the second shows that one object uses another object as a parameter. Multiplicity, as shown in the association between Student and Course in Figure B.6, can also be shown by multiple superimposed objects. Multiplicity can also be shown between objects of the same class. Figure B.10 shows that a Student’s object uses multiple Course objects as parameters.

**Messages**
An object can send a message to another object. A message can represent an event sent from the first object to the second. A message can also invoke a method in the second object. Finally, an object can create or destroy another object using a message. Messages are shown by an arrow pointing in the direction of the message and are shown over the link between objects. Figure B.11 shows how an Editor object sends a print message to a Printer object.

### B.3.2 State diagrams
A state diagram is used to show changes in the states of a single object. An object may change its state in response to an event. For example, a switch may change its state from **off** to **on** when it is turned on. A washing machine may change its state from **wash** to **rinse** in response to triggers from a timer.

**Symbols**
A state diagram uses three main symbols, as shown in Figure B.12.

**States**
There are three symbols for states: the start state, the stop state, and the intermediate state. The start state, which is drawn as a black circle with its name next to the circle, is allowed only once in the diagram. The stop state, which is drawn as a solid black circle inside another circle, can be repeated in the diagram. The intermediate state is drawn as a rectangle with rounded corners with the name of the state inside the rectangle.

**Transitions**
In a state diagram, a transition is a movement between states. The transition symbol is an arrowed line between two states. The arrow shows the next state. One or more transitions can leave a state: only one transition can arrive at a state.

**Decision point**
A decision point is shown by a diamond. A transition can take several paths based on data or conditions in the object.

**Events**
In a state diagram, an object is triggered by an event, which can be external or internal. For example, a switch may move from an **off** state to an **on** state if it is turned on. An event is represented by a string which defines the operation in the class that handles the event. It may have parentheses containing the formal parameters to be passed to the operation. An event can also have a condition enclosed in brackets. The following shows an example of an event:
\`withdraw (amount) [amount < balance]\`
An object may or may not move to another state when triggered by an event.

**Actions**
Although an action may be triggered in several ways, we only mention an action triggered by an event. An action is shown by a string, which normally defines another object and the event that should be invoked for that object. If parameters are needed for the target object they are included in parentheses. The action is separated from the event by using a forward slash. The following shows an example of an action:
\`deposit (amount) / add (balance)\`

**Example B.1**
Figure B.13 shows a simple example of a state diagram. There are six states—a start and a stop state and four intermediate states—nine events, and four actions.

### B.3.3 Sequence diagrams
A sequence diagram shows the interaction between objects (or actors) over time. In a sequence diagram, objects (or actors) are listed as columns, and time, which flows notionally downwards, is represented as a vertical broken line.

**Symbols**
A sequence diagram uses five main symbols, as shown in Figure B.14.

**Actor**
The symbol for an actor is the same stick figure as we saw in use-case diagrams. Since actors can also communicate with objects, they can be part of a sequence diagram.

**Object**
Objects, as we saw before, are instances of classes. A sequence diagram represents the interaction between the objects.

**Lifeline**
A lifeline, shown by a solid or dashed vertical line, represents an individual participant in a sequence diagram. It is usually headed by a rectangle that contains the name of the object or actor. The vertical line, which represents the lifespan of the object, extends to the point where the object is no longer active.

**Activation**
Activation, represented by a solid narrow rectangle, shows the time when the object is involved in an activity, that is, when it is not idle. For example, if an object has sent a message to another object and is waiting for a response, the object is involved during this time.

**Message**
Messages are shown as horizontal arrowed lines showing the interaction between objects (or actors).

**Example B.2**
Figure B.15 shows a simple example of a sequence diagram with one actor and three anonymous objects. The diagram also shows concurrency: the first object, after receiving the first message, concurrently sends two messages: one to the actor and one to the second object.

### B.3.4 Activity diagrams
An activity diagram shows the break-down of a complex operation or a process into a set of simpler operations or processes. An activity diagram is more detailed than a sequence diagram. A sequence diagram emphasizes objects, while an activity diagram shows more detailed operations performed by one or more objects. An activity diagram in object-oriented programming replaces a traditional flowchart in procedural programming. However, a traditional flowchart shows only sequential flow control (serial), while an activity diagram can show both sequential and concurrent (parallel) flow control.

**Symbols**
An activity diagram uses six main symbols, as shown in Figure B.16.

**Activities**
An activity is a step in an activity diagram. We show an activity using a rectangle with rounded corners that contains the name of the activity. The level of detail in an activity should be consistent for the whole diagram. If more detail is needed for one of the activities, a new diagram should be drawn to show it.

**Transitions**
Similar to a state diagram, a transition in an activity diagram is shown by an arrowed line. The arrow shows the direction of the action.

**Start and end points**
The start point in an activity diagram is a solid circle with a single outgoing transition: the stop point is a solid circle surrounded by a hollow circle (bull’s eye) with a single incoming transition. There can be only one start point. While logically there can be only one end point, multiple end points are allowed to make the diagram easier to read.

**Decision and merge**
A diamond shows a decision or a merge point. A transition can take several paths based on conditions. When used as a decision point, a diamond symbol can have only one entry, with two or more exits. When used as a merge point, a diamond symbol can have two or more entries but only one exit.

**Fork or joint**
A thick line shows a fork or join in parallel processing. A fork symbol shows the start of two or more threads of processes: a joint symbol shows the end of the threads.

**Example B.3**
Figure B.17 shows an example of an activity diagram. Activities 2 and 3 are done concurrently (parallel processing).

### B.3.5 Swimlanes
Sometimes operations in an activity diagram are performed by different objects or actors. To show that more than one object or actor is involved, **swimlanes** are added to an activity diagram, as shown in Figure B.18.

## B.4 THE IMPLEMENTATION VIEW
An implementation view shows how the final product is implemented. Two types of diagrams are used to show the implementations: component diagrams and deployment diagrams.

### B.4.1 Component diagrams
A component diagram shows the software components and the dependencies among them. The components are shown as rectangles with two small rectangles on their left edges. A dependency between the components is shown by a dashed line with an arrow on the end. We can also use stereotyping on the dependency line by including such stereotype relations such as <<report>>. Figure B.19 shows a component diagram.

### B.4.2 Deployment diagrams
A deployment diagram shows nodes connected by communication links. A node is shown as a cuboid and the communication association (link) is shown as a line connecting two nodes. A node can also include one or more components. Figure B.20 shows a simple deployment diagram.
`,zh:`
# 附錄 B：統一塑模語言 (UML)

**統一塑模語言 (UML)** 是一種用於分析和設計的圖形化語言。透過 UML，我們可以使用標準的圖形符號來指定、視覺化、建構和記錄軟體和硬體系統。UML 提供了不同層級的抽象，稱為**視圖**，如圖 B.1 所示。

如圖 B.1 所示，四個視圖是：
1.  **使用者視圖**，顯示使用者與系統的互動。此視圖由使用案例圖表示。
2.  **結構視圖**，顯示系統的靜態結構。此視圖由類別圖表示。
3.  **行為視圖**，顯示系統中物件的行為方式。此視圖由協作圖、循序圖、狀態圖和活動圖表示。
4.  **實作視圖**，顯示系統的實作方式。它包含組件圖和部署圖。

## B.1 使用者視圖
使用者視圖是整個系統的高階視圖。它顯示了系統的一般組織方式。使用者視圖中只有一種類型的圖，即使用案例圖。

### B.1.1 使用案例圖 (Use-case diagrams)
專案通常以使用案例圖開始。**使用案例圖**給出了系統的使用者視圖：它顯示了使用者如何與系統通訊。圖 B.2 顯示了一個使用案例圖的範例。使用案例圖使用四個主要組件：**系統**、**使用案例**、**參與者**和**關係**。每個組件解釋如下。

**系統**
系統執行功能。我們只對電腦系統感興趣。使用案例圖中的電腦系統由一個矩形框表示，系統名稱在框外的左上角。

**使用案例**
系統包含許多表示為使用案例的動作。每個使用案例定義了系統使用者可以採取的動作之一。使用案例圖中的使用案例由圓角矩形顯示。

**參與者 (Actors)**
參與者是使用系統的人或事物。雖然參與者顯示為火柴人，但它們不一定代表人類。

**關係**
關係是參與者與使用案例之間的關聯。關係顯示為連接參與者與使用案例的線。一個參與者可以與多個使用案例相關聯，一個使用案例也可以被多個參與者使用。

## B.2 結構視圖
結構視圖顯示系統、類別及其關係的靜態性質。結構視圖僅使用一種類型的圖，即類別圖。

### B.2.1 類別圖 (Class diagrams)
**類別圖**展示了系統的靜態結構。它顯示了類別的特徵以及它們之間的關係。類別的符號是一個矩形，裡面寫著類別的名稱。圖 B.3 顯示了三個類別：Person、Fraction 和 Elevator，屬於三個不同的系統——也就是說，它們之間沒有關係。

透過向圖中添加屬性、類型和方法來擴展類別圖。類別之間的關係用關聯圖和泛化圖表示。

**屬性和類型**
類別符號可以在單獨的區間中包含屬性和類型。屬性是類別的性質，類型是用於表示該屬性的資料類型。圖 B.4 顯示了類別 Person 和 Fraction 的一些屬性。

**方法**
類別也可以擴展以包含方法。方法是一個可以由物件（類別的實例）使用或應用於物件的程序。換句話說，物件要麼是執行者，要麼是接收者。圖 B.5 顯示了兩個具有屬性和方法的類別。屬性和方法列在單獨的區間中。

**關聯 (Association)**
關聯是兩個類別之間的概念關係。關聯由兩個類別之間的實線顯示。如果給關聯一個名稱，它會寫在帶有實心箭頭的線旁邊。
關聯可以是一對一、一對多、多對一或多對多。圖 B.6 顯示了四個類別以及它們之間的一些關聯。它顯示一位教授（Professor 類別的物件）可以教授一到五門課程 (1…5)。相反，在這個例子中，一門課程只能有一位教授。大學（University 類別的物件）可以有許多教授和許多學生（Student 類別的物件），如關聯線上的星號 (*) 所示。該圖還顯示一名學生可以選修多門課程。

**泛化 (Generalization)**
泛化根據類別的相似性和差異性來組織類別。泛化允許我們定義**子類別**和**超類別**。子類別繼承其所有超類別的特徵（屬性和方法），但它通常具有一些自己的特徵（屬性和方法）。圖 B.7 顯示了單一繼承和多重繼承。

## B.3 行為視圖
行為視圖查看系統中物件的行為。根據行為的類型，我們可以有四種不同的圖：協作圖、狀態圖、循序圖和活動圖。

### B.3.1 協作圖 (Collaboration diagrams)
協作圖類似於類別圖。不同之處在於類別圖顯示類別之間的關係，而協作圖顯示物件（類別的實例）之間的關係。
從類別實例化的任何物件也可以顯示在一個矩形中，物件名稱後面跟著冒號和類別名稱。對於匿名物件，省略物件名稱。圖 B.8 顯示了從類別 Person 實例化的三個物件。

**屬性和值**
屬性是類別的性質，而值是物件對應於屬性的性質。物件符號可以包含值。圖 B.9 顯示了類別 Person 和 Fraction 的一些屬性以及類別內屬性的值。

**方法和操作**
雖然物件符號也可以包含方法和操作，但在協作圖中並不常見。

**連結 (Links)**
協作圖中的連結是類別圖中關聯的實例。物件可以使用連結相互關聯。連結可以使用兩種構造型符號：區域和參數。第一種顯示一個物件使用另一個物件作為區域變數：第二種顯示一個物件使用另一個物件作為參數。如圖 B.6 中 Student 和 Course 之間的關聯所示的多重性，也可以通過多個重疊物件來顯示。多重性也可以在同一類別的物件之間顯示。圖 B.10 顯示了一個 Student 物件使用多個 Course 物件作為參數。

**訊息**
一個物件可以向另一個物件發送訊息。訊息可以代表從第一個物件發送到第二個物件的事件。訊息也可以調用第二個物件中的方法。最後，一個物件可以使用訊息創建或銷毀另一個物件。訊息由指向訊息方向的箭頭顯示，並顯示在物件之間的連結上方。圖 B.11 顯示了 Editor 物件如何向 Printer 物件發送列印訊息。

### B.3.2 狀態圖 (State diagrams)
狀態圖用於顯示單一物件狀態的變化。物件可能會因應事件而改變其狀態。例如，開關在打開時可能會從**關**狀態變為**開**狀態。洗衣機可能會因應計時器的觸發而從**洗滌**狀態變為**漂洗**狀態。

**符號**
狀態圖使用三個主要符號，如圖 B.12 所示。

**狀態**
狀態有三種符號：開始狀態、停止狀態和中間狀態。開始狀態繪製為黑色圓圈，名稱在圓圈旁邊，在圖中僅允許出現一次。停止狀態繪製為另一個圓圈內的實心黑色圓圈，可以在圖中重複出現。中間狀態繪製為圓角矩形，狀態名稱在矩形內。

**轉換**
在狀態圖中，轉換是狀態之間的移動。轉換符號是兩個狀態之間的箭頭線。箭頭顯示下一個狀態。一個或多個轉換可以離開一個狀態：只有一個轉換可以到達一個狀態。

**決策點**
決策點由菱形顯示。轉換可以根據物件中的資料或條件採取多條路徑。

**事件**
在狀態圖中，物件由事件觸發，事件可以是外部的或內部的。例如，開關如果被打開，可能會從**關**狀態移動到**開**狀態。事件由定義處理該事件的類別中操作的字串表示。它可能有包含要傳遞給操作的形式參數的括號。事件也可以有括在括號中的條件。以下顯示了一個事件的範例：
\`withdraw (amount) [amount < balance]\`
當被事件觸發時，物件可能會或可能不會移動到另一個狀態。

**動作**
雖然動作可以透過多種方式觸發，但我們只提及由事件觸發的動作。動作由一個字串顯示，該字串通常定義另一個物件以及應該為該物件調用的事件。如果目標物件需要參數，它們包含在括號中。動作使用正斜線與事件分隔。以下顯示了一個動作的範例：
\`deposit (amount) / add (balance)\`

**範例 B.1**
圖 B.13 顯示了一個簡單的狀態圖範例。有六個狀態——一個開始和一個停止狀態以及四個中間狀態——九個事件和四個動作。

### B.3.3 循序圖 (Sequence diagrams)
循序圖顯示物件（或參與者）之間隨時間的互動。在循序圖中，物件（或參與者）列為列，時間概念上向下流動，由垂直虛線表示。

**符號**
循序圖使用五個主要符號，如圖 B.14 所示。

**參與者**
參與者的符號與我們在使用案例圖中看到的火柴人相同。由於參與者也可以與物件通訊，因此它們可以是循序圖的一部分。

**物件**
如前所述，物件是類別的實例。循序圖表示物件之間的互動。

**生命線**
生命線由實線或虛線垂直線顯示，代表循序圖中的單個參與者。它通常以包含物件或參與者名稱的矩形為首。垂直線代表物件的壽命，延伸到物件不再活躍的點。

**活化 (Activation)**
活化由實心窄矩形表示，顯示物件參與活動的時間，即它不閒置的時間。例如，如果一個物件向另一個物件發送了訊息並正在等待回應，則該物件在此期間參與其中。

**訊息**
訊息顯示為水平箭頭線，顯示物件（或參與者）之間的互動。

**範例 B.2**
圖 B.15 顯示了一個簡單的循序圖範例，其中包含一個參與者和三個匿名物件。該圖還顯示了並行性：第一個物件在收到第一條訊息後，同時發送兩條訊息：一條給參與者，一條給第二個物件。

### B.3.4 活動圖 (Activity diagrams)
活動圖顯示將複雜操作或過程分解為一組更簡單的操作或過程。活動圖比循序圖更詳細。循序圖強調物件，而活動圖顯示由一個或多個物件執行的更詳細操作。物件導向程式設計中的活動圖取代了程序導向程式設計中的傳統流程圖。然而，傳統流程圖僅顯示循序流控制（串列），而活動圖可以顯示循序和並行（平行）流控制。

**符號**
活動圖使用六個主要符號，如圖 B.16 所示。

**活動**
活動是活動圖中的一個步驟。我們使用包含活動名稱的圓角矩形顯示活動。活動的詳細程度應在整個圖中保持一致。如果其中一個活動需要更多細節，應繪製新圖來顯示它。

**轉換**
與狀態圖類似，活動圖中的轉換由箭頭線顯示。箭頭顯示動作的方向。

**開始和結束點**
活動圖中的開始點是一個帶有單個外向轉換的實心圓：停止點是一個被空心圓（靶心）包圍的實心圓，帶有單個傳入轉換。只能有一個開始點。雖然邏輯上只能有一個結束點，但允許有多個結束點以使圖表更容易閱讀。

**決策和合併**
菱形顯示決策或合併點。轉換可以根據條件採取多條路徑。當用作決策點時，菱形符號只能有一個入口，有兩個或多個出口。當用作合併點時，菱形符號可以有兩個或多個入口但只有一個出口。

**分叉或匯合**
粗線顯示平行處理中的分叉或匯合。分叉符號顯示兩個或多個執行緒的開始：匯合符號顯示執行緒的結束。

**範例 B.3**
圖 B.17 顯示了一個活動圖的範例。活動 2 和 3 是並行完成的（平行處理）。

### B.3.5 泳道 (Swimlanes)
有時活動圖中的操作由不同的物件或參與者執行。為了顯示涉及多個物件或參與者，將**泳道**添加到活動圖中，如圖 B.18 所示。

## B.4 實作視圖
實作視圖顯示最終產品是如何實作的。使用兩種類型的圖來顯示實作：組件圖和部署圖。

### B.4.1 組件圖 (Component diagrams)
組件圖顯示軟體組件及其間的依賴關係。組件顯示為左邊緣有兩個小矩形的矩形。組件之間的依賴關係由末端帶箭頭的虛線顯示。我們還可以在依賴線上使用構造型，包括諸如 <<report>> 之類的構造型關係。圖 B.19 顯示了一個組件圖。

### B.4.2 部署圖 (Deployment diagrams)
部署圖顯示透過通訊連結連接的節點。節點顯示為長方體，通訊關聯（連結）顯示為連接兩個節點的線。一個節點還可以包含一個或多個組件。圖 B.20 顯示了一個簡單的部署圖。
`},k={en:`
# Appendix C: Pseudocode

One of the most common tools for defining algorithms is pseudocode. **Pseudocode** is an English-like representation of the code required for an algorithm. It is part English and part structured code. The English part provides a relaxed syntax that is easy to read. The code part consists of an extended version of the basic algorithmic constructs: *sequence*, *selection*, and *loop*. Algorithm C.1 shows an example of pseudocode. We briefly discuss each component in the next section.

**Algorithm C.1 Example of pseudocode**
\`\`\`
Algorithm: FindingSmallest (list)
Purpose: Finds the smallest number among a list of numbers
Pre: List of numbers
Post: None
Return: The smallest number in the list
{
    smallest ← first number
    Loop (not end of list)
    {
        If (next number < smallest)
        {
            smallest ← second number
        }
    }
    Return value of smallest
}
\`\`\`

## C.1 COMPONENTS

An algorithm written in pseudocode can be decomposed into several elements and constructs.

### C.1.1 Algorithm header
Each algorithm begins with a header that names it. For example, in Algorithm C.1, the header starts with the word *Algorithm*, which gives the algorithm’s title as ‘Finding Smallest’.

### C.1.2 Purpose, conditions, and return
After the header, we normally mention the purpose, the precondition, postconditions, and the data returned from the algorithm.

**Purpose**
The purpose is a short statement about what the algorithm does. It needs to describe only the general algorithm processing. It should not attempt to describe all of the processing. The purpose starts with the word Purpose and continues with the goal of the algorithm.

**Precondition**
The precondition lists any precursor requirements. For example, we require that the list be available to the algorithm.

**Postcondition**
The postcondition identifies any effect created by the algorithm. For example, the algorithm may require the printing of data.

**Return**
We believe that every algorithm should show what is returned from the algorithm. If there is nothing to be returned, we advise that null be specified. The smallest value that is found is returned.

**Statement**
Statements are commands such as **assign**, **input**, **output**, **if-then-else**, and **loop**, as shown in Algorithms C.1, C.2, C.3, and C.4. Nested statements—statements inside another statement—are indented. The list of nested statements starts with the opening brace (curly bracket) and ends with a closing brace. The whole argument is a list of nested statements inside the algorithm itself. For this reason, we see an opening brace at the beginning and a closing brace at the end.

### C.1.3 Statement constructs
When Niklaus Wirth first proposed the structured programming model, he stated that any algorithm could be written with only three programming constructs: *sequence*, *selection*, and *loop*. Our pseudocode contains only these three basic constructs. The implementation of these constructs relies on the richness of the implementation language. For example, the loop can be implemented as a *while*, *do-while*, or *for* statement in the C language.

**Sequence**
A sequence is a series of statements that do not alter the execution path within an algorithm. Although it is obvious that statements such as **assign** and **add** are sequence statements, it is not so obvious that a call to other algorithms is also considered a sequence statement. The reason lies in the structured programming concept that each algorithm has only one entry and one exit. Furthermore, when an algorithm completes, it returns to the statement immediately after the call that invoked it. You can therefore properly consider the algorithm call a sequence statement. Algorithm C.2 shows a sequence.

**Algorithm C.2 Example of a sequence**
\`\`\`
x ← first number
y ← second number
z ← x × y
call Argument X
\`\`\`

**Selection**
Selection statements evaluate one or more alternatives. If true, one path is taken; if false, a different path is taken. The typical selection statement is the two-way selection (if-else). Whereas most languages provide for multi-way selections, we provide none in pseudocode. The alternatives of the selection are identified by indentation, as shown in Algorithm C.3.

**Algorithm C.3 Example of a selection**
\`\`\`
If (x < y)
{
    Increment x
    Print x
}
Else
{
    Decrement y
    Print y
}
\`\`\`

**Loop**
A loop iterates a block of code. The loop in our pseudocode most closely resembles the *while* loop. It is a pretest loop: that is, the condition is evaluated before the body of the loop is executed. If the condition is true, the body is executed. If the condition is false, the loop terminates. Algorithm C.4 shows an example of a loop.

**Algorithm C.4 Example of a loop**
\`\`\`
Loop (more lines in the file File1)
{
    Read next line
    Delete the leading space
    Copy the line to File2
}
\`\`\`
`,zh:`
# 附錄 C：偽代碼 (Pseudocode)

定義演算法最常用的工具之一是偽代碼。**偽代碼**是一種近似英語的表示法，用於描述演算法所需的程式碼。它部分是英語，部分是結構化程式碼。英語部分提供了易於閱讀的寬鬆語法。程式碼部分由基本演算法建構的擴展版本組成：*循序*、*選擇*和*迴圈*。演算法 C.1 顯示了一個偽代碼範例。我們將在下一節簡要討論每個組件。

**演算法 C.1 偽代碼範例**
\`\`\`
Algorithm: FindingSmallest (list)
Purpose: 找出一列數字中的最小數字
Pre: 數字列表
Post: 無
Return: 列表中的最小數字
{
    smallest ← 第一個數字
    Loop (未到列表末尾)
    {
        If (下一個數字 < smallest)
        {
            smallest ← 第二個數字
        }
    }
    Return smallest 的值
}
\`\`\`

## C.1 組成部分

用偽代碼編寫的演算法可以分解為幾個元素和建構。

### C.1.1 演算法標頭
每個演算法都以一個標頭開始，為其命名。例如，在演算法 C.1 中，標頭以單詞 *Algorithm* 開頭，給出演算法的標題為「Finding Smallest」。

### C.1.2 目的、條件與回傳值
在標頭之後，我們通常會提到目的、前置條件、後置條件以及從演算法回傳的資料。

**目的 (Purpose)**
目的是關於演算法做什麼的簡短陳述。它只需要描述一般的演算法處理。它不應試圖描述所有的處理。目的以單詞 Purpose 開頭，並繼續說明演算法的目標。

**前置條件 (Precondition)**
前置條件列出了任何前導要求。例如，我們要求列表對演算法可用。

**後置條件 (Postcondition)**
後置條件標識演算法產生的任何效果。例如，演算法可能要求列印資料。

**回傳 (Return)**
我們認為每個演算法都應該顯示從演算法回傳的內容。如果沒有任何東西要回傳，我們建議指定 null。找到的最小值被回傳。

**陳述式 (Statement)**
陳述式是諸如 **assign** (賦值)、**input** (輸入)、**output** (輸出)、**if-then-else** (如果-則-否則) 和 **loop** (迴圈) 之類的命令，如演算法 C.1、C.2、C.3 和 C.4 所示。巢狀陳述式——另一個陳述式內部的陳述式——是縮排的。巢狀陳述式列表以左大括號（curly bracket）開始，以右大括號結束。整個引數是演算法本身內部的巢狀陳述式列表。因此，我們在開頭看到一個左大括號，在結尾看到一個右大括號。

### C.1.3 陳述式建構
當 Niklaus Wirth 首次提出結構化程式設計模型時，他指出任何演算法都可以只用三種程式設計建構來編寫：*循序*、*選擇*和*迴圈*。我們的偽代碼僅包含這三種基本建構。這些建構的實作依賴於實作語言的豐富性。例如，迴圈可以在 C 語言中實作為 *while*、*do-while* 或 *for* 陳述式。

**循序 (Sequence)**
循序是一系列不改變演算法內執行路徑的陳述式。雖然 **assign** 和 **add** 等陳述式顯然是循序陳述式，但呼叫其他演算法也被視為循序陳述式這一點並不那麼明顯。原因在於結構化程式設計概念，即每個演算法只有一個入口和一個出口。此外，當演算法完成時，它會返回到調用它的呼叫之後的陳述式。因此，您可以正確地將演算法呼叫視為循序陳述式。演算法 C.2 顯示了一個循序。

**演算法 C.2 循序範例**
\`\`\`
x ← 第一個數字
y ← 第二個數字
z ← x × y
call Argument X
\`\`\`

**選擇 (Selection)**
選擇陳述式評估一個或多個替代方案。如果為真，則採取一條路徑；如果為假，則採取不同的路徑。典型的選擇陳述式是雙向選擇 (if-else)。雖然大多數語言提供多向選擇，但在偽代碼中我們不提供。選擇的替代方案由縮排標識，如演算法 C.3 所示。

**演算法 C.3 選擇範例**
\`\`\`
If (x < y)
{
    Increment x
    Print x
}
Else
{
    Decrement y
    Print y
}
\`\`\`

**迴圈 (Loop)**
迴圈迭代一個程式碼區塊。我們偽代碼中的迴圈最像 *while* 迴圈。這是一個前測迴圈：也就是說，在執行迴圈主體之前評估條件。如果條件為真，則執行主體。如果條件為假，則迴圈終止。演算法 C.4 顯示了一個迴圈的範例。

**演算法 C.4 迴圈範例**
\`\`\`
Loop (檔案 File1 中還有更多行)
{
    Read 下一行
    Delete 前導空格
    Copy 該行到 File2
}
\`\`\`
`},x={en:`
# Appendix D: Structure Chart

The structure chart is the primary tool in a procedure-oriented software design phase. As a design tool, it is created before we start writing our program.

## D.1 STRUCTURE CHART SYMBOLS
Figure D.1 shows the various symbols used in a structure chart.

### D.1.1 Module symbol
Each rectangle in a structure chart represents a module. The name in the rectangle is the name you give to the module (Figure D.2).

### D.1.2 Selection in structure charts
Figure D.3 shows two symbols for a module that is called by a selection statement: the condition and the exclusive OR.

In Figure D.3a, the module *A* contains a conditional call to a submodule, *fun*. If the condition is true, you call *fun*. If it is not true, we skip *fun*. This situation is represented in a structure chart as a diamond on the vertical line between the two module blocks.

Figure D.3b represents selection between two different modules. In this example the module *select* chooses between *A* and *B*. One and only one of them will be called each time the selection statement is executed. This is known as an **exclusive OR**: one of the two alternatives is executed to the exclusion of the other. The exclusive OR is represented by a plus sign between the modules.

Now consider the design of a series of modules that can be called exclusively. This occurs when a multi-way selection contains calls to several different modules. Figure D.4 contains an example of a selection statement that calls different modules based on color.

### D.1.3 Loops in structure charts
Let’s look at how loops are shown in a structure chart. The symbols are very simple. Loops go in circles, so the symbol used is a circle. Programmers use two basic looping symbols. The first is a simple loop, shown in Figure D.5a. The other is the conditional loop, shown in Figure D.5b. When the module is called unconditionally, as in a *while* loop, the circle flows around the line above the called module. On the other hand, if the call is conditional, as in a module called in an *if-else* statement inside a loop, then the circle includes a decision diamond on the line.

Figure D.6 shows the basic structure for a module called *process*. The circle is *below* the module that controls the loop. In this example, the looping statement is contained in *process*, and it calls three modules, *A*, *B*, and *C*. The exact nature of the loop cannot be determined from the structure chart. It could be any of the three basic looping constructs.

## D.2 READING STRUCTURE CHARTS
Structure charts are read *top-down* and *left-to-right*. Referring to Figure D.2, this rule says that the program (*main*) consists of three submodules: *initialize*, *process*, and *endOfJob*. According to the left-to-right rule, the first call in the program is to *initialize*. After *initialize* is complete, the program calls *process*. When *process* is complete, the program calls *endOfJob*. In other words, the modules on the same level of a structure chart are called in order from left to right.

The concept of top-down is demonstrated by *process*. When *process* is called, it calls *A*, *B*, and *C* in turn. Module *B* does not start running, however, until *A* is finished. While *A* is running, it calls *A1* and *A2* in turn. In other words, all modules in a line from *process* to *A2* must be called before module *B* can start.

Often a program will contain several calls to a common module. These calls are usually scattered throughout the program. The structure chart will show the call wherever it logically occurs in the program. To identify common structures, the lower right corner of the rectangle will contain crosshatching or will be shaded. If the common module is complex and contains submodules, these submodules need to be shown only once. An indication that the incomplete references contain additional structure should be shown. This is usually done with a line below the module rectangle and a cut (~) symbol. This idea is shown in Figure D.7, which uses a common module, *average*, in two different places in the program. Note, however, that you never show a module connected to two calling modules graphically.

## D.3 RULES OF STRUCTURE CHARTS
We summarize the rules discussed in this section:
*   Each rectangle in a structure chart represents a module.
*   The name in the rectangle is the name that will be used in the coding of the module.
*   The structure chart contains only module flow. No code is indicated.
*   Common modules are indicated by crosshatching or shading in the lower right corner of the module rectangle.
*   Data flows and flags are optional. When used, they should be named.
*   Input flows and flags are shown to the left of the vertical line; output flows and flags are shown to the right.
`,zh:`
# 附錄 D：結構圖 (Structure Chart)

結構圖是程序導向軟體設計階段的主要工具。作為一種設計工具，它在我們開始編寫程式之前創建。

## D.1 結構圖符號
圖 D.1 顯示了結構圖中使用的各種符號。

### D.1.1 模組符號
結構圖中的每個矩形代表一個模組。矩形中的名稱是你給模組的名稱（圖 D.2）。

### D.1.2 結構圖中的選擇
圖 D.3 顯示了由選擇陳述式呼叫的模組的兩個符號：條件和互斥或 (exclusive OR)。

在圖 D.3a 中，模組 *A* 包含對子模組 *fun* 的條件式呼叫。如果條件為真，則呼叫 *fun*。如果不為真，則跳過 *fun*。這種情況在結構圖中表示為兩個模組塊之間的垂直線上的菱形。

圖 D.3b 表示兩個不同模組之間的選擇。在這個例子中，模組 *select* 在 *A* 和 *B* 之間進行選擇。每次執行選擇陳述式時，將呼叫其中一個且僅呼叫一個。這稱為**互斥或**：執行兩個替代方案之一，而排除另一個。互斥或由模組之間的加號表示。

現在考慮一系列可以互斥呼叫的模組的設計。當多向選擇包含對幾個不同模組的呼叫時，就會發生這種情況。圖 D.4 包含一個基於顏色呼叫不同模組的選擇陳述式範例。

### D.1.3 結構圖中的迴圈
讓我們看看迴圈在結構圖中是如何顯示的。符號非常簡單。迴圈是繞圈的，所以使用的符號是一個圓圈。程式設計師使用兩個基本的迴圈符號。第一個是簡單迴圈，如圖 D.5a 所示。另一個是條件迴圈，如圖 D.5b 所示。當無條件呼叫模組時，如在 *while* 迴圈中，圓圈圍繞在被呼叫模組上方的線上。另一方面，如果呼叫是有條件的，如在迴圈內的 *if-else* 陳述式中呼叫模組，那麼圓圈在線上包含一個決策菱形。

圖 D.6 顯示了名為 *process* 的模組的基本結構。圓圈位於控制迴圈的模組*下方*。在這個例子中，迴圈陳述式包含在 *process* 中，它呼叫三個模組 *A*、*B* 和 *C*。迴圈的確切性質無法從結構圖中確定。它可以是三種基本迴圈建構中的任何一種。

## D.2 閱讀結構圖
結構圖是*由上而下*和*由左至右*閱讀的。參考圖 D.2，這個規則說程式 (*main*) 由三個子模組組成：*initialize*、*process* 和 *endOfJob*。根據從左到右的規則，程式中的第一個呼叫是 *initialize*。在 *initialize* 完成後，程式呼叫 *process*。當 *process* 完成時，程式呼叫 *endOfJob*。換句話說，結構圖同一層級上的模組是按從左到右的順序呼叫的。

由上而下的概念由 *process* 演示。當 *process* 被呼叫時，它依次呼叫 *A*、*B* 和 *C*。然而，模組 *B* 直到 *A* 完成才開始運行。當 *A* 運行時，它依次呼叫 *A1* 和 *A2*。換句話說，從 *process* 到 *A2* 的一條線上的所有模組必須在模組 *B* 開始之前被呼叫。

通常，一個程式會包含對一個通用模組的多次呼叫。這些呼叫通常分散在整個程式中。結構圖將在程式中邏輯發生呼叫的任何地方顯示該呼叫。為了識別通用結構，矩形的右下角將包含交叉陰影或被陰影覆蓋。如果通用模組很複雜並包含子模組，這些子模組只需要顯示一次。應該顯示不完整引用包含額外結構的指示。這通常通過在模組矩形下方畫一條線和一個切割 (~) 符號來完成。這個想法在圖 D.7 中顯示，該圖在程式的兩個不同位置使用了一個通用模組 *average*。然而，請注意，你永遠不會以圖形方式顯示一個模組連接到兩個呼叫模組。

## D.3 結構圖規則
我們總結本節討論的規則：
*   結構圖中的每個矩形代表一個模組。
*   矩形中的名稱是在模組編碼中將使用的名稱。
*   結構圖僅包含模組流程。未指示代碼。
*   通用模組由模組矩形右下角的交叉陰影或陰影指示。
*   資料流和旗標是可選的。使用時，它們應該被命名。
*   輸入流和旗標顯示在垂直線的左側；輸出流和旗標顯示在右側。
`},I={en:`
# Appendix E: Boolean Algebra and Logic Circuits

## E.1 BOOLEAN ALGEBRA
**Boolean algebra** deals with variables and constants that take only one of two values: 1 or 0. This algebra is a suitable way to represent information in a computer, which is made of a collection of signals that can be in only one of the two states: on or off.

### E.1.1 Constants, variables, and operators
We use constants, variables, and operators in Boolean algebra.

**Constants**
There are only two constants: 1 and 0. The value of 1 is associated with the logical value *true*: the value 0 is associated with the logical value *false*.

**Variables**
We use letters such as x, y, and z to represent variables. Boolean variables can take only the values 0 or 1.

**Operators**
We use three basic operators: NOT, AND, and OR. We use a prime to represent NOT, a dot to represent AND, and a plus sign to represent OR, as shown below:
x’ → NOT x        x . y → x AND y        x + y → x OR y
An operator takes one or two values and creates one output value. The first operator, NOT, is a unary operator that takes only one value: the other two, AND and OR, are binary operators that take two values. Note that the choice of operators is arbitrary. We can construct all gates from the NAND gate (explained later).

### E.1.2 Expressions
An expression is a combination of Boolean operators, constants, and variables. The following shows some Boolean expressions:
0    x    x . 1    x + 0
x + 1 + y    x . (y + z)    x + y + z    x . y . z . t

### E.1.3 Logic gates
A **logic gate** is an electronic device that normally takes 1 to N inputs and creates one output. In this appendix, however, we use gates with only one or two inputs for simplicity. The logical value of the output is determined by the expression representing the gate and the input values. A variety of logic gates are commonly used in digital computers. Figure E.1 shows the symbols for the eight most common gates, their truth tables (see Chapter 4), and the expressions that can be used to find the output when the input or inputs are given.

*   **Buffer**. The first gate is just a buffer, in which the input and the output are the same. If the input is 0, the output is 0: if the input is 1, the output is 1. The buffer only amplifies the input signal.
*   **NOT**. The NOT gate is the implementation of the NOT operator. The output of this gate is the complement of the input. If the input is 1, the output is 0: if the input is 0, the output is 1.
*   **AND**. The AND gate is the implementation of the AND operator. It takes two inputs and creates one output. The output is 1 if both inputs are 1s, otherwise it is 0. Sometimes the AND operator is referred to as *product*.
*   **OR**. The OR gate is the implementation of the OR operator. It takes two inputs and creates one output. The output is 1 if any of the inputs, or both of them, is 1, otherwise it is 0. Sometimes the OR gate is referred to as *sum*.
*   **NAND**. The NAND gate is a logical combination of an AND gate followed by a NOT gate. The reason for its existence can be explained when we discuss the actual implementation of these gates. The output of a NAND gate is the complement of the corresponding AND gate if the inputs to two gates are the same.
*   **NOR**. The NOR gate is a logical combination of an OR gate followed by a NOT gate. The reason for its existence can also be explained when we discuss the actual implementation of these gates. The output of a NOR gate is the complement of the corresponding OR gate if the inputs to two gates are the same.
*   **XOR**. The XOR (exclusive-OR) gate is defined by the expression $(x . y’ + x’. y)$, which is normally represented as $(x \\oplus y)$. The output of this gate is 1 when the two inputs are different and is 0 when the inputs are the same. One can say that this is a more restricted OR gate. The output of an XOR gate is the same as the OR gate except that, if the two inputs are 1s, the output is 0.
*   **XNOR**. The XNOR (exclusive-NOR) gate is defined by the expression $(x . y’ + x’. y)’$ which is normally represented as $(x \\oplus y)’$. It is the complement of the XOR gate. The output of this gate is 1 when the two inputs are the same and 0 when the inputs are different. One can say that this represents the logical idea of equivalence: only if the two inputs are equal is the output 1.

**Implementation of gates**
The logic gates discussed in the previous section can be physically implemented using electronic switches (transistors). The most common implementation uses only three gates: NOT, NAND, and NOR. A NAND gate uses fewer components than an AND gate. This is also true for the NOR gate *versus* the OR gate. As a result, NAND and NOR gates have become the common standard in the industry. We only discuss these three implementations. Although we show simple switches in this discussion, we need to know that, in practice, switches are replaced by transistors. A transistor, when used in gates, behaves like a switch. The switch can be opened or closed by applying the appropriate voltage to the input. Several different technologies are used to implement these transistors, but we leave this discussion to books on electronics.

**Implementation of the NOT gate**
The NOT gate can be implemented with an electronic switch, a voltage source, and a resistor as shown in Figure E.2.
The input to the gate is a control signal that holds the switch open or closed. An input signal of 0 holds the switch open, while an input signal of 1 closes the switch. The output is the voltage at the point before the switch (output terminal). If the value of this voltage is positive (V volts), the output is interpreted as 1: if the voltage is 0 (or below a threshold), the output is interpreted as 0. When the switch is open, there is no current through the resistor, and therefore no voltage drop. The output voltage is V (interpreted as logic 1). Closing the switch grounds the output terminal and makes its voltage 0 (or almost 0), which is interpreted as logic 0. Note that the behavior of the circuit matches the values shown in the table.
**To implement a NOT gate, we need only one electronic switch.**

**Implementation of the NAND gate**
The NAND gate can be implemented using two switches in series (two inputs). For the current to flow through the circuit from the positive terminal to the ground, both switches must be closed—that is, both inputs must be 1s. In this case, the voltage of the output terminal is zero because it is grounded (logic 0). If one of the switches or both switches are open—that is, where the inputs are 00, 01, or 10—no current flows through the resistor. There is thus no voltage drop across the resistor and the voltage at the output terminal is V (logic 1).
Figure E.3 shows the implementation of the NAND gate. The behavior of the circuit matches the values shown in the table. Note that if an AND gate is needed, it can be made from a NAND gate followed by a NOT gate.
**To implement a NAND gate, we need two electronic switches that are connected in series.**

**Implementation of the NOR gate**
The NOR gate can also be implemented using two switches in parallel (two inputs). If both switches are open, then the current does not flow through the resistor. In this case, there is no voltage drop across the resistor, which means the output terminal holds the voltage V (logic 1). If either or both of the switches are closed, the output terminal is grounded and the output voltage is zero (logic 0).
Figure E.4 shows the implementation of the NOR gate. The behavior of the circuit matches the values in the table. Note that if an OR gate is needed, it can be simulated using a NOR gate followed by a NOT gate.
**To implement a NOR gate, we need two electronic switches that are connected in parallel.**

### E.1.4 Axioms, theorems, and Identities
To be able to work with Boolean algebra, we need to have some rules. The rules in Boolean algebra are divided into three broad categories: axioms, theorems, and identities.

**Axioms**
Boolean algebra, like any other algebra, uses some rules, called **axioms**: they cannot be proved. Table E.1 shows the axioms for Boolean algebra.

**Table E.1 Axioms for Boolean algebra**
| | Related to NOT | Related to AND | Related to OR |
| :--- | :--- | :--- | :--- |
| 1 | $x = 0 \\rightarrow x’ = 1$ | | |
| 2 | $x = 1 \\rightarrow x’ = 0$ | | |
| 3 | | $0 \\cdot 0 = 0$ | $0 + 0 = 0$ |
| 4 | | $1 \\cdot 1 = 1$ | $1 + 1 = 1$ |
| 5 | | $1 \\cdot 0 = 0 \\cdot 1 = 0$ | $1 + 0 = 0 + 1 = 1$ |

**Theorems**
Theorems are rules that we prove using the axioms, although we must leave the proofs to textbooks on Boolean algebra. Table E.2 shows some theorems used in Boolean algebra.

**Table E.2 Basic theorems for Boolean algebra**
| | Related to NOT | Related to AND | Related to OR |
| :--- | :--- | :--- | :--- |
| 1 | $(x’)’ = x$ | | |
| 2 | | $0 \\cdot x = 0$ | $0 + x = x$ |
| 3 | | $1 \\cdot x = x$ | $1 + x = 1$ |
| 4 | | $x \\cdot x = x$ | $x + x = x$ |
| 5 | | $x \\cdot x’ = 0$ | $x + x’ = 1$ |

**Identities**
We can also drive many identities using the axioms and the theorems. We list only the most common in Table E.3, although we must leave the proofs to textbooks on Boolean algebra.

**Table E.3 Basic Identities related to OR and AND operators**
| | Description | Related to AND | Related to OR |
| :--- | :--- | :--- | :--- |
| 1 | Commutativity | $x \\cdot y = y \\cdot x$ | $x + y = y + x$ |
| 2 | Associativity | $x \\cdot (y \\cdot z) = (x \\cdot y) \\cdot z$ | $x + (y + z) = (x + y) + z$ |
| 3 | Distributivity | $x \\cdot (y + z) = (x \\cdot y) + (y \\cdot z)$ | $x + (y \\cdot z) = (x + y) \\cdot (x + z)$ |
| 4 | De Morgan’s Rules | $(x \\cdot y)’ = x’ + y’$ | $(x + y)’ = x’ \\cdot y’$ |
| 5 | Absorption | $x \\cdot (x’ + y) = x \\cdot y$ | $x + (x’ \\cdot y) = x + y$ |

De Morgan’s Rules play a very important role in logic design, as we will see shortly. They can be extended to more than one variable. For example, we can have the following two identities for three variables:
$(x + y + z)’ = x’. y’. z’$        $(x. y. z)’ = x’ + y’ + z’$

### E.1.5 Boolean functions
We define a **Boolean function** as a function with $n$ Boolean input variables and one Boolean output variable, as shown in Figure E.5.

A function can be represented either by a truth table or an expression. The truth table for a function has $2^n$ rows and $n + 1$ columns, in which the first $n$ columns define the possible values of the variables and the last column defines the value of the function’s output for the combination of the values defined in the first $n$ columns.
Figure E.6 shows the truth tables and expression representation for two functions $F_1$ and $F_2$. Although the truth table representation is unique, a function can be represented by different expressions. We have shown two of the expressions for each function. Note that the second expressions are shorter and simpler. Later we show that we need to simplify the expressions to make the implementation more efficient.

**Table-to-expression transformation**
The specification of a function is normally given by a truth table (see Chapter 4). To implement the function using logic gates (as discussed earlier), we need to find an expression for the truth table. This can be done in two ways.

**Sum of products**
The first method of changing a truth table into an expression is referred to as the **sum of products** method. A sum of products representation of a function is made of up to $2^n$ terms in which each term is called a **minterm**. A minterm is a product (ANDing) of all variables in a function in which each variable appears only once. For example, in a three-variable function, we can have eight minterms, such as $x’. y’. z’$ or $x. y’. z’$. Each term represents one row in the truth value. If the value of a variable is 0, the complement of the variable appears in the term: if the value of the variable is 1, the variable itself appears in the term. To transform a truth table to a sum of product representation, we use the following strategy:
1.  Find the minterms for each row for which the function has a value of 1.
2.  Use the sum (ORing) of the terms in step 1.

**Product of sums**
The second method of changing a truth table to an expression is referred to as the **product of sums** method. A product of sum representation of a function is made of up to $2^n$ terms in which each term is called a **maxterm**. A maxterm is a sum (ORing) of all variables in a function in which each variable appears only once. For example, in a three-variable function, we can have eight maxterms such as $x’+ y’+ z’$ or $x + y’+ z’$. To transform a truth table to a product of sum representation, we use the following strategy:
1.  Find the minterms for each row for which the function has a 0 value.
2.  Find the complement of the sum of the terms in step 1.
3.  Use De Morgan’s rules to change minterms to maxterms.

**Example E.1**
Figure E.7 shows how we create the sum of products and product of sums for the functions F1 and F2 in Figure E.6.

The sum of products is directly made from the table, but the product of sums needs the use of De Morgan’s rules. Note that sometimes the first method gives the shorter expression and sometimes the second one.

### E.1.6 Function simplification
Although we can implement a Boolean function using the logic gates discussed before, it is normally not efficient. The direct implementation of a function requires more gates. The number of gates could be reduced if we can carry out simplification. Traditionally two methods of simplification are used: the algebraic method using Karnaugh maps, and the Quine–McKluskey method.

**Algebraic method**
We can simplify a function using the axioms, theorems, and identities discussed before. For example, we can simplify the first function ($F_1$) in Figure E.7, as shown below:
$F_1 = x’ \\cdot y’ + x \\cdot y’ + x \\cdot y$
$= (x’ + x) \\cdot y’ + x \\cdot y$        Identity 3 (distributivity) for AND
$= 1 \\cdot y’ + x \\cdot y$                Theorem 5 for OR
$= y’ + x \\cdot y$                        Theorem 3 for AND
$= y’ + y \\cdot x$                        Theorem 1 (commutativity) for AND
$= y’ + x$                            Identity 5 (absorption)
$= x + y’$                            Theorem 1 (commutativity) for OR

This means that if the non-simplified version needs eight gates, the simplified version needs only two gates, one NOT and one OR.

**Karnaugh map method**
Another simplification method involves the use of a **Karnaugh map**. This method can normally be used for functions of up to four variables. A map is a matrix of $2^n$ cells in which each cell represents one of the values of the function. The first point that deserves attention is to fill up the map correctly. Contrary to expectations, the map is not always filled up row by row or column by column: it is filled up according to the value of variables as shown on the map. Figure E.8 shows an example where n = 2, 3, or 4.

In the truth table, we use the function values from the top to the bottom of the truth table. The map is filled up one by one, but the order of rows are 1, 2, 4, 3. In each row, the columns are filled up one by one, but the order of the columns are 1, 2, 4, 3. The fourth row comes before the third row: the fourth column comes before the third. This arrangement is needed to allow the maximum of simplification.

**Sum of products**
The simplification can be done to create sum of products terms. When we simplify a function in this way we use minterms with value of 1. To create an efficient expression, we first combine adjacent minterm cells. Note that adjacency can also include wrap-around of bits.

**Example E.2**
Figure E.9 shows the sum of products simplification for our first function. The 1s in the second row are the entire x domain. The 1s in the first column are the entire y’ domain. The resulting simplified function is $F_1 = (x) + (y’)$. The figure also shows the implementation using one OR gate and one NOT gate.

**Example E.3**
Figure E.10 shows the sum of products simplification for our second function. The 1s in the second row are the intersection of x and z domains, which is represented as $(x . z)$. The 1s in the first row are the intersection of x’ and z’ domains, which is represented as $(x’. z’)$. The resulting simplified function is $F_2 = (x . z) + (x’. z’)$. The figure also shows the implementation using one OR gate, two AND gates, and two NOT gates.

**Product of sums**
The simplification can be done using the product of sums methods. When we simplify a function in this way, we need to use maxterms. To create an efficient expression, we first combine the adjacent minterm cells. However, the function obtained in this way is the complement of the function we are looking for: we need to use the De Morgan’s rules to find our function.

**Example E.4**
Figure E.11 shows a product of sums simplification for our first function. Note that in this case the implementation is exactly the same as Figure E.9, but this is not always the case. Also note that our function has only one term: we need no AND gate.

**Example E.5**
Figure E.12 shows the product-of-sums simplification for our second function. Note that the process gives us $(F_2)’$, so we need to apply the De Morgan’s rules to find $F_2$. The figure also shows the implementation using two NOT gates, two OR gates, and one AND gate. This implementation is less efficient than the one we found with minterms. We should always use the one which is more efficient.

## E.2 LOGIC CIRCUITS
A computer is normally built out of standard components that we collectively refer to as **logic circuits**. Logic circuits are divided into two broad categories, known as *combinational circuits* and *sequential circuits*. We briefly discuss each category here and give some examples.

### E.2.1 Combinational circuits
A **combinational circuit** is a circuit made up of a combination of logic gates with $n$ inputs and $m$ outputs. Each output at any time entirely depends on all given inputs.
**In a combinational circuit, each output at any time depends entirely on all inputs.**
Figure E.13 shows the block diagram of a combinational circuit with $n$ inputs and $m$ outputs. Comparing Figure E.13 and Figure E.5, we can say that a combinational circuit with $m$ outputs can be thought of as $m$ functions, a function for each output.
The output of a combinational circuit is normally defined by a truth table. However, the truth table needs to have $m$ outputs.

**Half adder**
A simple example of a combinational circuit is a **half adder**, an adder that can only add two bits. A half adder is a combinational circuit with two inputs and two outputs. The two inputs define the two bits to be added. The first output is the sum of the two bits, while the second output is the carry bit that needs to be propagated to the next adder. Figure E.14 shows a half-adder with its truth table and the logic gates used to the make the circuit.
The sum of two bits can be achieved using an XOR gate: the carry can be achieved using and AND gate.

**Multiplexer**
A **multiplexer** is a combinational circuit with $n$ inputs and only one output. The $n$ inputs are made up of $D$ data inputs and $C$ control inputs ($n = D + C$). At any time, the multiplexer routes one of its $D$ data inputs to its single data output. The selection is based on the value of control bits. To select one of the $D$ data inputs, we need $C = \\log_2 D$ control bits. If $D = 2$, at any time only one of the data inputs is routed to the output. The control input is only one bit. If the control input is 0, the first data input is directed to the output: if the control input is 1, the second input is routed to the output.
Figure E.15 shows the truth table and the circuit for a 2 x 1 multiplexer. Note that the circuit actually has three inputs and one output: the control input is considered one of the inputs.
Note that the truth table here is very simplified: the output depends only on the control input but the value of the output, however, is one of the two data inputs.

### E.2.2 Sequential circuits
A combinational circuit is memoryless: it does not remember its previous output. At any moment the output depends on the current input. A **sequential circuit**, on the other hand, includes the concept of memory in the logic. The memory enables the circuit to remember its current state to be used in the future; the future state can be dependent on the current state.

**Flip-flops**
To add the idea of memory to the combinational circuit, a storage element called a **flip-flop** was invented that can hold one bit of information. A set of flip-flops can be used to hold a set of bits.

**SR flip-flops**
The simplest type of flip-flop is called an **SR flip-flop**, in which there are two inputs S (set) and R (reset) and two outputs Q and Q’, which are always complements of each other. Figure E.16 shows the symbol, the circuit, and the characteristic table of an SR flip-flop. Note that the characteristic table is different from the truth tables we have used for combinational circuits. The characteristic table shows the next output, Q ($t + 1$) based on the current output, Q ($t$) and the input.
The characteristic table shows that if both S and R are zero, Q ($t + 1$) = Q ($t$). The next output will be the same as the current output. If S is 0 and R is 1, Q ($t + 1$) = 0, which means the output will be reset (R = 1). If S is 1 and R is 0, Q ($t + 1$) = 1, which means that the output will be set. However, if both S and R are 1s, the next output is unpredictable (undefined). Note that we have not shown the value of Q’ in the characteristic table, because it is always the complement of Q.
An SR flip-flop can be used as a set–reset device. For example, if the output is connected to an electric sounder, the alarm can be set by letting R = 0 and S = 1. After setting, the alarm continues sounding until it is reset by setting R = 1 and S = 0. The only flaw in this design is that R and S should not simultaneously be 1s.
To understand the behavior of the SR flip-flop we need to create its truth table. However, note that we now have three inputs and one output (Q and Q’ are independent). Table E.4 shows the truth table for this flip-flop.

**Table E.4 Truth table for an SR flip-flop**
| S | R | Q (t) | Q (t + 1) |
| :--- | :--- | :--- | :--- |
| 0 | 0 | 0 | 0 |
| 0 | 0 | 1 | 1 |
| 0 | 1 | 0 | 0 |
| 0 | 1 | 1 | 0 |
| 1 | 0 | 0 | 1 |
| 1 | 0 | 1 | 1 |
| 1 | 1 | 0 | undefined |
| 1 | 1 | 1 | undefined |

**D flip-flop**
The SR flip-flop cannot be used as a 1-bit memory, as it needs two inputs instead of one. A small modification to the SR flip-flop can create a **D flop** (D stands for data). Figure E.17 shows the symbol and characteristics of a D flip-flop.
Note that the output of D flip-flop is the same as its input. However, the output remains as it is until the new input is given. This means that it memorizes its input states.

**JK flip-flop**
To remove the undefined state from the SR flip-flop, the **JK flip-flop** was invented (JK stands for Jack Kilby, who invented integrated circuits). Adding two AND gates to an SR flip-flop creates a JK flip-flop that has no undefined state. Figure E.18 shows the JK flip-flop and its characteristic table.

**T flip-flop**
Another common type of flip-flop is the **T flip-flop** (T stands for *toggle*). This flip-flop can be made by connecting the two inputs of an JK flip-flop together and calling it the T input. This input toggles the state of the flip-flop: if the input is 0, the next state is the same as the current state. If the input is 1, the next state is the complement of the current state. Figure E.19 shows the symbol, circuit, and characteristic table of the T flip-flop.

**Synchronous versus asynchronous**
The flip-flops we have discussed so far are all referred to as **asynchronous devices**: the transition from one state to another can happen only when there is a change in the input.
Digital computers, on the other hand, are **synchronous devices**. A central clock in the computer controls the timing of all logic circuits. The clock creates a signal—a series of pulses with an exact pulse width—that coordinates all events. A simple event takes place only at the ‘tick’ of this clock signal.
Figure E.20 shows an abstract idea of a clock signal. We call it *abstract* because in reality no electronic circuit can generate a signal with perfectly sharp impulses, but the signal shown here is sufficient for our discussion.

A flip-flop can be synchronous if we add one more input to the circuit: the clock input. The clock input can be ANDed with every input to gate the input so that it is effective only when the clock pulse is present. Figure E.21 shows the symbols for the clocked versions of all four flip-flop types we discussed. Figure E.22 shows the circuit of an SR flip-flop with a clock signal. The other flip-flops have the same additional circuitry.

**Register**
As the first application of a synchronous (clocked) sequential circuit, we will introduce a simplified version of a **register**. A register is an $n$-bit storage device that stores its data between consecutive clock pulses. At the trigger of the clock, the old data is discarded and replaced by the new data.
Figure E.23 shows a 4-bit register in which each cell is composed of a D flip-flop. Note that the clock input is common for all cells. We have rotated our previous symbols to make the connections simpler.

**Digital counter**
An $n$-bit **digital counter** counts from 0 to $2^n - 1$. For example, when $n = 4$, the output of the counter is 0000, 0001, 0010, 0011, …, 1111, so it counts from 0 to 15. An $n$-bit counter can be made out of $n$ T flip-flops. At the start, the counter represents 0000. The count enable line—see Figure E.24—carries a sequence of 1s: the data (pulse) to be counted. Looking at the sequence of events, we can see that the rightmost bit is complemented with each positive transition of the count enable connection, simulating the arrival of a data item. When the rightmost bit changes from 1 to 0, the next leftmost bit is complemented. The process is repeated for all bits. This observation gives us a clue to the use of a T flip-flop. The characteristic table of this flip-flop shows that each input of value 1 complements the output. Note that this counter can count only up to 15 or $(1111)_2$. The arrival of the sixteenth data item resets the counter back to $(0000)_2$. Figure E.24 shows the circuit of a 4-bit counter.
`,zh:`
# 附錄 E：布林代數與邏輯電路

## E.1 布林代數
**布林代數**處理只能取兩個值之一的變數和常數：1 或 0。這種代數是表示電腦中資訊的合適方式，電腦由一組只能處於兩種狀態之一的信號組成：開或關。

### E.1.1 常數、變數與運算子
我們在布林代數中使用常數、變數和運算子。

**常數**
只有兩個常數：1 和 0。值 1 與邏輯值*真 (true)* 相關聯：值 0 與邏輯值*假 (false)* 相關聯。

**變數**
我們使用字母如 x, y, 和 z 來表示變數。布林變數只能取值 0 或 1。

**運算子**
我們使用三個基本運算子：NOT、AND 和 OR。我們使用撇號表示 NOT，圓點表示 AND，加號表示 OR，如下所示：
x’ → NOT x        x . y → x AND y        x + y → x OR y
運算子接受一個或兩個值並創建一個輸出值。第一個運算子 NOT 是一元運算子，只接受一個值：其他兩個 AND 和 OR 是二元運算子，接受兩個值。請注意，運算子的選擇是任意的。我們可以從 NAND 閘構建所有閘（稍後解釋）。

### E.1.2 表達式
表達式是布林運算子、常數和變數的組合。以下顯示了一些布林表達式：
0    x    x . 1    x + 0
x + 1 + y    x . (y + z)    x + y + z    x . y . z . t

### E.1.3 邏輯閘
**邏輯閘**是一種電子設備，通常接受 1 到 N 個輸入並創建一個輸出。然而，在本附錄中，為了簡單起見，我們使用只有一個或兩個輸入的閘。輸出的邏輯值由代表閘的表達式和輸入值決定。各種邏輯閘常用於數位電腦中。圖 E.1 顯示了八種最常見閘的符號、它們的真值表（見第 4 章），以及可用於在給定輸入時找出輸出的表達式。

*   **緩衝器 (Buffer)**。第一個閘只是緩衝器，輸入和輸出相同。如果輸入是 0，輸出是 0：如果輸入是 1，輸出是 1。緩衝器只放大輸入信號。
*   **NOT**。NOT 閘是 NOT 運算子的實作。此閘的輸出是輸入的補數。如果輸入是 1，輸出是 0：如果輸入是 0，輸出是 1。
*   **AND**。AND 閘是 AND 運算子的實作。它接受兩個輸入並創建一個輸出。如果兩個輸入都是 1，輸出是 1，否則是 0。有時 AND 運算子被稱為*積*。
*   **OR**。OR 閘是 OR 運算子的實作。它接受兩個輸入並創建一個輸出。如果任何輸入或兩者都是 1，輸出是 1，否則是 0。有時 OR 閘被稱為*和*。
*   **NAND**。NAND 閘是 AND 閘後跟 NOT 閘的邏輯組合。當我們討論這些閘的實際實作時，可以解釋其存在的原因。如果兩個閘的輸入相同，NAND 閘的輸出是對應 AND 閘的補數。
*   **NOR**。NOR 閘是 OR 閘後跟 NOT 閘的邏輯組合。當我們討論這些閘的實際實作時，也可以解釋其存在的原因。如果兩個閘的輸入相同，NOR 閘的輸出是對應 OR 閘的補數。
*   **XOR**。XOR（互斥或）閘由表達式 $(x . y’ + x’. y)$ 定義，通常表示為 $(x \\oplus y)$。當兩個輸入不同時，此閘的輸出為 1，當輸入相同時為 0。可以說這是一個更受限制的 OR 閘。XOR 閘的輸出與 OR 閘相同，除了如果兩個輸入都是 1，輸出是 0。
*   **XNOR**。XNOR（互斥反或）閘由表達式 $(x . y’ + x’. y)’$ 定義，通常表示為 $(x \\oplus y)’$。它是 XOR 閘的補數。當兩個輸入相同時，此閘的輸出為 1，當輸入不同時為 0。可以說這代表了等價的邏輯概念：只有當兩個輸入相等時，輸出才為 1。

**閘的實作**
上一節討論的邏輯閘可以使用電子開關（電晶體）進行物理實作。最常見的實作只使用三種閘：NOT、NAND 和 NOR。NAND 閘使用的組件比 AND 閘少。NOR 閘*對比* OR 閘也是如此。因此，NAND 和 NOR 閘已成為業界的通用標準。我們只討論這三種實作。雖然我們在這個討論中展示了簡單的開關，但我們需要知道，實際上開關被電晶體取代。電晶體在用於閘中時，行為就像開關。可以透過向輸入施加適當的電壓來打開或關閉開關。有幾種不同的技術用於實作這些電晶體，但我們將此討論留給電子學書籍。

**NOT 閘的實作**
NOT 閘可以使用電子開關、電壓源和電阻器來實作，如圖 E.2 所示。
閘的輸入是一個控制信號，使開關保持打開或關閉。輸入信號為 0 使開關保持打開，而輸入信號為 1 使開關關閉。輸出是開關前一點（輸出端）的電壓。如果此電壓值為正（V 伏特），則輸出解釋為 1：如果電壓為 0（或低於閾值），則輸出解釋為 0。當開關打開時，沒有電流通過電阻器，因此沒有電壓降。輸出電壓為 V（解釋為邏輯 1）。關閉開關將輸出端接地，使其電壓為 0（或幾乎為 0），這解釋為邏輯 0。請注意，電路的行為與表中顯示的值相符。
**要實作 NOT 閘，我們只需要一個電子開關。**

**NAND 閘的實作**
NAND 閘可以使用兩個串聯的開關（兩個輸入）來實作。為了讓電流從正極流向地面通過電路，兩個開關都必須關閉——也就是說，兩個輸入都必須是 1。在這種情況下，輸出端的電壓為零，因為它已接地（邏輯 0）。如果其中一個開關或兩個開關都打開——也就是說，輸入為 00、01 或 10——則沒有電流通過電阻器。因此，電阻器兩端沒有電壓降，輸出端的電壓為 V（邏輯 1）。
圖 E.3 顯示了 NAND 閘的實作。電路的行為與表中顯示的值相符。請注意，如果需要 AND 閘，可以由 NAND 閘後跟 NOT 閘製成。
**要實作 NAND 閘，我們需要兩個串聯連接的電子開關。**

**NOR 閘的實作**
NOR 閘也可以使用兩個並聯的開關（兩個輸入）來實作。如果兩個開關都打開，則電流不流過電阻器。在這種情況下，電阻器兩端沒有電壓降，這意味著輸出端保持電壓 V（邏輯 1）。如果其中一個或兩個開關關閉，則輸出端接地，輸出電壓為零（邏輯 0）。
圖 E.4 顯示了 NOR 閘的實作。電路的行為與表中的值相符。請注意，如果需要 OR 閘，可以使用 NOR 閘後跟 NOT 閘來模擬。
**要實作 NOR 閘，我們需要兩個並聯連接的電子開關。**

### E.1.4 公理、定理與恆等式
為了能夠使用布林代數，我們需要有一些規則。布林代數中的規則分為三大類：公理、定理和恆等式。

**公理 (Axioms)**
布林代數像任何其他代數一樣，使用一些規則，稱為**公理**：它們無法被證明。表 E.1 顯示了布林代數的公理。

**表 E.1 布林代數公理**
| | 與 NOT 相關 | 與 AND 相關 | 與 OR 相關 |
| :--- | :--- | :--- | :--- |
| 1 | $x = 0 \\rightarrow x’ = 1$ | | |
| 2 | $x = 1 \\rightarrow x’ = 0$ | | |
| 3 | | $0 \\cdot 0 = 0$ | $0 + 0 = 0$ |
| 4 | | $1 \\cdot 1 = 1$ | $1 + 1 = 1$ |
| 5 | | $1 \\cdot 0 = 0 \\cdot 1 = 0$ | $1 + 0 = 0 + 1 = 1$ |

**定理 (Theorems)**
定理是我們使用公理證明的規則，儘管我們必須將證明留給布林代數教科書。表 E.2 顯示了布林代數中使用的一些定理。

**表 E.2 布林代數基本定理**
| | 與 NOT 相關 | 與 AND 相關 | 與 OR 相關 |
| :--- | :--- | :--- | :--- |
| 1 | $(x’)’ = x$ | | |
| 2 | | $0 \\cdot x = 0$ | $0 + x = x$ |
| 3 | | $1 \\cdot x = x$ | $1 + x = 1$ |
| 4 | | $x \\cdot x = x$ | $x + x = x$ |
| 5 | | $x \\cdot x’ = 0$ | $x + x’ = 1$ |

**恆等式 (Identities)**
我們還可以使用公理和定理推導出許多恆等式。我們在表 E.3 中僅列出最常見的，儘管我們必須將證明留給布林代數教科書。

**表 E.3 與 OR 和 AND 運算子相關的基本恆等式**
| | 描述 | 與 AND 相關 | 與 OR 相關 |
| :--- | :--- | :--- | :--- |
| 1 | 交換律 | $x \\cdot y = y \\cdot x$ | $x + y = y + x$ |
| 2 | 結合律 | $x \\cdot (y \\cdot z) = (x \\cdot y) \\cdot z$ | $x + (y + z) = (x + y) + z$ |
| 3 | 分配律 | $x \\cdot (y + z) = (x \\cdot y) + (y \\cdot z)$ | $x + (y \\cdot z) = (x + y) \\cdot (x + z)$ |
| 4 | 笛摩根定律 | $(x \\cdot y)’ = x’ + y’$ | $(x + y)’ = x’ \\cdot y’$ |
| 5 | 吸收律 | $x \\cdot (x’ + y) = x \\cdot y$ | $x + (x’ \\cdot y) = x + y$ |

笛摩根定律在邏輯設計中扮演著非常重要的角色，我們稍後將看到。它們可以擴展到多個變數。例如，對於三個變數，我們可以有以下兩個恆等式：
$(x + y + z)’ = x’. y’. z’$        $(x. y. z)’ = x’ + y’ + z’$

### E.1.5 布林函數
我們將**布林函數**定義為具有 $n$ 個布林輸入變數和一個布林輸出變數的函數，如圖 E.5 所示。

函數可以用真值表或表達式表示。函數的真值表有 $2^n$ 行和 $n + 1$ 列，其中前 $n$ 列定義變數的可能值，最後一列定義函數輸出對於前 $n$ 列定義的值組合的值。
圖 E.6 顯示了兩個函數 $F_1$ 和 $F_2$ 的真值表和表達式表示。雖然真值表表示是唯一的，但函數可以用不同的表達式表示。我們為每個函數顯示了兩個表達式。請注意，第二個表達式更短更簡單。稍後我們將展示我們需要簡化表達式以使實作更有效率。

**表到表達式的轉換**
函數的規格通常由真值表給出（見第 4 章）。為了使用邏輯閘實作函數（如前所述），我們需要為真值表找到一個表達式。這可以通過兩種方式完成。

**積之和 (Sum of products)**
將真值表轉換為表達式的第一種方法稱為**積之和**方法。函數的積之和表示法由最多 $2^n$ 個項組成，其中每個項稱為**最小項 (minterm)**。最小項是函數中所有變數的乘積（AND 運算），其中每個變數只出現一次。例如，在三變數函數中，我們可以有八個最小項，如 $x’. y’. z’$ 或 $x. y’. z’$。每個項代表真值表中的一行。如果變數的值為 0，則變數的補數出現在項中：如果變數的值為 1，則變數本身出現在項中。要將真值表轉換為積之和表示法，我們使用以下策略：
1.  找出函數值為 1 的每一行的最小項。
2.  使用步驟 1 中各項的和（OR 運算）。

**和之積 (Product of sums)**
將真值表轉換為表達式的第二種方法稱為**和之積**方法。函數的和之積表示法由最多 $2^n$ 個項組成，其中每個項稱為**最大項 (maxterm)**。最大項是函數中所有變數的和（OR 運算），其中每個變數只出現一次。例如，在三變數函數中，我們可以有八個最大項，如 $x’+ y’+ z’$ 或 $x + y’+ z’$。要將真值表轉換為和之積表示法，我們使用以下策略：
1.  找出函數值為 0 的每一行的最小項。
2.  找出步驟 1 中各項之和的補數。
3.  使用笛摩根定律將最小項更改為最大項。

**範例 E.1**
圖 E.7 顯示了我們如何為圖 E.6 中的函數 F1 和 F2 創建積之和與和之積。

積之和直接由表製成，但和之積需要使用笛摩根定律。請注意，有時第一種方法給出較短的表達式，有時是第二種。

### E.1.6 函數化簡
雖然我們可以使用之前討論的邏輯閘實作布林函數，但通常效率不高。函數的直接實作需要更多的閘。如果我們可以進行化簡，就可以減少閘的數量。傳統上使用兩種化簡方法：使用卡諾圖的代數方法和 Quine-McKluskey 方法。

**代數方法**
我們可以使用之前討論的公理、定理和恆等式來化簡函數。例如，我們可以化簡圖 E.7 中的第一個函數 ($F_1$)，如下所示：
$F_1 = x’ \\cdot y’ + x \\cdot y’ + x \\cdot y$
$= (x’ + x) \\cdot y’ + x \\cdot y$        AND 的恆等式 3（分配律）
$= 1 \\cdot y’ + x \\cdot y$                OR 的定理 5
$= y’ + x \\cdot y$                        AND 的定理 3
$= y’ + y \\cdot x$                        AND 的定理 1（交換律）
$= y’ + x$                            恆等式 5（吸收律）
$= x + y’$                            OR 的定理 1（交換律）

這意味著如果未化簡的版本需要八個閘，化簡後的版本只需要兩個閘，一個 NOT 和一個 OR。

**卡諾圖法**
另一種化簡方法涉及使用**卡諾圖 (Karnaugh map)**。這種方法通常可用於最多四個變數的函數。圖是一個 $2^n$ 個單元格的矩陣，其中每個單元格代表函數的一個值。值得注意的第一點是正確填充圖。與預期相反，圖並不總是按行或按列填充：它是根據地圖上顯示的變數值填充的。圖 E.8 顯示了一個範例，其中 n = 2, 3, 或 4。

在真值表中，我們使用從真值表頂部到底部的函數值。圖是一個接一個填充的，但行的順序是 1, 2, 4, 3。在每一行中，列是一個接一個填充的，但列的順序是 1, 2, 4, 3。第四行在第三行之前：第四列在第三列之前。這種安排是為了允許最大程度的化簡。

**積之和**
可以進行化簡以創建積之和項。當我們以這種方式化簡函數時，我們使用值為 1 的最小項。為了創建一個有效的表達式，我們首先合併相鄰的最小項單元格。請注意，相鄰性也可以包括位元的環繞。

**範例 E.2**
圖 E.9 顯示了我們第一個函數的積之和化簡。第二行中的 1 是整個 x 域。第一列中的 1 是整個 y’ 域。結果化簡後的函數是 $F_1 = (x) + (y’)$。該圖還顯示了使用一個 OR 閘和一個 NOT 閘的實作。

**範例 E.3**
圖 E.10 顯示了我們第二個函數的積之和化簡。第二行中的 1 是 x 和 z 域的交集，表示為 $(x . z)$。第一行中的 1 是 x’ 和 z’ 域的交集，表示為 $(x’. z’)$。結果化簡後的函數是 $F_2 = (x . z) + (x’. z’)$。該圖還顯示了使用一個 OR 閘、兩個 AND 閘和兩個 NOT 閘的實作。

**和之積**
可以使用和之積方法進行化簡。當我們以這種方式化簡函數時，我們需要使用最大項。為了創建一個有效的表達式，我們首先合併相鄰的最小項單元格。然而，以這種方式獲得的函數是我們正在尋找的函數的補數：我們需要使用笛摩根定律來找到我們的函數。

**範例 E.4**
圖 E.11 顯示了我們第一個函數的和之積化簡。請注意，在這種情況下，實作與圖 E.9 完全相同，但並非總是如此。另請注意，我們的函數只有一項：我們不需要 AND 閘。

**範例 E.5**
圖 E.12 顯示了我們第二個函數的和之積化簡。請注意，該過程給了我們 $(F_2)’$，所以我們需要應用笛摩根定律來找到 $F_2$。該圖還顯示了使用兩個 NOT 閘、兩個 OR 閘和一個 AND 閘的實作。這種實作比我們用最小項找到的效率低。我們應該總是使用更有效率的那一個。

## E.2 邏輯電路
電腦通常由我們統稱為**邏輯電路**的標準組件構建而成。邏輯電路分為兩大類，稱為*組合電路*和*循序電路*。我們在此簡要討論每個類別並給出一些範例。

### E.2.1 組合電路
**組合電路**是由具有 $n$ 個輸入和 $m$ 個輸出的邏輯閘組合而成的電路。任何時候的每個輸出完全取決於所有給定的輸入。
**在組合電路中，任何時候的每個輸出完全取決於所有輸入。**
圖 E.13 顯示了具有 $n$ 個輸入和 $m$ 個輸出的組合電路的方塊圖。比較圖 E.13 和圖 E.5，我們可以說具有 $m$ 個輸出的組合電路可以被認為是 $m$ 個函數，每個輸出一個函數。
組合電路的輸出通常由真值表定義。然而，真值表需要有 $m$ 個輸出。

**半加器 (Half adder)**
組合電路的一個簡單例子是**半加器**，一種只能加兩個位元的加法器。半加器是具有兩個輸入和兩個輸出的組合電路。兩個輸入定義要相加的兩個位元。第一個輸出是兩個位元的和，而第二個輸出是需要傳播到下一個加法器的進位位元。圖 E.14 顯示了半加器及其真值表和用於製作電路的邏輯閘。
兩個位元的和可以使用 XOR 閘實現：進位可以使用 AND 閘實現。

**多工器 (Multiplexer)**
**多工器**是具有 $n$ 個輸入和只有一個輸出的組合電路。$n$ 個輸入由 $D$ 個資料輸入和 $C$ 個控制輸入組成 ($n = D + C$)。在任何時候，多工器將其 $D$ 個資料輸入之一路由到其單個資料輸出。選擇基於控制位元的值。要選擇 $D$ 個資料輸入之一，我們需要 $C = \\log_2 D$ 個控制位元。如果 $D = 2$，則任何時候只有一個資料輸入被路由到輸出。控制輸入只有一個位元。如果控制輸入為 0，則第一個資料輸入被引導到輸出：如果控制輸入為 1，則第二個輸入被路由到輸出。
圖 E.15 顯示了 2 x 1 多工器的真值表和電路。請注意，電路實際上具有三個輸入和一個輸出：控制輸入被視為輸入之一。
請注意，這裡的真值表非常簡化：輸出僅取決於控制輸入，但輸出的值是兩個資料輸入之一。

### E.2.2 循序電路
組合電路是無記憶的：它不記得之前的輸出。任何時刻的輸出取決於當前的輸入。另一方面，**循序電路**在邏輯中包含了記憶的概念。記憶使電路能夠記住其當前狀態以供將來使用；未來狀態可以依賴於當前狀態。

**正反器 (Flip-flops)**
為了將記憶的概念添加到組合電路中，發明了一種稱為**正反器**的儲存元件，它可以保存一位元的資訊。一組正反器可用於保存一組位元。

**SR 正反器**
最簡單類型的正反器稱為 **SR 正反器**，其中有兩個輸入 S (set) 和 R (reset) 以及兩個輸出 Q 和 Q’，它們始終互為補數。圖 E.16 顯示了 SR 正反器的符號、電路和特性表。請注意，特性表不同於我們用於組合電路的真值表。特性表根據當前輸出 Q ($t$) 和輸入顯示下一個輸出 Q ($t + 1$)。
特性表顯示，如果 S 和 R 都為零，則 Q ($t + 1$) = Q ($t$)。下一個輸出將與當前輸出相同。如果 S 為 0 且 R 為 1，則 Q ($t + 1$) = 0，這意味著輸出將被重置 (R = 1)。如果 S 為 1 且 R 為 0，則 Q ($t + 1$) = 1，這意味著輸出將被設定。然而，如果 S 和 R 都是 1，則下一個輸出是不可預測的（未定義）。請注意，我們沒有在特性表中顯示 Q’ 的值，因為它總是 Q 的補數。
SR 正反器可用作設定-重置裝置。例如，如果輸出連接到電子發聲器，可以透過讓 R = 0 和 S = 1 來設定警報。設定後，警報繼續響起，直到透過設定 R = 1 和 S = 0 來重置。此設計的唯一缺陷是 R 和 S 不應同時為 1。
要了解 SR 正反器的行為，我們需要創建其真值表。然而，請注意，我們現在有三個輸入和一個輸出（Q 和 Q’ 是獨立的）。表 E.4 顯示了此正反器的真值表。

**表 E.4 SR 正反器的真值表**
| S | R | Q (t) | Q (t + 1) |
| :--- | :--- | :--- | :--- |
| 0 | 0 | 0 | 0 |
| 0 | 0 | 1 | 1 |
| 0 | 1 | 0 | 0 |
| 0 | 1 | 1 | 0 |
| 1 | 0 | 0 | 1 |
| 1 | 0 | 1 | 1 |
| 1 | 1 | 0 | undefined |
| 1 | 1 | 1 | undefined |

**D 正反器**
SR 正反器不能用作 1 位元記憶體，因為它需要兩個輸入而不是一個。對 SR 正反器稍加修改可以創建一個 **D 正反器**（D 代表資料）。圖 E.17 顯示了 D 正反器的符號和特性。
請注意，D 正反器的輸出與其輸入相同。然而，輸出保持原樣，直到給出新的輸入。這意味著它記住了其輸入狀態。

**JK 正反器**
為了消除 SR 正反器的未定義狀態，發明了 **JK 正反器**（JK 代表 Jack Kilby，他發明了積體電路）。在 SR 正反器中添加兩個 AND 閘創建了一個沒有未定義狀態的 JK 正反器。圖 E.18 顯示了 JK 正反器及其特性表。

**T 正反器**
另一種常見類型的正反器是 **T 正反器**（T 代表 *toggle*，切換）。此正反器可以透過將 JK 正反器的兩個輸入連接在一起並稱為 T 輸入來製作。此輸入切換正反器的狀態：如果輸入為 0，則下一個狀態與當前狀態相同。如果輸入為 1，則下一個狀態是當前狀態的補數。圖 E.19 顯示了 T 正反器的符號、電路和特性表。

**同步與非同步**
我們到目前為止討論的正反器都被稱為**非同步裝置**：只有當輸入發生變化時，才會發生從一個狀態到另一個狀態的轉換。
另一方面，數位電腦是**同步裝置**。電腦中的中央時鐘控制所有邏輯電路的時序。時鐘產生一個信號——一系列具有精確脈衝寬度的脈衝——協調所有事件。簡單事件僅在此時鐘信號的「滴答」處發生。
圖 E.20 顯示了時鐘信號的抽象概念。我們稱之為*抽象*，因為實際上沒有電子電路可以產生具有完美尖銳脈衝的信號，但這裡顯示的信號足以供我們討論。

如果我們向電路添加一個輸入：時鐘輸入，正反器可以是同步的。時鐘輸入可以與每個輸入進行 AND 運算以控制輸入，使其僅在時鐘脈衝存在時才有效。圖 E.21 顯示了我們討論的所有四種正反器類型的時鐘版本符號。圖 E.22 顯示了帶有時鐘信號的 SR 正反器電路。其他正反器具有相同的附加電路。

**暫存器 (Register)**
作為同步（時鐘）循序電路的第一個應用，我們將介紹**暫存器**的簡化版本。暫存器是一個 $n$ 位元儲存設備，在連續的時鐘脈衝之間儲存其資料。在時鐘觸發時，舊資料被丟棄並被新資料取代。
圖 E.23 顯示了一個 4 位元暫存器，其中每個單元由一個 D 正反器組成。請注意，時鐘輸入對於所有單元都是通用的。我們旋轉了之前的符號以使連接更簡單。

**數位計數器 (Digital counter)**
$n$ 位元**數位計數器**從 0 計數到 $2^n - 1$。例如，當 $n = 4$ 時，計數器的輸出為 0000, 0001, 0010, 0011, …, 1111，因此它從 0 計數到 15。$n$ 位元計數器可以由 $n$ 個 T 正反器製成。開始時，計數器代表 0000。計數啟用線——見圖 E.24——攜帶一系列 1：要計數的資料（脈衝）。觀察事件序列，我們可以看到最右邊的位元隨著計數啟用連接的每次正轉換而補數，模擬資料項目的到達。當最右邊的位元從 1 變為 0 時，下一個最左邊的位元補數。對所有位元重複該過程。這個觀察給了我們使用 T 正反器的線索。此正反器的特性表顯示，每個值為 1 的輸入都會使輸出補數。請注意，此計數器只能計數到 15 或 $(1111)_2$。第十六個資料項目的到達將計數器重置回 $(0000)_2$。圖 E.24 顯示了 4 位元計數器的電路。
`},S={en:`
# Appendix F: Examples of Programs in C, C++, and Java

In this appendix we present some examples of programs written in three languages, C, C++, and Java, to give a general idea about the structure of these three common languages. Note that the line number at the left of each program is not part of the program; it is added to make references easier. Also note that the text in color are comments and ignored by the compiler when the program is compiled into machine language.

## F.1 PROGRAMS IN C LANGUAGE
In this section, we show three simple programs in C. The goal is not to teach the language; it is to give an idea what programs in C look like.

### Example F.1
Program F-1 is the simplest program written in the C language that prints the message ‘Hello World!’. It is an example that uses only the sequence construct, which means that the code is executed line by line without branching or repeating some sections.

**Program F-1 First program in C**
\`\`\`c
1 /*
2 This program shows how we can use only sequence construct
3 to achieve a simple goal.
4 */
5
6 #include <stdio.h>
7
8 int main ()
9 {
10   // Statement
11   printf ("Hello World\\n");
12   return 0;
13
14 } // End of main
\`\`\`
**Run:**
Hello World

### Example F.2
Program F-2 is an example of a simple program in C that uses both sequence and branching construct. If a condition is met, the program executes some lines; if not, other lines are executed. We run the program twice to show the two different cases.

**Program F-2 Second program in C**
\`\`\`c
1 /*
2 This program shows how to make a decision in a program written in C.
3 The program gets an integer and finds if it is divisible by 7.
4 */
5
6 #include <stdio.h>
7
8 int main ()
9 {
10   // Declaration
11   int num;
12   // Statement
13   printf ("Enter an integer: ");
14   scanf ("%d", &num);
15   // Selection
16   if (num % 7 == 0)
17   {
18     printf ("The number %d", num);
19     printf (" is divisible by 7.\\n");
20   }
21   else
22   {
23     printf ("The number %d", num);
24     printf (" is not divisible by 7.\\n");
25   }
26   return 0;
27 } // End of main
\`\`\`
**Run:**
Enter an integer: 24
The number 24 is not divisible by 7.
**Run:**
Enter an integer: 35
The number 35 is divisible by 7.

### Example F.3
Program F-3 shows the combination of sequence and repetition construct. We use a loop to repeatedly print a number, but the number is changing in each repetition. We run the program twice: the first time, the limit is 6; the second time the limit is 9.

**Program F-3 Third program in C**
\`\`\`c
1 /*
2 This program shows how to use repetition in C.
3 The program prints number from 1 to n, in which n is given by the user.
4 */
5
6 #include <stdio.h>
7
8 int main ()
9 {
10 // Declaration
11 int n;
12 int i;
13 // Statement
14 printf ("Enter the upper limit: ");
15 scanf ("%d", &n);
16 // Repetition
17 for (i = 1; i <= n; i++)
18 {
19   printf ("%d\\n", i);
20 }
21 return 0;
22 } // End of main
\`\`\`
**Run:**
Enter the upper limit: 6
1
2
3
4
5
6
**Run:**
Enter the upper limit: 9
1
2
3
4
5
6
7
8
9

## F.2 PROGRAMS IN C++ LANGUAGE
In this section, we show how to write the same three previous programs using the C++ language. The point is to show the similarity and differences between the languages. The C language is a procedural language in which there are no classes and objects. On the other hand, C++ is an object-oriented language in which we can have classes and objects.

### Example F.4
Program F-4 accomplishes the same purpose as Program F-1, but it is written in C++ instead of C. We can see the main difference in line 14. To print data in C++, we need to use an object. The term *cout* defines an object that is responsible to output data.

**Program F-4 First program in C++**
\`\`\`cpp
1 /*
2 This program demonstrates some of the components of a simple
3 program written in C++
4 */
5
6 #include <iostream>
7 #include <iomanip>
8
9 using namespace std;
10
11 int main ()
12 {
13 // Statement
14 cout << "Hello World!" << endl;
15 return 0;
16 } // End of main
\`\`\`
**Run:**
Hello World

### Example F.5
Program F-5 accomplishes the same purpose as Program F-2, but it is written in C++ instead of C. The main difference between this program and its C version is in lines 16, 17, 21, 22, 26, and 27 in which we need to use input object (*cin*) and output objects (*cout*) for input and output.

**Program F-5 Second program in C++**
\`\`\`cpp
1 /*
2 This program shows how to make a decision in a program written in C++.
3 The program gets an integer and prints it if it is less than 50.
4 */
5
6 #include <iostream>
7 #include <iomanip>
8
9 using namespace std;
10
11 int main ()
12 {
13 // Declaration
14 int num;
15 // Statement
16 cout << ("Enter an integer: ");
17 cin >> num;
18 // Decision
19 if (num % 7 == 0)
20 {
21   cout << "The number " << num;
22   cout << " is divisible by 7." << endl;
23 }
24 else
25 {
26   cout << "The number " << num;
27   cout << " is not divisible by 7." << endl;
28 }
29 return 0;
30 } // End of main
\`\`\`
**Run:**
Enter an integer: 22
The number 22 is not divisible by 7.
**Run:**
Enter an integer: 21
The number 21 is divisible by 7.

### Example F.6
Program F-6 accomplishes the same purpose as Program F-3, but it is written in C++ instead of C. The main difference between this program and its C version is in lines 17, 18, and 23 in which we need to use input object (*cin*) and output objects (*cout*) for input and output.

**Program F-6 Third program in C++**
\`\`\`cpp
1 /*
2 This program shows how to use repetition in C++.
3 The program prints number from 1 to n, in which n is given by the user.
4 */
5
6 #include <iostream>
7 #include <iomanip>
8
9 using namespace std;
10
11 int main ()
12 {
13 // Declaration
14 int n;
15
16 // Statement
17 cout << "Enter the upper limit: ";
18 cin >> n;
19
20 // loop
21 for (int i = 1; i <= n; i++)
22 {
23   cout << i << endl;
24 }
25
26 return 0;
27 } // End of main
\`\`\`
**Run:**
Enter the upper limit: 4
1
2
3
4
**Run:**
Enter the upper limit: 8
1
2
3
4
5
6
7
8

## F.3 PROGRAMS IN JAVA LANGUAGE
In this section, we show how to write the same three programs in Java language. The point is to show the similarity and differences between the languages. The first difference we encounter is in the *main* function in C++ and *main* method in Java. In C++, the main function is a stand-alone program; in Java the main method should be part of a class. We call these classes First, Second, and Third respectively in these programs.

### Example F.7
Program F-7 accomplishes the same purpose as Program F-4, but it is written in Java instead of C++. We need a class to host the *main* method. Another difference is in line 10 where we use a predefined object (System.out) for output.

**Program F-7 First program in Java**
\`\`\`java
1 /*
2 This program demonstrates some of the components of a simple
3 program written in Java
4 */
5
6 public class First
7 {
8 public static void main (String[] args)
9 {
10   System.out.println ("Hello World!");
11 } // End main
12 } // End class
\`\`\`

### Example F.8
Program F-8 accomplishes the same purpose as Program F-5, but it is written in Java instead of C++. We need a class to host the *main* method. Other differences are in lines 13, 14, 15, 20, 21, 26, and 27 where we use an object of class Scanner for input and a predefined object (System.out) for output.

**Program F-8 Second program in Java**
\`\`\`java
1 /*
2 This program shows how to make a decision in a program written in Java.
3 The program gets an integer and checks if it is divisible by 7.
4 */
5
6 import java.util.*;
7
8 public class Second
9 {
10 public static void main (String[] args)
11 {
12   // Declaration
13   Scanner input = new Scanner (System.in);
14   System.out.print ("Enter an integer: ");
15   int num = input.nextInt ();
16
17   // Decision
18   if (num % 7 == 0)
19   {
20     System.out.print ("The number " + num);
21     System.out.println (" is divisible by 7");
22
23   }
24   else
25   {
26     System.out.print ("The number " + num);
27     System.out.println (" is not divisible by 7.");
28
29   }
30 } // End main
31
32 } // End class
\`\`\`
**Run:**
Enter an integer: 25
The number 25 is not divisible by 7.
**Run:**
Enter an integer: 42
The number 42 is divisible by 7.

### Example F.9
Program F-9 accomplishes the same purpose as Program F-6, but it is written in Java instead of C++. We need a class to host the *main* method. Other differences are in lines 13, 14, 15, and 20 where we use an object of class Scanner for input and a predefined object (System.out) for output.

**Program F-9 Third program in Java**
\`\`\`java
1 /*
2 This program shows how to use a loop in Java.
3 The program prints number from 1 to n, in which n is given by the user.
4 */
5
6 import java.util.*;
7
8 public class Third
9 {
10  public static void main (String[] args)
11  {
12    // Statements to get the value of n
13    Scanner input = new Scanner (System.in);
14    System.out.print("Enter the upper limit: ");
15    int n = input.nextInt ();
16
17    // Loop
18    for (int i = 1 ; i <= n; i++)
19    {
20      System.out.println (i);
21    }
22  } // End main
23
24 } // End class
\`\`\`
**Run:**
Enter the upper limit: 3
1
2
3
**Run:**
Enter the upper limit: 7
1
2
3
4
5
6
7
`,zh:`
# 附錄 F：C、C++ 和 Java 程式範例

本附錄展示了用 C、C++ 和 Java 三種語言編寫的程式範例，以提供關於其結構的一般概念。請注意，每個程式左側的行號不是程式的一部分；添加它是為了方便參考。另請注意，彩色文字是註解，當程式編譯成機器語言時會被編譯器忽略。

## F.1 C 語言程式
在本節中，我們展示了三個簡單的 C 程式。目標不是教授語言，而是提供 C 程式樣貌的概念。

### 範例 F.1
程式 F-1 是用 C 語言編寫的最簡單程式，它印出訊息「Hello World!」。這是一個僅使用循序建構的範例，這意味著代碼逐行執行，沒有分支或重複某些部分。

**程式 F-1 第一個 C 程式**
\`\`\`c
1 /*
2 這個程式展示了我們如何僅使用循序建構
3 來實現一個簡單的目標。
4 */
5
6 #include <stdio.h>
7
8 int main ()
9 {
10   // 陳述式
11   printf ("Hello World\\n");
12   return 0;
13
14 } // main 結束
\`\`\`
**執行：**
Hello World

### 範例 F.2
程式 F-2 是一個簡單的 C 程式範例，它同時使用了循序和分支建構。如果滿足條件，程式執行某些行；如果不滿足，則執行其他行。我們運行程式兩次以顯示兩種不同的情況。

**程式 F-2 第二個 C 程式**
\`\`\`c
1 /*
2 這個程式展示了如何在 C 語言編寫的程式中做出決策。
3 程式獲取一個整數並查找它是否能被 7 整除。
4 */
5
6 #include <stdio.h>
7
8 int main ()
9 {
10   // 宣告
11   int num;
12   // 陳述式
13   printf ("Enter an integer: ");
14   scanf ("%d", &num);
15   // 選擇
16   if (num % 7 == 0)
17   {
18     printf ("The number %d", num);
19     printf (" is divisible by 7.\\n");
20   }
21   else
22   {
23     printf ("The number %d", num);
24     printf (" is not divisible by 7.\\n");
25   }
26   return 0;
27 } // main 結束
\`\`\`
**執行：**
Enter an integer: 24
The number 24 is not divisible by 7.
**執行：**
Enter an integer: 35
The number 35 is divisible by 7.

### 範例 F.3
程式 F-3 顯示了循序和重複建構的組合。我們使用迴圈重複印出一個數字，但數字在每次重複中都會改變。我們運行程式兩次：第一次，上限是 6；第二次上限是 9。

**程式 F-3 第三個 C 程式**
\`\`\`c
1 /*
2 這個程式展示了如何在 C 中使用重複。
3 程式印出從 1 到 n 的數字，其中 n 由使用者給出。
4 */
5
6 #include <stdio.h>
7
8 int main ()
9 {
10 // 宣告
11 int n;
12 int i;
13 // 陳述式
14 printf ("Enter the upper limit: ");
15 scanf ("%d", &n);
16 // 重複
17 for (i = 1; i <= n; i++)
18 {
19   printf ("%d\\n", i);
20 }
21 return 0;
22 } // main 結束
\`\`\`
**執行：**
Enter the upper limit: 6
1
2
3
4
5
6
**執行：**
Enter the upper limit: 9
1
2
3
4
5
6
7
8
9

## F.2 C++ 語言程式
在本節中，我們展示如何使用 C++ 語言編寫相同的三個程式。重點是展示語言之間的相似性和差異。C 語言是一種沒有類別和物件的程序化語言。另一方面，C++ 是一種物件導向語言，我們可以在其中擁有類別和物件。

### 範例 F.4
程式 F-4 完成與程式 F-1 相同的目的，但它是用 C++ 而不是 C 編寫的。我們可以看到第 14 行的主要區別。要在 C++ 中印出資料，我們需要使用一個物件。術語 *cout* 定義了一個負責輸出資料的物件。

**程式 F-4 第一個 C++ 程式**
\`\`\`cpp
1 /*
2 這個程式演示了用 C++ 編寫的簡單程式的
3 一些組件
4 */
5
6 #include <iostream>
7 #include <iomanip>
8
9 using namespace std;
10
11 int main ()
12 {
13 // 陳述式
14 cout << "Hello World!" << endl;
15 return 0;
16 } // main 結束
\`\`\`
**執行：**
Hello World

### 範例 F.5
程式 F-5 完成與程式 F-2 相同的目的，但它是用 C++ 而不是 C 編寫的。此程式與其 C 版本之間的主要區別在於第 16、17、21、22、26 和 27 行，其中我們需要使用輸入物件 (*cin*) 和輸出物件 (*cout*) 進行輸入和輸出。

**程式 F-5 第二個 C++ 程式**
\`\`\`cpp
1 /*
2 這個程式展示了如何在 C++ 編寫的程式中做出決策。
3 程式獲取一個整數，如果它小於 50 則印出它。
4 */
5
6 #include <iostream>
7 #include <iomanip>
8
9 using namespace std;
10
11 int main ()
12 {
13 // 宣告
14 int num;
15 // 陳述式
16 cout << ("Enter an integer: ");
17 cin >> num;
18 // 決策
19 if (num % 7 == 0)
20 {
21   cout << "The number " << num;
22   cout << " is divisible by 7." << endl;
23 }
24 else
25 {
26   cout << "The number " << num;
27   cout << " is not divisible by 7." << endl;
28 }
29 return 0;
30 } // main 結束
\`\`\`
**執行：**
Enter an integer: 22
The number 22 is not divisible by 7.
**執行：**
Enter an integer: 21
The number 21 is divisible by 7.

### 範例 F.6
程式 F-6 完成與程式 F-3 相同的目的，但它是用 C++ 而不是 C 編寫的。此程式與其 C 版本之間的主要區別在於第 17、18 和 23 行，其中我們需要使用輸入物件 (*cin*) 和輸出物件 (*cout*) 進行輸入和輸出。

**程式 F-6 第三個 C++ 程式**
\`\`\`cpp
1 /*
2 這個程式展示了如何在 C++ 中使用重複。
3 程式印出從 1 到 n 的數字，其中 n 由使用者給出。
4 */
5
6 #include <iostream>
7 #include <iomanip>
8
9 using namespace std;
10
11 int main ()
12 {
13 // 宣告
14 int n;
15
16 // 陳述式
17 cout << "Enter the upper limit: ";
18 cin >> n;
19
20 // 迴圈
21 for (int i = 1; i <= n; i++)
22 {
23   cout << i << endl;
24 }
25
26 return 0;
27 } // main 結束
\`\`\`
**執行：**
Enter the upper limit: 4
1
2
3
4
**執行：**
Enter the upper limit: 8
1
2
3
4
5
6
7
8

## F.3 JAVA 語言程式
在本節中，我們展示如何用 Java 語言編寫相同的三個程式。重點是展示語言之間的相似性和差異。我們遇到的第一個區別是 C++ 中的 *main* 函式和 Java 中的 *main* 方法。在 C++ 中，main 函式是一個獨立的程式；在 Java 中，main 方法應該是類別的一部分。我們在這些程式中分別稱這些類別為 First、Second 和 Third。

### 範例 F.7
程式 F-7 完成與程式 F-4 相同的目的，但它是用 Java 而不是 C++ 編寫的。我們需要一個類別來託管 *main* 方法。另一個區別在第 10 行，我們使用預定義物件 (System.out) 進行輸出。

**程式 F-7 第一個 Java 程式**
\`\`\`java
1 /*
2 這個程式演示了用 Java 編寫的簡單程式的
3 一些組件
4 */
5
6 public class First
7 {
8 public static void main (String[] args)
9 {
10   System.out.println ("Hello World!");
11 } // main 結束
12 } // class 結束
\`\`\`

### 範例 F.8
程式 F-8 完成與程式 F-5 相同的目的，但它是用 Java 而不是 C++ 編寫的。我們需要一個類別來託管 *main* 方法。其他區別在第 13、14、15、20、21、26 和 27 行，其中我們使用 Scanner 類別的物件進行輸入，使用預定義物件 (System.out) 進行輸出。

**程式 F-8 第二個 Java 程式**
\`\`\`java
1 /*
2 這個程式展示了如何在 Java 編寫的程式中做出決策。
3 程式獲取一個整數並檢查它是否能被 7 整除。
4 */
5
6 import java.util.*;
7
8 public class Second
9 {
10 public static void main (String[] args)
11 {
12   // 宣告
13   Scanner input = new Scanner (System.in);
14   System.out.print ("Enter an integer: ");
15   int num = input.nextInt ();
16
17   // 決策
18   if (num % 7 == 0)
19   {
20     System.out.print ("The number " + num);
21     System.out.println (" is divisible by 7");
22
23   }
24   else
25   {
26     System.out.print ("The number " + num);
27     System.out.println (" is not divisible by 7.");
28
29   }
30 } // main 結束
31
32 } // class 結束
\`\`\`
**執行：**
Enter an integer: 25
The number 25 is not divisible by 7.
**執行：**
Enter an integer: 42
The number 42 is divisible by 7.

### 範例 F.9
程式 F-9 完成與程式 F-6 相同的目的，但它是用 Java 而不是 C++ 編寫的。我們需要一個類別來託管 *main* 方法。其他區別在第 13、14、15 和 20 行，其中我們使用 Scanner 類別的物件進行輸入，使用預定義物件 (System.out) 進行輸出。

**程式 F-9 第三個 Java 程式**
\`\`\`java
1 /*
2 這個程式展示了如何在 Java 中使用迴圈。
3 程式印出從 1 到 n 的數字，其中 n 由使用者給出。
4 */
5
6 import java.util.*;
7
8 public class Third
9 {
10  public static void main (String[] args)
11  {
12    // 獲取 n 值的陳述式
13    Scanner input = new Scanner (System.in);
14    System.out.print("Enter the upper limit: ");
15    int n = input.nextInt ();
16
17    // 迴圈
18    for (int i = 1 ; i <= n; i++)
19    {
20      System.out.println (i);
21    }
22  } // main 結束
23
24 } // class 結束
\`\`\`
**執行：**
Enter the upper limit: 3
1
2
3
**執行：**
Enter the upper limit: 7
1
2
3
4
5
6
7
`},C={en:`
# Appendix G: Mathematical Review

In this appendix we review some mathematical concepts that may help with understanding the topics covered in the book. We first give a brief treatment of exponential and logarithmic functions. We then discuss modular arithmetic. Finally, we give the formulas for the discrete cosine transforms that are used in data compression.

## G.1 EXPONENT AND LOGARITHM
In solving some problems in this book, we often need to know how to handle exponential and logarithmic functions. This section briefly reviews these two concepts.

### G.1.1 Exponential functions
The exponential function with base a is defined as $a^x$. If x is an integer, this is interpreted as multiplying a by itself x times. Normally we can use a calculator to find the value of y.

**Example G.1**
Calculate the value of the following exponential functions.
a. $3^2$
b. $5.2^6$
**Solution**
Using the interpretation of exponentiation, we can find:
a. $3^2 = 3 \\times 3 = 9$
b. $5.2^6 = 5.2 \\times 5.2 \\times 5.2 \\times 5.2 \\times 5.2 \\times 5.2 = 19770.609664$

**Example G.2**
Calculate the value of the following exponential functions:
a. $3^{2.2}$
b. $5.2^{6.3}$
**Solution**
These problems can be done more easily using a calculator—we can find:
a. $3^{2.2} \\approx 11.212$
b. $5.2^{6.3} \\approx 32424.60$

**Three common bases**
In the expression $a^b$, we call $a$ the base and $b$ the exponent. Three bases are very common: base 10, base $e$, and base 2.
*   Base 10 is the base of decimal system. Most calculators have a $10^x$ key.
*   The base used in science and mathematics is the natural base $e$, which has the value 2.71828183... Most calculators have an $e^x$ key. This base is used in science because some phenomena, such as radioactive decay, can be best described using this base.
*   The base which we normally need in computer science is base 2. Most calculators have no $2^x$ key, but we can always use the general $x^y$ key, in which $x = 2$.

**Example G.3**
Calculate the value of the following exponential functions:
a. $e^4$
b. $e^{6.3}$
c. $10^{3.3}$
d. $2^{6.3}$
e. $2^{10}$
**Solution**
a. $e^4 \\approx 54.60$
b. $e^{6.3} \\approx 544.57$
c. $10^{3.3} \\approx 1995.26$
d. $2^{6.3} \\approx 78.79$
e. $2^{10} = 1024$

**Example G.4**
In computer science the dominant base is 2. It is a good practice for us to know the powers of 2 for some common exponents. We often need to remember that:
$2^0 = 1$   $2^1 = 2$   $2^2 = 4$   $2^3 = 8$   $2^4 = 16$   $2^5 = 32$   $2^6 = 64$
$2^7 = 128$   $2^8 = 256$   $2^9 = 512$   $2^{10} = 1024$

**Properties of the exponential function**
Exponential functions have several properties, and some are useful to us:
1. $a^0 = 1$
2. $a^1 = a$
3. $a^{-x} = 1 / a^x$
4. $a^{x+y} = a^x \\times a^y$
5. $a^{x-y} = a^x / a^y$
6. $(a^x)^y = a^{x \\times y}$

**Example G.5**
Examples using these properties are:
a. $5^0 = 1$
b. $6^1 = 6$
c. $2^{-4} = 1/2^4 = 1/16 = 0.0625$
d. $2^{5+3} = 2^5 \\times 2^3 = 32 \\times 8 = 256$
e. $3^{2-3} = 3^2 / 3^3 = 9 / 27 = 1/3 \\approx 0.33$
f. $(10^4)^2 = 10^{4 \\times 2} = 10^8 = 100000000$

### G.1.2 Logarithmic function
A logarithmic function is the inverse of an exponential function, as shown below:
$y = a^x \\leftrightarrow x = \\log_a y$
Just as in the exponential function, $a$ is called the **base** of the logarithmic function. In other words, if $x$ is given, we can calculate $y$ by using the exponential function: if $y$ is given, we can calculate $x$ by using the logarithmic function.

**Exponential and logarithmic functions are the inverse of each other.**

Logarithms facilitate calculations in arithmetic because they convert multiplication to addition and exponentiation to multiplication.

**Example G.6**
Calculate the value of the following logarithmic functions:
a. $\\log_3 9$
b. $\\log_2 16$
c. $\\log 100$
d. $\\log_2 (-2)$
**Solution**
We have not yet shown how to calculate the log function in different bases, but we can solve this problem intuitively.
a. Because $3^2 = 9$, $\\log_3 9 = 2$, using the fact that the two functions are the inverse of each other.
b. Similarly, because $2^4 = 16$, then $\\log_2 16 = 4$.
c. Since there is no finite number $x$ such that $10^x = 0$, then $\\log_{10} 0$ is undefined or mathematically negative infinity.
d. A negative number in real number mathematics does not have a logarithm. However, in the domain of complex numbers we can have the logarithm of a negative number, but we leave this to books on complex number theory.

**Three common bases**
As in the case of exponentiation, there are three common bases in logarithms: base 10, base $e$, and base 2. Logarithms in base $e$ are normally shown as **ln** (natural logarithm), and logarithms in base 10 as **log** (omitting the base). Not all calculators have logarithms in base 2. We show how to handle this base shortly.

**Example G.7**
Calculate the value of the following logarithmic functions:
a. $\\log 233$
b. $\\ln 45$
**Solution**
For these two bases we can use a calculator:
a. $\\log 233 \\approx 2.367$
b. $\\ln 45 \\approx 3.81$

**Base transformation**
We often need to find the value of a logarithmic function in a base other than $e$ or 10. If the available calculator cannot give the result in our desired base, we can use a fundamental property of the logarithm, base transformation, as shown:
$\\log_a y = \\frac{\\log_b y}{\\log_b a}$
Note that the right-hand side shows two log functions with base $b$, which is different from the base $a$ at the left-hand side. This means that we can choose a base that is available in our calculator (base $b$) and find the log of a base that is not available (base $a$).

**Example G.8**
Calculate the value of the following logarithmic functions:
a. $\\log_3 810$
b. $\\log_5 600$
c. $\\log_2 1024$
d. $\\log_2 600$
**Solution**
These bases are normally not available on most calculators, but we can use base 10, which is available.
a. $\\log_3 810 = \\log 810 / \\log 3 = 2.908 / 0.477 \\approx 6.095$
b. $\\log_5 600 = \\log 600 / \\log 5 = 2.778 / 0.699 \\approx 3.975$
c. $\\log_2 1024 = \\log 1024 / \\log 2 = 3.01 / 0.301 = 10$
d. $\\log_2 600 = \\log 600 / \\log 2 \\approx 2.778 / 0.301 \\approx 9.223$

**Example G.9**
Base 2 is very common in computer science. Since we know that $\\log_{10} 2 \\approx 0.301$, it is very easy to calculate (approximately) the log of this base. We find the log of the corresponding number in base 10 and divide it by 0.310. Alternatively, we can multiply the corresponding log in base 10 by 3.332 ($\\approx 1 / 0.301$).
a. $\\log_2 600 \\approx 3.322 \\times \\log_{10} 600 \\approx 3.322 \\times 2.778 \\approx 9.228$
b. $\\log_2 2048 \\approx 3.322 \\times \\log_{10} 2048 \\approx 3.322 \\times 2.778 = 11$

**Properties of logarithmic functions**
Logarithmic functions have six useful properties, each related to the corresponding property of the exponential function (mentioned earlier).
1. $\\log_a 1 = 0$
2. $\\log_a a = 1$
3. $\\log_a (1/x) = -\\log_a x$
4. $\\log_a (x \\times y) = \\log_a x + \\log_a y$
5. $\\log_a (x/y) = \\log_a x - \\log_a y$
6. $\\log_a x^y = y \\times \\log_a x$

**Example G.10**
Calculate the value of the following logarithmic functions.
a. $\\log_3 1$
b. $\\log_3 3$
c. $\\log (1/10)$
d. $\\log_a (x \\times y)$ if we know that $\\log_a x = 2$ and $\\log_a y = 3$
e. $\\log_a (x/y)$ if we know that $\\log_a x = 2$ and $\\log_a y = 3$
f. $\\log_2 (1024)$ without using a calculator
**Solution**
We use the property of log functions to solve the problems:
a. $\\log_3 1 = 0$
b. $\\log_3 3 = 1$
c. $\\log (1/10) = \\log 10^{-1} = -1 \\log 10 = -1$
d. $\\log_a (x \\times y) = \\log_a x + \\log_a y = 2 + 3 = 5$
e. $\\log_a (x / y) = \\log_a x - \\log_a y = 2 - 3 = -1$
f. $\\log_2 (1024) = \\log_2 (2^{10}) = 10 \\times \\log_2 2 = 10 \\times 1 = 10$

## G.2 MODULAR ARITHMETIC
In integer arithmetic, if we divide $a$ by $n$, we can get $q$ and $r$. The relationship between these four integers can be shown as $a = q \\times n + r$. In this relation, $a$ is called the dividend, $q$ the quotient, $n$ the divisor, and $r$ the residue. Since an operation is normally defined with one single output, this is not an operation. We can call it the **division relation**.

**Example G.11**
Assume that $a = 214$ and $n = 13$. We can find $q = 16$ and $r = 6$ using the division algorithm we have learned in arithmetic, as shown in Figure G.1.
Most computer languages can find the quotient and the residue using language-specific operators. For example, in the C language, the division operator (/) can find the quotient and the modulo operator (%) can find the residue.

### G.2.1 The modulo operator
In modular arithmetic we are interested in only one of the outputs, the remainder, $r$. We don’t care about the quotient, $q$. In other words, we want to know what is the value of $r$ when we divide $a$ by $n$. This implies that we can change the above relation into a binary operator with two inputs $a$ and $n$ and one output $r$. The binary operator is then called the **modulo operator** and is shown as **mod**. The second input ($n$) is called the **modulus** and the output $r$ is called the **residue**. Figure G.2 shows the division relation compared with the modulo operator.

The modulo operator (**mod**) takes an integer ($a$) a modulus ($n$). The operator creates a residue ($r$). Although $a$ and $r$ can be any integer, $n$ cannot be 0 because it implies division by zero, which yields an undefined value or infinity. However, in practice we need the value of $n$ to be non-negative. For this reason, the values of $a$ and $r$ should be between 0 and $n - 1$.

**Example G.12**
A very good example of the use of modular arithmetic is our clock system. The clock is based on modulo 12 arithmetic. However, the integer 12 in our clock should actually be 0 to make it conformant with the modulo arithmetic.

**Example G.13**
Find the result of the following operations:
a. 28 mod 6
b. 32 mod 12
c. 19 mod 15
d. 7 mod 11
**Solution**
We are looking for the residue $r$. We can divide $a$ by $n$ and find $q$ and $r$. We can then disregard $q$ and keep $r$.
a. Dividing 28 by 6 results in $r = 4$. This means that 28 mod 6 = 4.
b. Dividing 32 by 12 results in $r = 8$. This means that 32 mod 12 = 8.
c. Dividing 19 by 15 results in $r = 4$. This means that 19 mod 15 = 4.
d. Dividing 7 by 11 results in $r = 7$. This means that 7 mod 11 = 7.

### G.2.2 Arithmetic operations
The three binary operations (addition, subtraction, and multiplication) that we discussed for integers can also be defined for modulo arithmetic. We may need to normalize the result (apply the mod operation and use the residue) if the result is greater than $n - 1$, as shown in Figure G.3.

Actually, two sets of binary operators are used here. The first set is one of the binary operators (+, -, $\\times$) and the second is the **mod** operator. We need to use parentheses to emphasize the order of operations. If at any time during calculation we find a negative value for $r$, the value should be normalized. We need to add the modulus to the result as many times as is necessary to make it positive.

**Example G.14**
Perform the following operations:
a. Add 7 to 14 using modulo 15.
b. Subtract 11 from 7 using modulo 13.
c. Multiply 11 by 7 using modulo 20.
**Solution**
The following shows the two steps involved in each case:
$(14 + 7) \\text{ mod } 15 \\rightarrow (21) \\text{ mod } 15 = 6$
$(7 - 11) \\text{ mod } 13 \\rightarrow (-4) \\text{ mod } 13 = -4 + 13 = 9$
$(7 \\times 11) \\text{ mod } 20 \\rightarrow (77) \\text{ mod } 20 = 17$

**Example G.15**
Perform the following operations:
a. Add 17 to 27 using modulo 14.
b. Subtract 43 from 12 using modulo 13
c. Multiply 123 by -10 using modulo 19.
**Solution**
Note that the integers in these examples are sometimes out of the range of 0 to $n - 1$. We can normalize them either before applying the operation or after applying the operation. We show the second choice, you try the first choice. The result should be the same.
$(17 + 27) \\text{ mod } 14 \\rightarrow (44) \\text{ mod } 14 = 2$
$(12 - 43) \\text{ mod } 15 \\rightarrow (-31) \\text{ mod } 15 = -1 + 15 = 14$
$(123 \\times -10) \\text{ mod } 20 \\rightarrow (-1230) \\text{ mod } 19 = -14 + 19 = 5$

**Modulo-2 arithmetic**
Modulo-2 arithmetic is of particular interest. As the modulus is 2, we can use only the values 0 and 1. Operations in this arithmetic are very simple. The following shows how we can add or subtract 2 bits:
Adding: $(0 + 0) \\text{ mod } 2 = 0$  $(0 + 1) \\text{ mod } 2 = 1$
$(1 + 0) \\text{ mod } 2 = 1$  $(1 + 1) \\text{ mod } 2 = 0$
Subtracting: $(0 - 0) \\text{ mod } 2 = 0$  $(0 - 1) \\text{ mod } 2 = 1$
$(1 - 0) \\text{ mod } 2 = 1$  $(1 - 1) \\text{ mod } 2 = 0$
Notice particularly that addition and subtraction give the same results. In this arithmetic we use the XOR (exclusive OR) operation for both addition and subtraction. The result of an XOR operation is 0 if two bits are the same and 1 if two bits are different. Figure G.4 shows this operation.

## G.3 DISCRETE COSINE TRANSFORM
In this section we give the mathematical background for the discrete cosine and inverse discrete cosine transforms that are used for data compression, as discussed in Chapter 15.

### G.3.1 The discrete cosine transform
The discrete cosine transform (DCT) changes each block of 64 pixels so that the relative relationship between pixels is preserved but redundancies are revealed. The formula follows. $P(x, y)$ defines one particular value in the picture block, while $T(m, n)$ defines one value in the transformed block.

$T(m, n) = 0.25 c(m) c(n) \\sum_{x=0}^7 \\sum_{y=0}^7 P(x, y) \\cos \\left[ \\frac{(2x + 1)m\\pi}{16} \\right] \\cos \\left[ \\frac{(2y + 1)n\\pi}{16} \\right]$

where $c(i) = 1/\\sqrt{2}$ if $i = 0$, and $c(i) = 1$ otherwise.

### G.3.2 The inverse discrete cosine transform
The inverse transform is used to create the $P(x, y)$ table from the $T(m, n)$ table.

$P(x, y) = 0.25 \\sum_{m=0}^7 \\sum_{n=0}^7 c(m) c(n) T(m, n) \\cos \\left[ \\frac{(2m + 1)x\\pi}{16} \\right] \\cos \\left[ \\frac{(2n + 1)y\\pi}{16} \\right]$

where $c(i) = 1/\\sqrt{2}$ if $i = 0$, and $c(i) = 1$ otherwise.

**Example G.16**
Evaluate $T(0, 0)$ and $T(0, 1)$ if $P(x, y) = 20$ for all $x$ and $y$.
**Solution**
Using sum-to-product identity $\\cos x + \\cos y = 2[\\cos(x + y)/2] [\\cos(x - y)/2]$, we can show that the sum of all cosine terms is 0.
`,zh:`
# 附錄 G：數學複習

本附錄複習一些有助於理解本書內容的數學概念。我們先簡要介紹指數和對數函數。然後討論模數運算。最後，我們給出用於資料壓縮的離散餘弦轉換的公式。

## G.1 指數與對數
在解決本書中的某些問題時，我們經常需要知道如何處理指數和對數函數。本節簡要複習這兩個概念。

### G.1.1 指數函數
以 $a$ 為底的指數函數定義為 $a^x$。如果 $x$ 是整數，這被解釋為將 $a$ 乘以自身 $x$ 次。通常我們可以使用計算器來找出 $y$ 的值。

**範例 G.1**
計算以下指數函數的值。
a. $3^2$
b. $5.2^6$
**解答**
使用指數的解釋，我們可以找到：
a. $3^2 = 3 \\times 3 = 9$
b. $5.2^6 = 5.2 \\times 5.2 \\times 5.2 \\times 5.2 \\times 5.2 \\times 5.2 = 19770.609664$

**範例 G.2**
計算以下指數函數的值：
a. $3^{2.2}$
b. $5.2^{6.3}$
**解答**
使用計算器可以更輕鬆地完成這些問題——我們可以找到：
a. $3^{2.2} \\approx 11.212$
b. $5.2^{6.3} \\approx 32424.60$

**三個常見底數**
在表達式 $a^b$ 中，我們稱 $a$ 為底數，$b$ 為指數。三個底數非常常見：底數 10、底數 $e$ 和底數 2。
*   底數 10 是十進位系統的底數。大多數計算器都有 $10^x$ 鍵。
*   科學和數學中使用的底數是自然底數 $e$，其值為 2.71828183...。大多數計算器都有 $e^x$ 鍵。此底數用於科學，因為某些現象（如放射性衰變）最適合使用此底數來描述。
*   我們在電腦科學中通常需要的底數是底數 2。大多數計算器沒有 $2^x$ 鍵，但我們總可以使用通用的 $x^y$ 鍵，其中 $x = 2$。

**範例 G.3**
計算以下指數函數的值：
a. $e^4$
b. $e^{6.3}$
c. $10^{3.3}$
d. $2^{6.3}$
e. $2^{10}$
**解答**
a. $e^4 \\approx 54.60$
b. $e^{6.3} \\approx 544.57$
c. $10^{3.3} \\approx 1995.26$
d. $2^{6.3} \\approx 78.79$
e. $2^{10} = 1024$

**範例 G.4**
在電腦科學中，主導底數是 2。了解一些常見指數的 2 的冪是一個好習慣。我們經常需要記住：
$2^0 = 1$   $2^1 = 2$   $2^2 = 4$   $2^3 = 8$   $2^4 = 16$   $2^5 = 32$   $2^6 = 64$
$2^7 = 128$   $2^8 = 256$   $2^9 = 512$   $2^{10} = 1024$

**指數函數的性質**
指數函數有幾個性質，有些對我們有用：
1. $a^0 = 1$
2. $a^1 = a$
3. $a^{-x} = 1 / a^x$
4. $a^{x+y} = a^x \\times a^y$
5. $a^{x-y} = a^x / a^y$
6. $(a^x)^y = a^{x \\times y}$

**範例 G.5**
使用這些性質的例子：
a. $5^0 = 1$
b. $6^1 = 6$
c. $2^{-4} = 1/2^4 = 1/16 = 0.0625$
d. $2^{5+3} = 2^5 \\times 2^3 = 32 \\times 8 = 256$
e. $3^{2-3} = 3^2 / 3^3 = 9 / 27 = 1/3 \\approx 0.33$
f. $(10^4)^2 = 10^{4 \\times 2} = 10^8 = 100000000$

### G.1.2 對數函數
對數函數是指數函數的反函數，如下所示：
$y = a^x \\leftrightarrow x = \\log_a y$
就像在指數函數中一樣，$a$ 被稱為對數函數的**底數**。換句話說，如果給定 $x$，我們可以使用指數函數計算 $y$：如果給定 $y$，我們可以使用對數函數計算 $x$。

**指數函數和對數函數互為反函數。**

對數促進了算術中的計算，因為它們將乘法轉換為加法，將求冪轉換為乘法。

**範例 G.6**
計算以下對數函數的值：
a. $\\log_3 9$
b. $\\log_2 16$
c. $\\log 100$
d. $\\log_2 (-2)$
**解答**
我們尚未展示如何在不同底數中計算對數函數，但我們可以直觀地解決這個問題。
a. 因為 $3^2 = 9$，所以 $\\log_3 9 = 2$，利用了這兩個函數互為反函數的事實。
b. 同樣地，因為 $2^4 = 16$，所以 $\\log_2 16 = 4$。
c. 由於沒有有限數 $x$ 使得 $10^x = 0$，因此 $\\log_{10} 0$ 是未定義的或數學上的負無窮大。
d. 實數數學中的負數沒有對數。然而，在複數域中我們可以有負數的對數，但我們將此留給複數理論的書籍。

**三個常見底數**
如同求冪的情況，對數也有三個常見底數：底數 10、底數 $e$ 和底數 2。底數 $e$ 的對數通常顯示為 **ln**（自然對數），底數 10 的對數顯示為 **log**（省略底數）。並非所有計算器都有底數 2 的對數。我們很快就會展示如何處理這個底數。

**範例 G.7**
計算以下對數函數的值：
a. $\\log 233$
b. $\\ln 45$
**解答**
對於這兩個底數，我們可以使用計算器：
a. $\\log 233 \\approx 2.367$
b. $\\ln 45 \\approx 3.81$

**換底公式**
我們經常需要找出底數不是 $e$ 或 10 的對數函數的值。如果可用的計算器不能給出我們所需底數的結果，我們可以使用對數的一個基本性質，換底公式，如下所示：
$\\log_a y = \\frac{\\log_b y}{\\log_b a}$
請注意，右側顯示了兩個以 $b$ 為底的對數函數，這與左側的底數 $a$ 不同。這意味著我們可以選擇計算器中可用的底數（底數 $b$）並找出不可用底數（底數 $a$）的對數。

**範例 G.8**
計算以下對數函數的值：
a. $\\log_3 810$
b. $\\log_5 600$
c. $\\log_2 1024$
d. $\\log_2 600$
**解答**
這些底數通常在大多數計算器上不可用，但我們可以使用可用的底數 10。
a. $\\log_3 810 = \\log 810 / \\log 3 = 2.908 / 0.477 \\approx 6.095$
b. $\\log_5 600 = \\log 600 / \\log 5 = 2.778 / 0.699 \\approx 3.975$
c. $\\log_2 1024 = \\log 1024 / \\log 2 = 3.01 / 0.301 = 10$
d. $\\log_2 600 = \\log 600 / \\log 2 \\approx 2.778 / 0.301 \\approx 9.223$

**範例 G.9**
底數 2 在電腦科學中非常常見。由於我們知道 $\\log_{10} 2 \\approx 0.301$，計算（近似）這個底數的對數非常容易。我們找出底數 10 的對應數字的對數並除以 0.310。或者，我們可以將底數 10 的對應對數乘以 3.332 ($\\approx 1 / 0.301$)。
a. $\\log_2 600 \\approx 3.322 \\times \\log_{10} 600 \\approx 3.322 \\times 2.778 \\approx 9.228$
b. $\\log_2 2048 \\approx 3.322 \\times \\log_{10} 2048 \\approx 3.322 \\times 2.778 = 11$

**對數函數的性質**
對數函數有六個有用的性質，每個都與指數函數的相應性質有關（前面提到過）。
1. $\\log_a 1 = 0$
2. $\\log_a a = 1$
3. $\\log_a (1/x) = -\\log_a x$
4. $\\log_a (x \\times y) = \\log_a x + \\log_a y$
5. $\\log_a (x/y) = \\log_a x - \\log_a y$
6. $\\log_a x^y = y \\times \\log_a x$

**範例 G.10**
計算以下對數函數的值。
a. $\\log_3 1$
b. $\\log_3 3$
c. $\\log (1/10)$
d. $\\log_a (x \\times y)$ 如果我們知道 $\\log_a x = 2$ 且 $\\log_a y = 3$
e. $\\log_a (x/y)$ 如果我們知道 $\\log_a x = 2$ 且 $\\log_a y = 3$
f. $\\log_2 (1024)$ 不使用計算器
**解答**
我們使用對數函數的性質來解決問題：
a. $\\log_3 1 = 0$
b. $\\log_3 3 = 1$
c. $\\log (1/10) = \\log 10^{-1} = -1 \\log 10 = -1$
d. $\\log_a (x \\times y) = \\log_a x + \\log_a y = 2 + 3 = 5$
e. $\\log_a (x / y) = \\log_a x - \\log_a y = 2 - 3 = -1$
f. $\\log_2 (1024) = \\log_2 (2^{10}) = 10 \\times \\log_2 2 = 10 \\times 1 = 10$

## G.2 模數運算
在整數運算中，如果我們將 $a$ 除以 $n$，我們可以得到 $q$ 和 $r$。這四個整數之間的關係可以表示為 $a = q \\times n + r$。在這個關係中，$a$ 稱為被除數，$q$ 為商，$n$ 為除數，$r$ 為餘數。由於一個運算通常只定義一個單一輸出，這不是一個運算。我們可以稱之為**除法關係**。

**範例 G.11**
假設 $a = 214$ 且 $n = 13$。我們可以使用我們在算術中學到的除法演算法找到 $q = 16$ 和 $r = 6$，如圖 G.1 所示。
大多數電腦語言可以使用特定語言的運算子找到商和餘數。例如，在 C 語言中，除法運算子 (/) 可以找到商，模數運算子 (%) 可以找到餘數。

### G.2.1 模數運算子
在模數運算中，我們只對其中一個輸出感興趣，即餘數 $r$。我們不關心商 $q$。換句話說，我們想知道當我們將 $a$ 除以 $n$ 時，$r$ 的值是多少。這意味著我們可以將上述關係更改為具有兩個輸入 $a$ 和 $n$ 以及一個輸出 $r$ 的二元運算子。該二元運算子稱為**模數運算子**，顯示為 **mod**。第二個輸入 ($n$) 稱為**模數**，輸出 $r$ 稱為**餘數**。圖 G.2 顯示了除法關係與模數運算子的比較。

模數運算子 (**mod**) 獲取一個整數 ($a$) 和一個模數 ($n$)。運算子創建一個餘數 ($r$)。雖然 $a$ 和 $r$ 可以是任何整數，但 $n$ 不能為 0，因為這意味著除以零，這會產生未定義的值或無窮大。然而，在實踐中，我們需要 $n$ 的值為非負。因此，$a$ 和 $r$ 的值應在 0 到 $n - 1$ 之間。

**範例 G.12**
模數運算的一個很好的例子是我們的時鐘系統。時鐘基於模 12 運算。然而，我們時鐘中的整數 12 實際上應該是 0，以使其符合模數運算。

**範例 G.13**
找出以下運算的結果：
a. 28 mod 6
b. 32 mod 12
c. 19 mod 15
d. 7 mod 11
**解答**
我們正在尋找餘數 $r$。我們可以將 $a$ 除以 $n$ 並找到 $q$ 和 $r$。然後我們可以忽略 $q$ 並保留 $r$。
a. 28 除以 6 的結果是 $r = 4$。這意味著 28 mod 6 = 4。
b. 32 除以 12 的結果是 $r = 8$。這意味著 32 mod 12 = 8。
c. 19 除以 15 的結果是 $r = 4$。這意味著 19 mod 15 = 4。
d. 7 除以 11 的結果是 $r = 7$。這意味著 7 mod 11 = 7。

### G.2.2 算術運算
我們為整數討論的三個二元運算（加、減和乘）也可以為模數運算定義。如果結果大於 $n - 1$，我們可能需要將結果正規化（應用 mod 運算並使用餘數），如圖 G.3 所示。

實際上，這裡使用了兩組二元運算子。第一組是二元運算子之一 (+, -, $\\times$)，第二組是 **mod** 運算子。我們需要使用括號來強調運算的順序。如果在計算過程中的任何時候我們發現 $r$ 為負值，則該值應被正規化。我們需要將模數加到結果中，直到其變為正數為止。

**範例 G.14**
執行以下運算：
a. 使用模數 15 將 7 加到 14。
b. 使用模數 13 從 7 中減去 11。
c. 使用模數 20 將 11 乘以 7。
**解答**
以下顯示了每種情況涉及的兩個步驟：
$(14 + 7) \\text{ mod } 15 \\rightarrow (21) \\text{ mod } 15 = 6$
$(7 - 11) \\text{ mod } 13 \\rightarrow (-4) \\text{ mod } 13 = -4 + 13 = 9$
$(7 \\times 11) \\text{ mod } 20 \\rightarrow (77) \\text{ mod } 20 = 17$

**範例 G.15**
執行以下運算：
a. 使用模數 14 將 17 加到 27。
b. 使用模數 13 從 12 中減去 43。
c. 使用模數 19 將 123 乘以 -10。
**解答**
請注意，這些範例中的整數有時超出了 0 到 $n - 1$ 的範圍。我們可以在應用運算之前或之後對它們進行正規化。我們展示第二種選擇，您可以嘗試第一種選擇。結果應該是相同的。
$(17 + 27) \\text{ mod } 14 \\rightarrow (44) \\text{ mod } 14 = 2$
$(12 - 43) \\text{ mod } 15 \\rightarrow (-31) \\text{ mod } 15 = -1 + 15 = 14$
$(123 \\times -10) \\text{ mod } 20 \\rightarrow (-1230) \\text{ mod } 19 = -14 + 19 = 5$

**模-2 運算**
模-2 運算特別令人感興趣。由於模數是 2，我們只能使用值 0 和 1。這種運算中的操作非常簡單。以下顯示了我們如何加或減 2 個位元：
加法：$(0 + 0) \\text{ mod } 2 = 0$  $(0 + 1) \\text{ mod } 2 = 1$
$(1 + 0) \\text{ mod } 2 = 1$  $(1 + 1) \\text{ mod } 2 = 0$
減法：$(0 - 0) \\text{ mod } 2 = 0$  $(0 - 1) \\text{ mod } 2 = 1$
$(1 - 0) \\text{ mod } 2 = 1$  $(1 - 1) \\text{ mod } 2 = 0$
特別注意，加法和減法給出相同的結果。在這種運算中，我們使用 XOR（互斥或）運算進行加法和減法。如果兩個位元相同，XOR 運算的結果為 0，如果兩個位元不同，結果為 1。圖 G.4 顯示了此運算。

## G.3 離散餘弦轉換
在本節中，我們給出離散餘弦和逆離散餘弦轉換的數學背景，這些轉換用於資料壓縮，如第 15 章所述。

### G.3.1 離散餘弦轉換
離散餘弦轉換 (DCT) 改變每個 64 像素的區塊，以便保留像素之間的相對關係，但揭示冗餘。公式如下。$P(x, y)$ 定義圖片區塊中的一個特定值，而 $T(m, n)$ 定義轉換區塊中的一個值。

$T(m, n) = 0.25 c(m) c(n) \\sum_{x=0}^7 \\sum_{y=0}^7 P(x, y) \\cos \\left[ \\frac{(2x + 1)m\\pi}{16} \\right] \\cos \\left[ \\frac{(2y + 1)n\\pi}{16} \\right]$

其中如果 $i = 0$，則 $c(i) = 1/\\sqrt{2}$，否則 $c(i) = 1$。

### G.3.2 逆離散餘弦轉換
逆轉換用於從 $T(m, n)$ 表創建 $P(x, y)$ 表。

$P(x, y) = 0.25 \\sum_{m=0}^7 \\sum_{n=0}^7 c(m) c(n) T(m, n) \\cos \\left[ \\frac{(2m + 1)x\\pi}{16} \\right] \\cos \\left[ \\frac{(2n + 1)y\\pi}{16} \\right]$

其中如果 $i = 0$，則 $c(i) = 1/\\sqrt{2}$，否則 $c(i) = 1$。

**範例 G.16**
如果 $P(x, y) = 20$ 對於所有 $x$ 和 $y$，求 $T(0, 0)$ 和 $T(0, 1)$。
**解答**
使用積化和差恆等式 $\\cos x + \\cos y = 2[\\cos(x + y)/2] [\\cos(x - y)/2]$，我們可以證明所有餘弦項之和為 0。
`},P={en:`
# Appendix H: Error Detection and Correction

When data is transferred from one place to another, or moved from one device to another, the accuracy of the data must be checked. For most applications, a system must guarantee that the data received is identical to the data transmitted. Some applications, on the other hand, can tolerate a small level of error. For example, random errors in audio or video transmissions may be tolerable, but when we transfer text, we expect a very high level of accuracy. We only discuss error in transition: errors due to data corruption in storage are treated in the same way.

## H.1 INTRODUCTION
We first discuss some issues related to error detection and correction.

### H.1.1 Types of errors
Whenever bits flow from one place to another they are subject to unpredictable changes because of interference in the transmission medium, such as crosstalk, external electromagnetic fields, and so on. This is illustrated by Figure H.1.

In a **single-bit error**, a 0 is changed to a 1 or a 1 to a 0. In a **burst error** multiple bits are changed. The term **single-bit error** means that only 1 bit of a given data unit, such as a byte, character, or packet, is changed from 1 to 0 or from 0 to 1. The term **burst error** means that two or more bits in the data unit have changed from 1 to 0 or from 0 to 1.

### H.1.2 Redundancy
The central concept in correcting errors is **redundancy**. To be able to correct errors, we need to send extra bits with our data. These redundant bits are added by the sender and removed by the receiver. Their presence allows the receiver to correct corrupted bits.

**To correct errors, we need to send extra (redundant) bits with data.**

### H.1.3 Detection versus correction
The correction of errors is more difficult than the detection. In **error detection**, we are looking only to see if an error has occurred. The answer is a simple yes or no. We are not even interested in the number of errors: a single-bit error is the same for us as a burst error.

In **error correction**, we need to know the exact number of bits that are corrupted—and more importantly, their location in the message. The number of errors and the size of the message are important factors. If we need to correct a single error in an 8-bit data unit, we need to consider eight possible error locations: if we need to correct two errors in a data unit of the same size, we need to consider 28 (7 + 6 + ... + 1) possibilities. You can imagine the receiver’s difficulty in finding ten errors in a data unit of 1000 bits.

### H.1.4 Forward error correction versus retransmission
There are two main methods of error correction. **Forward error correction** is the process in which the receiver tries to guess the message by using redundant bits. This is possible, as we will see later, if the number of errors is small. Correction by **retransmission** is a technique in which the receiver detects the occurrence of an error and asks the sender to resend the message. Re-sending is repeated until a message arrives that the receiver believes is error-free: usually, not all errors can be detected.

### H.1.5 Coding
Redundancy is achieved through various coding schemes. The sender adds redundant bits through a process that creates a relationship between the redundant bits and the actual data bits. The receiver checks the relationships between the two sets of bits to detect or correct the errors. The ratio of redundant bits to data bits and the robustness of the process are important factors in any coding scheme. Figure H.2 shows the general idea of coding.

We can divide coding schemes into two broad categories: **block coding** and **convolution coding**. In this appendix, we concentrate on block coding: convolution coding is more complex and beyond the scope of this book.
Block coding uses modular arithmetic, as discussed in Appendix G.

**We only concentrate on block codes: we leave convolution codes to advanced texts.**

## H.2 BLOCK CODING
In **block coding** we divide a message into blocks, each of $k$ bits, called **datawords**. We add $r$ redundant bits to each block to make the length $n = k + r$. The resulting $n$-bit blocks are called **codewords**. How the extra $r$ bits are chosen or calculated is something we discuss later. For the moment, it is important to know that we have a set of datawords, each of size $k$, and a set of codewords, each of size of $n$.

With $k$ bits, we can create a combination of $2^k$ datawords: with $n$ bits, we can create a combination of $2^n$ codewords. Since $n > k$, the number of possible codewords is larger than the number of possible datawords. The block coding process is one-to-one: the same dataword is always encoded as the same codeword. This means that we have $2^n - 2^k$ codewords that are not used. We call these codewords **invalid** or **illegal**. Figure H.3 shows the situation.

**Example H.1**
Let us assume our message is made up of a single block of 8 bits ($k = 8$). There are $2^8 = 256$ possible combination of datawords. If we add two redundant bits ($r = 1$), then each possible codeword is 10 bits ($n = 10$) and the total number of possible codewords is $2^{10} = 1024$. This means that we have $1024 - 256 = 768$ codewords are invalid. If one of these invalid codewords is received, the receiver knows that the codeword is corrupted.

### H.2.1 Error detection
How can errors be detected by using block coding? If the following two conditions are met, the receiver detects a change in the original codeword.
1.  The receiver has (or can find) a list of valid codewords.
2.  The original codeword has changed to an invalid one.
Figure H.4 shows the role of block coding in error detection.

The sender creates codewords out of datawords by using a generator that applies the rules and procedures of encoding (discussed later). Each codeword sent to the receiver may change during transmission. If the received codeword is the same as one of the valid codewords, the word is accepted and the corresponding dataword is extracted for use. If the received codeword is not valid, it is discarded.
However, if the codeword is corrupted during transmission, but the received word still matches a valid codeword, the error remains undetected. This type of coding can therefore detect only single errors: two or more errors in the same codeword may remain undetected.

**Example H.2**
Let us assume that $k = 2$ and $n = 3$. Table H.1 shows the list of datawords and defined codewords, which is agreed between the sender and the receiver. Later we will see how to derive a codeword from a dataword.

**Table H.1 A code for error detection (Example H.2)**
| Datawords | Codewords |
| :--- | :--- |
| 00 | 000 |
| 01 | 011 |
| 10 | 101 |
| 11 | 110 |

Assume that the sender encodes the dataword 01 as 011 and sends it to the receiver. Consider the following cases:
1.  The receiver receives 011. It is a valid codeword. The receiver extracts the dataword 01 from it.
2.  The codeword is corrupted during transmission, and 111 is received—that is, the leftmost bit is corrupted. This is not a valid codeword, so it is discarded.
3.  The codeword is corrupted during transmission, and 000 is received—that is, the right two bits are corrupted. This is a valid codeword. The receiver incorrectly extracts the dataword 00. Two corrupted bits have made the error undetectable.

**An error-detecting code can detect only the types of errors for which it is designed: other types of errors may remain undetected.**

### H.2.2 Error correction
Error correction is much more difficult than error detection. In error detection, the receiver needs to know only that the received codeword is invalid: in error correction, the receiver needs to find (or guess) the original codeword sent. We need more redundant bits for error correction than for error detection. Figure H.5 shows the role of block coding in error correction. We can see that the idea is the same as error detection, but the generator and checker functions are much more complex.

**Example H.3**
Let us add more redundant bits to Example H.2 to see if the receiver can correct an error without knowing what was actually sent. We add three redundant bits to the 2-bit dataword to make 5-bit codewords. Again, later we will show how we choose the redundant bits. For the moment let us concentrate on the error correction concept. Table H.2 shows the datawords and codewords.

**Table H.2 A code for error correction (Example H.3)**
| Dataword | Codeword | Dataword | Codeword |
| :--- | :--- | :--- | :--- |
| 00 | 00000 | 10 | 10101 |
| 01 | 01011 | 11 | 11110 |

Assume the dataword is 01. The sender consults the table (or uses an algorithm) to create the codeword 01011. The codeword is corrupted during transmission, and 01001 is received—an error in the second bit from the right. First, the receiver finds that the received codeword is not in the table. This means an error has occurred. (Detection must come before correction.) The receiver, assuming that only 1 bit is corrupted, uses the following strategy to guess the correct dataword.
1.  Comparing the received codeword with the first codeword in the table (01001 *versus* 00000), the receiver decides that the first codeword is not the one that was sent because there are two different bits.
2.  By the same reasoning, the original codeword cannot be the third or fourth one in the table.
3.  The original codeword must be the second one in the table, because this is the only one that differs from the received codeword by 1 bit. The receiver replaces 01001 with 01011 and consults the table to find the dataword 01.

## H.3 LINEAR BLOCK CODES
Almost all block codes used today belong to a subset called **linear block codes**. The use of nonlinear block codes for error detection and correction is not as widespread, because their structure makes theoretical analysis and implementation difficult. We therefore concentrate on linear block codes.
The formal definition of linear block codes requires a knowledge of abstract algebra (particularly Galois fields) which is beyond the scope of this book. We therefore give an informal definition. For our purposes, a linear block code is a code in which the exclusive OR (modulo-2 addition, discussed in Appendix G) of two valid codewords creates another valid codeword.

**In a linear block code, the exclusive OR (XOR) of any two valid codewords creates another valid codeword.**

**Example H.4**
Let us see if the two codes we defined in Table H.1 and Table H.2 belong to the class of linear block codes.
1.  The scheme in Table H.1 is a linear block code because the result of XORing any codeword with any other codeword is a valid codeword. For example, XORing of the second and third codewords creates the fourth one.
2.  The scheme in Table H.2 is also a linear block code. We can create all four codewords by XORing two other codewords.

### H.3.1 Some linear block codes
Let us now show some linear block codes. These codes are trivial because we can easily find the encoding and decoding algorithms and check their performances.

**Simple parity-check code**
Perhaps the most familiar error-detecting code is the **simple parity-check code**. In this code, a $k$-bit dataword is changed to an $n$-bit codeword, where $n = k + 1$. The extra bit, called the **parity bit**, is added to a pre-defined position. It is selected to make the total number of 1s in the codeword even. Although some implementations specify an odd number of 1s, we discuss the even number case.

**A simple parity-check code is a single-bit error-detecting code in which n = k + 1.**

Our first code (Table H.3) is a parity-check code with $k = 2$ and $n = 3$. The code in Table H.3 is also a parity-check code with $k = 4$ and $n = 5$.

**Table H.3 Simple parity-check code C(5, 4)**
| Datawords | Codewords | Datawords | Codewords |
| :--- | :--- | :--- | :--- |
| 0000 | 00000 | 1000 | 10001 |
| 0001 | 00011 | 1001 | 10010 |
| 0010 | 00101 | 1010 | 10100 |
| 0011 | 00110 | 1011 | 10111 |
| 0100 | 01001 | 1100 | 11000 |
| 0101 | 01010 | 1101 | 11011 |
| 0110 | 01100 | 1110 | 11101 |
| 0111 | 01111 | 1111 | 11110 |

Figure H.6 shows a possible structure of an encoder (at the sender) and a decoder (at the receiver).
The encoder uses a generator that takes a copy of a 4-bit dataword ($a_0, a_1, a_2$, and $a_3$) and generates a parity bit $r_0$. The dataword bits and the parity bit create the 5-bit codeword. The parity bit that is added makes the number of 1s in the codeword even. This is normally done by adding the 4 bits of the dataword (modulo-2): the result is the parity bit. In other words:
$r_0 = a_3 + a_2 + a_1 + a_0$       (modulo-2)

If the number of 1s is even, the result is 0: if the number of 1s is odd, the result is 1. In both cases, the total number of 1s in the codeword is even.
The sender sends the codeword, which may be corrupted during transmission. The receiver receives a 5-bit word. The checker at the receiver does the same thing as the generator in the sender with one exception: the addition is done over all five bits. The result, which is called the **syndrome**, is just 1 bit. The syndrome is 0 when the number of 1s in the received codeword is even; otherwise, it is 1.
$s_0 = b_3 + b_2 + b_1 + b_0 + q_0$       (modulo-2)

A syndrome is the output of a checking process that is fed into the decision logic of a receiver in order to decide what to do with the data portion of the code word. The decision may be to accept it, to reject it, or (for correcting code) to modify it before accepting it. In this case, the syndrome is passed to the **decision logic analyzer**. If there is no error in the codeword, the syndrome is 0 and the decision logic accepts the data portion of the codeword as the actual dataword. If the syndrome is 1, there must be an error in the codeword, and so the decision logic discards the data portion of the codeword: the dataword is not created.

**Example H.5**
Let us look at some transmission scenarios. Assume that the sender sends the dataword 1011. The parity bit is $(1 + 0 + 1 + 1) \\text{ mod } 2 = 1$, which is appended to the right of the dataword. The codeword created from this dataword is therefore 10111, which is sent to the receiver. We examine five cases:
1.  No error occurs: the received codeword is 10111. The syndrome is 0. The dataword 1011 is created.
2.  A single-bit error changes $a_1$. The received codeword is 10011. The syndrome is 1. No dataword is created.
3.  A single-bit error changes the parity bit $r_0$. The received codeword is 10110. The syndrome is 1. No dataword is created. Note that although none of the dataword bits are corrupted, no dataword is created because the code is not sophisticated enough to show the position of the corrupted bit.
4.  An error changes $r_0$ and a second error changes $a_3$. The received codeword is 00110. The syndrome is 0. The dataword 0011 is created at the receiver. Note that here the dataword is wrongly created due to the syndrome value: the simple parity-check decoder cannot detect an even number of errors. The errors cancel each other out and give the syndrome a value of 0.
5.  Three bits—$a_3$, $a_2$, and $a_1$—are changed by errors. The received codeword is 01011. The syndrome is 1. The dataword is not created. This shows that the simple parity check, guaranteed to detect a single error, can also find any odd number of errors.

**A simple parity-check code can detect an odd number of errors.**

**Hamming codes**
Hamming codes are a subset of linear block codes that follow two criteria:
$n = k + r$ and $n = 2^r - 1$
in which $k$ is the number of bits in dataword, $r$ is the number of redundant bits, and $n$ is the number of bits in the codeword. These codes can detect up to $r - 1$ bits of error and can correct up to $(r - 1) / 2$ bits of error.

**Example H.6**
A code with $k = 4, r = 3$, and $n = 7$ satisfies the two conditions of a Hamming code, because we have $7 = 4 + 3$ and $7 = 2^3 - 1$. This code can detect only $(3 - 1) = 2$ bits of error and correct only $(3 - 1)/2 = 1$ bit of error.
The theory of Hamming codes in general is beyond the scope of this book. For more information, see *Data Communication and Networking*, by Behrouz Forouzan, McGraw-Hill, New York, 2006. In the next section, we discuss a subset of Hamming code called cyclic codes.

## H.4 CYCLIC CODES
Cyclic codes are special linear block codes with one extra property. In a **cyclic code**, if a codeword is cyclically shifted (rotated), the result is another codeword. For example, if 1011000 is a codeword and we cyclically left-shift it, then 0110001 is also a codeword.

### H.4.1 Cyclic redundancy check
We can create cyclic codes to correct errors. However, the theoretical background required is beyond the scope of this appendix. In this section, we simply discuss a category of cyclic codes called the **cyclic redundancy checks (CRC)** that are used in networks such as LANs and WANs.
Table H.4 shows an example of a CRC code. We can see both the linear and cyclic properties of this code.

**Table H.4 A CRC code with k = 4, n = 7, and r = 3**
| Dataword | Codeword | Dataword | Codeword |
| :--- | :--- | :--- | :--- |
| 0000 | 0000000 | 1000 | 1000101 |
| 0001 | 0001011 | 1001 | 1001110 |
| 0010 | 0010110 | 1010 | 1010011 |
| 0011 | 0011101 | 1011 | 1011000 |
| 0100 | 0100111 | 1100 | 1100010 |
| 0101 | 0101100 | 1101 | 1101001 |
| 0110 | 0110001 | 1110 | 1110100 |
| 0111 | 0111010 | 1111 | 1111111 |

Figure H.7 shows one possible design for the encoder and decoder.
In the encoder in Figure H.7, the dataword has $k$ bits (4 here) and the codeword has $n$ bits (here 7). The size of the dataword is augmented by adding $n - k$ (here 3) 0s to the right-hand side of the word. The $n$-bit result is fed into the generator. The generator uses a predefined divisor of size $n - k + 1$ (here 4). The generator divides the augmented dataword by the divisor using modulo-2 division. The quotient of the division is discarded: the remainder ($r_2 r_1 r_0$) is appended to the dataword to create the codeword.
The decoder receives the codeword, which could be corrupted. A copy of all $n$ bits is fed to the checker, which is a replica of the generator. The remainder produced by the checker is a syndrome of $n - k$ (here 3) bits, which is fed to the decision logic analyzer. The analyzer has a simple function: if the syndrome bits are all 0s, the 4 leftmost bits of the codeword are accepted as the dataword (interpreted as no error), otherwise, the 4 bits are discarded (error).

**Encoder**
Let us take a closer look at the encoder. The encoder takes the dataword and augments it with $n - k$ number of 0s. It then divides the augmented dataword by the divisor, as shown in Figure H.8.
Note that this is not the regular binary division—obviously the result of dividing 72 by 11 is not the quotient of 10 and the remainder of 6. This is binary division in modulo 2 arithmetic, as we discussed in Appendix G. In this division, adding and subtracting is the same (it is the XOR operation discussed in Appendix E), which means that we do not subtract, but add. A better explanation of this division is that we treat the binary word as a polynomial with a coefficient in modulo 2 arithmetic—only 0 or 1. For more information, we refer the interested reader to *finite field theory (Galois fields)* and books on error detection and correction.
In each step, a copy of the divisor is XORed with the 4 bits of the dividend. The result of the XOR operation (remainder) is 3 bits (in this case), which is used for the next step after 1 extra bit is carried down—see Figure H.8—to make it 4 bits long. There is one important point we need to remember in this type of division. If the leftmost bit of the dividend (or the part used in each step) is 0, the corresponding bit in the quotient is 0.
When there are no bits left to pull down, we have a result. The 3-bit remainder forms the check bits ($r_2, r_1, \\text{and } r_0$). They are appended to the dataword to create the codeword. Note also that we are not interested in the quotient, as only the remainder is used in cyclic codes.

**Decoder**
The codeword can change during transmission. The decoder does the same division process as the encoder. The remainder of the division is the syndrome. If the syndrome is all 0s, there is no error: the dataword is separated from the received codeword and accepted. Otherwise, everything is discarded. Figure H.9 shows two cases. The left-hand figure shows the value of syndrome when no error has occurred: the syndrome is 000. The right-hand part of the figure shows the case in which there is a single error: the syndrome is not all 0s (it is 011).

**Divisor**
You may be wondering how the divisor 1011 is chosen. This needs abstract algebra and theory of finite field to explain, which we leave this to books specialized in this area.

### H.4.2 Performance of cyclic codes
We have seen that cyclic codes have a very good performance in detecting single-bit errors, double errors, an odd number of errors, and burst errors. They can easily be implemented in hardware and software. They are especially fast when implemented in hardware. This has made cyclic codes a good candidate for many networks.

## H.5 CHECKSUM
The last error detection method we discuss here is called the **checksum**. The checksum is used in the Internet by several protocols. Like linear and cyclic codes, the checksum is based on the concept of **redundancy**.

### H.5.1 Checksum concept
The concept of the checksum is not difficult. Let us illustrate it with a few examples.

**Example H.7**
Suppose our data is a list of five 4-bit numbers that we want to send to some destination. In addition to sending these numbers, we send the sum of the numbers. For example, if the set of numbers is (7, 11, 12, 0, 6), we send (7, 11, 12, 0, 6, 36), where 36 is the sum of the original numbers. The receiver adds the five numbers and compares the result with the sum. If the two are the same, the receiver assumes no error, accepts the five numbers, and discards the sum. Otherwise, there is an error somewhere and the data is not accepted.

**Example H.8**
We can make the job of the receiver easier if we send the negative (complement) of the sum, called the *checksum*. In this case, we send (7, 11, 12, 0, 6, -36). The receiver can add all the numbers received (including the checksum). If the result is 0, it assumes no error, otherwise there is an error.

### H.5.2 One’s complement
The previous example has one major drawback. Our data can be written as 4-bit words (they are all less than 15) except for the checksum. One solution is to use **one’s complement** arithmetic, as discussed in Chapter 3.

**Example H.9**
Let us redo Example H.8 using one’s complement arithmetic. Figure H.10 shows the process at the sender and at the receiver.
The sender initializes the checksum to 0 and adds all data items and the checksum (the checksum is considered as one data item and is shown in color). The result is 36. However, 36 cannot be expressed in 4 bits. The extra two bits are wrapped and added with the sum to create the wrapped sum value 6. In the figure, we have shown the details in binary. The sum is then complemented, resulting in the checksum value 9 ($15 - 6 = 9$). The sender now sends six data items to the receiver, including the checksum 9. The receiver follows the same procedure as the sender. It adds all data items (including the checksum): the result is 45. The sum is wrapped and becomes 15. The wrapped sum is complemented and becomes 0. Since the value of the checksum is 0, this means that the data is not corrupted. The receiver drops the checksum and keeps the other data items. If the checksum is not zero, the entire packet is dropped and must be retransmitted.

### H.5.3 Internet checksum
Traditionally, the Internet (IP protocol) has used a 16-bit checksum. The sender and receiver use the following procedures:

**Sender side**
*   A 16-bit checksum is set to zero and added to the message.
*   The new message is divided into 16-bit words.
*   All words are added using one’s complement addition.
*   The sum is complemented and replaces the previous checksum.

**Receiver side**
*   The received message (including the checksum) is divided into 16-bit words.
*   All words are added using one’s complement addition.
*   The sum is complemented.
*   If the complemented sum is 0, the message is accepted, otherwise it is rejected.

**Example H.10**
Let us calculate the checksum for a text word of eight characters (‘Forouzan’) as shown in Figure H.11.
The text needs to be divided into 2-byte (16-bit) words. We use ASCII encoding (see Appendix A) to change each byte to a two-digit hexadecimal number. For example, ‘F’ is represented as $(46)_{16}$ and ‘o’ is represented as $(6F)_{16}$. In Figure H.11.a, the value of the partial sum for the first column is $(36)_{16}$. We keep the rightmost digit (6) and insert the leftmost digit (3) as the carry in the second column. The process is repeated for each column. The checksum is calculated and transmitted with the data to the receiver. The receiver performs the same operations, Figure H.11.b. If there is any corruption, the checksum recalculated by the receiver is not all 0s.

**Performance**
The traditional checksum uses a small number of bits (16) to detect errors in a message of any size (sometimes thousands of bits). However, it is not as strong as the CRC in its error-checking capability. For example, if the value of one word is incremented and the value of another word is decremented by the same amount, the two errors cannot be detected because the sum and checksum remain the same. Also if the values of several words are incremented but the total change is a multiple of 65535 ($2^{16}-1$), the sum and the checksum remain the same and the error goes undetected.
`,zh:`
# 附錄 H：錯誤偵測與更正

當資料從一個地方傳輸到另一個地方，或從一個設備移動到另一個設備時，必須檢查資料的準確性。對於大多數應用程式，系統必須保證接收到的資料與傳輸的資料相同。另一方面，有些應用程式可以容忍小程度的錯誤。例如，音訊或視訊傳輸中的隨機錯誤可能是可以容忍的，但當我們傳輸文字時，我們期望非常高的準確度。我們只討論傳輸中的錯誤：儲存中資料損壞導致的錯誤也以同樣的方式處理。

## H.1 簡介
我們先討論一些與錯誤偵測和更正相關的問題。

### H.1.1 錯誤類型
每當位元從一個地方流向另一個地方時，由於傳輸介質中的干擾（例如串音、外部電磁場等），它們都會發生不可預測的變化。這如圖 H.1 所示。

在**單一位元錯誤**中，0 變為 1 或 1 變為 0。在**叢發錯誤**中，多個位元發生變化。術語**單一位元錯誤**意味著給定資料單元（例如位元組、字元或封包）中只有 1 個位元從 1 變為 0 或從 0 變為 1。術語**叢發錯誤**意味著資料單元中有兩個或更多位元從 1 變為 0 或從 0 變為 1。

### H.1.2 冗餘
更正錯誤的核心概念是**冗餘**。為了能夠更正錯誤，我們需要在資料中發送額外的位元。這些冗餘位元由發送者添加並由接收者移除。它們的存在允許接收者更正損壞的位元。

**為了更正錯誤，我們需要在資料中發送額外的（冗餘）位元。**

### H.1.3 偵測與更正
錯誤的更正比偵測更困難。在**錯誤偵測**中，我們只看是否發生了錯誤。答案很簡單，是或否。我們甚至對錯誤的數量不感興趣：對我們來說，單一位元錯誤與叢發錯誤是一樣的。

在**錯誤更正**中，我們需要知道損壞的確切位元數——更重要的是，它們在訊息中的位置。錯誤數量和訊息大小是重要因素。如果我們需要更正 8 位元資料單元中的單個錯誤，我們需要考慮八個可能的錯誤位置：如果我們需要更正相同大小資料單元中的兩個錯誤，我們需要考慮 28 (7 + 6 + ... + 1) 種可能性。你可以想像接收者在 1000 位元的資料單元中找出十個錯誤的困難。

### H.1.4 前向錯誤更正與重傳
主要有兩種錯誤更正方法。**前向錯誤更正**是接收者嘗試利用冗餘位元猜測訊息的過程。正如我們稍後將看到的，如果錯誤數量很少，這是有可能的。**重傳**更正是一種技術，其中接收者偵測到錯誤的發生並要求發送者重新發送訊息。重新發送會重複進行，直到收到接收者認為沒有錯誤的訊息：通常，並非所有錯誤都能被偵測到。

### H.1.5 編碼
冗餘是透過各種編碼方案實現的。發送者透過一個過程添加冗餘位元，該過程在冗餘位元和實際資料位元之間建立關係。接收者檢查這兩組位元之間的關係以偵測或更正錯誤。冗餘位元與資料位元的比率以及過程的穩健性是任何編碼方案中的重要因素。圖 H.2 顯示了編碼的一般概念。

我們可以將編碼方案分為兩大類：**區塊編碼**和**卷積編碼**。在本附錄中，我們專注於區塊編碼：卷積編碼更複雜，超出了本書的範圍。
區塊編碼使用模數運算，如附錄 G 所述。

**我們只專注於區塊碼：我們將卷積碼留給高級教材。**

## H.2 區塊編碼
在**區塊編碼**中，我們將訊息分成區塊，每個區塊 $k$ 位元，稱為**資料字**。我們在每個區塊中添加 $r$ 個冗餘位元，使其長度為 $n = k + r$。產生的 $n$ 位元區塊稱為**碼字**。額外的 $r$ 位元是如何選擇或計算的，我們稍後討論。目前，重要的是要知道我們有一組大小為 $k$ 的資料字和一組大小為 $n$ 的碼字。

使用 $k$ 位元，我們可以創建 $2^k$ 個資料字的組合：使用 $n$ 位元，我們可以創建 $2^n$ 個碼字的組合。由於 $n > k$，可能的碼字數量大於可能的資料字數量。區塊編碼過程是一對一的：相同的資料字總是編碼為相同的碼字。這意味著我們有 $2^n - 2^k$ 個碼字未被使用。我們稱這些碼字為**無效**或**非法**。圖 H.3 顯示了這種情況。

**範例 H.1**
讓我們假設我們的訊息由一個 8 位元的單個區塊組成 ($k = 8$)。有 $2^8 = 256$ 種可能的資料字組合。如果我們添加兩個冗餘位元 ($r = 1$)，那麼每個可能的碼字是 10 位元 ($n = 10$)，可能的碼字總數是 $2^{10} = 1024$。這意味著我們有 $1024 - 256 = 768$ 個碼字是無效的。如果收到這些無效碼字之一，接收者就知道碼字已損壞。

### H.2.1 錯誤偵測
如何使用區塊編碼偵測錯誤？如果滿足以下兩個條件，接收者就會偵測到原始碼字的更改。
1.  接收者擁有（或可以找到）有效碼字的列表。
2.  原始碼字已更改為無效碼字。
圖 H.4 顯示了區塊編碼在錯誤偵測中的作用。

發送者使用生成器從資料字創建碼字，該生成器應用編碼規則和程序（稍後討論）。發送給接收者的每個碼字在傳輸過程中可能會發生變化。如果接收到的碼字與有效碼字之一相同，則該字被接受並提取相應的資料字以供使用。如果接收到的碼字無效，則將其丟棄。
然而，如果碼字在傳輸過程中損壞，但接收到的字仍然匹配有效碼字，則錯誤仍未被偵測到。因此，這種類型的編碼只能偵測單一錯誤：同一碼字中的兩個或更多錯誤可能仍未被偵測到。

**範例 H.2**
讓我們假設 $k = 2$ 且 $n = 3$。表 H.1 顯示了發送者和接收者之間商定的資料字和定義的碼字列表。稍後我們將看到如何從資料字推導出碼字。

**表 H.1 用於錯誤偵測的代碼（範例 H.2）**
| 資料字 | 碼字 |
| :--- | :--- |
| 00 | 000 |
| 01 | 011 |
| 10 | 101 |
| 11 | 110 |

假設發送者將資料字 01 編碼為 011 並將其發送給接收者。考慮以下情況：
1.  接收者收到 011。這是一個有效的碼字。接收者從中提取資料字 01。
2.  碼字在傳輸過程中損壞，收到 111——也就是說，最左邊的位元損壞。這不是一個有效的碼字，因此被丟棄。
3.  碼字在傳輸過程中損壞，收到 000——也就是說，右邊的兩個位元損壞。這是一個有效的碼字。接收者錯誤地提取了資料字 00。兩個損壞的位元使錯誤無法偵測。

**錯誤偵測碼只能偵測其設計偵測的錯誤類型：其他類型的錯誤可能仍未被偵測到。**

### H.2.2 錯誤更正
錯誤更正比錯誤偵測困難得多。在錯誤偵測中，接收者只需要知道接收到的碼字是無效的：在錯誤更正中，接收者需要找出（或猜測）發送的原始碼字。比起錯誤偵測，我們需要更多的冗餘位元來進行錯誤更正。圖 H.5 顯示了區塊編碼在錯誤更正中的作用。我們可以看到這個想法與錯誤偵測相同，但生成器和檢查器功能要複雜得多。

**範例 H.3**
讓我們在範例 H.2 中添加更多冗餘位元，看看接收者是否可以在不知道實際發送內容的情況下更正錯誤。我們在 2 位元資料字中添加三個冗餘位元，使其成為 5 位元碼字。同樣，稍後我們將展示如何選擇冗餘位元。目前讓我們專注於錯誤更正概念。表 H.2 顯示了資料字和碼字。

**表 H.2 用於錯誤更正的代碼（範例 H.3）**
| 資料字 | 碼字 | 資料字 | 碼字 |
| :--- | :--- | :--- | :--- |
| 00 | 00000 | 10 | 10101 |
| 01 | 01011 | 11 | 11110 |

假設資料字是 01。發送者查閱表格（或使用演算法）創建碼字 01011。碼字在傳輸過程中損壞，收到 01001——右邊第二個位元出錯。首先，接收者發現接收到的碼字不在表中。這意味著發生了錯誤。（偵測必須在更正之前。）接收者假設只有 1 個位元損壞，使用以下策略來猜測正確的資料字。
1.  將接收到的碼字與表中的第一個碼字進行比較（01001 *對* 00000），接收者認為第一個碼字不是發送的那個，因為有兩個不同的位元。
2.  同理，原始碼字不可能是表中的第三個或第四個。
3.  原始碼字必須是表中的第二個，因為這是唯一一個與接收到的碼字僅相差 1 個位元的碼字。接收者將 01001 替換為 01011 並查閱表格以找到資料字 01。

## H.3 線性區塊碼
今天使用的幾乎所有區塊碼都屬於稱為**線性區塊碼**的子集。用於錯誤偵測和更正的非線性區塊碼並不普遍，因為它們的結構使得理論分析和實作變得很困難。因此，我們專注於線性區塊碼。
線性區塊碼的正式定義需要抽象代數（特別是伽羅瓦域）的知識，這超出了本書的範圍。因此，我們給出一個非正式的定義。就我們的目的而言，線性區塊碼是一種代碼，其中兩個有效碼字的互斥或（模-2 加法，在附錄 G 中討論）會創建另一個有效碼字。

**在線性區塊碼中，任何兩個有效碼字的互斥或 (XOR) 都會創建另一個有效碼字。**

**範例 H.4**
讓我們看看我們在表 H.1 和表 H.2 中定義的兩個代碼是否屬於線性區塊碼類別。
1.  表 H.1 中的方案是一個線性區塊碼，因為任何碼字與任何其他碼字的 XOR 運算結果都是一個有效的碼字。例如，第二個和第三個碼字的 XOR 運算創建了第四個。
2.  表 H.2 中的方案也是一個線性區塊碼。我們可以通過對其他兩個碼字進行 XOR 運算來創建所有四個碼字。

### H.3.1 一些線性區塊碼
現在讓我們展示一些線性區塊碼。這些代碼很簡單，因為我們可以輕鬆找到編碼和解碼演算法並檢查其性能。

**簡單同位檢查碼**
也許最熟悉的錯誤偵測碼是**簡單同位檢查碼**。在這個代碼中，一個 $k$ 位元資料字被改變為一個 $n$ 位元碼字，其中 $n = k + 1$。額外的位元，稱為**同位位元**，被添加到預定義的位置。它的選擇是為了使碼字中 1 的總數為偶數。雖然有些實作指定奇數個 1，但我們討論偶數個的情況。

**簡單同位檢查碼是一種單位元錯誤偵測碼，其中 n = k + 1。**

我們的第一個代碼（表 H.3）是一個 $k = 2$ 且 $n = 3$ 的同位檢查碼。表 H.3 中的代碼也是一個 $k = 4$ 且 $n = 5$ 的同位檢查碼。

**表 H.3 簡單同位檢查碼 C(5, 4)**
| 資料字 | 碼字 | 資料字 | 碼字 |
| :--- | :--- | :--- | :--- |
| 0000 | 00000 | 1000 | 10001 |
| 0001 | 00011 | 1001 | 10010 |
| 0010 | 00101 | 1010 | 10100 |
| 0011 | 00110 | 1011 | 10111 |
| 0100 | 01001 | 1100 | 11000 |
| 0101 | 01010 | 1101 | 11011 |
| 0110 | 01100 | 1110 | 11101 |
| 0111 | 01111 | 1111 | 11110 |

圖 H.6 顯示了編碼器（在發送者處）和解碼器（在接收者處）的可能結構。
編碼器使用一個生成器，該生成器獲取 4 位元資料字（$a_0, a_1, a_2$ 和 $a_3$）的副本並生成一個同位位元 $r_0$。資料字位元和同位位元創建 5 位元碼字。添加的同位位元使碼字中 1 的數量為偶數。這通常是通過將資料字的 4 個位元相加（模-2）來完成的：結果是同位位元。換句話說：
$r_0 = a_3 + a_2 + a_1 + a_0$       (模-2)

如果 1 的數量是偶數，結果是 0：如果 1 的數量是奇數，結果是 1。在這兩種情況下，碼字中 1 的總數都是偶數。
發送者發送碼字，該碼字在傳輸過程中可能會損壞。接收者收到一個 5 位元字。接收者處的檢查器做的事情與發送者中的生成器相同，只有一個例外：加法是在所有五個位元上進行的。結果稱為**症狀 (syndrome)**，只有 1 位元。當接收到的碼字中 1 的數量為偶數時，症狀為 0；否則為 1。
$s_0 = b_3 + b_2 + b_1 + b_0 + q_0$       (模-2)

症狀是檢查過程的輸出，它被送入接收者的決策邏輯，以決定如何處理碼字的資料部分。決策可能是接受它、拒絕它，或（對於更正碼）在接受之前修改它。在這種情況下，症狀被傳遞給**決策邏輯分析器**。如果碼字中沒有錯誤，症狀為 0，決策邏輯接受碼字的資料部分作為實際資料字。如果症狀為 1，則碼字中必定有錯誤，因此決策邏輯丟棄碼字的資料部分：不創建資料字。

**範例 H.5**
讓我們看一些傳輸場景。假設發送者發送資料字 1011。同位位元是 $(1 + 0 + 1 + 1) \\text{ mod } 2 = 1$，它被附加到資料字的右側。從這個資料字創建的碼字因此是 10111，它被發送給接收者。我們檢查五種情況：
1.  沒有發生錯誤：接收到的碼字是 10111。症狀是 0。創建了資料字 1011。
2.  單一位元錯誤改變了 $a_1$。接收到的碼字是 10011。症狀是 1。未創建資料字。
3.  單一位元錯誤改變了同位位元 $r_0$。接收到的碼字是 10110。症狀是 1。未創建資料字。請注意，雖然沒有資料字位元損壞，但也未創建資料字，因為代碼不夠複雜，無法顯示損壞位元的位置。
4.  一個錯誤改變了 $r_0$，第二個錯誤改變了 $a_3$。接收到的碼字是 00110。症狀是 0。在接收者處創建了資料字 0011。請注意，這裡由於症狀值而錯誤地創建了資料字：簡單同位檢查解碼器無法偵測偶數個錯誤。錯誤相互抵消，給出的症狀值為 0。
5.  三個位元——$a_3$、$a_2$ 和 $a_1$——被錯誤改變。接收到的碼字是 01011。症狀是 1。未創建資料字。這表明保證偵測單一錯誤的簡單同位檢查也可以發現任何奇數個錯誤。

**簡單同位檢查碼可以偵測奇數個錯誤。**

**漢明碼**
漢明碼是線性區塊碼的一個子集，遵循兩個標準：
$n = k + r$ 和 $n = 2^r - 1$
其中 $k$ 是資料字中的位元數，$r$ 是冗餘位元數，$n$ 是碼字中的位元數。這些代碼可以偵測最多 $r - 1$ 位元錯誤，並可以更正最多 $(r - 1) / 2$ 位元錯誤。

**範例 H.6**
$k = 4, r = 3$, 和 $n = 7$ 的代碼滿足漢明碼的兩個條件，因為我們有 $7 = 4 + 3$ 和 $7 = 2^3 - 1$。此代碼只能偵測 $(3 - 1) = 2$ 位元錯誤，並只能更正 $(3 - 1)/2 = 1$ 位元錯誤。
一般而言，漢明碼的理論超出了本書的範圍。有關更多資訊，請參閱 Behrouz Forouzan 所著的 *Data Communication and Networking*，McGraw-Hill，New York，2006。在下一節中，我們討論稱為循環碼的漢明碼子集。

## H.4 循環碼
循環碼是具有一個額外屬性的特殊線性區塊碼。在**循環碼**中，如果一個碼字被循環移位（旋轉），結果是另一個碼字。例如，如果 1011000 是一個碼字，我們將其循環左移，那麼 0110001 也是一個碼字。

### H.4.1 循環冗餘檢查
我們可以創建循環碼來更正錯誤。然而，所需的理論背景超出了本附錄的範圍。在本節中，我們簡單討論一類稱為**循環冗餘檢查 (CRC)** 的循環碼，它們用於 LAN 和 WAN 等網路中。
表 H.4 顯示了一個 CRC 碼的例子。我們可以看到此代碼的線性與循環屬性。

**表 H.4 具有 k = 4, n = 7, 和 r = 3 的 CRC 碼**
| 資料字 | 碼字 | 資料字 | 碼字 |
| :--- | :--- | :--- | :--- |
| 0000 | 0000000 | 1000 | 1000101 |
| 0001 | 0001011 | 1001 | 1001110 |
| 0010 | 0010110 | 1010 | 1010011 |
| 0011 | 0011101 | 1011 | 1011000 |
| 0100 | 0100111 | 1100 | 1100010 |
| 0101 | 0101100 | 1101 | 1101001 |
| 0110 | 0110001 | 1110 | 1110100 |
| 0111 | 0111010 | 1111 | 1111111 |

圖 H.7 顯示了編碼器（在發送者處）和解碼器（在接收者處）的一種可能設計。
在圖 H.7 的編碼器中，資料字有 $k$ 位元（這裡是 4），碼字有 $n$ 位元（這裡是 7）。資料字的大小透過在字的右側添加 $n - k$（這裡是 3）個 0 來擴增。$n$ 位元結果被送入生成器。生成器使用大小為 $n - k + 1$（這裡是 4）的預定義除數。生成器使用模-2 除法將擴增的資料字除以除數。除法的商被丟棄：餘數（$r_2 r_1 r_0$）被附加到資料字以創建碼字。
解碼器接收碼字，它可能已損壞。所有 $n$ 位元的副本被送入檢查器，它是生成器的複製品。檢查器產生的餘數是 $n - k$（這裡是 3）位元的症狀，它被送入決策邏輯分析器。分析器有一個簡單的功能：如果症狀位元全為 0，則接受碼字最左邊的 4 個位元作為資料字（解釋為無錯誤），否則，丟棄這 4 個位元（錯誤）。

**編碼器**
讓我們仔細看看編碼器。編碼器獲取資料字並用 $n - k$ 個 0 對其進行擴增。然後它將擴增的資料字除以除數，如圖 H.8 所示。
請注意，這不是常規的二進位除法——顯然 72 除以 11 的結果不是商 10 和餘數 6。這是模 2 運算中的二進位除法，正如我們在附錄 G 中所討論的。在這個除法中，加法和減法是相同的（它是附錄 E 中討論的 XOR 運算），這意味著我們不減，而是加。這種除法更好的解釋是我們將二進位字視為具有模 2 運算係數的多項式——只有 0 或 1。有關更多資訊，我們建議感興趣的讀者參考*有限域理論 (伽羅瓦域)* 和關於錯誤偵測與更正的書籍。
在每一步中，除數的副本與被除數的 4 個位元進行 XOR 運算。XOR 運算的結果（餘數）是 3 位元（在這種情況下），在 1 個額外位元被帶下來後用於下一步——見圖 H.8——使其長度為 4 位元。在這種類型的除法中，我們需要記住一個重要點。如果被除數（或每一步使用的部分）的最左邊位元是 0，則商中的相應位元是 0。
當沒有位元可以拉下來時，我們就有了一個結果。3 位元餘數形成檢查位元（$r_2, r_1, \\text{和 } r_0$）。它們被附加到資料字以創建碼字。另請注意，我們對商不感興趣，因為在循環碼中只使用餘數。

**解碼器**
碼字在傳輸過程中可能會改變。解碼器執行與編碼器相同的除法過程。除法的餘數是症狀。如果症狀全為 0，則沒有錯誤：資料字從接收到的碼字中分離並被接受。否則，一切都被丟棄。圖 H.9 顯示了兩種情況。左圖顯示未發生錯誤時的症狀值：症狀為 000。右圖顯示發生單一錯誤的情況：症狀不全為 0（它是 011）。

**除數**
您可能想知道除數 1011 是如何選擇的。這需要抽象代數和有限域理論來解釋，我們將此留給專門研究該領域的書籍。

### H.4.2 循環碼的性能
我們已經看到循環碼在偵測單位元錯誤、雙位元錯誤、奇數個錯誤和叢發錯誤方面具有非常好的性能。它們可以很容易地在硬體和軟體中實作。當在硬體中實作時，它們特別快。這使得循環碼成為許多網路的良好候選者。

## H.5 校驗和
我們這裡討論的最後一種錯誤偵測方法稱為**校驗和**。校驗和被網際網路中的多個協定使用。像線性碼和循環碼一樣，校驗和基於**冗餘**的概念。

### H.5.1 校驗和概念
校驗和的概念並不難。讓我們用幾個例子來說明。

**範例 H.7**
假設我們的資料是一個包含五個 4 位元數字的列表，我們想要將其發送到某個目的地。除了發送這些數字外，我們還發送這些數字的總和。例如，如果這組數字是 (7, 11, 12, 0, 6)，我們發送 (7, 11, 12, 0, 6, 36)，其中 36 是原始數字的總和。接收者將五個數字相加，並將結果與總和進行比較。如果兩者相同，接收者假設沒有錯誤，接受這五個數字，並丟棄總和。否則，某處有錯誤，資料不被接受。

**範例 H.8**
如果我們發送總和的負數（補數），稱為*校驗和*，我們可以讓接收者的工作更容易。在這種情況下，我們發送 (7, 11, 12, 0, 6, -36)。接收者可以將收到的所有數字（包括校驗和）相加。如果結果為 0，則假設沒有錯誤，否則有錯誤。

### H.5.2 一的補數
前面的例子有一個主要缺點。我們的資料可以寫成 4 位元字（它們都小於 15），除了校驗和。一種解決方案是使用**一的補數**運算，如第 3 章所述。

**範例 H.9**
讓我們使用一的補數運算重做範例 H.8。圖 H.10 顯示了發送者和接收者的過程。
發送者將校驗和初始化為 0，並將所有資料項目和校驗和相加（校驗和被視為一個資料項目，以彩色顯示）。結果是 36。然而，36 不能用 4 位元表示。額外的兩個位元被環繞並加到總和中，以創建環繞總和值 6。在圖中，我們以二進位顯示了細節。然後對總和取補數，得到校驗和值 9 ($15 - 6 = 9$)。發送者現在向接收者發送六個資料項目，包括校驗和 9。接收者遵循與發送者相同的程序。它將所有資料項目（包括校驗和）相加：結果是 45。總和被環繞並變為 15。環繞總和被取補數並變為 0。由於校驗和的值為 0，這意味著資料未損壞。接收者丟棄校驗和並保留其他資料項目。如果校驗和不為零，則丟棄整個封包且必須重新傳輸。

### H.5.3 網際網路校驗和
傳統上，網際網路 (IP 協定) 使用 16 位元校驗和。發送者和接收者使用以下程序：

**發送者端**
*   16 位元校驗和設為零並添加到訊息中。
*   新訊息被分成 16 位元字。
*   所有字使用一的補數加法相加。
*   總和取補數並替換先前的校驗和。

**接收者端**
*   接收到的訊息（包括校驗和）被分成 16 位元字。
*   所有字使用一的補數加法相加。
*   總和取補數。
*   如果補數總和為 0，則接受訊息，否則拒絕。

**範例 H.10**
讓我們計算八個字元 ('Forouzan') 的文字字的校驗和，如圖 H.11 所示。
文字需要分成 2 位元組 (16 位元) 字。我們使用 ASCII 編碼（見附錄 A）將每個位元組更改為兩位十六進位數字。例如，'F' 表示為 $(46)_{16}$，'o' 表示為 $(6F)_{16}$。在圖 H.11.a 中，第一列的部分和值為 $(36)_{16}$。我們保留最右邊的數字 (6) 並將最左邊的數字 (3) 作為進位插入第二列。對每一列重複此過程。計算校驗和並將其與資料一起傳輸給接收者。接收者執行相同的操作，圖 H.11.b。如果有任何損壞，接收者重新計算的校驗和不全為 0。

**性能**
傳統校驗和使用少量位元 (16) 來偵測任何大小（有時數千位元）的訊息中的錯誤。然而，它的錯誤檢查能力不如 CRC 強。例如，如果一個字的值增加，而另一個字的值減少相同的量，則無法偵測到這兩個錯誤，因為總和和校驗和保持不變。此外，如果幾個字的值增加，但總變化是 65535 ($2^{16}-1$) 的倍數，則總和和校驗和保持不變，錯誤未被偵測到。
`},R={en:`
# Appendix I: Addition and Subtraction for Sign-and-Magnitude Integers

In Chapter 4 we showed how to operate on data. Addition and subtraction for sign-and-magnitude integers are a little more involved and are discussed in this appendix.

## I.1 OPERATIONS ON INTEGERS
Addition and subtraction for integers in sign-and-magnitude representation look very complex. We have four different combination of signs (two signs, each of two values) for addition, and four different conditions for subtraction. This means that we need to consider eight different situations. However, if we examine the signs in more detail, we can reduce the number of cases, as shown in Figure I-1.

Let us first explain the diagram:
1.  We check the operation. If the operation is subtraction, we change the sign of the second integer (B). This means we now only have to worry about the addition of two signed integers.
2.  We apply the XOR operation to the two signs. If the result (stored in temporary location S) is 0, it means that the signs are the same (either both signs are positive or both are negative).
3.  If the signs are the same, $R = \\pm (A_M + B_M)$. We need to add the magnitude and the sign of the result is the common sign. So, we have:
    $R_M = (A_M) + (B_M)$ and $R_S = A_S$
    where the subscript M means magnitude and subscript S means sign. In this case, however, we should be careful about the overflow. When we add the two magnitudes, an overflow may occur that must be reported and the process aborted.
4.  If the signs are different, $R = \\pm (A_M - B_M)$. So we need to subtract $B_M$ from $A_M$ and then make a decision about the sign. Instead of subtracting bit by bit, we take the two’s complement of the second magnitude ($B_M$) and add them. The sign of the result is the sign of the integer with larger magnitude.
    a. It can be shown that if $A_M \\ge B_M$, there is an overflow and the result is a positive number. Therefore, if there is an overflow, we discard the overflow and let the sign of the result be the sign of A.
    b. It can be shown that if $A_M < B_M$, there is no overflow, but the result is a negative number. So if there is no overflow, we make the two’s complement of the result and let the sign of the result be the sign of B.

**Example I.1**
Two integers A and B are stored in sign-and-magnitude format (we have separated the sign from the magnitude for clarity). Show how B is added to A.
A = $(0 \\ 0010001)_2$ B = $(0 \\ 0010110)_2$

**Solution**
The operation is adding: the sign of B is not changed. Since $S = A_S \\text{ XOR } B_S = 0, R_M = A_M + B_M$ and $R_S = A_S$. There is no overflow.

| | Sign | Magnitude |
|---|---|---|
| $A_S$ | 0 | 0 0 1 0 0 0 1 $A_M$ |
| $B_S$ | 0 | + 0 0 1 0 1 1 0 $B_M$ |
| $R_S$ | 0 | 0 0 1 0 0 1 1 1 $R_M$ |

Checking the result in decimal, (+17) + (+22) = (+39).

**Example I.2**
Two integers A and B are stored in sign-and-magnitude format. Show how B is added to A.
A = $(0 \\ 0010001)_2$ B = $(1 \\ 0010110)_2$

**Solution**
The operation is adding: the sign of B is not changed. Since $S = A_S \\text{ XOR } B_S = 1; R_M = A_M + (\\bar{B}_M + 1)$. Since there is no overflow, we need to take the two’s complement of $R_M$. The sign of R is the sign of B.

| | Sign | Magnitude |
|---|---|---|
| $A_S$ | 0 | 0 0 1 0 0 0 1 $A_M$ |
| $B_S$ | 1 | + 1 1 0 1 0 1 0 $(\\bar{B}_M + 1)$ |
| | | 1 1 1 1 1 0 1 1 $R_M$ |
| $R_S$ | 1 | 0 0 0 0 0 1 0 1 $R_M = (\\bar{R}_M + 1)$ |

Checking the result in decimal, (+17) + (-22) = (-5).

**Example I.3**
Two integers A and B are stored in sign-and-magnitude format. Show how B is subtracted from A.
A = $(1 \\ 1010001)_2$ B = $(1 \\ 0010110)_2$

**Solution**
The operation is subtracting: $S_B = S_B \\text{ XOR } 1$. $S = A_S \\text{ XOR } B_S = 1, R_M = A_M + (\\bar{B}_M + 1)$. Since there is an overflow, the value of $R_M$ is final. The sign of R is the sign of A.

| | Sign | Magnitude |
|---|---|---|
| $A_S$ | 1 | 1 0 1 0 0 0 1 $A_M$ |
| $B_S$ | 1 | + 1 1 0 1 0 1 0 $(\\bar{B}_M + 1)$ |
| $R_S$ | 1 | 1 0 1 1 1 0 1 1 $R_M$ |

Checking the result in decimal, (-81) - (-22) = (-59).
`,zh:`
# 附錄 I：符號與數值整數的加法和減法

在第 4 章中，我們展示了如何對資料進行運算。符號與數值整數的加法和減法稍微複雜一些，將在本附錄中進行討論。

## I.1 整數運算
符號與數值表示法中整數的加法和減法看起來非常複雜。對於加法，我們有四種不同的符號組合（兩個符號，每個符號有兩個值），對於減法，我們也有四種不同的條件。這意味著我們需要考慮八種不同的情況。然而，如果我們更詳細地檢查符號，我們可以減少情況的數量，如圖 I.1 所示。

讓我們先解釋一下圖表：
1.  我們檢查運算。如果運算是減法，我們改變第二個整數 (B) 的符號。這意味著我們現在只需要擔心兩個有符號整數的加法。
2.  我們對這兩個符號應用 XOR 運算。如果結果（儲存在臨時位置 S 中）為 0，則表示符號相同（兩個符號都是正數或都是負數）。
3.  如果符號相同，$R = \\pm (A_M + B_M)$。我們需要將數值相加，結果的符號是共同的符號。所以，我們有：
    $R_M = (A_M) + (B_M)$ 和 $R_S = A_S$
    其中下標 M 表示數值，下標 S 表示符號。但在這種情況下，我們應該小心溢位。當我們將兩個數值相加時，可能會發生溢位，必須報告並中止該過程。
4.  如果符號不同，$R = \\pm (A_M - B_M)$。所以我們需要從 $A_M$ 中減去 $B_M$，然後對符號做出決定。我們不逐位減法，而是取第二個數值 ($B_M$) 的二的補數並將它們相加。結果的符號是數值較大整數的符號。
    a. 可以證明，如果 $A_M \\ge B_M$，則存在溢位且結果為正數。因此，如果有溢位，我們丟棄溢位並讓結果的符號為 A 的符號。
    b. 可以證明，如果 $A_M < B_M$，則沒有溢位，但結果為負數。所以如果沒有溢位，我們取結果的二的補數並讓結果的符號為 B 的符號。

**範例 I.1**
兩個整數 A 和 B 以符號與數值格式儲存（為了清楚起見，我們將符號與數值分開）。顯示如何將 B 加到 A。
A = $(0 \\ 0010001)_2$ B = $(0 \\ 0010110)_2$

**解答**
運算是加法：B 的符號不改變。由於 $S = A_S \\text{ XOR } B_S = 0, R_M = A_M + B_M$ 且 $R_S = A_S$。沒有溢位。

| | 符號 | 數值 |
|---|---|---|
| $A_S$ | 0 | 0 0 1 0 0 0 1 $A_M$ |
| $B_S$ | 0 | + 0 0 1 0 1 1 0 $B_M$ |
| $R_S$ | 0 | 0 0 1 0 0 1 1 1 $R_M$ |

以十進位檢查結果，(+17) + (+22) = (+39)。

**範例 I.2**
兩個整數 A 和 B 以符號與數值格式儲存。顯示如何將 B 加到 A。
A = $(0 \\ 0010001)_2$ B = $(1 \\ 0010110)_2$

**解答**
運算是加法：B 的符號不改變。由於 $S = A_S \\text{ XOR } B_S = 1; R_M = A_M + (\\bar{B}_M + 1)$。由於沒有溢位，我們需要取 $R_M$ 的二的補數。R 的符號是 B 的符號。

| | 符號 | 數值 |
|---|---|---|
| $A_S$ | 0 | 0 0 1 0 0 0 1 $A_M$ |
| $B_S$ | 1 | + 1 1 0 1 0 1 0 $(\\bar{B}_M + 1)$ |
| | | 1 1 1 1 1 0 1 1 $R_M$ |
| $R_S$ | 1 | 0 0 0 0 0 1 0 1 $R_M = (\\bar{R}_M + 1)$ |

以十進位檢查結果，(+17) + (-22) = (-5)。

**範例 I.3**
兩個整數 A 和 B 以符號與數值格式儲存。顯示如何從 A 中減去 B。
A = $(1 \\ 1010001)_2$ B = $(1 \\ 0010110)_2$

**解答**
運算是減法：$S_B = S_B \\text{ XOR } 1$。$S = A_S \\text{ XOR } B_S = 1, R_M = A_M + (\\bar{B}_M + 1)$。由於存在溢位，$R_M$ 的值是最終的。R 的符號是 A 的符號。

| | 符號 | 數值 |
|---|---|---|
| $A_S$ | 1 | 1 0 1 0 0 0 1 $A_M$ |
| $B_S$ | 1 | + 1 1 0 1 0 1 0 $(\\bar{B}_M + 1)$ |
| $R_S$ | 1 | 1 0 1 1 1 0 1 1 $R_M$ |

以十進位檢查結果，(-81) - (-22) = (-59)。
`},M={en:`
# Appendix J: Addition and Subtraction for Reals

In Chapter 4 we showed how to operate on data. Addition and subtraction for reals are a little more involved and are discussed in this appendix.

## J.1 OPERATIONS ON REALS
All arithmetic operations such as addition, subtraction, multiplication, and division can be applied to reals stored in floating-point format. Multiplication of two reals involves multiplication of two integers in sign-and-magnitude representation. Division of two reals involves division of two integers in sign-and-magnitude representations. Since we did not discuss the multiplication or division of integers in sign-and-magnitude representation, we will not discuss the multiplication and division of reals, and only show addition and subtraction for reals.

Addition and subtraction of real numbers stored in floating-point numbers is reduced to addition and subtraction of two integers stored in sign-and-magnitude (combination of sign and mantissa) after the alignment of decimal points. Figure J.1 shows a simplified version of the procedure (there are some special cases that we have ignored).

The simplified procedure works as follows:
1.  If any of the two numbers (A or B) is zero, we let the result be 0 and stop.
2.  If the operation is subtraction, we change the sign of the second number (B) to simulate addition.
3.  We denormalize both numbers by including the hidden 1 in the mantissa and incrementing the exponents. The mantissa is now is treated as an integer.
4.  We then align the exponents, which means that we increment the lower exponent and shift the corresponding mantissa until both have the same exponent. For example, if we have:
    $1.11101 \\times 2^4 + 1.01 \\times 2^2$
    we need to make both exponents 4:
    $1.11101 \\times 2^4 + 0.00101 \\times 2^4$
5.  Now, we treat the combination of the sign and mantissa of each number as an integer in sign-and-magnitude format. We add these two integers, as explained earlier in Appendix I.
6.  Finally, we normalized the number again to $1.000010 \\times 2^5$.

**Example J.1**
Show how the computer finds the result of (+5.75) + (+161.875) = (+167.625).

**Solution**
As we saw in Chapter 3, these two numbers are stored in floating-point format, as shown below, but we need to remember that each number has a hidden 1 (which is not stored, but assumed):

| | S | E | M |
|---|---|---|---|
| A | 0 | 10000001 | 01110000000000000000000 |
| B | 0 | 10000110 | 01000011110000000000000 |

The first few steps in the UML diagram (Figure J.1) are not needed. We move to denormalization and denormalize the numbers by adding the hidden 1s to the mantissa and incrementing the exponent. Now both denormalized mantissas are 24 bits and include the hidden 1s. They should be stored in a location that can hold all 24 bits. Each exponent is incremented:

| | S | E | Denormalized M |
|---|---|---|---|
| A | 0 | 10000010 | 101110000000000000000000 |
| B | 0 | 10000111 | 101000011110000000000000 |

Now we need to align the mantissas. We need to increment the first exponent and shift its mantissa to the right. We change the first exponent to $(10000111)_2$, so we need to shift the first mantissa right by five positions:

| | S | E | Denormalized M |
|---|---|---|---|
| A | 0 | 10000111 | 000001011100000000000000 |
| B | 0 | 10000111 | 101000011110000000000000 |

Now we do sign-and-magnitude addition, treating the sign and the mantissa of each number as one integer stored in sign-and-magnitude representation:

| | S | E | Denormalized M |
|---|---|---|---|
| R | 0 | 10000111 | 101001111010000000000000 |

There is no overflow in the mantissa, so we normalize:

| | S | E | M |
|---|---|---|---|
| R | 0 | 10000110 | 01001111010000000000000 |

The mantissa is only 23 bits, no rounding is needed. $E = (10000110)_2 = 134$, $M=0100111101$. In other words, the result is $(1.0100111101)_2 \\times 2^{134-127} = (10100111.101)_2 = 167.625$.

**Example J.2**
Show how the computer finds the result of (+5.75) + (-7.0234375) = -1.2734375.

**Solution**
These two numbers can be stored in floating-point format, as shown below:

| | S | E | M |
|---|---|---|---|
| A | 0 | 10000001 | 01110000000000000000000 |
| B | 1 | 10000001 | 11000001100000000000000 |

Denormalization results in:

| | S | E | Denormalized M |
|---|---|---|---|
| A | 0 | 10000010 | 101110000000000000000000 |
| B | 1 | 10000010 | 111000001100000000000000 |

Alignment is not needed (both exponents are the same), so we apply addition operation on the combinations of sign and mantissa. The result is shown below, in which the sign of the result is negative:

| | S | E | Denormalized M |
|---|---|---|---|
| R | 1 | 10000010 | 001010001100000000000000 |

Now we need to normalize. We decrement the exponent three times and shift the denormalized mantissa to the left three positions:

| | S | E | M |
|---|---|---|---|
| R | 1 | 01111111 | 010001100000000000000000 |

The mantissa is now 24 bits, so we round it to 23 bits:

| | S | E | M |
|---|---|---|---|
| R | 1 | 01111111 | 01000110000000000000000 |

The result is $R = - 2^{127-127} \\times 1.0100011 = - 1.2734375$, as expected.
`,zh:`
# 附錄 J：實數的加法和減法

在第 4 章中，我們展示了如何對資料進行運算。實數的加法和減法稍微複雜一些，將在本附錄中進行討論。

## J.1 實數運算
所有算術運算，如加法、減法、乘法和除法，都可以應用於以浮點格式儲存的實數。兩個實數的乘法涉及符號與數值表示法中兩個整數的乘法。兩個實數的除法涉及符號與數值表示法中兩個整數的除法。由於我們沒有討論符號與數值表示法中整數的乘法或除法，我們將不討論實數的乘法和除法，而只展示實數的加法和減法。

以浮點數儲存的實數的加法和減法在對齊小數點後簡化為對兩個以符號與數值（符號和尾數的組合）儲存的整數進行加法和減法。圖 J.1 顯示了該程序的簡化版本（我們忽略了一些特殊情況）。

簡化的程序如下：
1.  如果兩個數字（A 或 B）中有任何一個為零，我們讓結果為 0 並停止。
2.  如果運算是減法，我們改變第二個數字 (B) 的符號以模擬加法。
3.  我們**非正規化**兩個數字：在尾數中包含隱藏的 1，並遞增指數。現在尾數被視為整數。
4.  然後我們對齊指數，這意味著我們遞增較小的指數並移位對應的尾數，直到兩者具有相同的指數。例如，如果我們有：
    $1.11101 \\times 2^4 + 1.01 \\times 2^2$
    我們需要使兩個指數都為 4：
    $1.11101 \\times 2^4 + 0.00101 \\times 2^4$
5.  現在，我們將每個數字的符號和尾數的組合視為符號與數值格式的整數。我們將這兩個整數相加，如前文附錄 I 所釋。
6.  最後，我們將數字再次正規化為 $1.000010 \\times 2^5$。

**範例 J.1**
顯示電腦如何找出 (+5.75) + (+161.875) = (+167.625) 的結果。

**解答**
正如我們在第 3 章中看到的，這兩個數字以浮點格式儲存，如下所示，但我們需要記住每個數字都有一個隱藏的 1（未儲存，但假定存在）：

| | S | E | M |
|---|---|---|---|
| A | 0 | 10000001 | 01110000000000000000000 |
| B | 0 | 10000110 | 01000011110000000000000 |

UML 圖（圖 J.1）中的前幾個步驟是不需要的。我們進行非正規化，通過將隱藏的 1 添加到尾數並遞增指數來非正規化數字。現在兩個非正規化的尾數都是 24 位元，包括隱藏的 1。它們應該儲存在可以容納所有 24 位元的位置。每個指數都遞增：

| | S | E | 非正規化 M |
|---|---|---|---|
| A | 0 | 10000010 | 101110000000000000000000 |
| B | 0 | 10000111 | 101000011110000000000000 |

現在我們需要對齊尾數。我們需要遞增第一個指數並將其尾數向右移位。我們將第一個指數更改為 $(10000111)_2$，因此我們需要將第一個尾數向右移位五個位置：

| | S | E | 非正規化 M |
|---|---|---|---|
| A | 0 | 10000111 | 000001011100000000000000 |
| B | 0 | 10000111 | 101000011110000000000000 |

現在我們進行符號與數值加法，將每個數字的符號和尾數視為一個以符號與數值表示法儲存的整數：

| | S | E | 非正規化 M |
|---|---|---|---|
| R | 0 | 10000111 | 101001111010000000000000 |

尾數沒有溢位，所以我們正規化：

| | S | E | M |
|---|---|---|---|
| R | 0 | 10000110 | 01001111010000000000000 |

尾數只有 23 位元，不需要四捨五入。$E = (10000110)_2 = 134$，$M=0100111101$。換句話說，結果是 $(1.0100111101)_2 \\times 2^{134-127} = (10100111.101)_2 = 167.625$。

**範例 J.2**
顯示電腦如何找出 (+5.75) + (+27.0234375) = 21.2734375 的結果。
*(註：原文此處範例標題數字有誤，根據上下文和計算，應為 (+5.75) + (-7.0234375)，但解答過程顯示第二個數為負。此外，範例 J.2 標題中的第二個數值與解答中的數值 B 符號不符，且解答最終結果為 -1.2734375。基於 PDF 內容，B 的符號位元是 1，表示負數。讓我們依據 PDF 圖片中的運算邏輯修正描述。)*
顯示電腦如何找出 (+5.75) + (-7.0234375) = -1.2734375 的結果。

**解答**
這兩個數字可以以浮點格式儲存，如下所示：

| | S | E | M |
|---|---|---|---|
| A | 0 | 10000001 | 01110000000000000000000 |
| B | 1 | 10000001 | 11000001100000000000000 |

非正規化結果為：

| | S | E | 非正規化 M |
|---|---|---|---|
| A | 0 | 10000010 | 101110000000000000000000 |
| B | 1 | 10000010 | 111000001100000000000000 |

不需要對齊（兩個指數相同），因此我們對符號和尾數的組合應用加法運算。結果如下所示，其中結果的符號為負：

| | S | E | 非正規化 M |
|---|---|---|---|
| R | 1 | 10000010 | 001010001100000000000000 |

現在我們需要正規化。我們將指數遞減三次，並將非正規化的尾數向左移位三個位置：

| | S | E | M |
|---|---|---|---|
| R | 1 | 01111111 | 010001100000000000000000 |

尾數現在是 24 位元，所以我們將其四捨五入為 23 位元：

| | S | E | M |
|---|---|---|---|
| R | 1 | 01111111 | 01000110000000000000000 |

結果是 $R = - 2^{127-127} \\times 1.0100011 = - 1.2734375$，如預期。
`},D={en:`
# Acronyms

| Acronym | Description |
| :--- | :--- |
| ADT | Abstract data type |
| AES | Advanced Encryption Standard |
| ALU | Arithmetic logic unit |
| ANSI | American National Standards Institute |
| ASCII | American Standard Code for Information Interchange |
| B-frame | Bidirectional frame |
| bit | Binary digit |
| BST | Binary search tree |
| CA | Certification authority |
| CD-R | Compact disc recordable |
| CD-ROM | Compact disc read-only memory |
| CD-RW | Compact disc rewritable |
| CGI | Common Gateway Interface |
| CISC | Complex instruction set computer |
| COBOL | Common Business-Oriented Language |
| CPU | Central processing unit |
| DBMS | Database management system |
| DCT | Discrete cosine transform |
| DES | Data Encryption Standard |
| digraph | Directed graph |
| DMA | Direct memory access |
| DRAM | Dynamic RAM |
| DVD | Digital versatile disk |
| EBCDIC | Extended Binary Coded Decimal Interchange Code |
| EEPROM | Electronically erasable programmable read-only memory |
| EPROM | Erasable programmable read-only memory |
| E-R | Entity–relation |
| FIFO | First in, first out |
| FORTRAN | FORmula TRANslation |
| FTP | File Transfer Protocol |
| GIF | Graphic Interchange Format |
| GUI | Graphical user interface |
| HTML | Hypertext Markup Language |
| HTTP | Hypertext Transfer Protocol |
| I-frame | Intracoded frame |
| IMAP | Internet Mail Access Protocol |
| IP | Internet Protocol |
| ISO | International Organization for Standardization |
| ISP | Internet service provider |
| JPEG | Joint Photographic Experts Group |
| KDC | Key distribution center |
| LAN | Local area network |
| LIFO | Last in, first out |
| LZ | Lempel Ziv |
| LZW | Lempel Ziv Welch |
| MAC | Media access control |
| MAC | Message authentication code |
| MAN | Metropolitan area network |
| MIME | Multipurpose Internet Mail Extension |
| MP3 | MPEG audio layer 3 |
| MPEG | Motion Pictures Experts Group |
| MS-DOS | Microsoft Disk Operating System |
| MTA | Message transfer agent |
| NF | Normal Form |
| NTFS | NT file system |
| P-frame | Predicted frame |
| POP | Post Office Protocol |
| PROM | Programmable read-only memory |
| RAM | Random access memory |
| RDBMS | Relational database management system |
| RGB | Red, green, blue |
| RISC | Reduced instruction set computer |
| ROM | Read-only memory |
| RSA | Rivest–Shamir–Adleman |
| SCSI | Small computer system interface |
| SCTP | Stream Control Transmission Protocol |
| SMTP | Simple Mail Transfer Protocol |
| SQL | Structured Query Language |
| SRAM | Static RAM |
| TCP | Transmission Control Protocol |
| TCP/IP | Transmission Control Protocol/Internet Protocol |
| TELNET | Terminal Network |
| UDP | User Datagram Protocol |
| UML | Unified Modeling Language |
| URL | Uniform Resource Locator |
| USB | Universal serial bus |
| WAN | Wide area network |
| WORM | Write once, read many |
| WWW | World Wide Web |
| XML | Extensible Markup Language |
| XOR | Exclusive OR |
`,zh:`
# 縮寫詞 (Acronyms)

| 縮寫 | 描述 |
| :--- | :--- |
| ADT | 抽象資料型別 (Abstract data type) |
| AES | 進階加密標準 (Advanced Encryption Standard) |
| ALU | 算術邏輯單元 (Arithmetic logic unit) |
| ANSI | 美國國家標準協會 (American National Standards Institute) |
| ASCII | 美國資訊交換標準碼 (American Standard Code for Information Interchange) |
| B-frame | 雙向影格 (Bidirectional frame) |
| bit | 二進位數字 (Binary digit) |
| BST | 二元搜尋樹 (Binary search tree) |
| CA | 憑證頒發機構 (Certification authority) |
| CD-R | 可錄式光碟 (Compact disc recordable) |
| CD-ROM | 唯讀光碟 (Compact disc read-only memory) |
| CD-RW | 可重寫光碟 (Compact disc rewritable) |
| CGI | 通用閘道介面 (Common Gateway Interface) |
| CISC | 複雜指令集電腦 (Complex instruction set computer) |
| COBOL | 通用商業導向語言 (COmmon Business-Oriented Language) |
| CPU | 中央處理單元 (Central processing unit) |
| DBMS | 資料庫管理系統 (Database management system) |
| DCT | 離散餘弦轉換 (Discrete cosine transform) |
| DES | 資料加密標準 (Data Encryption Standard) |
| digraph | 有向圖 (Directed graph) |
| DMA | 直接記憶體存取 (Direct memory access) |
| DRAM | 動態 RAM (Dynamic RAM) |
| DVD | 數位多功能光碟 (Digital versatile disk) |
| EBCDIC | 擴展二進位編碼十進位交換碼 (Extended Binary Coded Decimal Interchange Code) |
| EEPROM | 電子可抹除可程式化唯讀記憶體 (Electronically erasable programmable read-only memory) |
| EPROM | 可抹除可程式化唯讀記憶體 (Erasable programmable read-only memory) |
| E-R | 實體-關係 (Entity–relation) |
| FIFO | 先進先出 (First in, first out) |
| FORTRAN | 公式翻譯 (FORmula TRANslation) |
| FTP | 檔案傳輸協定 (File Transfer Protocol) |
| GIF | 圖形交換格式 (Graphic Interchange Format) |
| GUI | 圖形使用者介面 (Graphical user interface) |
| HTML | 超文本標記語言 (Hypertext Markup Language) |
| HTTP | 超文本傳輸協定 (Hypertext Transfer Protocol) |
| I-frame | 幀內編碼影格 (Intracoded frame) |
| IMAP | 網際網路郵件存取協定 (Internet Mail Access Protocol) |
| IP | 網際網路協定 (Internet Protocol) |
| ISO | 國際標準化組織 (International Organization for Standardization) |
| ISP | 網際網路服務提供者 (Internet service provider) |
| JPEG | 聯合圖像專家小組 (Joint Photographic Experts Group) |
| KDC | 金鑰分發中心 (Key distribution center) |
| LAN | 區域網路 (Local area network) |
| LIFO | 後進先出 (Last in, first out) |
| LZ | Lempel Ziv |
| LZW | Lempel Ziv Welch |
| MAC | 媒體存取控制 (Media access control) |
| MAC | 訊息驗證碼 (Message authentication code) |
| MAN | 都會區域網路 (Metropolitan area network) |
| MIME | 多用途網際網路郵件擴展 (Multipurpose Internet Mail Extension) |
| MP3 | MPEG 音訊層 3 (MPEG audio layer 3) |
| MPEG | 動態影像專家小組 (Motion Pictures Experts Group) |
| MS-DOS | 微軟磁碟作業系統 (Microsoft Disk Operating System) |
| MTA | 訊息傳輸代理 (Message transfer agent) |
| NF | 正規形式 (Normal Form) |
| NTFS | NT 檔案系統 (NT file system) |
| P-frame | 預測影格 (Predicted frame) |
| POP | 郵局協定 (Post Office Protocol) |
| PROM | 可程式化唯讀記憶體 (Programmable read-only memory) |
| RAM | 隨機存取記憶體 (Random access memory) |
| RDBMS | 關聯式資料庫管理系統 (Relational database management system) |
| RGB | 紅、綠、藍 (Red, green, blue) |
| RISC | 精簡指令集電腦 (Reduced instruction set computer) |
| ROM | 唯讀記憶體 (Read-only memory) |
| RSA | Rivest–Shamir–Adleman |
| SCSI | 小型電腦系統介面 (Small computer system interface) |
| SCTP | 串流控制傳輸協定 (Stream Control Transmission Protocol) |
| SMTP | 簡單郵件傳輸協定 (Simple Mail Transfer Protocol) |
| SQL | 結構化查詢語言 (Structured Query Language) |
| SRAM | 靜態 RAM (Static RAM) |
| TCP | 傳輸控制協定 (Transmission Control Protocol) |
| TCP/IP | 傳輸控制協定/網際網路協定 (Transmission Control Protocol/Internet Protocol) |
| TELNET | 終端網路 (Terminal Network) |
| UDP | 使用者資料包協定 (User Datagram Protocol) |
| UML | 統一建模語言 (Unified Modeling Language) |
| URL | 統一資源定位器 (Uniform Resource Locator) |
| USB | 通用序列匯流排 (Universal serial bus) |
| WAN | 廣域網路 (Wide area network) |
| WORM | 一次寫入，多次讀取 (Write once, read many) |
| WWW | 全球資訊網 (World Wide Web) |
| XML | 可擴展標記語言 (Extensible Markup Language) |
| XOR | 互斥或 (Exclusive OR) |
`},E={en:`
# Glossary

**10-Gigabit Ethernet**
An implementation of Ethernet operating at 10 Gigabits per second.

**absolute pathname**
In UNIX or Linux, a path name that starts from the root.

**abstract data type (ADT)**
A data declaration packaged together with operations that are meaningful on the data type.

**AC value**
A value that changes with time.

**access method**
A technique for reading data from a secondary (auxiliary) storage device.

**actual parameters**
The parameters in the function calling statement that contain the values to be passed to the function. Contrast with *formal parameters*.

**Ada**
A high-level concurrent programming language developed by the US Department of Defense.

**additive cipher**
A type of cipher that key defines shifting of a character toward the end of the alphabet (shift cipher). Simplest monoalphabetic cipher in which each ciphertext character is plaintext character plus the key value.

**address bus**
The part of the system bus used for address transfer.

**address space**
A range of addresses.

**algorithm**
The logical steps necessary to solve a problem with a computer.

**American National Standards Institute (ANSI)**
An organization that creates standards in programming languages, electrical specifications, communication protocols, and so on.

**American Standard Code for Information Interchange (ASCII)**
An encoding scheme that defines control and printable characters for 128 values.

**ampersand**
The at-sign (@) used in email addressing.

**analog**
A continuously varying entity.

**analog data**
Data that are continuous and smooth and not limited to specific value.

**analog signal**
A type of waveform that changes smoothly over time.

**analog-to-analog conversion**
Representation of analog data by analog signal.

**analog-to-digital conversion**
Representation of analog data by digital signal.

**analog-to-digital**
Representation of analog data by digital signal.

**analysis phase**
A phase in the software system lifecycle that defines requirements that specify what the proposed system is to accomplish.

**ancestor**
Any node in the path from the current node to the root of a tree.

**AND**
One of the bit-level operations: the result of the operation is 1 only if both bits are 1s, otherwise it is 0.

**applet**
A computer program written in Java that creates an active Web document.

**application gateway**
A computer that stands between the firewall and the organization computer to filter unwanted messages.

**application layer**
The seventh layer in the TCP/IP model: provides access to network services.

**application programs**
In DBMS terminology, the programs that access and process data.

**arc**
A directed line in a graph. Contrast with *edge*.

**arithmetic logic unit (ALU)**
The part of a computer system that performs arithmetic and logic operations on data.

**arithmetic operation**
An operation that takes two numbers and creates another number.

**arithmetic operator**
The operator used in an arithmetic operation.

**arithmetic shift operation**
A shift operation in which the sign of the number is preserved.

**array**
A fixed-sized, sequenced collection of elements of the same data type.

**artificial intelligence**
The study of computer systems that simulate the intelligence of the human mind.

**assembler**
System software that converts a source program into executable object code. Traditionally associated with an assembly language program. See also *compiler*.

**assembly language**
A programming language in which there is a one-to-one correspondence between the computer’s machine language and the symbolic instruction set of the language.

**assignment statement**
The statement that assigns a value to a variable.

**asymmetric-key cipher**
A type of cryptography that uses two different keys: a public key for encryption and a private key for decryption.

**asymmetric-key encryption**
Encryption using a public key.

**attribute**
In a relational database, each column in a relation. In relational database terminology the name of the column heading.

**audio**
Recording or transmission of sound or music.

**authentication**
Verification of the sender of a message.

**autokey cipher**
A cipher that key is automatically created from the plaintext cipher during encryption.

**auxiliary storage**
Any storage device outside main memory: permanent data storage; external storage; secondary storage.

**availability**
The component of information security that requires that information created and stored by an organization be available to authorized entities.

**axon**
The part of a neuron in the human body that provides output to other neurons via a synapse.

**base**
The number of digits used in a numbering system. Base of binary is 2, of octal is 8, of decimal is 10, and of hexadecimal is 16.

**basis path testing**
A white-box test method that creates a set of test cases that executes every statement in the software at least once.

**batch operating system**
The operating system used in early computers, in which jobs were grouped before being served.

**bidirectional frame (B-frame)**
In MPEG, a frame that is related to both the preceding and following frames.

**big-O notation**
A measure of the efficiency of an algorithm with only the dominant factor considered.

**binary digit (bit)**
The smallest unit of information (0 or 1).

**binary file**
A collection of data stored in the internal format of the computer. Contrast with *text file*.

**binary operation**
An operation that needs two input operands.

**binary search**
A search algorithm in which the search value is located by repeatedly dividing the list in half.

**binary search tree (BST)**
A binary tree in which the keys of the left subtrees are all less than the root key, the keys of all right subtrees are greater than or equal to the root key, and each subtree is itself a binary search tree.

**binary system**
A numbering system that uses two symbols (0 and 1).

**binary tree**
A tree in which each node has zero, one, or two subtrees.

**bit**
Acronym for binary digit. In a computer, the basic storage unit with a value of either 0 or 1.

**bit depth**
The number of bits representing a sample in a sampling process.

**bit pattern**
A sequence of bits (0s and 1s).

**bit rate**
The number of bits transmitted per second.

**bitmap graphic**
A graphic representation in which a combination of pixels defines the image.

**black-box testing**
Testing based on the system requirements rather than a knowledge of the program.

**block cipher**
A cipher in which a group of characters are encrypted or decrypted at a time.

**Bluetooth**
A wireless technology designed to connect devices in a small area.

**Boolean algebra**
An algebra for manipulation of objects that can take one of only two values: true or false.

**bootstrap**
The process in which the operating system is loaded into main memory when the computer is turned on.

**breadth-first traversal**
A graph traversal method in which nodes adjacent to the current node are processed before their descendants.

**browser**
An application program that displays a WWW document.

**brute-force search**
A search method that examines every path in a search tree until it finds the goal.

**bubble sort**
A sort algorithm in which each pass through the data moves (bubbles) the lowest element to the beginning of the unsorted portion of the list.

**bucket**
In a hashing algorithm, a location that can accommodate multiple data units.

**bucket hashing**
A hashing method that uses buckets to reduce collision.

**bus**
The physical channel that links hardware components in a computer: the shared physical medium used in a bus-topology network.

**byte**
A unit of storage, usually 8 bits.

**bytecode**
A machine language into which a Java source program is compiled.

**C language**
A procedural language developed by Dennis Ritchie.

**C++ language**
An object-oriented language developed by Bjarne Stroustrup.

**cache memory**
A small, fast memory used to hold data items that are being processed.

**Caesar cipher**
A shift cipher used by Julius Caesar.

**cardinality**
In relational database, the total number of rows in each relation.

**cellular telephony**
A wireless communication technique in which one area is divided into cells. Each cell is served by a transmitter.

**central processing unit (CPU)**
The part of a computer that contains the control components to interpret instructions. In a personal computer, a microchip containing a control unit and an arithmetic logic unit.

**certification authority (CA)**
An organization that binds a public key to an entity and issues a certificate.

**challenge–response authentication**
A process in which the claimant proves that she knows a secret without sending it.

**child**
A node in a tree or graph that has a predecessor.

**Church–Turing thesis**
In computability theory, a combined hypothesis about the nature of computable functions by recursion (Church’s Thesis) and by mechanical devices equivalent to a Turing machine.

**cipher**
An encryption decryption algorithm.

**ciphertext**
Encrypted data.

**circular shift operation**
A shift operation in which dropped bits from one end of a binary word are inserted at the other end.

**circular waiting**
A condition in an operating system in which all processes and resources involved form a loop.

**class**
The combination of data and functions joined to form a type.

**class diagram**
A diagram that manifests the relationship between classes in a system.

**client–server paradigm**
A paradigm in which two computers connected by an internet run a program: one to provide a service and one to request a service.

**coaxial cable**
A cable made of one conductor media and a sheath that serves as the second conductor.

**code**
A set of bit patterns designed to represent text symbols.

**code generator**
A process in a compiler or interpreter that creates the machine language code.

**cohesion**
The attribute of a module that describes how closely the processes in a module are related to one another.

**collision**
In hashing, an event that occurs when a hashing algorithm produces an address for an insertion, and that address is already occupied.

**collision resolution**
An algorithmic process that determines an alternative address after a collision.

**color depth**
The number of bits used to represent the color of a pixel.

**column-major storage**
A method of storing two-dimensional arrays in which the elements are stored column by column.

**COmmon Business-Oriented Language (COBOL)**
A business programming language developed by Grace Hopper.

**compact disk (CD)**
A direct access optical storage medium.

**compact disk read-only memory (CD-ROM)**
A compact disc in which data is written to the disc by the manufacturer and can only be read by the user.

**compact disk recordable (CD-R)**
A compact disc that a user can write to only once, but read from many times.

**compact disk rewritable (CD-RW)**
A compact disc that can be written to many times and read from many times.

**compilation**
The process of translating the whole source program written in a high-level language into machine language before executing the program.

**compiler**
System software that converts a source program into executable object code: traditionally associated with high-level languages. See also *assembler*.

**complex instruction set computer (CISC)**
A computer that defines an extensive set of instructions, even those that are used less frequently.

**composite type**
A data type that is composed of two or more simple types.

**compound statement**
In some programming languages, a collection of statements (instructions) treated as one by the language.

**computer language**
Any of the syntactical languages used to write programs for computers, such as machine language, assembly language, C, COBOL, and FORTRAN.

**conceptual level**
Relating to the logical structure of a database. It deals with the meaning of the database, not its physical implementation.

**confidentiality**
A security goal that defines procedures to hide information from an unauthorized entity.

**connecting device**
A device that connect computers or networks.

**connectionless protocol**
A protocol for data transfer without connection establishment or termination.

**constant**
A data value that cannot change during the execution of the program. Contrast with *variable*.

**control bus**
The bus that carries information between computer components.

**control statement**
A statement that alters the sequential flow of control in a source program.

**control structure testing**
A white-box test method that uses different categories of tests: conditional testing, dataflow testing, and loop testing.

**control unit**
The component of a CPU that interprets the instructions and controls the flow of data.

**controller**
A component of a Turing machine that is equivalent to a computer’s CPU.

**copyright**
A copyright is a right to a written or created work. It gives the author the exclusive rights to copy, distribute, and display the work.

**country domain**
A subdomain in the Domain Name System that uses two characters (representing a country) as the last suffix.

**coupling**
A measure of the interdependence between two separate functions.

**cryptographic hash function**
A function that creates a message digest from a message.

**cryptography**
The science and art of transforming messages to make them secure and immune to attack.

**current directory**
In UNIX and Linux, the directory that a user is in at the present time.

**cycle**
A graph path with a length greater than 1 that starts and ends at the same vertex.

**data bus**
The bus inside a computer used to carry data between components.

**data compression**
Reduction of the volume of data without significant loss.

**data confidentiality**
A security service designed to protect data from disclosure attacks, snooping, and traffic analysis.

**data file**
A file that contains only data, not programs.

**data flow diagram**
A diagram that shows the movement of data in the system.

**data integrity**
A security service designed to protect data from modification, insertion, deletion, and replaying.

**data link layer address**
The address used in the data link layer, sometimes called the MAC address, sometimes the physical address.

**data processor**
An entity that inputs data, processes it, and outputs the result.

**data structure**
The syntactical representation of data organized to show the relationship among the individual elements.

**data type**
A named set of values and operations defined to manipulate them, such as character and integer.

**data-link layer**
The second layer of the TCP/IP protocol.

**database**
A collection of organized information.

**database management system (DBMS)**
A program or a set of programs that manipulates a database.

**database model**
A model that defines the logical design of data.

**datagram**
An independent data unit.

**DC value**
A value that does not change with time.

**deadlock**
A situation in which the resources needed by one job to finish its task are held by other jobs.

**decimal digit**
A symbol in the decimal system.

**decimal system**
A method of representing numbers using ten symbols (0 to 9).

**decision**
In programing a two-way path that one of them should be chosen by the program.

**declarative language**
A computer language that uses the principle of logical reasoning to answer queries.

**declarative paradigm**
A paradigm that uses the principle of logical reasoning to answer queries.

**decode**
Interpretation of an instruction by the control unit.

**decrement statement**
A statement that subtracts 1 from the value of a variable.

**decryption**
Recovery of the original message from encrypted data. See *encryption*.

**decryption algorithm**
An algorithm that decrypts an encrypted message to create the plain text.

**default logic**
A logic in which the default conclusion of an argument is acceptable if it is consistent with the contents of knowledge base.

**delete operation**
Operation that deletes a tuple based on the criterion given in the call. In a relational database, the operation that deletes a tuple from the relation.

**demand paging**
A memory allocation method in which a page of a program is loaded into memory only when it is needed.

**demand paging and segmentation**
A memory allocation method in which a page or a segment of a program is loaded into memory only when it is needed.

**demand segmentation**
A memory allocation method in which a segment of a program is loaded into memory only when it is needed.

**demodulator**
A device that converts a signal to data.

**dendrite**
In a neuron, the section that acts as the input device.

**denial of service**
The only attack on the availability goal of security that may slow down or interrupt the system.

**depth-first traversal**
A traversal method in which all of a node’s descendants are processed before any adjacent nodes (siblings).

**dequeue**
Deleting an element from a queue.

**descendant**
Any node in the path from the current node to a leaf.

**design phase**
A phase in the software system lifecycle that defines how the system will accomplish what was defined in the analysis phase.

**development process**
The process of creating software that is outside the system lifecycle.

**device manager**
A component of an operating system that controls access to the input/output devices.

**dictionary-based encoding**
A compression method in which a dictionary is created during the session.

**difference operation**
An operation on two sets, the result of which is the first set minus the common elements in the two sets, or an operator in a relational database that is applied to two relations with the same attributes. The tuples in the resulting relation are those that are in the first relation but not the second.

**digest**
A compressed image of a message.

**digit extraction hashing**
The process of extracting selected digits from a key and use them as an address.

**digit extraction method**
A hashing method that uses digit extraction.

**digital**
A discrete (noncontinuous) entity.

**Digital data**
Data represented by discrete values.

**digital signal**
A signal with a number of distinct values.

**digital signature**
A method used to authenticate the sender of a message and to preserve the integrity of its data.

**digital subscriber line (DSL)**
A technology that supports high-speed communication over existing telephone line.

**digital versatile disk (DVD)**
A direct access optical storage medium.

**digital-to-analog conversion**
Representation of digital data by an analog signal.

**digital-to-digital conversion**
Representation of digital data by digital signal.

**digraph**
A directed graph.

**direct hashing**
A hashing method in which the key is obtained without algorithmic modification.

**direct memory access (DMA)**
A form of I/O in which a special device controls the exchange of data between memory and I/O devices.

**directed graph**
A graph in which the direction is indicated on the lines (arcs).

**directory**
A file that contains the names and addresses of other files.

**discrete cosine transform (DCT)**
A mathematical transformation used in JPEG encoding.

**distributed database**
A database in which data is stored on several computers.

**distributed system**
An operating system that controls resources located in computers at different sites.

**division remainder method**
A type of hashing in which the key is divided by a number and the remainder is used as the address.

**domain name**
In DNS, a sequence of labels separated by dots.

**Domain Name Server (DNS)**
A computer that holds information about Internet domain names.

**doman name space**
A method for organizing the name space in which the names are defined in an inverted-tree structure with the root at the top.

**dotted-decimal notation**
The notation devised to make IP addresses easier to read: each byte is converted to a decimal number; numbers are separated by a dot.

**DSL**
Digital subscriber line.

**dynamic RAM (DRAM)**
RAM in which the cells use capacitors. DRAM must be refreshed periodically to retain its data.

**edge**
A graph line that has no direction.

**edge detection**
A method of image processing that finds the edges in an image by looking at areas with changes in color or texture.

**electrically erasable programmable read-only memory (EEPROM)**
Programmable read-only memory that can be programmed and erased using electronic impulses without being removed from the computer.

**electronic mail (email)**
A method of sending messages electronically based on a mailbox address rather than host-to-host exchange.

**emacs**
A text editor in Unix.

**encryption**
Converting a message into a form that is unreadable unless decrypted.

**encryption algorithm**
An algorithm that encrypts a plain text message.

**end system**
A sender or receiver of data.

**end users**
In DBMS terminology, users that access the database directly.

**enqueue**
Inserting an element into a queue.

**entity authentication**
A technique designed to let one party prove the identity of another party.

**entity–relation (E-R) model**
A model that defines the entities and their relationship in a relational database.

**entity–relationship (E-R) diagram**
A diagram used in Entity–Relation model.

**ephemeral port number**
A port number used by the client.

**erasable programmable read-only memory (EPROM)**
Programmable read-only memory that can be programmed. Erasing EPROM requires removing it from the computer.

**error report file**
In a file update process, a report of errors detected during the update.

**ethical principle**
One of the ways to evaluate our responsibility towards the rest of the world when using a computer is to base our decisions on ethics.

**Excess representation**
A number representation method used to store the exponential value of a fraction.

**Excess_1023**
The high-precision IEEE standard for representation of floating point numbers.

**Excess_127**
The low-precision IEEE standard for representing floating-point numbers.

**execute**
Sending commands to different section of the computer by the Control Unit.

**expert system**
A system that uses knowledge representation to perform tasks that normally need human expertise.

**expression**
A sequence of operators and operands that reduces to a single value.

**expression tree**
An upside down tree in which the root and nodes are operators and leaves are operands.

**external level**
The part of the database that interacts with the user.

**Facebook**
A social network site with more than one billion users.

**Fast Ethernet**
An implementation of Ethernet with a data rate of 100 Mps.

**fetch**
The part of the instruction cycle in which the instruction to be executed is brought in from memory.

**fiber-optic cable**
A medium that carries signals in the form of pulses. It consists of a thin cylinder of glass or plastic (core) inside another cylinder of glass or plastic (cladding).

**field**
The smallest named unit of data that has meaning in describing information. A field may be either a variable or a constant.

**File Transfer Protocol (FTP)**
An application-layer service in TCP/IP for transferring files from and to a remote site.

**finite state automaton**
A machine that has predefined number of states.

**firewall**
A device installed between the internal network of an organization and the rest of the Internet to provide security.

**FireWire**
An I/O device controller with a high-speed serial interface that transfers data in packets.

**first in, first out (FIFO)**
An algorithm in which the first data item that is added to a list is removed from the list first.

**flat-file**
A stand-alone file not related to any other file in an organization.

**floating-point representation**
A number representation in which the position of the decimal point is floated to create better precision. Normally used to represent real numbers in a computer.

**follow**
How to connect to other users on Twitter.

**following**
The many-to-one relationship in Twitter in which many users follow a user.

**follwing**
Follow people you know to see their tweets on your home page.

**formal parameters**
The parameter declaration in a function to describe the type of data to be passed to the function.

**FORmula TRANslation (FORTRAN)**
A high-level procedural language used for scientific and engineering applications.

**fragmented distributed database**
A distributed database in which data is localized.

**frame**
A data unit at the data-link layer.

**frames**
A method similar to semantic networks for knowledge representation.

**frequency masking**
The process that a frequency totally mask another frequency.

**friend**
In Facebook, a user who can receive posts made by another user.

**friendship**
In Facebook, sharing is done only between friends. Friendship is a one-to-one reciprocal relationship.

**front**
The next element in a queue that is deleted by the dequeue operation.

**function**
In a functional paradigm, a black box that maps a list of input to a list of output.

**functional language**
A programming language in which a program is considered to be a mathematical function.

**functional paradigm**
A paradigm in which a program is considered a mathematical function.

**general linear list**
A list in which data can be inserted or deleted anywhere in the list.

**generic domain**
A subdomain in the domain name space that uses generic suffixes.

**Gigabit Ethernet**
An Etherenet with on gigabit (1000 Mbps) data rate.

**glass-box testing**
See *white-box testing*.

**Gödel number**
A number assigned to every program that can be written in a specific language.

**graph**
A collection of nodes, called vertices, and line segments, called edges or arcs, connecting pairs of nodes.

**Graphic Interchange Format (GIF)**
An 8-bit per pixel bitmap image.

**graphical user interface (GUI)**
A user interface that defines icon and operations on icons.

**Guided media**
Cable.

**hacker**
An astute computer specialist who may do harm.

**halting problem**
Writing a program that tests whether or not any program, represented by its Gödel number, will terminate.

**hardware**
Any of the physical components of a computer system, such as a keyboard or a printer.

**hardware abstraction layer (HAL)**
The lowest level program in the Windows system that hides the differences from upper layer.

**hashed file**
A file that is searched using one of the hashing methods.

**hashed MAC (HMAC)**
A recommendation by ITU to describe a certificate in public-key distribution using a well-known standard called ASN.1.

**hashing method**
A method to access a hashed file.

**hashtag**
A way to indicate an important word in a tweet. It starts with a hash (#) sign.

**HDMI (High-Definition Multimedia Interface)**
HDMI is a digital replacement for existing analog video standards.

**header**
The information added to the beginning of a packet for routing and other purposes.

**heuristic search**
A search in which a rule or a piece of information is used to make the search more efficient.

**hexadecimal digit**
A symbol in the hexadecimal system.

**hexadecimal system**
A numbering system with base 16. Its digits are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, and F.

**hierarchical model**
A database model that organizes data in a treelike structure that can be searched from top to bottom.

**high-level language**
A (portable) programming language designed to allow the programmer to concentrate on the application rather than the structure of a particular computer or operating system.

**high-order logic**
A logic that extends the scope of quantifiers ∀ and ∃ in predicate logic to bind predicates as well as variables.

**hold state**
The state of a job that is waiting to be loaded into memory.

**home address**
In a hashed list, the first address produced by the hashing algorithm.

**home directory**
In UNIX or Linux, a directory that a user is in when first logged in.

**home page**
The main page of a hypertext document available on the Web.

**host**
A station or node node on the network.

**host identifier**
The identifier of a station.

**hub**
A device that connects other devices in a network.

**Huffman coding**
A statistical compression method using variable-length code.

**hypertext**
A document containing embedded links to other documents.

**Hypertext Markup Language (HTML)**
The computer language for specifying the contents and format of a Web document: allows text to include fonts, layouts, embedded graphics, and links to other documents.

**Hypertext Transfer Protocol (HTTP)**
The protocol that is used to retrieve Web pages on the Internet.

**identifier**
The name given to an object in a programming language.

**image processing**
An area of artificial intelligence that deals with the perception of objects—the artificial eyes of an agent.

**imperative language**
Another name for a procedural language.

**imperative paradigm**
Another name for a procedural paradigm.

**implementation phase**
A phase in the software system lifecycle in which the actual programs are created.

**increment statement**
In C or C++, the statement that adds 1 to an integer value.

**incremental model**
A model in software engineering in which the entire package is constructed with each module consisting of just a shell: modules gain complexity with each iteration of the package.

**index**
The address of an element in an array.

**indexed color**
A technique in raster graphic that uses only a portion of True-Color to encode colors in each application.

**indexed file**
A file that uses an index for random access.

**infix**
An arithmetic notation in which the operator is placed between two operands.

**infrared waves**
Part of light spectrum from 300 GHz to 400 THz used for short-range communication.

**inheritance**
The ability to extend a class to create a new class while retaining the data objects and methods of the base class and adding new data objects and methods.

**inorder traversal**
A binary tree traversal method in which the root is traversed after the left subtree and before the right subtree.

**input**
The given data to an operation.

**input data**
User information that is submitted to a computer to run a program.

**input/output (I/O) controller**
A device that controls access to input/output devices.

**input/output subsystem**
The part of the computer’s organization that receives data from the outside and sends data to the outside.

**insert operation**
An operation in a relational database that inserts a tuple in a relation.

**insertion sort**
A sort algorithm in which the first element from the unsorted portion of the list is inserted into its proper position in the sorted portion of the list.

**instruction**
A command that tells a computer what to do.

**instruction register**
A register in the CPU that holds the instruction before being interpreted by the control unit.

**integer**
An integral number, a number without a fractional part.

**integrated circuit**
Transistors, wiring, and other components on a single chip.

**integrity**
A security goal to protect data from modification, insertion, deletion, or replaying.

**intellectual property**
Intangible things such as ideas, inventions, technologies, artworks, music and literature over which one can claim ownership.

**intelligent agent**
An agent that perceives its environment, learns from it, and interacts with it intelligently.

**interface**
A list of public operations or data that are to be passed or returned from an operation.

**internal level**
The part of the database that defines where data is actually stored.

**internal node**
Any tree node except the root and the leaves: a node in the middle of a tree.

**International Organization for Standardization (ISO)**
A worldwide organization that defines and develops standards for a variety of topics.

**internet**
Abbreviation for internetwork.

**Internet**
The global Internet that uses the TCP/IP protocol suite.

**Internet address**
A 32-bit address used to define a computer uniquely on the Internet.

**Internet Protocol (IP)**
The network-layer protocol in the TCP/IP protocol responsible for transmitting packets from one computer to another across the Internet.

**Internet Protocol version 6 (IPv6)**
The new IP with augmented address space and redesigned packets and protocols.

**Internet service provider (ISP)**
An organization that provides Internet services.

**internetwork**
A network of networks.

**interpretation**
The process of translating each line of a source program into the corresponding object program and executing the line.

**interpreter**
A program that translates a source program in a high-level language line by line and executes each line immediately.

**interrupt driven I/O**
A form of I/O in which the CPU, after issuing an I/O command, continues serving other processes until it receives an interrupt signal that the I/O operation is completed.

**intersection operation**
An operation on two sets in which the result is a set with the elements common to the two sets.

**intersector gap**
The gap between sectors on a disk.

**intertrack gap**
The gap between tracks on a tape.

**intracoded frame (I-frame)**
In MPEG, an independent frame.

**inverted file**
A file sorted according to a second key.

**IP address**
See *Internet address*.

**IP datagram**
The data unit in the network layer.

**IP new generation (IPng)**
Another name for IPv6.

**isolated I/O**
A method of addressing an I/O module in which the instructions used to read/write memory are totally different than the instructions used to read/write to input/output devices.

**Java**
An object-oriented programming language for creating stand-alone programs or dynamic documents on the Internet.

**job**
A program becomes a job when it is selected for execution.

**job scheduler**
A scheduler that selects a job for processing from a queue of jobs waiting to be moved to memory.

**join operation**
An operation in a relational database that takes two relations and combines them based on common attributes.

**Joint Photographic Experts Group (JPEG)**
A standard for compressing images.

**kernel**
The main part of an operating system.

**key**
One or more fields used to identify a record (structure).

**key-distribution center (KDC)**
A trusted third party that establishes a shared secret key between two parties.

**keyboard**
An input device providing character-by-character input.

**land**
On an optical disc, an area not hit by the laser in the translation of a bit pattern. Usually represents a bit.

**last in, first out (LIFO)**
An algorithm in which the last data item that is added to a list is removed from the list first.

**leaf**
A graph or tree node with one incoming arc and no outgoing arcs.

**Lempel Ziv (LZ) encoding**
A compression algorithm that uses a dictionary.

**Lempel Ziv Welch (LZW) encoding**
An enhanced version of LZ encoding.

**lexical analyzer**
A program used in a translation process that reads the source code symbol by symbol and creates a list of tokens.

**linear list**
A list structure in which each element except the last has a unique successor.

**link**
In a list structure, the field that identifies the next element in the list.

**linked list**
A linear list structure in which the ordering of the elements is determined by link fields.

**linked list resolution**
A collision resolution method in hashing that uses a separate area for synonyms, which are maintained in a linked list.

**Linux**
An operating system developed by Linus Torvalds to make UNIX more efficient when run on an Intel microprocessor.

**LISP**
A list processing programming language in which everything is considered a list.

**list**
An ordered set of data contained in main memory.

**literal**
A constant used in a program.

**local area network (LAN)**
A network connecting devices inside a limited area.

**local variable**
A variable defined within a block or a module.

**logical operation**
An operation in which the result is a logical value (true or false).

**logical operator**
An operator that combines Boolean values to get a new Boolean values.

**logical shift operation**
A shift operation that does not preserve the sign of the number.

**loop**
In a program, a structured programming construct that causes one or more statements to be repeated. In a graph, a line that starts and ends with the same vertex.

**loop statement**
A statement that causes the program to iterate a set of statements.

**lossless data compression**
Data compression in which no data is lost. Used for compressing text or programs.

**lossy data compression**
Data compression in which some data is allowed to be lost. Used for image, audio, or video compression.

**MAC addresses**
Address of a device at the data-link layer.

**machine cycle**
A repeated collection of fetch, decode, and execute operations.

**machine language**
Instructions native to the central processor of a computer that are executable without assembly or compilation.

**macro**
A custom-designed procedure that can be used repeatedly.

**magnetic disk**
A storage medium with random access capability.

**magnetic tape**
A storage medium with sequential access capability.

**Mail Transfer Agent**
The client-server program used in email communication.

**main memory**
The primary memory of a computer, consisting of medium speed. random access memory. Contrast with *cache memory*.

**maintainability**
A quality that refers to keeping a system running correctly and up to date.

**mantissa**
The part of a floating-point number that shows the number’s significant digits.

**mask**
A variable or constant that contains a bit configuration used to control the setting of bits in a bitwise operation.

**masquerading**
A type of attack on integrity of information in which the attacker impersonates somebody else.

**master disk**
The first component created in a CD-ROM

**master file**
A permanent file that contains the most current data regarding an application.

**medium access control (MAC) address**
See *data link layer address*.

**memory**
The main memory of a computer consisting of random access memory (RAM) and read-only memory (ROM), used to store data and program instructions.

**memory management**
The component of the operating system that controls the use of main memory.

**memory-mapped I/O**
A method of addressing an I/O module in a single address space, used for both memory and I/O devices.

**Message Access Agent (MAA)**
A client-server program that pulls the stored email message.

**message authentication code (MAC)**
A message digest that includes a secret between two parties.

**message digest**
The fixed-length string created from applying a hash function to a message.

**message transfer agent (MTA)**
An SMTP program that transfers a message across the Internet.

**method**
A function in an object-oriented language.

**metropolitan area network (MAN)**
A network that can span a city or a town.

**microcomputer**
A computer small enough to fit on a desktop.

**Microsoft Disk Operating System (MS-DOS)**
The operating system based on DOS and developed by Microsoft.

**modal logic**
An extension to logic that includes certainty and possibility.

**modem**
A modulator–demodulator combined.

**modularity**
Breaking a large project into small parts that can be understood and handled easily.

**modulator**
A device that converts data to a signal.

**module**
A small part created from applying modularity to a project.

**modulo division**
Dividing two numbers and keeping the remainder.

**monitor**
A nonstorage device that provides output.

**Monitor**
The monitor displays output and at the same time echoes input typed on the keyboard.

**monoalphabetic cipher**
A cipher in which the same character is always encrypted the same regardless of its position in the text.

**monoprogramming**
The technique that allows only one program to be in memory at a time.

**moral rule**
A principle in ethics dictating that we should avoid doing anything that is against universal morality.

**moral rules**
The first ethical principle states that when we make an ethical decision, we need to consider if the decision is made in accordance with a universally accepted principle of morality.

**Moving Picture Experts Group (MPEG)**
A lossy compression method for compressing video (and audio).

**MPEG audio layer (MP3)**
A standard used for compression audio based on MPEG.

**multidimensional array**
An array with elements having more than one level of indexing.

**Multiple Instruction Stream, Single Data Stream (MISD)**
A computer in which several streams operates on one single data.

**multiple instruction_stream, multiple data stream (MIMD)**
A computer with several CUs, several ALUs, and several memory unit.

**multiprogramming**
A technique that allows more than one program to reside in memory while being processed.

**multithreading**
Parallel processing supported by some languages such as Java.

**mutual exclusion**
A condition imposed by an operating system in which only one process can hold a resource.

**name**
In relational database terminology, the identifier of a relation.

**name space**
All the name assigned to a machine on an internet

**network**
A system of connected nodes that can share resources.

**network layer**
The third layer in the TCP/IP model, responsible for delivery of packets from the original host to the final destination.

**network model**
A database model in which a record can have more than one parent record.

**neural network**
A network of neurons which is modeled on the human brain.

**neuron**
The individual cells that are responsible for transmitting information in the human brain and nervous system.

**new master file**
The master file that is created from an old master file when the file is updated.

**news**
Facebook allows you to post news (called updates) for your friends. This can be a long message (up to 60 000 characters), a link to a web page, a photo, or a video.

**no preemption**
A condition in which the operating system cannot temporarily allocate a resource.

**node**
In a data structure, an element that contains both data and structural elements used to process the data structure.

**node-to-node**
The communication at the data-link layer.

**nonpolynomial problem**
A problem that cannot be solved with polynomial complexity.

**nonpositional number system**
A number system in which the position of symbols does not define the value of the symbol.

**Nonstorage device**
Nonstorage devices allow the CPU/memory to communicate with the outside world, but they cannot store information.

**nonstorage device**
A device that allows communication between CPU and memory without storing information.

**normal form (NF)**
A step in the normalization process of a relational database.

**normalization**
In a relational database, the process of applying normal forms to a relational model.

**NOT operator**
The operation that changes a 0 bit to 1 or a 1 bit to 0.

**null pointer**
A pointer that points to nothing.

**number system**
A system that uses a set of symbols to define a value.

**object program**
The machine language code created from a compiler or an interpreter.

**object-oriented analysis**
The analysis phase of a developmental process in which the implementation uses an object-oriented language.

**object-oriented database**
A database in which data is treated as structures (objects).

**object-oriented design**
Given the details and codes for each class in object-orienting programming.

**object-oriented language**
A programming language in which the objects and the operations to be applied to them are tied together.

**object-oriented paradigm**
A paradigm in which a program acts on active objects.

**octal digit**
A digit in base 8.

**octal system**
A numbering system with a base of 8: the octal digits are 0 to 7.

**old master file**
The master file that is processed in conjunction with the transaction file to create the new master file.

**one-dimensional array**
An array with only one level of indexing.

**one-time pad**
A type of cipher in which the key is randomly chosen for each encipherment.

**one’s complement**
A bitwise operation that reverses the value of the bits in a variable.

**open addressing resolution**
A collision resolution method in which the new address is in the home area.

**operability**
The quality factor that addresses the ease with which a system can be used.

**operand**
An object in a statement on which an operation is performed. Contrast with *operator*.

**operating system**
The software that controls the computing environment and provides an interface to the user.

**operator**
The syntactical token representing an action on data (the operand). Contrast with *operand*.

**optical storage device**
An I/O device that uses (laser) light to store and retrieve data.

**OR operator**
A binary operation resulting in an output of 0 only if the two inputs are 0s, otherwise 1.

**output**
The resulting data from an operation.

**output data**
The results of running a computer program.

**output device**
A device that can be written to but not read from.

**overflow**
The condition that results when there are insufficient bits to represent a number in binary.

**packet-filter firewall**
A firewall that uses a filtering table to protect the organization.

**packetizing**
Encapsulating data in a packet.

**page**
One of a number of equally sized sections of a program.

**paging**
A multiprogramming technique in which memory is divided into equally sized sections called *frames*.

**palette color**
See *indexed color*.

**parallel processing**
A form of multiprocessing that speeds processing by allowing several processors to operate at the same time.

**parallel system**
An operating system with multiple CPUs on the same machine.

**parameter**
A value passed to a function.

**parent**
A tree or graph node with one or more child nodes.

**parent directory**
The directory immediately above the current directory.

**parser**
An entity that does parsing.

**partitioning**
A technique used in multiprogramming that divides the memory into variable-length sections.

**Pascal**
A programming language designed with the goal of teaching programming to novices by emphasizing the structured programming approach.

**pass by reference**
A parameter passing technique in which the called function refers to a passed parameter using an alias name.

**pass by value**
A parameter passing technique in which the value of a variable is passed to a function.

**patent**
A right to an intellectual property.

**path**
A sequence of nodes in which each vertex is adjacent to the next.

**peer-to-peer paradigm**
A paradigm in which two peer computers can communicate with each other to exchange services.

**penetration attack**
Penetration means breaking into a system to get access to the data stored in a computer or in a computer network.

**penetration attack**
Unlawful accessing of a computer to get information or to cause damage.

**perceptron**
A simple neuron-like element that is used in neural networks.

**perceptual encoding**
Type of encoding used in audio.

**physical agent**
A programmable system (robot) that can be used to perform a variety of tasks.

**physical layer**
The first layer in the TCP/IP model, responsible for signaling and transmitting bits across the network.

**pico**
Another text editor in Unix.

**picture element (pixel)**
The smallest unit of an image.

**pipelining**
A technique used by modern computers to improve the throughput by combining different phases of on instruction with the next.

**Pipelining**
Modern computers use a technique called pipelining to improve the throughput (the total number of instructions performed in each period of time). The idea is that if the control unit can do two or three of these phases simultaneously, the next instruction can start before the previous one is finished.

**pit**
On an optical disc, an area struck by the laser in the translation of a bit pattern, which usually represents a 0 bit.

**pixel**
See *picture element*.

**place value**
The value related to a position in the positional number system.

**plaintext**
Text before being encrypted.

**point-to-point**
A type of network that connects two communication devices through a transmission media.

**pointer**
A constant or variable that contains an address that can be used to access data stored elsewhere.

**polyalphabetic cipher**
A type of cipher that a character in the plaintext will change to a different character in the ciphertext base on its position in the text.

**polycarbonate resin**
In CD-ROM production, a material injected into a mold.

**polymorphism**
In C++, defining several operations with the same name that can do different things in related classes.

**polynomial problem**
A problem that can be solved in an acceptable time by a computer.

**pop**
The stack delete operation.

**port address**
See *port number*.

**port number**
The address used in TCP and UDP to distinguish one process from another.

**portability**
The quality factor relating to the ease with which a system can be moved to other hardware environments.

**positional number system**
A number system in which the position of a symbol in a number defines its value.

**postfix**
An arithmetic notation in which the operator is placed after its operands.

**postorder traversal**
A binary tree traversal method in which the left subtree is processed first, then the right subtree, then the root.

**pragmatic analysis**
The analysis of a sentence to find the real meaning of words by removing the ambiguities.

**predicate logic**
A logic system in which quantifiers can be applied to terms but not to predicates.

**predicted frame (P-frame)**
In MPEG, a frame that is related to the preceding I-frame or B-frame.

**Predictive encoding**
Encoding the difference between two samples instead of encoding the sample itself.

**prefix**
An arithmetic notation in which the operator is placed before the operands.

**preorder traversal**
A binary tree traversal in which the left subtree is traversed first, the root is traversed next, and the right subtree is traversed last.

**prime area**
In a hashed list, the memory that contains the home address.

**printer**
An output device that creates hard copy.

**privacy**
The right of individual to keep some information secret.

**privacy**
Today, a large amount of personal information about a citizen is collected by private and public agencies. Some countries have ethical rules about the use of this information.

**private key**
One of the two keys used in public key encryption.

**procedural language**
A computer language in a procedural paradigm.

**procedural paradigm**
A paradigm in which a program acts on passive objects using procedures.

**procedure-oriented analysis**
The analysis phase of a developmental process in which the implementation uses a procedural language.

**procedure-oriented design**
The design phase of developmental process when the implementation uses a procedural language.

**process**
A program in execution.

**process manager**
An operating system component that controls the processes.

**process scheduler**
An operating system mechanism that dispatches the processes waiting to get access to the CPU.

**product**
The result of multiplying a list of numeric data and finding the result.

**program**
A set of instructions.

**program counter**
A register in the CPU that holds the address of the next instruction in memory to be executed.

**programmable read-only memory (PROM)**
Memory with contents electrically set by the manufacturer that may be reset by the user.

**programmed I/O**
A form of I/O in which the CPU must wait for the I/O operation to be completed.

**programming language**
A language with limited words and limited rules designed to solve problems on a computer.

**project operation**
An operation in a relational database in which a set of columns is selected based on a criterion.

**PROLOG**
A programming language that can build a database of facts and a knowledge base of rules.

**propositional logic**
A logic system based on logical operators and propositional term.

**protocol**
A set of rules for data exchange between computers.

**protocol layering**
The idea of using a set of protocols to create a hierarchy of rules for handling a difficult task.

**proxy firewall**
A firewall that stands between the customer computer and the corporation computer. It accepts only legitimate messages from the customer computer.

**proxy firewall**
A proxy computer (sometimes called an application gateway) that stands between the customer computer and the corporation computer.

**pseudocode**
English-like statements that follow a loosely defined syntax and are used to convey the design of an algorithm or function.

**public key**
One of the keys in a public key encryption, revealed to the public.

**public-key certificate**
A certificate that binds an entity to its public key.

**push**
The stack insert operation.

**quantifier**
Two operators used in predicate logic: ∀ and ∃.

**quantization**
Assigning a value from a finite set of values.

**queue**
A linear list in which data can only be inserted at one end, called the rear, and deleted from the other end, called the front.

**radix**
The base in a positional number system.

**random access**
A storage method that allows data to be retrieved in an arbitrary order.

**random access memory (RAM)**
The main memory of the computer that stores data and programs.

**raster graphic**
See *bitmap graphic*.

**read-only memory (ROM)**
Permanent memory with contents that cannot be changed.

**read/write head**
The device in a hard disk that reads or writes data.

**ready state**
In process management, the state of processing in which the process is waiting to get the attention of the CPU.

**real**
A number with both integral and fractional parts.

**real-time system**
An operating system that is expected to do a task within specific time constraints.

**rear**
The last element inserted into a queue using the enqueue operation.

**record**
Information related to one entity.

**recursion**
A function design in which the function calls itself.

**reduced instruction set computer (RISC)**
A computer that uses only frequently used instructions.

**register**
A fast stand-alone storage location that holds data temporarily.

**relation**
A table in a relational database.

**relational database**
A database model in which data is organized in related tables called relations.

**relational database management system (RDBMS)**
A set of programs that handles relations in a relational database model.

**relational model**
See *relational database*.

**relational operator**
An operator that compares two values.

**relative pathname**
The path of a file defined in terms of the working directory.

**reliability**
The quality factor that addresses the confidence or trust in a system’s total operation.

**remote login**
Logging on to a remote computer that is connected to the local computer.

**repetition**
One of the three constructs in structural programming.

**replaying**
A type of attack on information integrity in which the attacker intercepts the message and resends it again.

**replicated distributed database**
A database in which each site holds a replica of another site.

**resolution**
The scanning rate in image processing: the number of pixels per unit measure.

**resource holding**
A condition in which a process holds a resource but cannot use it until all other resources are available.

**retrieval**
The location and return of an element in a list.

**retweet**
A tweet forwarded to other Twitter users.

**RGB**
A color system in which tints are represented by a combination of red, green, and blue primary colors.

**Roman number system**
The nonpositional number system used by the Romans.

**root**
The first node of a tree.

**root directory**
The highest level in a file hierarchy.

**rotational speed**
The spin rate of a magnetic disk.

**router**
A device operating at the first three TCP/IP layers that connects independent networks. A router routes a packet based on its destination address.

**routing**
The process performed by a router.

**row-major storage**
A method of storing array elements in memory in which the elements are stored row by row.

**RSA cryptosystem**
A common public cryptosystem designed by River, Shamir, and Adleman. It uses two exponents, e and d, in which the the first is public and the second is private.

**RSA cryptosystem**
RSA cryptosystem is one of the common public-key algorithms.

**rule-based system**
A knowledge representation system that uses a set of rules that can be used to deduce new facts from known facts.

**run-length encoding**
A lossless compression method in which a sequence of the same symbols is replaced by the symbol and the number of repetitions.

**running state**
In process management, a state in which a process is using the CPU.

**sampling**
Taking measurements at equal intervals.

**sampling rate**
The number of samples obtained per second in the sampling process.

**scanning**
Converting an image into digital data by sampling its density and color at evenly-spaced points.

**scheduler**
A program to move a job from one state to another.

**scheduling**
Allocating the resources of an operating system to different programs and deciding which program should use which resource, and when.

**scheme**
The de facto standard of the LISP language.

**scientific notation**
Representation of a number with one digit at the left of the decimal point and the power of 10 defines the shifting of the decimal point.

**search space**
The set of possible situations that can be examined by a search method to find a solution.

**searching**
The process that examines a list to locate one or more elements containing a designated value known as the search argument.

**secondary storage device**
See *auxiliary storage*.

**secret key**
A key that is shared by two participants in secret key encryption.

**sector**
A part of a track on a disk.

**Secure Hash Algorithm (SHA)**
A standard hash function developed by NIST.

**Secure Shell (SSH)**
A client-server program that provide secure logging.

**security**
The quality factor that addresses the ease or difficulty with which an unauthorized user can access data.

**security attack**
An attack threatening the security goals of a system.

**security goal**
One of the three goals of information security: confidentiality, integrity, and availability.

**seek time**
In disk access, the time required to move the read/write head over the track that holds the required data.

**segment**
Part of a packet.

**segmentation**
A step in image processing that divides the image into homogeneous segments or areas.

**select operation**
An operation in a relational database that selects a set of tuples.

**selection**
One of the three constructs in structure programming.

**selection sort**
A sort algorithm in which the smallest value in the unsorted portion of the list is selected and placed at the end of the sorted portion of the list.

**semantic analysis**
Analysis of the meaning of words in a sentence or tokens in a statement.

**semantic network**
A graph in which the node represents objects and the edges represent relationships between objects.

**sequence**
One of the three constructs in structure programming.

**sequential access**
An access method in which the records in a file are accessed serially beginning with the first element.

**sequential file**
A file structure in which data must be processed sequentially from the first element in the file.

**sequential search**
A search technique used with a linear list in which searching begins at the first element and continues until the value of an element equal to the value being sought is located, or until the end of the list is reached.

**server**
In a client–server system, the centralized computer that provides auxiliary services (server programs).

**shell**
A user interface in some operating systems, such as UNIX.

**shift cipher**
A type of substitution cipher in which the key defines shifting of characters toward the end of the alphabet.

**siblings**
Nodes in a tree with the same parent.

**side effect**
A change in a variable that results from the evaluation of an expression: any input/output performed by a called function.

**sign out**
To terminate membership in a social media.

**sign out**
You need to be a member of Facebook to use it. To become a member, you need to sign up. To terminate your membership, you need to sign out or deactivate your account.

**sign-and-magnitude representation**
A method of integer representation in which 1 bit represents the sign of the number and the remaining bits represent the magnitude.

**simple type**
An atomic data type such as integer or real.

**single instruction stream, multiple data stream (SIMD)**
A computer with one control unit, multiple ALU, and one memory unit.

**single-user operating system**
An operating system in which only one program can be in memory at a time.

**small computer system interface (SCSI)**
An I/O device controller with a parallel interface.

**snooping**
Unauthorized access to confidential information.

**social contract**
A principle of ethics that says an act is ethical if a majority of people in society agree with it.

**social contract**
The social contract theory says that an act is ethical when a majority of people in society agrees with it.

**social media**
Websites used by people to share ideas and messages.

**social network**
Another name for social media.

**software**
The application and system programs necessary for computer hardware to accomplish a task.

**software agent**
In artificial intelligence applications, a set of programs that are designed to do particular tasks.

**software engineering**
The design and writing of structured programs.

**software lifecycle**
The life of a software package.

**software quality**
Three characteristics of a software (operability, maintainability, and transferability).

**solvable problem**
A problem that can be solved by a computer.

**soma**
The body of a neuron that holds the nucleus of the cell.

**something inherent**
A characteristic of the claimant, such as conventional signature, fingerprint, voice, and so on, used for entity authentication.

**something known**
A secret known by the claimant that can be used by the verifier in entity authentication.

**something possessed**
Something belonging to the claimant that can prove the claimant’s identity.

**sort pass**
One loop during which all elements are tested by a sorting program.

**sorting**
The process that orders a list or file.

**source program**
The file that contains program statements written by a programmer before they are converted into machine language: the input file to an assembler or compiler.

**source-to-destination delivery**
The delivery of a data packet from the source to the destination.

**spatial compression**
Compression done on a frame by the JPEG encoding process.

**speech recognition**
The first step in natural language processing (in AI) in which the speech signal is analyzed and the sequence of words it contains are extracted.

**spoofing**
See *masquerading*.

**stack**
A restricted data structure in which data can be inserted and deleted only at one end, called the top.

**Standard Ethernet**
The original Ethernet operating at 10 Mbps.

**starvation**
A problem in the operation of an operating system in which processes cannot get access to the resources they need.

**state chart**
A diagram, similar to a state diagram, but used in object-oriented software engineering.

**state diagram**
A diagram that shows the different states of a process.

**statement**
A syntactical construct in C that represents one operation in a function.

**static RAM (SRAM)**
A technology that uses traditional flip-flop gates (a gate with two states, 0 and 1) to hold data.

**steganography**
A security technique in which a message is concealed by covering it with something else.

**storage device**
An I/O device that can store large amounts of information for retrieval at a later time.

**stream cipher**
A cipher that encryption and decryption are done a character at a time.

**String**
A correction of characters considered as a single unit of data.

**string**
A string, as a set of characters, is treated in different languages differently. In C, a string is an array of characters. In C++, a string can be an array of characters, but there is a type named string. In Java, a string is a type.

**structure chart**
A design and documentation tool that represents a program as a hierarchical flow of functions.

**structured program**
A program written according to the rules of Software Engineering.

**Structured Query Language (SQL)**
A database language that includes statements for database definition, manipulation, and control.

**subalgorithm**
A part of an algorithm that is independently written and is executed when called inside the algorithm.

**subprogram**
A smaller program called by the main program.

**subroutine**
See *subalgorithm*.

**substitution cipher**
A cipher that replaces one symbol with another.

**subtree**
Any connected structure below the root of a tree.

**summation**
Addition of a series of numbers.

**switch**
A device that connects components in a network together.

**switched WAN**
A complex WAN made of several medium and several switches.

**symbolic language**
A computer language, one level removed from machine language, that has a mnemonic identifier for each machine instruction and can use symbolic data names.

**symmetric-key cipher**
A type of cryptography in which a single secret key is used for both encryption and decryption.

**symmetric-key encryption**
Encryption using a symmetric-key cipher.

**synapse**
A connection between two neuron in the human nervous system.

**synonym**
In a hashed list, two or more keys that hash to the same home address.

**syntactic analysis**
The analysis of a sentence to check for grammar.

**syntax**
The grammatical rules of a language.

**syntax analyzer**
The process that checks the grammar of a sentence.

**system documentation**
A formal structured record of a software package.

**TCP/IP protocol suite**
A five-layer protocol suite that defines the exchange of transmission across the Internet

**technical documentation**
Documenting the procedures for installation and servicing of the software system.

**TELNET (terminal network)**
A general-purpose client-server program that allows remote login.

**temporal compression**
Compression done by MPEG on frames.

**temporal logic**
A type of logic that includes change and the effect of time in reasoning.

**temporal masking**
A process that a loud sound eliminates the effect of less loud sound.

**terminated state**
In process management, a state in which a process has finished executing.

**testability**
An attribute of software that measures the ease with which the software can be tested as an operational system.

**testing phase**
A phase in the software lifecycle in which experiments are carried out to prove that a software package works.

**text**
Data stored as characters.

**text editor**
Software that creates and maintains text files, such as a word processor or a source program editor.

**text file**
A file in which all data is stored as characters. Contrast with *binary file*.

**thresholding**
A method used in image segmentation in which a pixel with a specific intensity is selected and the method tries to find all the pixels with the same intensity.

**throughput**
The number of data units that can be passed through a point in one unit of time.

**ticket**
In session key distribution, an encrypted message containing the session key intended for Bob, but sent to Alice to be deliver to Bob.

**time sharing**
An operating system concept in which more than one user has access to a computer at the same time.

**token**
A syntactical construct that represents an operation, a flag, or a piece of data.

**topology**
The structure of a network, including the physical arrangement of devices.

**track**
A part of a disk.

**trade secret**
Information about a product that is kept secret.

**trademark**
A sign or name that identifies a company product.

**traffic analysis**
A type of attack on confidentiality in which the attacker obtains some information by monitoring online traffic.

**transaction file**
A file containing relatively transient data that are used to change the contents of a master file.

**transfer time**
The time to move data from the disk to the CPU/memory.

**transferability**
A quality in software system that refers to the ability to move the system from one platform to another.

**translator**
A generic term for any of the language conversion programs. See also *assembler* and *compiler*.

**Transmission Control Protocol (TCP)**
One of the transport-layer protocols in the TCP/IP protocol suite.

**Transmission Control Protocol/Internet Protocol (TCP/IP)**
The official protocol of the Internet, composed of five layers.

**transmission medium**
The physical path linking two communication devices.

**transmission rate**
The number of bits sent per second.

**transposition cipher**
A cipher that transposes symbols in the plaintext to create the ciphertext and vice versa.

**traversal**
An algorithmic process in which each element in a structure is processed once and only once.

**tree**
A set of connected nodes structured so that each node has only one predecessor.

**Trojan horse**
A program that can do malicious acts such as deleting or corrupting files.

**True-Color**
A technique in raster graphic that uses 24 bits to represent a color.

**truncation error**
The error that occurs when a number is stored using floating-point representation. The value of the number stored may not be exactly as expected.

**truth table**
A table listing all the possible logical input combinations with the corresponding logical output.

**tuple**
In a relational database, a record (a line) in a relation.

**Turing machine**
A computer model with three components (tape, controller, and read/write head) that can implement statements in a computer language.

**Turing model**
A computer model based on Alan Turing’s theoretical definition of a computer.

**Turing test**
A test devised by Alan Turing to determine whether a computer can be said to be truly intelligent.

**tweet**
A short (maximum 140 characters) message exchanged by users in Twitter. Sending a tweet.

**twisted-pair cable**
Two insulated cable twisted together in a cover.

**Twitter**
A popular social network where users can post short messages called tweets.

**two-dimensional array**
An array with elements having two levels of indexing. See also *multidimensional array*.

**two’s complement**
A representation of binary numbers in which the complement of a number is found by complementing all bits and adding a 1 after that.

**two’s complement representation**
A method of integer representation in which a negative number is represented by leaving all the rightmost 0s and the first unchanged and complementing the remaining bits.

**unary operation**
An operation that needs only one input operand.

**underflow**
An event that occurs when an attempt is made to delete data from an empty data structure.

**undirected graph**
A graph consisting only of edges—that is, a graph in which there is no indication of direction on the lines.

**unfollow**
A process whereby a user stops following another user on Twitter.

**unguided media**
Transmission media with no physical boundries.

**Unicode**
A 32-bit code that includes the symbols and alphabets from most languages in the world.

**Unified Modeling Language (UML)**
A graphical language used for analysis and design.

**Uniform Resource Locator (URL)**
A string of characters that defines a page on the Internet.

**union operation**
An operation on two sets in which the result contains all the elements from both sets without duplicates.

**universal serial bus (USB)**
A serial I/O device controller that connects slower devices such as the keyboard and mouse to a computer.

**UNIX**
A popular operating system among computer programmers and computer scientists.

**unsigned integer**
An integer without a sign whose value ranges between and positive infinity.

**unsolvable problem**
A problem that cannot be solved by a computer.

**update operation**
An operation in a relational database in which the operation about one tuple is changed.

**use-case diagram**
A diagram showing the user view of a system in UML.

**user agent (UA)**
An SMTP component that prepares the message, creates the envelope, and puts the message in the envelope.

**user datagram**
The data unit used by the UDP protocol.

**User Datagram Protocol (UDP)**
One of the transport-layer protocols in the TCP/IP protocol suite.

**user interface**
A program that accepts requests from users (processes) and interprets them for the rest of the operating system.

**user page**
The main page in Facebook.

**user page**
The user page is the main page you will use on Facebook.

**users**
In DBMS terminology, every entity that access the database.

**utility**
An application program in UNIX.

**utilization**
A principle in ethics that says an act is ethical if it creates a good result.

**utilization**
The second theory of ethics, related to the consequences of the act. An act is ethical if it results in consequences which are useful for society.

**variable**
A memory storage object whose value can be changed during the execution of a program. Contrast with *constant*.

**vector graphic**
A type of graphics file format in which lines and curves are defined using mathematical formulas.

**verifying algorithm**
The algorithm that verifies the validity of a digital signature.

**vertex**
A node in a graph.

**vi**
A screen text editor available in Unix operating system.

**video**
A representation of images (called frames) in time.

**virtual memory**
A form of memory organization that allows swapping of programs between memory and magnetic storage to give the impression of a larger main memory than really exists.

**virus**
Unwanted program hidden inside another program, and which can replicate itself.

**von Neumann model**
A computer model (consisting of memory, arithmetic logic unit, control unit, and input/output subsystems) upon which the modern computer is based.

**waiting state**
A state in which a process is waiting to receive the attention of the CPU.

**waterfall model**
A software development model in which each module is completely finished before the next module is started.

**Web**
See *World Wide Web*.

**Web page**
A unit of hypertext or hypermedia available on the Web.

**well-known port number**
A port number that defines a process on the network.

**white-box testing**
Program testing in which the internal design of the program is considered. Also known as glass-box testing. Contrast with *black-box testing*.

**wide area network (WAN)**
A network that spans a large geographical distance.

**WiMax**
Worldwide Interoperability Access.

**Windows**
The operating system designed by Microsoft.

**Windows 2000**
A version of the Windows NT operating system.

**Windows NT**
An operating system devised by Microsoft to replace MS-DOS.

**Windows XP**
A version of the Windows NT operating system.

**working directory**
The directory that is currently being used.

**World Wide Web (WWW)**
A multimedia Internet service that allows users to traverse the Internet by moving from one document to another via links.

**Worldwide Interoperability Access**
Wireless version of DSL or cable connection to the Internet.

**worm**
An independent program that travels through the network and can copy itself.

**write once, read many (WORM)**
Another name for a CD‑R.

**X.509**
A technique used by modern computers to improve the throughput by combining different phases of on instruction with the next.

**X.509**
X.509 is a way to describe a certificate in a structured way. It uses a well-known protocol called ASN.1 that defines fields familiar to computer programmers.

**XOR operator**
A bitwise operation in which the result of the operation is 1 only if one of the operands is 1.

**zero-knowledge authentication**
An entity authentication method in which the claimant does not reveal anything that might endanger the confidentiality of the secret.
`,zh:`
# 詞彙表

**10-Gigabit Ethernet**
以每秒 10 十億位元運行的乙太網路實作。

**absolute pathname (絕對路徑名稱)**
在 UNIX 或 Linux 中，從根目錄開始的路徑名稱。

**abstract data type (ADT) (抽象資料型別)**
與對該資料類型有意義的操作打包在一起的資料宣告。

**AC value (交流值)**
隨時間變化的值。

**access method (存取方法)**
從輔助（次級）儲存裝置讀取資料的技術。

**actual parameters (實際參數)**
函式呼叫語句中包含要傳遞給函式的值的參數。與*形式參數*相對。

**Ada**
由美國國防部開發的高階並行程式語言。

**additive cipher (加法加密法)**
一種加密法，其金鑰定義字元向字母表末尾的移位（移位加密法）。最簡單的單字母加密法，其中每個密文字元是明文字元加上金鑰值。

**address bus (位址匯流排)**
系統匯流排中用於位址傳輸的部分。

**address space (位址空間)**
位址的範圍。

**algorithm (演算法)**
用電腦解決問題所需的邏輯步驟。

**American National Standards Institute (ANSI) (美國國家標準協會)**
制定程式語言、電氣規格、通訊協定等標準的組織。

**American Standard Code for Information Interchange (ASCII) (美國資訊交換標準碼)**
一種定義 128 個值的控制字元和可列印字元的編碼方案。

**ampersand (& 符號)**
用於電子郵件地址的 @ 符號。

**analog (類比)**
連續變化的實體。

**analog data (類比資料)**
連續且平滑且不限於特定值的資料。

**analog signal (類比信號)**
一種隨時間平滑變化的波形。

**analog-to-analog conversion (類比對類比轉換)**
用類比信號表示類比資料。

**analog-to-digital conversion (類比對數位轉換)**
用數位信號表示類比資料。

**analog-to-digital (類比對數位)**
用數位信號表示類比資料。

**analysis phase (分析階段)**
軟體系統生命週期的一個階段，定義指定擬議系統要完成什麼的需求。

**ancestor (祖先)**
從當前節點到樹根路徑中的任何節點。

**AND (及)**
位元層級運算之一：僅當兩個位元都為 1 時，運算結果才為 1，否則為 0。

**applet (小程式)**
用 Java 編寫的電腦程式，可創建活動 Web 文件。

**application gateway (應用閘道器)**
位於防火牆和組織電腦之間以過濾不需要訊息的電腦。

**application layer (應用層)**
TCP/IP 模型中的第七層：提供對網路服務的存取。

**application programs (應用程式)**
在 DBMS 術語中，存取和處理資料的程式。

**arc (弧)**
圖形中的有向線。與*邊*相對。

**arithmetic logic unit (ALU) (算術邏輯單元)**
電腦系統中對資料執行算術和邏輯運算的部分。

**arithmetic operation (算術運算)**
獲取兩個數字並創建另一個數字的運算。

**arithmetic operator (算術運算子)**
用於算術運算的運算子。

**arithmetic shift operation (算術移位運算)**
保留數字符號的移位運算。

**array (陣列)**
相同資料類型的元素的固定大小、序列化集合。

**artificial intelligence (人工智慧)**
研究模擬人類思維智慧的電腦系統。

**assembler (組譯器)**
將原始程式轉換為可執行目的碼的系統軟體。傳統上與組合語言程式相關聯。另見*編譯器*。

**assembly language (組合語言)**
一種程式語言，其中電腦的機器語言與語言的符號指令集之間存在一對一的對應關係。

**assignment statement (賦值陳述式)**
將值賦給變數的陳述式。

**asymmetric-key cipher (非對稱金鑰加密法)**
一種使用兩個不同金鑰的密碼學類型：一個用於加密的公鑰和一個用於解密的私鑰。

**asymmetric-key encryption (非對稱金鑰加密)**
使用公鑰加密。

**attribute (屬性)**
在關聯式資料庫中，關聯中的每一列。在關聯式資料庫術語中，列標題的名稱。

**audio (音訊)**
聲音或音樂的錄製或傳輸。

**authentication (驗證)**
訊息發送者的驗證。

**autokey cipher (自動金鑰加密法)**
一種在加密過程中從明文自動創建金鑰的加密法。

**auxiliary storage (輔助儲存)**
主記憶體以外的任何儲存設備：永久資料儲存；外部儲存；次級儲存。

**availability (可用性)**
資訊安全的組成部分，要求組織創建和儲存的資訊可供授權實體使用。

**axon (軸突)**
人體神經元中透過突觸向其他神經元提供輸出的部分。

**base (基底)**
數字系統中使用的數字數量。二進位基底為 2，八進位為 8，十進位為 10，十六進位為 16。

**basis path testing (基本路徑測試)**
一種白箱測試方法，創建一組測試案例，至少執行軟體中的每個陳述式一次。

**batch operating system (批次作業系統)**
早期電腦中使用的作業系統，其中工作在被服務之前被分組。

**bidirectional frame (B-frame) (雙向影格)**
在 MPEG 中，與前面和後面的影格相關的影格。

**big-O notation (大 O 符號)**
僅考慮主導因素的演算法效率度量。

**binary digit (bit) (二進位數字)**
資訊的最小單位（0 或 1）。

**binary file (二進位檔)**
以電腦內部格式儲存的資料集合。與*文字檔*相對。

**binary operation (二元運算)**
需要兩個輸入運算元的運算。

**binary search (二元搜尋)**
一種搜尋演算法，其中透過反覆將列表減半來定位搜尋值。

**binary search tree (BST) (二元搜尋樹)**
一種二元樹，其中左子樹的鍵都小於根鍵，右子樹的所有鍵都大於或等於根鍵，並且每個子樹本身也是二元搜尋樹。

**binary system (二進位系統)**
使用兩個符號（0 和 1）的數字系統。

**binary tree (二元樹)**
每個節點有零、一或兩個子樹的樹。

**bit (位元)**
二進位數字的縮寫。在電腦中，值為 0 或 1 的基本儲存單元。

**bit depth (位元深度)**
在取樣過程中代表樣本的位元數。

**bit pattern (位元模式)**
位元的序列（0 和 1）。

**bit rate (位元率)**
每秒傳輸的位元數。

**bitmap graphic (點陣圖形)**
一種圖形表示，其中像素的組合定義圖像。

**black-box testing (黑箱測試)**
基於系統需求而非程式知識的測試。

**block cipher (區塊加密法)**
一種一次加密或解密一組字元的加密法。

**Bluetooth (藍牙)**
旨在小範圍內連接設備的無線技術。

**Boolean algebra (布林代數)**
用於操作只能取兩個值之一（真或假）的物件的代數。

**bootstrap (啟動程序)**
當電腦開啟時將作業系統載入主記憶體的過程。

**breadth-first traversal (廣度優先遍歷)**
一種圖遍歷方法，其中與當前節點相鄰的節點在其後代之前處理。

**browser (瀏覽器)**
顯示 WWW 文件的應用程式。

**brute-force search (暴力搜尋)**
一種檢查搜尋樹中每條路徑直到找到目標的搜尋方法。

**bubble sort (氣泡排序)**
一種排序演算法，其中每次遍歷資料都會將最低元素移動（冒泡）到列表未排序部分的開頭。

**bucket (桶)**
在雜湊演算法中，可以容納多個資料單元的位置。

**bucket hashing (桶式雜湊)**
一種使用桶來減少碰撞的雜湊方法。

**bus (匯流排)**
連接電腦中硬體元件的實體通道：匯流排拓撲網路中使用的共享實體介質。

**byte (位元組)**
儲存單位，通常為 8 位元。

**bytecode (位元組碼)**
Java 原始程式編譯成的機器語言。

**C language (C 語言)**
由 Dennis Ritchie 開發的程序化語言。

**C++ language (C++ 語言)**
由 Bjarne Stroustrup 開發的物件導向語言。

**cache memory (快取記憶體)**
一種小型、快速的記憶體，用於保存正在處理的資料項目。

**Caesar cipher (凱撒密碼)**
Julius Caesar 使用的一種移位加密法。

**cardinality (基數)**
在關聯式資料庫中，每個關聯中的總行數。

**cellular telephony (行動電話)**
一種無線通訊技術，其中一個區域被劃分為蜂巢。每個蜂巢由發射器服務。

**central processing unit (CPU) (中央處理單元)**
包含控制元件以解釋指令的電腦部分。在個人電腦中，包含控制單元和算術邏輯單元的微晶片。

**certification authority (CA) (憑證頒發機構)**
將公鑰綁定到實體並頒發憑證的組織。

**challenge–response authentication (挑戰–回應驗證)**
索賠人證明她知道秘密而不發送它的過程。

**child (子節點)**
樹或圖中具有前驅的節點。

**Church–Turing thesis (邱奇-圖靈論題)**
在可計算性理論中，關於透過遞迴（邱奇論題）和等效於圖靈機的機械裝置的可計算函數性質的聯合假設。

**cipher (加密法)**
一種加密解密演算法。

**ciphertext (密文)**
加密的資料。

**circular shift operation (循環移位運算)**
一種移位運算，其中從二進位字一端掉落的位元被插入另一端。

**circular waiting (循環等待)**
作業系統中的一種情況，其中所有涉及的行程和資源形成一個迴圈。

**class (類別)**
資料和函數結合形成一種類型的組合。

**class diagram (類別圖)**
顯示系統中類別之間關係的圖表。

**client–server paradigm (主從式範式)**
一種範式，其中透過網際網路連接的兩台電腦運行程式：一台提供服務，一台請求服務。

**coaxial cable (同軸電纜)**
由一根導體介質和一個作為第二導體的護套製成的電纜。

**code (代碼)**
一組設計用於表示文字符號的位元模式。

**code generator (代碼生成器)**
編譯器或直譯器中創建機器語言代碼的過程。

**cohesion (內聚)**
描述模組中過程彼此相關程度的模組屬性。

**collision (碰撞)**
在雜湊中，當雜湊演算法為一次插入產生一個位址，而該位址已被佔用時發生的事件。

**collision resolution (碰撞解決)**
碰撞後確定替代位址的演算法過程。

**color depth (色彩深度)**
用於表示像素顏色的位元數。

**column-major storage (以行為主儲存)**
一種儲存二維陣列的方法，其中元素按列儲存。

**COmmon Business-Oriented Language (COBOL) (通用商業導向語言)**
由 Grace Hopper 開發的商業程式語言。

**compact disk (CD) (光碟)**
一種直接存取光學儲存介質。

**compact disk read-only memory (CD-ROM) (唯讀光碟)**
一種光碟，其中資料由製造商寫入光碟，並且只能由使用者讀取。

**compact disk recordable (CD-R) (可錄式光碟)**
使用者只能寫入一次，但可以讀取多次的光碟。

**compact disk rewritable (CD-RW) (可重寫光碟)**
可以多次寫入和多次讀取的光碟。

**compilation (編譯)**
在執行程式之前將用高階語言編寫的整個原始程式翻譯成機器語言的過程。

**compiler (編譯器)**
將原始程式轉換為可執行目的碼的系統軟體：傳統上與高階語言相關聯。另見*組譯器*。

**complex instruction set computer (CISC) (複雜指令集電腦)**
定義了廣泛指令集的電腦，即使是那些較少使用的指令。

**composite type (複合型別)**
由兩個或多個簡單型別組成的資料型別。

**compound statement (複合陳述式)**
在某些程式語言中，被語言視為一個整體的陳述式（指令）集合。

**computer language (電腦語言)**
用於為電腦編寫程式的任何語法語言，如機器語言、組合語言、C、COBOL 和 FORTRAN。

**conceptual level (概念層級)**
與資料庫的邏輯結構有關。它處理資料庫的意義，而不是其實體實作。

**confidentiality (機密性)**
定義程序以向未經授權的實體隱藏資訊的安全目標。

**connecting device (連接設備)**
連接電腦或網路的設備。

**connectionless protocol (無連接協定)**
無需建立連接或終止連接的資料傳輸協定。

**constant (常數)**
在程式執行期間不能更改的資料值。與*變數*相對。

**control bus (控制匯流排)**
在電腦組件之間傳遞資訊的匯流排。

**control statement (控制陳述式)**
改變原始程式中循序控制流程的陳述式。

**control structure testing (控制結構測試)**
一種白箱測試方法，使用不同類別的測試：條件測試、資料流測試和迴圈測試。

**control unit (控制單元)**
CPU 的組件，解釋指令並控制資料流。

**controller (控制器)**
圖靈機的一個組件，相當於電腦的 CPU。

**copyright (版權)**
版權是對書面或創作作品的權利。它賦予作者複製、分發和展示作品的專有權利。

**country domain (國家網域)**
網域名稱系統中的子網域，使用兩個字元（代表國家）作為最後的後綴。

**coupling (耦合)**
兩個獨立函數之間相互依賴性的度量。

**cryptographic hash function (密碼雜湊函數)**
從訊息創建訊息摘要的函數。

**cryptography (密碼學)**
轉換訊息使其安全並免受攻擊的科學與藝術。

**current directory (當前目錄)**
在 UNIX 和 Linux 中，使用者目前所在的目錄。

**cycle (週期)**
圖形路徑，其長度大於 1，起點和終點為同一頂點。

**data bus (資料匯流排)**
電腦內部用於在組件之間傳遞資料的匯流排。

**data compression (資料壓縮)**
在不顯著損失的情況下減少資料量。

**data confidentiality (資料機密性)**
旨在保護資料免受洩露攻擊、窺探和流量分析的安全服務。

**data file (資料檔)**
僅包含資料而不包含程式的檔案。

**data flow diagram (資料流程圖)**
顯示系統中資料移動的圖表。

**data integrity (資料完整性)**
旨在保護資料免受修改、插入、刪除和重播的安全服務。

**data link layer address (資料連結層位址)**
資料連結層中使用的位址，有時稱為 MAC 位址，有時稱為實體位址。

**data processor (資料處理器)**
輸入資料、處理資料並輸出結果的實體。

**data structure (資料結構)**
組織起來顯示個別元素之間關係的資料的語法表示。

**data type (資料型別)**
定義為操作它們的一組命名值和操作，例如字元和整數。

**data-link layer (資料連結層)**
TCP/IP 協定的第二層。

**database (資料庫)**
有組織的資訊集合。

**database management system (DBMS) (資料庫管理系統)**
操作資料庫的程式或一組程式。

**database model (資料庫模型)**
定義資料邏輯設計的模型。

**datagram (資料包)**
獨立的資料單元。

**DC value (直流值)**
不隨時間變化的值。

**deadlock (死結)**
一個工作完成任務所需的資源被其他工作佔用的情況。

**decimal digit (十進位數字)**
十進位系統中的符號。

**decimal system (十進位系統)**
使用十個符號（0 到 9）表示數字的方法。

**decision (決策)**
在程式設計中，程式應選擇的兩條路徑之一。

**declarative language (宣告式語言)**
使用邏輯推理原則回答查詢的電腦語言。

**declarative paradigm (宣告式範式)**
使用邏輯推理原則回答查詢的範式。

**decode (解碼)**
控制單元對指令的解釋。

**decrement statement (遞減陳述式)**
從變數值減 1 的陳述式。

**decryption (解密)**
從加密資料恢復原始訊息。見*加密*。

**decryption algorithm (解密演算法)**
解密加密訊息以創建明文的演算法。

**default logic (預設邏輯)**
一種邏輯，其中論證的預設結論如果是與知識庫內容一致的則可以接受。

**delete operation (刪除操作)**
根據呼叫中給出的標準刪除元組的操作。在關聯式資料庫中，從關聯中刪除元組的操作。

**demand paging (請求分頁)**
一種記憶體分配方法，其中程式的頁面僅在需要時才載入記憶體。

**demand paging and segmentation (請求分頁與分段)**
一種記憶體分配方法，其中程式的頁面或區段僅在需要時才載入記憶體。

**demand segmentation (請求分段)**
一種記憶體分配方法，其中程式的區段僅在需要時才載入記憶體。

**demodulator (解調器)**
將信號轉換為資料的設備。

**dendrite (樹突)**
在神經元中，充當輸入設備的部分。

**denial of service (阻斷服務)**
對安全可用性目標的唯一攻擊，可能會減慢或中斷系統。

**depth-first traversal (深度優先遍歷)**
一種遍歷方法，其中節點的所有後代都在任何相鄰節點（兄弟節點）之前處理。

**dequeue**
從佇列中刪除元素。

**descendant (後代)**
從當前節點到葉子的路徑中的任何節點。

**design phase (設計階段)**
軟體系統生命週期的一個階段，定義系統將如何完成分析階段定義的內容。

**development process (開發過程)**
系統生命週期之外創建軟體的過程。

**device manager (設備管理器)**
作業系統的一個組件，控制對輸入/輸出設備的存取。

**dictionary-based encoding (基於字典的編碼)**
一種在會話期間創建字典的壓縮方法。

**difference operation (差集操作)**
對兩個集合的操作，其結果是第一個集合減去兩個集合中的共同元素，或在關聯式資料庫中應用於具有相同屬性的兩個關聯的運算子。結果關聯中的元組是那些在第一個關聯中但不在第二個關聯中的元組。

**digest (摘要)**
訊息的壓縮影像。

**digit extraction hashing (數字提取雜湊)**
從鍵中提取選定數字並將其用作位址的過程。

**digit extraction method (數字提取方法)**
使用數字提取的雜湊方法。

**digital (數位)**
離散（非連續）實體。

**Digital data (數位資料)**
由離散值表示的資料。

**digital signal (數位信號)**
具有多個不同值的信號。

**digital signature (數位簽章)**
用於驗證訊息發送者並保護其資料完整性的方法。

**digital subscriber line (DSL) (數位用戶迴路)**
支援透過現有電話線進行高速通訊的技術。

**digital versatile disk (DVD) (數位多功能光碟)**
直接存取光學儲存介質。

**digital-to-analog conversion (數位對類比轉換)**
用類比信號表示數位資料。

**digital-to-digital conversion (數位對數位轉換)**
用數位信號表示數位資料。

**digraph (有向圖)**
有向圖。

**direct hashing (直接雜湊)**
一種無需演算法修改即可獲得鍵的雜湊方法。

**direct memory access (DMA) (直接記憶體存取)**
一種 I/O 形式，其中特殊設備控制記憶體和 I/O 設備之間的資料交換。

**directed graph (有向圖)**
在線（弧）上指示方向的圖。

**directory (目錄)**
包含其他檔案名稱和位址的檔案。

**discrete cosine transform (DCT) (離散餘弦轉換)**
JPEG 編碼中使用的數學轉換。

**distributed database (分散式資料庫)**
資料儲存在多台電腦上的資料庫。

**distributed system (分散式系統)**
控制位於不同地點電腦中資源的作業系統。

**division remainder method (除法餘數法)**
一種雜湊類型，其中鍵除以一個數字，餘數用作位址。

**domain name (網域名稱)**
在 DNS 中，由點分隔的一系列標籤。

**Domain Name Server (DNS) (網域名稱伺服器)**
保存有關網際網路網域名稱資訊的電腦。

**doman name space (網域名稱空間)**
組織名稱空間的方法，其中名稱定義在頂部為根的倒置樹結構中。

**dotted-decimal notation (點分十進位表示法)**
為使 IP 位址更易於閱讀而設計的表示法：每個位元組轉換為十進位數字；數字由點分隔。

**DSL**
數位用戶迴路。

**dynamic RAM (DRAM) (動態 RAM)**
單元使用電容器的 RAM。DRAM 必須定期刷新以保留其資料。

**edge (邊)**
沒有方向的圖形線。

**edge detection (邊緣偵測)**
一種影像處理方法，透過查看顏色或紋理變化的區域來找出影像中的邊緣。

**electrically erasable programmable read-only memory (EEPROM) (電子可抹除可程式化唯讀記憶體)**
可程式化唯讀記憶體，可以使用電子脈衝進行編程和擦除，而無需從電腦中移除。

**electronic mail (email) (電子郵件)**
一種基於信箱位址而不是主機對主機交換的電子發送訊息的方法。

**emacs**
Unix 中的文字編輯器。

**encryption (加密)**
將訊息轉換為除非解密否則無法讀取的形式。

**encryption algorithm (加密演算法)**
加密明文訊息的演算法。

**end system (終端系統)**
資料的發送者或接收者。

**end users (終端使用者)**
在 DBMS 術語中，直接存取資料庫的使用者。

**enqueue**
在佇列中插入一個元素。

**entity authentication (實體驗證)**
一種旨在讓一方驗證另一方身份的技術。

**entity–relation (E-R) model (實體-關係模型)**
定義關聯式資料庫中實體及其關係的模型。

**entity–relationship (E-R) diagram (實體-關係圖)**
在實體-關係模型中使用的圖表。

**ephemeral port number (臨時埠號)**
客戶端使用的埠號。

**erasable programmable read-only memory (EPROM) (可抹除可程式化唯讀記憶體)**
可程式化的唯讀記憶體。擦除 EPROM 需要將其從電腦中移除。

**error report file (錯誤報告檔)**
在檔案更新過程中，偵測到的錯誤報告。

**ethical principle (倫理原則)**
在使用電腦時評估我們對世界其他地方責任的一種方法是基於倫理做出決策。

**Excess representation (超額表示法)**
用於儲存分數指數值的數字表示方法。

**Excess_1023**
用於表示浮點數的高精度 IEEE 標準。

**Excess_127**
用於表示浮點數的低精度 IEEE 標準。

**execute (執行)**
控制單元向電腦不同部分發送命令。

**expert system (專家系統)**
使用知識表示來執行通常需要人類專業知識的任務的系統。

**expression (表達式)**
運算子和運算元的序列，可化簡為單一值。

**expression tree (表達式樹)**
一棵倒置的樹，其中根和節點是運算子，葉子是運算元。

**external level (外部層級)**
與使用者互動的資料庫部分。

**Facebook**
擁有超過十億使用者的社群網路網站。

**Fast Ethernet (快速乙太網路)**
資料速率為 100 Mps 的乙太網路實作。

**fetch (提取)**
指令週期中將要執行的指令從記憶體中取出的部分。

**fiber-optic cable (光纖電纜)**
以脈衝形式傳輸信號的介質。它由另一層玻璃或塑膠（包層）內的玻璃或塑膠薄圓柱體（芯）組成。

**field (欄位)**
在描述資訊中有意義的最小命名資料單位。欄位可以是變數或常數。

**File Transfer Protocol (FTP) (檔案傳輸協定)**
TCP/IP 中的應用層服務，用於從遠端站點傳輸檔案。

**finite state automaton (有限狀態自動機)**
具有預定義數量狀態的機器。

**firewall (防火牆)**
安裝在組織內部網路和網際網路其餘部分之間以提供安全性的設備。

**FireWire (火線)**
具有高速串列介面的 I/O 設備控制器，以封包形式傳輸資料。

**first in, first out (FIFO) (先進先出)**
一種演算法，其中添加到列表的第一個資料項目首先從列表中移除。

**flat-file (扁平檔案)**
與組織中任何其他檔案無關的獨立檔案。

**floating-point representation (浮點數表示法)**
一種數字表示法，其中小數點的位置浮動以產生更好的精度。通常用於在電腦中表示實數。

**follow (追蹤)**
如何在 Twitter 上連接其他使用者。

**following (正在追蹤)**
Twitter 中的多對一關係，其中許多使用者追蹤一個使用者。

**follwing**
追蹤您認識的人以在您的首頁上查看他們的推文。

**formal parameters (形式參數)**
函式中的參數宣告，用於描述要傳遞給函式的資料類型。

**FORmula TRANslation (FORTRAN) (公式翻譯)**
用於科學和工程應用的高階程序化語言。

**fragmented distributed database (分割式分散式資料庫)**
資料本地化的分散式資料庫。

**frame (訊框)**
資料連結層的資料單元。

**frames (框架)**
類似於語意網路的知識表示方法。

**frequency masking (頻率掩蔽)**
一個頻率完全掩蓋另一個頻率的過程。

**friend (朋友)**
在 Facebook 中，可以接收其他使用者發布內容的使用者。

**friendship (朋友關係)**
在 Facebook 中，分享僅在朋友之間進行。朋友關係是一對一的互惠關係。

**front (前端)**
由 dequeue 操作刪除的佇列中的下一個元素。

**function (函式)**
在函數式範式中，將輸入列表映射到輸出列表的黑盒子。

**functional language (函數式語言)**
一種程式被視為數學函數的程式語言。

**functional paradigm (函數式範式)**
一種將程式視為數學函數的範式。

**general linear list (一般線性串列)**
可以在列表中任何位置插入或刪除資料的列表。

**generic domain (通用網域)**
網域名稱空間中的子網域，使用通用後綴。

**Gigabit Ethernet (十億位元乙太網路)**
具有十億位元 (1000 Mbps) 資料速率的乙太網路。

**glass-box testing (玻璃箱測試)**
見*白箱測試*。

**Gödel number (哥德爾數)**
分配給可以用特定語言編寫的每個程式的數字。

**graph (圖形)**
稱為頂點的節點和連接節點對的線段（稱為邊或弧）的集合。

**Graphic Interchange Format (GIF) (圖形交換格式)**
每像素 8 位元的點陣圖圖像。

**graphical user interface (GUI) (圖形使用者介面)**
定義圖示和圖示操作的使用者介面。

**Guided media (導引介質)**
電纜。

**hacker (駭客)**
可能造成傷害的精明電腦專家。

**halting problem (停機問題)**
編寫一個程式來測試任何由其哥德爾數表示的程式是否會終止。

**hardware (硬體)**
電腦系統的任何實體組件，例如鍵盤或印表機。

**hardware abstraction layer (HAL) (硬體抽象層)**
Windows 系統中隱藏上層差異的最低層級程式。

**hashed file (雜湊檔案)**
使用雜湊方法之一搜尋的檔案。

**hashed MAC (HMAC) (雜湊 MAC)**
ITU 的一項建議，使用稱為 ASN.1 的知名標準描述公鑰分發中的憑證。

**hashing method (雜湊方法)**
存取雜湊檔案的方法。

**hashtag (主題標籤)**
指示推文中重要單詞的方法。它以井號 (#) 開頭。

**HDMI (High-Definition Multimedia Interface) (高畫質多媒體介面)**
HDMI 是現有類比視訊標準的數位替代品。

**header (標頭)**
添加到封包開頭用於路由和其他目的的資訊。

**heuristic search (啟發式搜尋)**
使用規則或一條資訊使搜尋更有效率的搜尋。

**hexadecimal digit (十六進位數字)**
十六進位系統中的符號。

**hexadecimal system (十六進位系統)**
基底為 16 的數字系統。其數字為 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, 和 F。

**hierarchical model (階層式模型)**
將資料組織成可以從上到下搜尋的樹狀結構的資料庫模型。

**high-level language (高階語言)**
一種（可移植）程式語言，旨在允許程式設計師專注於應用程式而不是特定電腦或作業系統的結構。

**high-order logic (高階邏輯)**
一種將謂詞邏輯中量詞 ∀ 和 ∃ 的範圍擴展到綁定謂詞和變數的邏輯。

**hold state (保持狀態)**
工作等待載入記憶體的狀態。

**home address (主位址)**
在雜湊列表中，由雜湊演算法產生的第一個位址。

**home directory (家目錄)**
在 UNIX 或 Linux 中，使用者首次登入時所在的目錄。

**home page (首頁)**
Web 上可用的超文本文件的主要頁面。

**host (主機)**
網路上的站點或節點。

**host identifier (主機標識符)**
站點的標識符。

**hub (集線器)**
連接網路中其他設備的設備。

**Huffman coding (霍夫曼編碼)**
使用可變長度代碼的統計壓縮方法。

**hypertext (超文本)**
包含指向其他文件嵌入連結的文件。

**Hypertext Markup Language (HTML) (超文本標記語言)**
用於指定 Web 文件內容和格式的電腦語言：允許文本包含字體、佈局、嵌入式圖形和指向其他文件的連結。

**Hypertext Transfer Protocol (HTTP) (超文本傳輸協定)**
用於在網際網路上檢索網頁的協定。

**identifier (識別碼)**
程式語言中賦予物件的名稱。

**image processing (影像處理)**
人工智慧的一個領域，處理透過代理的人造眼睛對物體的感知。

**imperative language (指令式語言)**
程序化語言的另一個名稱。

**imperative paradigm (指令式範式)**
程序化範式的另一個名稱。

**implementation phase (實作階段)**
軟體系統生命週期的一個階段，在此階段創建實際程式。

**increment statement (遞增陳述式)**
在 C 或 C++ 中，將整數值加 1 的陳述式。

**incremental model (增量模型)**
軟體工程中的一種模型，其中整個套件是以每個模組僅包含一個外殼構建的：模組隨著套件的每次迭代而增加複雜性。

**index (索引)**
陣列中元素的位址。

**indexed color (索引色)**
點陣圖形中的一種技術，在每個應用程式中僅使用全彩的一部分來編碼顏色。

**indexed file (索引檔案)**
使用索引進行隨機存取的檔案。

**infix (中綴)**
運算子位於兩個運算元之間的算術表示法。

**infrared waves (紅外線)**
光譜中 300 GHz 到 400 THz 的部分，用於短距離通訊。

**inheritance (繼承)**
擴展類別以創建新類別的能力，同時保留基類的資料物件和方法並添加新的資料物件和方法。

**inorder traversal (中序遍歷)**
一種二元樹遍歷方法，其中根在左子樹之後和右子樹之前遍歷。

**input (輸入)**
操作的給定資料。

**input data (輸入資料)**
提交給電腦以運行程式的使用者資訊。

**input/output (I/O) controller (輸入/輸出控制器)**
控制對輸入/輸出設備存取的設備。

**input/output subsystem (輸入/輸出子系統)**
電腦組織中從外部接收資料並向外部發送資料的部分。

**insert operation (插入操作)**
在關聯式資料庫中，將元組插入關聯的操作。

**insertion sort (插入排序)**
一種排序演算法，其中來自列表未排序部分的第一個元素被插入到列表已排序部分的適當位置。

**instruction (指令)**
告訴電腦做什麼的命令。

**instruction register (指令暫存器)**
CPU 中在控制單元解釋之前保存指令的暫存器。

**integer (整數)**
整數，沒有小數部分的數字。

**integrated circuit (積體電路)**
單一晶片上的電晶體、佈線和其他組件。

**integrity (完整性)**
保護資料免受修改、插入、刪除或重播的安全目標。

**intellectual property (智慧財產)**
諸如思想、發明、技術、藝術品、音樂和文學等無形的東西，一個人可以聲稱擁有所有權。

**intelligent agent (智慧代理)**
感知其環境、從中學習並與之智慧互動的代理。

**interface (介面)**
要傳遞或從操作回傳的公開操作或資料的列表。

**internal level (內部層級)**
定義資料實際儲存位置的資料庫部分。

**internal node (內部節點)**
除根和葉之外的任何樹節點：樹中間的節點。

**International Organization for Standardization (ISO) (國際標準化組織)**
定義和開發各種主題標準的全球性組織。

**internet (互連網)**
internetwork 的縮寫。

**Internet (網際網路)**
使用 TCP/IP 協定套件的全球網際網路。

**Internet address (網際網路位址)**
用於在網際網路上唯一識別電腦的 32 位元位址。

**Internet Protocol (IP) (網際網路協定)**
TCP/IP 協定中的網路層協定，負責將封包從一台電腦傳輸到網際網路上的另一台電腦。

**Internet Protocol version 6 (IPv6) (網際網路協定第六版)**
具有增強位址空間和重新設計的封包及協定的新 IP。

**Internet service provider (ISP) (網際網路服務提供者)**
提供網際網路服務的組織。

**internetwork (互連網)**
網路的網路。

**interpretation (直譯)**
將原始程式的每一行翻譯成相應的目的程式並執行該行的過程。

**interpreter (直譯器)**
將高階語言的原始程式逐行翻譯並立即執行每一行的程式。

**interrupt driven I/O (中斷驅動 I/O)**
一種 I/O 形式，其中 CPU 發出 I/O 命令後，繼續服務其他行程，直到收到 I/O 操作完成的中斷信號。

**intersection operation (交集操作)**
對兩個集合的操作，其結果是具有兩個集合共同元素的集合。

**intersector gap (磁區間隙)**
磁碟上磁區之間的間隙。

**intertrack gap (磁軌間隙)**
磁帶上磁軌之間的間隙。

**intracoded frame (I-frame) (幀內編碼影格)**
在 MPEG 中，一個獨立的影格。

**inverted file (倒排檔案)**
根據第二個鍵排序的檔案。

**IP address (IP 位址)**
見*網際網路位址*。

**IP datagram (IP 資料包)**
網路層的資料單元。

**IP new generation (IPng) (IP 新一代)**
IPv6 的另一個名稱。

**isolated I/O (獨立 I/O)**
一種定址 I/O 模組的方法，其中用於讀/寫記憶體的指令與用於讀/寫輸入/輸出設備的指令完全不同。

**Java**
一種物件導向的程式語言，用於在網際網路上創建獨立程式或動態文件。

**job (工作)**
當程式被選中執行時，它就變成了工作。

**job scheduler (工作排程器)**
從等待移至記憶體的工作佇列中選擇要處理的工作的排程器。

**join operation (連接操作)**
關聯式資料庫中的一種操作，它獲取兩個關聯並基於共同屬性將它們組合起來。

**Joint Photographic Experts Group (JPEG) (聯合圖像專家小組)**
壓縮圖像的標準。

**kernel (核心)**
作業系統的主要部分。

**key (鍵)**
用於識別記錄（結構）的一個或多個欄位。

**key-distribution center (KDC) (金鑰分發中心)**
在兩方之間建立共享秘密金鑰的受信任第三方。

**keyboard (鍵盤)**
提供逐字元輸入的輸入設備。

**land (平台)**
在光碟上，位元模式轉換中未被雷射擊中的區域。通常代表一個位元。

**last in, first out (LIFO) (後進先出)**
一種演算法，其中添加到列表的最後一個資料項目首先從列表中移除。

**leaf (葉)**
具有一個傳入弧且沒有傳出弧的圖或樹節點。

**Lempel Ziv (LZ) encoding (Lempel Ziv 編碼)**
一種使用字典的壓縮演算法。

**Lempel Ziv Welch (LZW) encoding (Lempel Ziv Welch 編碼)**
LZ 編碼的增強版本。

**lexical analyzer (詞彙分析器)**
翻譯過程中使用的程式，逐個符號讀取原始程式碼並創建符記列表。

**linear list (線性串列)**
一種列表結構，其中除最後一個元素外，每個元素都有唯一的後繼。

**link (連結)**
在列表結構中，標識列表中下一個元素的欄位。

**linked list (鏈結串列)**
一種線性列表結構，其中元素的順序由連結欄位決定。

**linked list resolution (鏈結串列解決)**
雜湊中的一種碰撞解決方法，使用單獨的區域用於同義詞，這些同義詞在鏈結串列中維護。

**Linux**
由 Linus Torvalds 開發的作業系統，使 UNIX 在 Intel 微處理器上運行時更有效率。

**LISP**
一種列表處理程式語言，其中一切都被視為列表。

**list (列表)**
包含在主記憶體中的有序資料集。

**literal (字面值)**
程式中使用的常數。

**local area network (LAN) (區域網路)**
連接有限區域內設備的網路。

**local variable (區域變數)**
在區塊或模組內定義的變數。

**logical operation (邏輯運算)**
結果為邏輯值（真或假）的運算。

**logical operator (邏輯運算子)**
組合布林值以獲得新布林值的運算子。

**logical shift operation (邏輯移位運算)**
不保留數字符號的移位運算。

**loop (迴圈)**
在程式中，導致一個或多個陳述式重複的結構化程式設計建構。在圖中，起點和終點為同一頂點的線。

**loop statement (迴圈陳述式)**
導致程式迭代一組陳述式的陳述式。

**lossless data compression (無損資料壓縮)**
沒有資料丟失的資料壓縮。用於壓縮文字或程式。

**lossy data compression (失真資料壓縮)**
允許丟失某些資料的資料壓縮。用於圖像、音訊或視訊壓縮。

**MAC addresses (MAC 位址)**
資料連結層設備的位址。

**machine cycle (機器週期)**
重複的提取、解碼和執行操作集合。

**machine language (機器語言)**
電腦中央處理器原生的指令，無需組譯或編譯即可執行。

**macro (巨集)**
可以重複使用的自訂設計程序。

**magnetic disk (磁碟)**
具有隨機存取能力的儲存介質。

**magnetic tape (磁帶)**
具有循序存取能力的儲存介質。

**Mail Transfer Agent (郵件傳輸代理)**
電子郵件通訊中使用的客戶端-伺服器程式。

**main memory (主記憶體)**
電腦的主要記憶體，由中速隨機存取記憶體組成。與*快取記憶體*相對。

**maintainability (可維護性)**
指保持系統正確運行和更新的品質。

**mantissa (尾數)**
浮點數中顯示數字有效數字的部分。

**mask (遮罩)**
包含用於控制位元運算中位元設定的位元配置的變數或常數。

**masquerading (偽裝)**
一種針對資訊完整性的攻擊類型，其中攻擊者冒充他人。

**master disk (母片)**
在 CD-ROM 中創建的第一個組件。

**master file (主檔)**
包含有關應用程式最新資料的永久檔案。

**medium access control (MAC) address (媒體存取控制位址)**
見*資料連結層位址*。

**memory (記憶體)**
電腦的主記憶體，由隨機存取記憶體 (RAM) 和唯讀記憶體 (ROM) 組成，用於儲存資料和程式指令。

**memory management (記憶體管理)**
控制主記憶體使用的作業系統組件。

**memory-mapped I/O (記憶體映射 I/O)**
一種在單一位址空間中定址 I/O 模組的方法，用於記憶體和 I/O 設備。

**Message Access Agent (MAA) (訊息存取代理)**
拉取儲存的電子郵件訊息的客戶端-伺服器程式。

**message authentication code (MAC) (訊息驗證碼)**
包含兩方之間秘密的訊息摘要。

**message digest (訊息摘要)**
透過對訊息應用雜湊函數創建的固定長度字串。

**message transfer agent (MTA) (訊息傳輸代理)**
透過網際網路傳輸訊息的 SMTP 程式。

**method (方法)**
物件導向語言中的函式。

**metropolitan area network (MAN) (都會區域網路)**
可以跨越城市或城鎮的網路。

**microcomputer (微電腦)**
小到足以放在桌面上的電腦。

**Microsoft Disk Operating System (MS-DOS) (微軟磁碟作業系統)**
基於 DOS 並由微軟開發的作業系統。

**modal logic (模態邏輯)**
包含確定性和可能性的邏輯擴展。

**modem (數據機)**
調變器-解調器的組合。

**modularity (模組化)**
將大型專案分解為易於理解和處理的小部分。

**modulator (調變器)**
將資料轉換為信號的設備。

**module (模組)**
應用模組化到專案所創建的小部分。

**modulo division (模數除法)**
除以兩個數字並保留餘數。

**monitor (監視器)**
提供輸出的非儲存設備。

**Monitor (監視器)**
監視器顯示輸出，同時回顯在鍵盤上輸入的內容。

**monoalphabetic cipher (單字母加密法)**
一種加密法，其中相同的字元總是加密成相同的，無論其在文本中的位置如何。

**monoprogramming (單道程式設計)**
允許一次只有一個程式在記憶體中的技術。

**moral rule (道德規則)**
倫理學中的一項原則，規定我們應該避免做任何違反普遍道德的事情。

**moral rules (道德規則)**
第一個倫理原則指出，當我們做出倫理決策時，我們需要考慮該決策是否符合普遍接受的道德原則。

**Moving Picture Experts Group (MPEG) (動態影像專家小組)**
壓縮視訊（和音訊）的失真壓縮方法。

**MPEG audio layer (MP3) (MPEG 音訊層 3)**
基於 MPEG 的音訊壓縮標準。

**multidimensional array (多維陣列)**
具有多於一級索引的元素的陣列。

**Multiple Instruction Stream, Single Data Stream (MISD) (多指令流，單資料流)**
多個流在單一資料上運行的電腦。

**multiple instruction_stream, multiple data stream (MIMD) (多指令流，多資料流)**
具有多個 CU、多個 ALU 和多個記憶體單元的電腦。

**multiprogramming (多重程式設計)**
允許在處理時有多個程式駐留在記憶體中的技術。

**multithreading (多執行緒)**
某些語言（如 Java）支援的平行處理。

**mutual exclusion (互斥)**
作業系統施加的一種條件，其中只有一個行程可以持有資源。

**name (名稱)**
在關聯式資料庫術語中，關聯的標識符。

**name space (名稱空間)**
分配給網際網路上機器的所有名稱。

**network (網路)**
可以共享資源的連接節點系統。

**network layer (網路層)**
TCP/IP 模型中的第三層，負責將封包從原始主機傳遞到最終目的地。

**network model (網路式模型)**
一種資料庫模型，其中記錄可以有多個父記錄。

**neural network (神經網路)**
以人腦為模型的神经元網路。

**neuron (神經元)**
負責在人腦和神經系統中傳輸資訊的個別細胞。

**new master file (新主檔)**
當檔案更新時從舊主檔創建的主檔。

**news (新聞)**
Facebook 允許您為朋友發布新聞（稱為動態更新）。這可以是一條長訊息（最多 60000 個字元）、指向網頁的連結、照片或影片。

**no preemption (無搶佔)**
作業系統無法暫時分配資源的情況。

**node (節點)**
在資料結構中，包含資料和用於處理資料結構的結構元素的元素。

**node-to-node (節點對節點)**
資料連結層的通訊。

**nonpolynomial problem (非多項式問題)**
無法以多項式複雜度解決的問題。

**nonpositional number system (非進位制數字系統)**
符號的位置不定義符號值的數字系統。

**Nonstorage device (非儲存設備)**
非儲存設備允許 CPU/記憶體與外部世界通訊，但它們不能儲存資訊。

**nonstorage device (非儲存設備)**
允許 CPU 和記憶體之間通訊而不儲存資訊的設備。

**normal form (NF) (正規形式)**
關聯式資料庫正規化過程中的一步。

**normalization (正規化)**
在關聯式資料庫中，將正規形式應用於關聯式模型的過程。

**NOT operator (NOT 運算子)**
將 0 位元更改為 1 或將 1 位元更改為 0 的操作。

**null pointer (空指標)**
不指向任何東西的指標。

**number system (數字系統)**
使用一組符號來定義值的系統。

**object program (目的程式)**
從編譯器或直譯器創建的機器語言代碼。

**object-oriented analysis (物件導向分析)**
開發過程的分析階段，其中實作使用物件導向語言。

**object-oriented database (物件導向資料庫)**
將資料視為結構（物件）的資料庫。

**object-oriented design (物件導向設計)**
給出物件導向程式設計中每個類別的細節和代碼。

**object-oriented language (物件導向語言)**
將物件和應用於它們的操作結合在一起的程式語言。

**object-oriented paradigm (物件導向範式)**
程式作用於主動物件的範式。

**octal digit (八進位數字)**
基底為 8 的數字。

**octal system (八進位系統)**
基底為 8 的數字系統：八進位數字是 0 到 7。

**old master file (舊主檔)**
與交易檔結合處理以創建新主檔的主檔。

**one-dimensional array (一維陣列)**
只有一級索引的陣列。

**one-time pad (一次性密碼本)**
一種加密法，其中為每次加密隨機選擇金鑰。

**one’s complement (一的補數)**
反轉變數中位元值的位元運算。

**open addressing resolution (開放定址解決)**
新位址在主區域中的碰撞解決方法。

**operability (可操作性)**
解決系統易用性的品質因素。

**operand (運算元)**
陳述式中執行操作的物件。與*運算子*相對。

**operating system (作業系統)**
控制計算環境並為使用者提供介面的軟體。

**operator (運算子)**
表示對資料（運算元）操作的語法符記。與*運算元*相對。

**optical storage device (光學儲存設備)**
使用（雷射）光來儲存和檢索資料的 I/O 設備。

**OR operator (OR 運算子)**
僅當兩個輸入為 0 時結果為 0，否則為 1 的二元運算。

**output (輸出)**
操作產生的資料。

**output data (輸出資料)**
運行電腦程式的結果。

**output device (輸出設備)**
可以寫入但不能讀取的設備。

**overflow (溢位)**
當沒有足夠的位元以二進位表示數字時產生的情況。

**packet-filter firewall (封包過濾防火牆)**
使用過濾表來保護組織的防火牆。

**packetizing (封包化)**
將資料封裝在封包中。

**page (頁面)**
程式的大小相等的部分之一。

**paging (分頁)**
一種多重程式設計技術，其中記憶體被劃分為大小相等的區段，稱為*頁框*。

**palette color (調色盤色)**
見*索引色*。

**parallel processing (平行處理)**
一種多重處理形式，透過允許數個處理器同時運作來加速處理。

**parallel system (平行系統)**
同一台機器上有多個 CPU 的作業系統。

**parameter (參數)**
傳遞給函式的值。

**parent (父節點)**
具有一個或多個子節點的樹或圖節點。

**parent directory (父目錄)**
當前目錄正上方的目錄。

**parser (解析器)**
進行解析的實體。

**partitioning (分割)**
一種在多重程式設計中使用的技術，將記憶體劃分為可變長度的區段。

**Pascal**
一種旨在透過強調結構化程式設計方法來教導新手程式設計的程式語言。

**pass by reference (傳參考)**
一種參數傳遞技術，其中被呼叫的函式使用別名引用傳遞的參數。

**pass by value (傳值)**
一種參數傳遞技術，其中變數的值被傳遞給函式。

**patent (專利)**
對智慧財產的權利。

**path (路徑)**
一系列節點，其中每個頂點與下一個頂點相鄰。

**peer-to-peer paradigm (點對點範式)**
兩台對等電腦可以相互通訊以交換服務的範式。

**penetration attack (滲透攻擊)**
滲透意味著侵入系統以存取儲存在電腦或電腦網路中的資料。

**penetration attack (滲透攻擊)**
非法存取電腦以獲取資訊或造成損害。

**perceptron (感知器)**
神經網路中使用的一種簡單的類神經元元件。

**perceptual encoding (感知編碼)**
用於音訊的編碼類型。

**physical agent (實體代理)**
可用於執行各種任務的可程式化系統（機器人）。

**physical layer (實體層)**
TCP/IP 模型中的第一層，負責在網路上發送信號和傳輸位元。

**pico**
Unix 中的另一個文字編輯器。

**picture element (pixel) (圖片元素 / 像素)**
圖像的最小單位。

**pipelining (管線化)**
現代電腦使用的一種技術，透過將指令的不同階段與下一個指令結合來提高吞吐量。

**Pipelining (管線化)**
現代電腦使用一種稱為管線化的技術來提高吞吐量（在每個時間段內執行的指令總數）。其想法是，如果控制單元可以同時執行這些階段中的兩個或三個，那麼下一個指令可以在前一個指令完成之前開始。

**pit (凹坑)**
在光碟上，位元模式轉換中被雷射擊中的區域，通常代表 0 位元。

**pixel (像素)**
見*圖片元素*。

**place value (位值)**
與進位制數字系統中位置相關的值。

**plaintext (明文)**
加密前的文字。

**point-to-point (點對點)**
一種透過傳輸介質連接兩個通訊設備的網路類型。

**pointer (指標)**
包含可用於存取儲存在其他地方的資料的位址的常數或變數。

**polyalphabetic cipher (多字母加密法)**
一種加密法，其中明文中的字元將根據其在文本中的位置更改為密文中的不同字元。

**polycarbonate resin (聚碳酸酯樹脂)**
在 CD-ROM 生產中，注入模具的材料。

**polymorphism (多型)**
在 C++ 中，定義具有相同名稱的數個操作，這些操作在相關類別中可以做不同的事情。

**polynomial problem (多項式問題)**
電腦可以在可接受的時間內解決的問題。

**pop**
堆疊刪除操作。

**port address (埠位址)**
見*埠號*。

**port number (埠號)**
TCP 和 UDP 中用於區分一個行程與另一個行程的位址。

**portability (可移植性)**
與將系統移動到其他硬體環境的難易程度相關的品質因素。

**positional number system (進位制數字系統)**
一種數字系統，其中符號在數字中的位置定義其值。

**postfix (後綴)**
運算子位於其運算元之後的算術表示法。

**postorder traversal (後序遍歷)**
一種二元樹遍歷方法，其中首先處理左子樹，然後是右子樹，然後是根。

**pragmatic analysis (語用分析)**
透過消除歧義來尋找單詞真實含義的句子分析。

**predicate logic (謂詞邏輯)**
一種邏輯系統，其中量詞可以應用於術語但不能應用於謂詞。

**predicted frame (P-frame) (預測影格)**
在 MPEG 中，與前面的 I-frame 或 B-frame 相關的影格。

**Predictive encoding (預測編碼)**
編碼兩個樣本之間的差異而不是編碼樣本本身。

**prefix (前綴)**
運算子位於運算元之前的算術表示法。

**preorder traversal (前序遍歷)**
一種二元樹遍歷，其中首先遍歷左子樹，接下來遍歷根，最後遍歷右子樹。 *(註：此處原文定義有誤，前序遍歷應為根->左->右，原文為左->根->右乃中序遍歷，或原文描述有誤。翻譯按標準定義修正為：一種二元樹遍歷，其中首先遍歷根，接下來遍歷左子樹，最後遍歷右子樹。)* (修正：原文是 "left subtree is traversed first, the root is traversed next"，這實際上是 Inorder。標準 Preorder 是 Root First。但為了保持 verbatim 翻譯原則，我將翻譯原文，並在括號中註明標準定義差異，或者如果原文定義錯誤，我應照翻嗎？通常是照翻，但在教學內容中錯誤會誤導。這裡原文寫的是 "preorder traversal ... left subtree is traversed first..." 這明顯是錯的。查看前面的章節內容，Figure 12.24 正確定義了 Preorder 是 Root first。這裡 Glossary 的定義與章節內容矛盾。為了準確性，我將根據章節內容修正，或照翻並標註。這裡照翻原文定義：左子樹先遍歷，根次之... 這其實是 Postorder 或 Inorder 的混淆。鑑於這是 Glossary，我將翻譯原文文字，讀者應參考章節內容。)
*(更正：再看原文 "preorder traversal: A binary tree traversal in which the left subtree is traversed first, the root is traversed next, and the right subtree is traversed last." 這描述的是 Inorder。真正的 Preorder 是 Root, Left, Right。Postorder 是 Left, Right, Root。鑑於這是一本教科書的附錄，可能存在錯誤。我會翻譯原文的文字，但也許在括號中加註正確定義。)*
(翻譯：一種二元樹遍歷，其中首先遍歷左子樹，其次遍歷根，最後遍歷右子樹。)

**prime area (主要區域)**
在雜湊列表中，包含主位址的記憶體。

**printer (印表機)**
產生硬拷貝的輸出設備。

**privacy (隱私權)**
個人保持某些資訊秘密的權利。

**privacy (隱私權)**
今天，私人和公共機構收集了大量關於公民的個人資訊。一些國家有關於使用這些資訊的道德規則。

**private key (私鑰)**
公鑰加密中使用的兩個金鑰之一。

**procedural language (程序化語言)**
程序化範式中的電腦語言。

**procedural paradigm (程序化範式)**
程式使用程序作用於被動物件的範式。

**procedure-oriented analysis (程序導向分析)**
開發過程的分析階段，其中實作使用程序化語言。

**procedure-oriented design (程序導向設計)**
實作使用程序化語言時的開發過程的設計階段。

**process (行程)**
執行中的程式。

**process manager (行程管理器)**
控制行程的作業系統組件。

**process scheduler (行程排程器)**
調度等待獲取 CPU 存取權的行程的作業系統機制。

**product (乘積)**
將一列數值資料相乘並找出結果的結果。

**program (程式)**
一組指令。

**program counter (程式計數器)**
CPU 中保存要執行的下一條指令在記憶體中位址的暫存器。

**programmable read-only memory (PROM) (可程式化唯讀記憶體)**
內容由製造商電氣設定的記憶體，可由使用者重置。

**programmed I/O (程式控制 I/O)**
一種 I/O 形式，其中 CPU 必須等待 I/O 操作完成。

**programming language (程式語言)**
具有有限單詞和有限規則的語言，旨在解決電腦上的問題。

**project operation (投影操作)**
關聯式資料庫中的一種操作，其中根據標準選擇一組列。

**PROLOG**
一種可以建立事實資料庫和規則知識庫的程式語言。

**propositional logic (命題邏輯)**
基於邏輯運算子和命題術語的邏輯系統。

**protocol (協定)**
電腦之間資料交換的一組規則。

**protocol layering (協定分層)**
使用一組協定來創建處理困難任務的規則層次結構的想法。

**proxy firewall (代理防火牆)**
位於客戶電腦和公司電腦之間的防火牆。它只接受來自客戶電腦的合法訊息。

**proxy firewall (代理防火牆)**
位於客戶電腦和公司電腦之間的代理電腦（有時稱為應用閘道器）。

**pseudocode (偽代碼)**
遵循寬鬆定義語法的類英語陳述式，用於傳達演算法或函數的設計。

**public key (公鑰)**
公鑰加密中的金鑰之一，向公眾公開。

**public-key certificate (公鑰憑證)**
將實體綁定到其公鑰的憑證。

**push**
堆疊插入操作。

**quantifier (量詞)**
謂詞邏輯中使用的兩個運算子：∀ 和 ∃。

**quantization (量化)**
從有限的值集合中分配一個值。

**queue (佇列)**
一種線性串列，其中資料只能在一端（稱為尾端）插入，並從另一端（稱為前端）刪除。

**radix (基數)**
進位制數字系統中的基底。

**random access (隨機存取)**
允許以任意順序檢索資料的儲存方法。

**random access memory (RAM) (隨機存取記憶體)**
儲存資料和程式的電腦主記憶體。

**raster graphic (點陣圖形)**
見*點陣圖形 (bitmap graphic)*。

**read-only memory (ROM) (唯讀記憶體)**
內容無法更改的永久記憶體。

**read/write head (讀/寫頭)**
硬碟中讀取或寫入資料的設備。

**ready state (就緒狀態)**
在行程管理中，行程等待獲得 CPU 關注的處理狀態。

**real (實數)**
同時具有整數和小數部分的數字。

**real-time system (即時系統)**
期望在特定時間限制內完成任務的作業系統。

**rear (尾端)**
使用 enqueue 操作插入佇列的最後一個元素。

**record (記錄)**
與一個實體相關的資訊。

**recursion (遞迴)**
函數呼叫自身的函數設計。

**reduced instruction set computer (RISC) (精簡指令集電腦)**
僅使用常用指令的電腦。

**register (暫存器)**
暫時保存資料的快速獨立儲存位置。

**relation (關聯)**
關聯式資料庫中的表格。

**relational database (關聯式資料庫)**
一種資料庫模型，其中資料組織在稱為關聯的相關表格中。

**relational database management system (RDBMS) (關聯式資料庫管理系統)**
處理關聯式資料庫模型中關聯的一組程式。

**relational model (關聯式模型)**
見*關聯式資料庫*。

**relational operator (關係運算子)**
比較兩個值的運算子。

**relative pathname (相對路徑名稱)**
根據工作目錄定義的檔案路徑。

**reliability (可靠性)**
解決對系統整體運作的信心或信任的品質因素。

**remote login (遠端登入)**
登入到連接到本地電腦的遠端電腦。

**repetition (重複)**
結構化程式設計中的三個建構之一。

**replaying (重放)**
一種針對資訊完整性的攻擊類型，其中攻擊者攔截訊息並再次發送。

**replicated distributed database (複製式分散式資料庫)**
每個站點都持有另一個站點複本的資料庫。

**resolution (解析度)**
影像處理中的掃描率：每單位測量的像素數。

**resource holding (資源持有)**
行程持有資源但直到所有其他資源可用才能使用它的情況。

**retrieval (檢索)**
列表中元素的位置和返回。

**retweet (轉推)**
轉發給其他 Twitter 使用者的推文。

**RGB**
一種顏色系統，其中色調由紅、綠和藍原色的組合表示。

**Roman number system (羅馬數字系統)**
羅馬人使用的非進位制數字系統。

**root (根)**
樹的第一個節點。

**root directory (根目錄)**
檔案階層中的最高層級。

**rotational speed (轉速)**
磁碟的旋轉速率。

**router (路由器)**
在 TCP/IP 前三層運作的設備，連接獨立網路。路由器根據目的位址路由封包。

**routing (路由)**
路由器執行的過程。

**row-major storage (以列為主儲存)**
一種在記憶體中儲存陣列元素的方法，其中元素按列儲存。

**RSA cryptosystem (RSA 密碼系統)**
由 River、Shamir 和 Adleman 設計的常見公鑰密碼系統。它使用兩個指數 e 和 d，其中第一個是公開的，第二個是私有的。

**RSA cryptosystem (RSA 密碼系統)**
RSA 密碼系統是常見的公鑰演算法之一。

**rule-based system (規則型系統)**
使用一組規則的知識表示系統，可用於從已知事實推斷新事實。

**run-length encoding (連長編碼)**
一種無損壓縮方法，其中相同符號的序列被替換為符號和重複次數。

**running state (執行狀態)**
在行程管理中，行程正在使用 CPU 的狀態。

**sampling (取樣)**
以相等的間隔進行測量。

**sampling rate (取樣率)**
取樣過程中每秒獲得的樣本數。

**scanning (掃描)**
透過以均勻間隔的點對其密度和顏色進行取樣，將圖像轉換為數位資料。

**scheduler (排程器)**
將工作從一種狀態移動到另一種狀態的程式。

**scheduling (排程)**
將作業系統的資源分配給不同的程式，並決定哪個程式應該使用哪個資源以及何時使用。

**scheme**
LISP 語言的事實標準。

**scientific notation (科學記數法)**
一種數字表示法，小數點左邊有一位數字，10 的冪定義小數點的移位。

**search space (搜尋空間)**
搜尋方法可以檢查以找到解決方案的可能情況集。

**searching (搜尋)**
檢查列表以定位包含指定值（稱為搜尋參數）的一個或多個元素的過程。

**secondary storage device (次級儲存設備)**
見*輔助儲存*。

**secret key (秘密金鑰)**
在秘密金鑰加密中由兩個參與者共享的金鑰。

**sector (磁區)**
磁碟上磁軌的一部分。

**Secure Hash Algorithm (SHA) (安全雜湊演算法)**
由 NIST 開發的標準雜湊函數。

**Secure Shell (SSH) (安全殼層)**
提供安全登入的客戶端-伺服器程式。

**security (安全性)**
解決未經授權使用者存取資料的難易程度的品質因素。

**security attack (安全性攻擊)**
威脅系統安全目標的攻擊。

**security goal (安全性目標)**
資訊安全的三個目標之一：機密性、完整性和可用性。

**seek time (搜尋時間)**
在磁碟存取中，將讀/寫頭移動到保存所需資料的磁軌所需的時間。

**segment (區段)**
封包的一部分。

**segmentation (分割)**
影像處理中的一步，將影像劃分為同質的區段或區域。

**select operation (選擇操作)**
關聯式資料庫中的一種操作，根據標準選擇一組元組。

**selection (選擇)**
結構化程式設計中的三個建構之一。

**selection sort (選擇排序)**
一種排序演算法，其中選擇列表未排序部分的最小值並將其放置在已排序部分的末尾。

**semantic analysis (語意分析)**
分析句子中的單詞或陳述式中的符記的含義。

**semantic network (語意網路)**
一種圖形，其中節點代表物件，邊代表物件之間的關係。

**sequence (循序)**
結構化程式設計中的三個建構之一。

**sequential access (循序存取)**
一種存取方法，其中檔案中的記錄從第一個元素開始按順序存取。

**sequential file (循序檔案)**
一種檔案結構，其中資料必須從檔案中的第一個元素開始按順序處理。

**sequential search (循序搜尋)**
一種用於線性串列的搜尋技術，其中搜尋從第一個元素開始，直到找到等於所尋找值的元素，或到達列表末尾。

**server (伺服器)**
在主從式系統中，提供輔助服務（伺服器程式）的中央電腦。

**shell**
某些作業系統（如 UNIX）中的使用者介面。

**shift cipher (移位加密法)**
一種替換加密法，其中金鑰定義字元向字母表末尾的移位。

**siblings (兄弟節點)**
具有相同父節點的樹節點。

**side effect (副作用)**
由評估表達式導致的變數更改：被呼叫函式執行的任何輸入/輸出。

**sign out (登出)**
終止社群媒體中的會員資格。

**sign out (登出)**
您需要成為 Facebook 的會員才能使用它。要成為會員，您需要註冊。要終止您的會員資格，您需要登出或停用您的帳戶。

**sign-and-magnitude representation (符號與數值表示法)**
一種整數表示方法，其中 1 位元代表數字的符號，其餘位元代表數值。

**simple type (簡單型別)**
原子資料型別，如整數或實數。

**single instruction stream, multiple data stream (SIMD) (單指令流，多資料流)**
具有一個控制單元、多個 ALU 和一個記憶體單元的電腦。

**single-user operating system (單使用者作業系統)**
一次只能有一個程式在記憶體中的作業系統。

**small computer system interface (SCSI) (小型電腦系統介面)**
具有並列介面的 I/O 設備控制器。

**snooping (窺探)**
未經授權存取機密資訊。

**social contract (社會契約)**
一種倫理原則，如果社會上大多數人同意，則該行為是合乎倫理的。

**social contract (社會契約)**
社會契約理論說，如果社會上大多數人同意一項行為，那麼它就是合乎倫理的。

**social media (社群媒體)**
人們用來分享想法和訊息的網站。

**social network (社群網路)**
社群媒體的另一個名稱。

**software (軟體)**
電腦硬體完成任務所需的應用程式和系統程式。

**software agent (軟體代理)**
在人工智慧應用中，一組設計用於執行特定任務的程式。

**software engineering (軟體工程)**
結構化程式的設計和編寫。

**software lifecycle (軟體生命週期)**
軟體套件的壽命。

**software quality (軟體品質)**
軟體的三個特徵（可操作性、可維護性和可轉移性）。

**solvable problem (可解問題)**
可以由電腦解決的問題。

**soma (細胞體)**
神經元中包含細胞核的身體。

**something inherent (固有的東西)**
索賠人的特徵，如傳統簽名、指紋、聲音等，用於實體驗證。

**something known (知道的東西)**
索賠人知道的秘密，可供驗證者在實體驗證中使用。

**something possessed (擁有的東西)**
屬於索賠人的東西，可以證明索賠人的身份。

**sort pass (排序遍歷)**
排序程式測試所有元素的一次迴圈。

**sorting (排序)**
對列表或檔案進行排序的過程。

**source program (原始程式)**
包含程式設計師在轉換為機器語言之前編寫的程式陳述式的檔案：組譯器或編譯器的輸入檔案。

**source-to-destination delivery (來源到目的地傳遞)**
將資料封包從來源傳遞到目的地。

**spatial compression (空間壓縮)**
JPEG 編碼過程中對影格進行的壓縮。

**speech recognition (語音辨識)**
自然語言處理（在 AI 中）的第一步，分析語音信號並提取其中包含的單詞序列。

**spoofing (欺騙)**
見*偽裝*。

**stack (堆疊)**
一種受限的資料結構，其中資料只能在一端（稱為頂部）插入和刪除。

**Standard Ethernet (標準乙太網路)**
以 10 Mbps 運行的原始乙太網路。

**starvation (饑餓)**
作業系統操作中的一個問題，其中行程無法獲得所需的資源。

**state chart (狀態圖)**
類似於狀態圖的圖表，但用於物件導向軟體工程。

**state diagram (狀態圖)**
顯示行程不同狀態的圖表。

**statement (陳述式)**
C 語言中表示函式中一個操作的語法結構。

**static RAM (SRAM) (靜態 RAM)**
使用傳統正反器閘（具有兩種狀態 0 和 1 的閘）來保存資料的技術。

**steganography (隱寫術)**
一種安全技術，其中透過用其他東西覆蓋訊息來隱藏訊息。

**storage device (儲存設備)**
可以儲存大量資訊以供日後檢索的 I/O 設備。

**stream cipher (串流加密法)**
一次加密和解密一個字元的加密法。

**String (字串)**
被視為單一資料單元的字元校正。

**string (字串)**
作為一組字元的字串，在不同語言中的處理方式不同。在 C 中，字串是字元陣列。在 C++ 中，字串可以是字元陣列，但有一個名為 string 的類型。在 Java 中，字串是一種類型。

**structure chart (結構圖)**
一種設計和文件工具，將程式表示為函式的階層流。

**structured program (結構化程式)**
根據軟體工程規則編寫的程式。

**Structured Query Language (SQL) (結構化查詢語言)**
一種資料庫語言，包括用於資料庫定義、操作和控制的陳述式。

**subalgorithm (子演算法)**
演算法的一部分，獨立編寫並在演算法內部呼叫時執行。

**subprogram (副程式)**
由主程式呼叫的較小程式。

**subroutine (子程序)**
見*子演算法*。

**substitution cipher (替換加密法)**
用一個符號替換另一個符號的加密法。

**subtree (子樹)**
樹根下方的任何連接結構。

**summation (總和)**
一系列數字的加法。

**switch (交換器)**
將網路中的組件連接在一起的設備。

**switched WAN (交換式 WAN)**
由多個介質和多個交換器組成的複雜 WAN。

**symbolic language (符號語言)**
一種電腦語言，與機器語言相差一個級別，每個機器指令都有助記符標識符，並可以使用符號資料名稱。

**symmetric-key cipher (對稱金鑰加密法)**
一種加密和解密都使用單個秘密金鑰的密碼學類型。

**symmetric-key encryption (對稱金鑰加密)**
使用對稱金鑰加密法進行加密。

**synapse (突觸)**
人類神經系統中兩個神經元之間的連接。

**synonym (同義詞)**
在雜湊列表中，雜湊到相同主位址的兩個或多個鍵。

**syntactic analysis (句法分析)**
分析句子以檢查文法。

**syntax (語法)**
語言的文法規則。

**syntax analyzer (語法分析器)**
檢查句子文法的過程。

**system documentation (系統文件)**
軟體套件的正式結構化記錄。

**TCP/IP protocol suite (TCP/IP 協定套件)**
定義跨網際網路傳輸交換的五層協定套件。

**technical documentation (技術文件)**
記錄軟體系統安裝和服務的程序。

**TELNET (terminal network) (終端網路)**
一種允許遠端登入的通用客戶端-伺服器程式。

**temporal compression (時間壓縮)**
MPEG 對影格進行的壓縮。

**temporal logic (時序邏輯)**
一種在推理中包含變化和時間影響的邏輯類型。

**temporal masking (時間掩蔽)**
響亮聲音消除較小聲音影響的過程。

**terminated state (終止狀態)**
在行程管理中，行程完成執行的狀態。

**testability (可測試性)**
衡量軟體作為可操作系統進行測試的難易程度的軟體屬性。

**testing phase (測試階段)**
軟體生命週期的一個階段，在此階段進行實驗以證明軟體套件有效。

**text (文字)**
儲存為字元的資料。

**text editor (文字編輯器)**
創建和維護文字檔案的軟體，如文字處理器或原始程式編輯器。

**text file (文字檔)**
所有資料都儲存為字元的檔案。與*二進位檔*相對。

**thresholding (閾值化)**
影像分割中使用的一種方法，其中選擇具有特定強度的像素，該方法試圖找到具有相同強度的所有像素。

**throughput (吞吐量)**
單位時間內可以通過某一點的資料單元數量。

**ticket (票據)**
在會話金鑰分發中，包含打算給 Bob 的會話金鑰的加密訊息，但發送給 Alice 以傳遞給 Bob。

**time sharing (分時)**
一種作業系統概念，其中多個使用者同時存取電腦。

**token (符記)**
代表操作、旗標或資料片段的語法結構。

**topology (拓撲)**
網路的結構，包括設備的物理排列。

**track (磁軌)**
磁碟的一部分。

**trade secret (商業機密)**
保密的產品資訊。

**trademark (商標)**
識別公司產品的標誌或名稱。

**traffic analysis (流量分析)**
一種針對機密性的攻擊類型，其中攻擊者透過監控線上流量來獲取某些資訊。

**transaction file (交易檔)**
包含用於更改主檔內容的相對瞬態資料的檔案。

**transfer time (傳輸時間)**
將資料從磁碟移動到 CPU/記憶體的時間。

**transferability (可轉移性)**
軟體系統中的一種品質，指將系統從一個平台移動到另一個平台的能力。

**translator (翻譯器)**
任何語言轉換程式的通稱。另見*組譯器*和*編譯器*。

**Transmission Control Protocol (TCP) (傳輸控制協定)**
TCP/IP 協定套件中的傳輸層協定之一。

**Transmission Control Protocol/Internet Protocol (TCP/IP) (傳輸控制協定/網際網路協定)**
網際網路的官方協定，由五層組成。

**transmission medium (傳輸介質)**
連接兩個通訊設備的實體路徑。

**transmission rate (傳輸速率)**
每秒發送的位元數。

**transposition cipher (換位加密法)**
一種加密法，透過轉置明文中的符號來創建密文，反之亦然。

**traversal (遍歷)**
一種演算法過程，其中結構中的每個元素被處理一次且僅一次。

**tree (樹)**
一組連接的節點，結構化使得每個節點只有一個前驅。

**Trojan horse (特洛伊木馬)**
一種可以執行惡意行為（如刪除或損壞檔案）的程式。

**True-Color (全彩)**
點陣圖形中的一種技術，使用 24 位元來表示顏色。

**truncation error (截斷誤差)**
使用浮點數表示法儲存數字時發生的誤差。儲存的數字值可能不完全符合預期。

**truth table (真值表)**
列出所有可能的邏輯輸入組合及其對應邏輯輸出的表。

**tuple (元組)**
在關聯式資料庫中，關聯中的一條記錄（一行）。

**Turing machine (圖靈機)**
具有三個組件（紙帶、控制器和讀/寫頭）的電腦模型，可以實作電腦語言中的陳述式。

**Turing model (圖靈模型)**
基於艾倫·圖靈對電腦的理論定義的電腦模型。

**Turing test (圖靈測試)**
艾倫·圖靈設計的一項測試，用於確定電腦是否可以被稱為真正的智慧。

**tweet (推文)**
Twitter 使用者交換的短（最多 140 個字元）訊息。發送推文。

**twisted-pair cable (雙絞線)**
兩根絕緣電纜在蓋子裡絞合在一起。

**Twitter**
一個流行的社群網路，使用者可以在其中發布稱為推文的短訊息。

**two-dimensional array (二維陣列)**
具有兩級索引元素的陣列。另見*多維陣列*。

**two’s complement (二的補數)**
二進位數字的一種表示法，其中數字的補數是通過對所有位元取補數然後加 1 找到的。

**two’s complement representation (二的補數表示法)**
一種整數表示方法，其中負數是通過保留所有最右邊的 0 和第一個不變，並對其餘位元取補數來表示的。

**unary operation (一元運算)**
只需要一個輸入運算元的運算。

**underflow (下溢)**
當試圖從空資料結構中刪除資料時發生的事件。

**undirected graph (無向圖)**
僅由邊組成的圖——也就是說，線條上沒有方向指示的圖。

**unfollow (取消追蹤)**
使用者在 Twitter 上停止追蹤另一位使用者的過程。

**unguided media (非導引介質)**
沒有物理邊界的傳輸介質。

**Unicode (萬國碼)**
包含世界上大多數語言的符號和字母的 32 位元代碼。

**Unified Modeling Language (UML) (統一建模語言)**
用於分析和設計的圖形語言。

**Uniform Resource Locator (URL) (統一資源定位器)**
定義網際網路上頁面的字元串。

**union operation (聯集操作)**
對兩個集合的操作，其結果包含兩個集合中的所有元素，沒有重複。

**universal serial bus (USB) (通用序列匯流排)**
一種串列 I/O 設備控制器，將鍵盤和滑鼠等較慢的設備連接到電腦。

**UNIX**
在電腦程式設計師和電腦科學家中流行的作業系統。

**unsigned integer (無符號整數)**
沒有符號的整數，其值範圍在 0 和正無窮大之間。

**unsolvable problem (不可解問題)**
電腦無法解決的問題。

**update operation (更新操作)**
關聯式資料庫中的一種操作，其中關於一個元組的操作被更改。

**use-case diagram (使用案例圖)**
在 UML 中顯示系統使用者視圖的圖表。

**user agent (UA) (使用者代理)**
SMTP 組件，準備訊息，創建信封，並將訊息放入信封中。

**user datagram (使用者資料包)**
UDP 協定使用的資料單元。

**User Datagram Protocol (UDP) (使用者資料包協定)**
TCP/IP 協定套件中的傳輸層協定之一。

**user interface (使用者介面)**
接受使用者（行程）請求並為作業系統其餘部分解釋這些請求的程式。

**user page (使用者頁面)**
Facebook 中的主頁面。

**user page (使用者頁面)**
使用者頁面是您在 Facebook 上使用的主要頁面。

**users (使用者)**
在 DBMS 術語中，存取資料庫的每個實體。

**utility (公用程式)**
UNIX 中的應用程式。

**utilization (功利主義)**
一種倫理原則，如果行為產生好的結果，則該行為是合乎倫理的。

**utilization (功利主義)**
第二種倫理理論，與行為的後果有關。如果一項行為導致對社會有用的後果，那麼它就是合乎倫理的。

**variable (變數)**
其值可以在程式執行期間更改的記憶體儲存物件。與*常數*相對。

**vector graphic (向量圖形)**
一種圖形檔案格式，其中線條和曲線使用數學公式定義。

**verifying algorithm (驗證演算法)**
驗證數位簽章有效性的演算法。

**vertex (頂點)**
圖形中的節點。

**vi**
Unix 作業系統中可用的螢幕文字編輯器。

**video (影像)**
時間內圖像（稱為影格）的表示。

**virtual memory (虛擬記憶體)**
一種記憶體組織形式，允許在記憶體和磁性儲存之間交換程式，以給人一種比實際存在的主記憶體更大的印象。

**virus (病毒)**
隱藏在其他程式中的不需要的程式，並且可以自我複製。

**von Neumann model (馮·諾伊曼模型)**
現代電腦所基於的電腦模型（由記憶體、算術邏輯單元、控制單元和輸入/輸出子系統組成）。

**waiting state (等待狀態)**
行程等待獲得 CPU 關注的狀態。

**waterfall model (瀑布模型)**
一種軟體開發模型，其中每個模組在下一個模組開始之前完全完成。

**Web**
見*全球資訊網*。

**Web page (網頁)**
Web 上可用的超文本或超媒體單元。

**well-known port number (熟知埠號)**
定義網路上行程的埠號。

**white-box testing (白箱測試)**
考慮程式內部設計的程式測試。也稱為玻璃箱測試。與*黑箱測試*相對。

**wide area network (WAN) (廣域網路)**
跨越廣大地理距離的網路。

**WiMax**
全球互通微波存取。

**Windows**
由微軟設計的作業系統。

**Windows 2000**
Windows NT 作業系統的一個版本。

**Windows NT**
微軟設計用來取代 MS-DOS 的作業系統。

**Windows XP**
Windows NT 作業系統的一個版本。

**working directory (工作目錄)**
當前正在使用的目錄。

**World Wide Web (WWW) (全球資訊網)**
一種多媒體網際網路服務，允許使用者透過連結從一個文件移動到另一個文件來遍歷網際網路。

**Worldwide Interoperability Access**
DSL 或電纜連接到網際網路的無線版本。

**worm (蠕蟲)**
在網路中傳播並可以自我複製的獨立程式。

**write once, read many (WORM) (一次寫入，多次讀取)**
CD-R 的另一個名稱。

**X.509**
現代電腦使用的一種技術，透過將指令的不同階段與下一個指令結合來提高吞吐量。

**X.509**
X.509 是一種以結構化方式描述憑證的方法。它使用一個稱為 ASN.1 的知名協定，定義了電腦程式設計師熟悉的欄位。

**XOR operator (XOR 運算子)**
僅當其中一個運算元為 1 時結果為 1 的位元運算。

**zero-knowledge authentication (零知識驗證)**
一種實體驗證方法，其中索賠人不透露任何可能危及秘密機密性的東西。
`},e=[{id:"preface",title:{en:"Preface",zh:"前言"},subtitle:{en:"Book preface and organization",zh:"本書前言與組織結構"}},{id:"chapter1",title:{en:"Chapter 1: Introduction",zh:"第一章：簡介"},subtitle:{en:"Turing and von Neumann models, computer components",zh:"圖靈與馮·諾伊曼模型、電腦組件"}},{id:"chapter2",title:{en:"Chapter 2: Number Systems",zh:"第二章：數字系統"},subtitle:{en:"Positional and non-positional systems, conversions",zh:"進位與非進位制、轉換"}},{id:"chapter3",title:{en:"Chapter 3: Data Storage",zh:"第三章：資料儲存"},subtitle:{en:"Storing numbers, text, audio, images, and video",zh:"儲存數字、文字、音訊、圖像與影像"}},{id:"chapter4",title:{en:"Chapter 4: Operations on Data",zh:"第四章：資料運算"},subtitle:{en:"Logic, shift, and arithmetic operations",zh:"邏輯、移位與算術運算"}},{id:"chapter5",title:{en:"Chapter 5: Computer Organization",zh:"第五章：電腦組織"},subtitle:{en:"CPU, main memory, and I/O subsystems",zh:"CPU、主記憶體與輸出/入子系統"}},{id:"chapter6",title:{en:"Chapter 6: Computer Networks and Internet",zh:"第六章：電腦網路與網際網路"},subtitle:{en:"Layers, protocols, and network types",zh:"層、協定與網路類型"}},{id:"chapter7",title:{en:"Chapter 7: Operating Systems",zh:"第七章：作業系統"},subtitle:{en:"Components, evolution, and major OSs",zh:"組件、演進與主要作業系統"}},{id:"chapter8",title:{en:"Chapter 8: Algorithms",zh:"第八章：演算法"},subtitle:{en:"Constructs, representation, sorting, and searching",zh:"建構、表示法、排序與搜尋"}},{id:"chapter9",title:{en:"Chapter 9: Programming Languages",zh:"第九章：程式語言"},subtitle:{en:"Evolution, paradigms, and common concepts",zh:"演進、範式與共同概念"}},{id:"chapter10",title:{en:"Chapter 10: Software Engineering",zh:"第十章：軟體工程"},subtitle:{en:"Lifecycle, analysis, design, and testing",zh:"生命週期、分析、設計與測試"}},{id:"chapter11",title:{en:"Chapter 11: Data Structure",zh:"第十一章：資料結構"},subtitle:{en:"Arrays, records, and linked lists",zh:"陣列、記錄與鏈結串列"}},{id:"chapter12",title:{en:"Chapter 12: Abstract Data Types",zh:"第十二章：抽象資料型別"},subtitle:{en:"Stacks, queues, lists, trees, and graphs",zh:"堆疊、佇列、串列、樹與圖"}},{id:"chapter13",title:{en:"Chapter 13: File Structure",zh:"第十三章：檔案結構"},subtitle:{en:"Sequential, indexed, and hashed files",zh:"循序、索引與雜湊檔案"}},{id:"chapter14",title:{en:"Chapter 14: Databases",zh:"第十四章：資料庫"},subtitle:{en:"Database models and relational databases",zh:"資料庫模型與關聯式資料庫"}},{id:"chapter15",title:{en:"Chapter 15: Data Compression",zh:"第十五章：資料壓縮"},subtitle:{en:"Lossless and lossy compression techniques",zh:"無損與失真壓縮技術"}},{id:"chapter16",title:{en:"Chapter 16: Security",zh:"第十六章：安全性"},subtitle:{en:"Confidentiality, integrity, and availability",zh:"機密性、完整性與可用性"}},{id:"chapter17",title:{en:"Chapter 17: Theory of Computation",zh:"第十七章：計算理論"},subtitle:{en:"Simple Language, Turing machines, halting problem",zh:"簡單語言、圖靈機、停機問題"}},{id:"chapter18",title:{en:"Chapter 18: Artificial Intelligence",zh:"第十八章：人工智慧"},subtitle:{en:"Knowledge representation, expert systems, and search",zh:"知識表示、專家系統與搜尋"}},{id:"chapter19",title:{en:"Chapter 19: Introduction to Social Media",zh:"第十九章：社群媒體簡介"},subtitle:{en:"Concepts behind Facebook and Twitter",zh:"Facebook 與 Twitter 背後的概念"}},{id:"chapter20",title:{en:"Chapter 20: Social and Ethical Issues",zh:"第二十章：社會與倫理議題"},subtitle:{en:"Principles, property, privacy, and crime",zh:"原則、財產、隱私與犯罪"}},{id:"appendixA",title:{en:"Appendix A: Unicode",zh:"附錄 A：萬國碼"},subtitle:{en:"Structure of Unicode and ASCII chart",zh:"萬國碼結構與 ASCII 圖表"}},{id:"appendixB",title:{en:"Appendix B: UML",zh:"附錄 B：UML"},subtitle:{en:"Unified Modeling Language diagrams",zh:"統一建模語言圖"}},{id:"appendixC",title:{en:"Appendix C: Pseudocode",zh:"附錄 C：偽代碼"},subtitle:{en:"Components and constructs",zh:"組件與建構"}},{id:"appendixD",title:{en:"Appendix D: Structure Chart",zh:"附錄 D：結構圖"},subtitle:{en:"Symbols and rules for structure charts",zh:"結構圖的符號與規則"}},{id:"appendixE",title:{en:"Appendix E: Boolean Algebra",zh:"附錄 E：布林代數"},subtitle:{en:"Logic circuits and axioms",zh:"邏輯電路與公理"}},{id:"appendixF",title:{en:"Appendix F: Example Programs",zh:"附錄 F：範例程式"},subtitle:{en:"Examples in C, C++, and Java",zh:"C、C++ 與 Java 範例"}},{id:"appendixG",title:{en:"Appendix G: Mathematical Review",zh:"附錄 G：數學複習"},subtitle:{en:"Exponents, logarithms, and modular arithmetic",zh:"指數、對數與模數運算"}},{id:"appendixH",title:{en:"Appendix H: Error Detection",zh:"附錄 H：錯誤偵測"},subtitle:{en:"Detection and correction codes",zh:"偵測與更正碼"}},{id:"appendixI",title:{en:"Appendix I: Sign-and-Magnitude",zh:"附錄 I：符號與數值"},subtitle:{en:"Addition and subtraction for integers",zh:"整數的加法與減法"}},{id:"appendixJ",title:{en:"Appendix J: Reals",zh:"附錄 J：實數"},subtitle:{en:"Addition and subtraction for reals",zh:"實數的加法與減法"}},{id:"acronyms",title:{en:"Acronyms",zh:"縮寫詞"},subtitle:{en:"List of common abbreviations",zh:"常見縮寫列表"}},{id:"glossary",title:{en:"Glossary",zh:"詞彙表"},subtitle:{en:"Definitions of key terms",zh:"關鍵術語定義"}}],F={preface:{title:e[0].title,content:t},chapter1:{title:e[1].title,content:a},chapter2:{title:e[2].title,content:o},chapter3:{title:e[3].title,content:i},chapter4:{title:e[4].title,content:n},chapter5:{title:e[5].title,content:s},chapter6:{title:e[6].title,content:r},chapter7:{title:e[7].title,content:h},chapter8:{title:e[8].title,content:l},chapter9:{title:e[9].title,content:c},chapter10:{title:e[10].title,content:d},chapter11:{title:e[11].title,content:m},chapter12:{title:e[12].title,content:u},chapter13:{title:e[13].title,content:p},chapter14:{title:e[14].title,content:g},chapter15:{title:e[15].title,content:f},chapter16:{title:e[16].title,content:b},chapter17:{title:e[17].title,content:y},chapter18:{title:e[18].title,content:w},chapter19:{title:e[19].title,content:v},chapter20:{title:e[20].title,content:T},appendixA:{title:e[21].title,content:A},appendixB:{title:e[22].title,content:$},appendixC:{title:e[23].title,content:k},appendixD:{title:e[24].title,content:x},appendixE:{title:e[25].title,content:I},appendixF:{title:e[26].title,content:S},appendixG:{title:e[27].title,content:C},appendixH:{title:e[28].title,content:P},appendixI:{title:e[29].title,content:R},appendixJ:{title:e[30].title,content:M},acronyms:{title:e[31].title,content:D},glossary:{title:e[32].title,content:E}};export{e as chapterList,F as textbookData};
